{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from math import sqrt\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "from torch_geometric.explain import Explanation\n",
    "from torch_geometric.explain.algorithm.utils import clear_masks, set_masks\n",
    "from torch_geometric.explain.config import (\n",
    "    ExplainerConfig,\n",
    "    MaskType,\n",
    "    ModelConfig,\n",
    "    ModelMode,\n",
    "    ModelTaskLevel,\n",
    ")\n",
    "\n",
    "from torch_geometric.explain.algorithm.base import ExplainerAlgorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import abstractmethod\n",
    "from typing import Optional, Tuple, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.explain import Explanation\n",
    "from torch_geometric.explain.config import (\n",
    "    ExplainerConfig,\n",
    "    ModelConfig,\n",
    "    ModelReturnType,\n",
    ")\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import k_hop_subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Entities\n",
    "from torch_geometric.nn import FastRGCNConv, RGCNConv\n",
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "path = '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/../data/Entities' #osp.join(osp.dirname(osp.realpath(__file__)), '..', 'data', 'Entities')\n",
    "dataset = Entities(path, 'AIFB')\n",
    "data = dataset[0]\n",
    "\n",
    "# BGS and AM graphs are too big to process them in a full-batch fashion.\n",
    "# Since our model does only make use of a rather small receptive field, we\n",
    "# filter the graph to only contain the nodes that are at most 2-hop neighbors\n",
    "# away from any training/test node.\n",
    "node_idx = torch.cat([data.train_idx, data.test_idx], dim=0)\n",
    "node_idx, edge_index, mapping, edge_mask = k_hop_subgraph(\n",
    "    node_idx, 2, data.edge_index, relabel_nodes=True)\n",
    "\n",
    "data.num_nodes = node_idx.size(0)\n",
    "data.edge_index = edge_index\n",
    "data.edge_type = data.edge_type[edge_mask]\n",
    "data.train_idx = mapping[:data.train_idx.size(0)]\n",
    "data.test_idx = mapping[data.train_idx.size(0):]\n",
    "node_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'edge_index': tensor([[   0,    1,    1,  ..., 6908, 6908, 6908],\n",
       "         [  26, 2003, 6825,  ..., 3612, 3612, 3881]]), 'edge_type': tensor([13, 13, 13,  ...,  0,  5,  2]), 'train_idx': tensor([6348, 2772, 1274, 3084, 2295, 1023,  615, 1909,  529, 4696, 6412, 2129,\n",
       "         4636, 5713, 6843, 4778, 4063,  396, 5200, 5278, 5462, 3954,  998, 5387,\n",
       "         4666,    3, 4759, 4333, 1073, 6787, 3085, 5517, 6824, 2611, 4273, 2808,\n",
       "         3867,  602, 3068, 6901, 4717,   59, 4354, 1130, 2853, 2363, 5927, 6021,\n",
       "         1173, 2612, 4132, 5091,  826, 3764, 6867, 5821, 5293,  704, 6658, 5569,\n",
       "         5014, 3022, 4979, 4256, 5982, 5148, 4165, 2852, 3087, 4812, 4091, 6366,\n",
       "         6578, 1895, 4798, 3449, 5662, 2584, 5668, 1592, 6083, 3053,  350,  632,\n",
       "         5697,  112, 2243, 2476, 5798, 6836, 3248, 4083, 3445, 4850, 5367, 3179,\n",
       "         5090, 5667, 1818,   98, 5751, 1460, 6337, 2475, 2779, 5711, 2882,  367,\n",
       "          919, 6463, 1654, 3914, 4039, 6809, 4709, 6461, 1917, 6218, 2001, 4161,\n",
       "         6138, 6579,  546, 4362, 6372, 5247, 2740, 4588, 1757, 2448, 1473, 2409,\n",
       "         6816, 1976, 1355, 2372, 3228, 4592, 6469, 6759]), 'train_y': tensor([3, 1, 2, 2, 3, 3, 3, 3, 3, 1, 3, 3, 1, 3, 3, 3, 3, 1, 2, 1, 2, 2, 1, 3,\n",
       "         1, 3, 1, 1, 3, 1, 3, 3, 1, 3, 1, 0, 2, 2, 1, 0, 3, 3, 1, 2, 3, 3, 1, 3,\n",
       "         0, 3, 0, 3, 1, 1, 3, 1, 1, 1, 3, 3, 2, 2, 1, 3, 3, 1, 1, 2, 3, 3, 1, 2,\n",
       "         3, 2, 1, 3, 1, 3, 3, 2, 3, 2, 1, 1, 1, 0, 1, 1, 1, 1, 1, 3, 0, 3, 3, 3,\n",
       "         2, 1, 2, 2, 1, 1, 3, 3, 3, 1, 1, 3, 1, 1, 2, 3, 1, 3, 0, 0, 3, 3, 3, 2,\n",
       "         0, 1, 3, 3, 3, 3, 0, 1, 1, 3, 1, 2, 1, 0, 3, 3, 1, 3, 0, 2]), 'test_idx': tensor([4229, 4471, 6187,  861, 5597, 1639, 2946, 2192, 5311, 2530,  448,  263,\n",
       "         4181, 2766, 4520, 5473, 1893, 4571, 4173, 4452, 5842,  617,  869, 5534,\n",
       "         5350, 6232, 6249, 2328, 3401,  576, 6533, 2131, 3521, 2235, 1443, 5698]), 'test_y': tensor([3, 1, 2, 1, 3, 1, 3, 3, 3, 3, 3, 3, 1, 3, 3, 3, 1, 2, 0, 1, 1, 3, 1, 1,\n",
       "         2, 2, 1, 1, 3, 1, 3, 2, 0, 3, 2, 0]), 'num_nodes': 6909}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.node_stores"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01, Loss: 1.3934, Train: 0.9429 Test: 0.7500\n",
      "Epoch: 02, Loss: 0.7704, Train: 0.9643 Test: 0.8333\n",
      "Epoch: 03, Loss: 0.3287, Train: 0.9714 Test: 0.8611\n",
      "Epoch: 04, Loss: 0.1438, Train: 0.9857 Test: 0.8611\n",
      "Epoch: 05, Loss: 0.0820, Train: 0.9857 Test: 0.9167\n",
      "Epoch: 06, Loss: 0.0562, Train: 0.9857 Test: 0.9167\n",
      "Epoch: 07, Loss: 0.0392, Train: 0.9857 Test: 0.9167\n",
      "Epoch: 08, Loss: 0.0240, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 09, Loss: 0.0117, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 10, Loss: 0.0063, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 11, Loss: 0.0054, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 12, Loss: 0.0047, Train: 1.0000 Test: 0.8611\n",
      "Epoch: 13, Loss: 0.0034, Train: 1.0000 Test: 0.8611\n",
      "Epoch: 14, Loss: 0.0020, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 15, Loss: 0.0011, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 16, Loss: 0.0006, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 17, Loss: 0.0004, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 18, Loss: 0.0003, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 19, Loss: 0.0002, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 20, Loss: 0.0002, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 21, Loss: 0.0002, Train: 1.0000 Test: 0.8889\n",
      "Epoch: 22, Loss: 0.0002, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 23, Loss: 0.0002, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 24, Loss: 0.0002, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 25, Loss: 0.0003, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 26, Loss: 0.0003, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 27, Loss: 0.0004, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 28, Loss: 0.0004, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 29, Loss: 0.0005, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 30, Loss: 0.0006, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 31, Loss: 0.0007, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 32, Loss: 0.0008, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 33, Loss: 0.0009, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 34, Loss: 0.0010, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 35, Loss: 0.0011, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 36, Loss: 0.0012, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 37, Loss: 0.0013, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 38, Loss: 0.0014, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 39, Loss: 0.0015, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 40, Loss: 0.0016, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 41, Loss: 0.0017, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 42, Loss: 0.0018, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 43, Loss: 0.0019, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 44, Loss: 0.0020, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 45, Loss: 0.0021, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 46, Loss: 0.0022, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 47, Loss: 0.0022, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 48, Loss: 0.0023, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 49, Loss: 0.0024, Train: 1.0000 Test: 0.9167\n",
      "Epoch: 50, Loss: 0.0024, Train: 1.0000 Test: 0.9167\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os.path as osp\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "# Trade memory consumption for faster computation.\n",
    "#if args.dataset in ['AIFB', 'MUTAG']:\n",
    "RGCNConv = FastRGCNConv\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = RGCNConv(data.num_nodes, 16, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "        self.conv2 = RGCNConv(16, dataset.num_classes, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "    def forward(self, data):\n",
    "        edge_index, edge_type = data.edge_index, data.edge_type\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def forward(self, edge_type, edge_index):\n",
    "        #edge_type edge_type.unsqueeze(1)\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')# if args.dataset == 'AM' else device\n",
    "model, data = Net().to(device), data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=0.0005)\n",
    "\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.edge_type, data.edge_index )\n",
    "    #out = model(data)\n",
    "    loss = F.nll_loss(out[data.train_idx], data.train_y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return float(loss)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.edge_type ,data.edge_index).argmax(dim=-1)\n",
    "    #pred = model(data).argmax(dim=-1)\n",
    "    train_acc = float((pred[data.train_idx] == data.train_y).float().mean())\n",
    "    test_acc = float((pred[data.test_idx] == data.test_y).float().mean())\n",
    "    torch.save(pred[data.test_idx], 'aifb_chk/prediction_aifb')\n",
    "    return train_acc, test_acc\n",
    "\n",
    "\n",
    "for epoch in range(1, 51):\n",
    "    loss = train()\n",
    "    train_acc, test_acc = test()\n",
    "    print(f'Epoch: {epoch:02d}, Loss: {loss:.4f}, Train: {train_acc:.4f} '\n",
    "          f'Test: {test_acc:.4f}')\n",
    "    \n",
    "torch.save(model, 'aifb_chk/model_aifb')    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K hop subgraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([   0,   26,  890, 1496, 2037, 2577, 4368, 5108, 5446, 5517, 6804, 6867]),\n",
       " tensor([[   0,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,   26,\n",
       "            26,   26,  890, 1496, 1496, 1496, 2037, 2577, 2577, 4368, 4368, 5108,\n",
       "          5108, 5446, 5517, 5517, 5517, 5517, 5517, 6804, 6804, 6804, 6867, 6867,\n",
       "          6867, 6867],\n",
       "         [  26,    0,  890, 1496, 2037, 2577, 4368, 5108, 5446, 5517, 5517, 6804,\n",
       "          6867, 6867,   26,   26, 5517, 6867,   26,   26, 5517,   26, 5108,   26,\n",
       "          4368,   26,   26,   26, 1496, 2577, 6804,   26, 5517, 6867,   26,   26,\n",
       "          1496, 6804]]),\n",
       " tensor([0]),\n",
       " tensor([ True, False, False,  ..., False, False, False]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def k_hop_subgraph(\n",
    "    node_idx: int,#Union[int, List[int], Tensor],\n",
    "    num_hops: int,\n",
    "    edge_index: Tensor,\n",
    "    relabel_nodes: bool = False,\n",
    "    num_nodes: Optional[int] = None,\n",
    "    flow: str = 'source_to_target',\n",
    ") -> Tuple[Tensor, Tensor, Tensor, Tensor]:\n",
    "    \n",
    "    #num_nodes = maybe_num_nodes(edge_index, num_nodes)\n",
    "    num_nodes = num_nodes\n",
    "    assert flow in ['source_to_target', 'target_to_source']\n",
    "    if flow == 'target_to_source':\n",
    "        row, col = edge_index\n",
    "    else:\n",
    "        col, row = edge_index\n",
    "\n",
    "    node_mask = row.new_empty(num_nodes, dtype=torch.bool)\n",
    "    edge_mask = row.new_empty(row.size(0), dtype=torch.bool)\n",
    "\n",
    "    if isinstance(node_idx, (int, list, tuple)):\n",
    "        node_idx = torch.tensor([node_idx], device=row.device).flatten()\n",
    "    else:\n",
    "        node_idx = node_idx.to(row.device)\n",
    "\n",
    "    subsets = [node_idx]\n",
    "\n",
    "    for _ in range(num_hops):\n",
    "        node_mask.fill_(False)\n",
    "        node_mask[subsets[-1]] = True\n",
    "        torch.index_select(node_mask, 0, row, out=edge_mask)\n",
    "        subsets.append(col[edge_mask])\n",
    "\n",
    "    subset, inv = torch.cat(subsets).unique(return_inverse=True)\n",
    "    inv = inv[:node_idx.numel()]\n",
    "\n",
    "    node_mask.fill_(False)\n",
    "    node_mask[subset] = True\n",
    "    edge_mask = node_mask[row] & node_mask[col]\n",
    "\n",
    "    edge_index = edge_index[:, edge_mask]\n",
    "\n",
    "    if relabel_nodes:\n",
    "        node_idx = row.new_full((num_nodes, ), -1)\n",
    "        node_idx[subset] = torch.arange(subset.size(0), device=row.device)\n",
    "        edge_index = node_idx[edge_index]\n",
    "\n",
    "    return subset, edge_index, inv, edge_mask\n",
    "\n",
    "k_hop_subgraph(0,2, data.edge_index, num_nodes=data.num_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ True, False, False,  ..., False, False, False]),\n",
       " tensor([ True, False, False,  ..., False, False, False]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def _get_hard_masks(\n",
    "    model: torch.nn.Module,\n",
    "    index: Optional[Union[int, Tensor]],\n",
    "    edge_index: Tensor,\n",
    "    num_nodes: int,\n",
    ") -> Tuple[Optional[Tensor], Optional[Tensor]]:\n",
    "    r\"\"\"Returns hard node and edge masks that only include the nodes and\n",
    "    edges visited during message passing.\"\"\"\n",
    "    if index is None:\n",
    "        return None, None  # Consider all nodes and edges.\n",
    "\n",
    "    index, _, _, edge_mask = k_hop_subgraph(\n",
    "        index,\n",
    "        num_hops= 2,\n",
    "        edge_index=edge_index,\n",
    "        num_nodes=num_nodes,\n",
    "        flow=ExplainerAlgorithm._flow(model),\n",
    "    )\n",
    "\n",
    "    node_mask = edge_index.new_zeros(num_nodes, dtype=torch.bool)\n",
    "    node_mask[index] = True\n",
    "\n",
    "    return node_mask, edge_mask\n",
    "\n",
    "_get_hard_masks(model, index = node_idx, edge_index=data.edge_index, num_nodes=data.num_nodes)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ExplainerAlgorithm : to inherit properties from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data.data import Data, warn_or_raise\n",
    "from typing import List, Optional\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explanation(Data):\n",
    "    r\"\"\"Holds all the obtained explanations of a homogenous graph.\n",
    "\n",
    "    The explanation object is a :obj:`~torch_geometric.data.Data` object and\n",
    "    can hold node-attribution, edge-attribution, feature-attribution. It can\n",
    "    also hold the original graph if needed.\n",
    "\n",
    "    Args:\n",
    "        node_mask (Tensor, optional): Node-level mask with shape\n",
    "            :obj:`[num_nodes]`. (default: :obj:`None`)\n",
    "        edge_mask (Tensor, optional): Edge-level mask with shape\n",
    "            :obj:`[num_edges]`. (default: :obj:`None`)\n",
    "        node_feat_mask (Tensor, optional): Node-level feature mask with shape\n",
    "            :obj:`[num_nodes, num_node_features]`. (default: :obj:`None`)\n",
    "        edge_feat_mask (Tensor, optional): Edge-level feature mask with shape\n",
    "            :obj:`[num_edges, num_edge_features]`. (default: :obj:`None`)\n",
    "        **kwargs (optional): Additional attributes.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self,\n",
    "        node_mask: Optional[Tensor] = None,\n",
    "        edge_mask: Optional[Tensor] = None,\n",
    "        node_feat_mask: Optional[Tensor] = None,\n",
    "        edge_feat_mask: Optional[Tensor] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            node_mask=node_mask,\n",
    "            edge_mask=edge_mask,\n",
    "            node_feat_mask=node_feat_mask,\n",
    "            edge_feat_mask=edge_feat_mask,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def available_explanations(self) -> List[str]:\n",
    "        \"\"\"Returns the available explanation masks.\"\"\"\n",
    "        return [\n",
    "            key for key in self.keys\n",
    "            if key.endswith('_mask') and self[key] is not None\n",
    "        ]\n",
    "\n",
    "    def validate(self, raise_on_error: bool = True) -> bool:\n",
    "        r\"\"\"Validates the correctness of the explanation\"\"\"\n",
    "        status = super().validate()\n",
    "\n",
    "        if 'node_mask' in self and self.num_nodes != self.node_mask.size(0):\n",
    "            status = False\n",
    "            warn_or_raise(\n",
    "                f\"Expected a 'node_mask' with {self.num_nodes} nodes \"\n",
    "                f\"(got {self.node_mask.size(0)} nodes)\", raise_on_error)\n",
    "\n",
    "        if 'edge_mask' in self and self.num_edges != self.edge_mask.size(0):\n",
    "            status = False\n",
    "            warn_or_raise(\n",
    "                f\"Expected an 'edge_mask' with {self.num_edges} edges \"\n",
    "                f\"(got {self.edge_mask.size(0)} edges)\", raise_on_error)\n",
    "\n",
    "        if 'node_feat_mask' in self:\n",
    "            if 'x' in self and self.x.size() != self.node_feat_mask.size():\n",
    "                status = False\n",
    "                warn_or_raise(\n",
    "                    f\"Expected a 'node_feat_mask' of shape \"\n",
    "                    f\"{list(self.x.size())} (got shape \"\n",
    "                    f\"{list(self.node_feat_mask.size())})\", raise_on_error)\n",
    "            elif self.num_nodes != self.node_feat_mask.size(0):\n",
    "                status = False\n",
    "                warn_or_raise(\n",
    "                    f\"Expected a 'node_feat_mask' with {self.num_nodes} nodes \"\n",
    "                    f\"(got {self.node_feat_mask.size(0)} nodes)\",\n",
    "                    raise_on_error)\n",
    "\n",
    "        if 'edge_feat_mask' in self:\n",
    "            if ('edge_attr' in self\n",
    "                    and self.edge_attr.size() != self.edge_feat_mask.size()):\n",
    "                status = False\n",
    "                warn_or_raise(\n",
    "                    f\"Expected an 'edge_feat_mask' of shape \"\n",
    "                    f\"{list(self.edge_attr.size())} (got shape \"\n",
    "                    f\"{list(self.edge_feat_mask.size())})\", raise_on_error)\n",
    "            elif self.num_edges != self.edge_feat_mask.size(0):\n",
    "                status = False\n",
    "                warn_or_raise(\n",
    "                    f\"Expected an 'edge_feat_mask' with {self.num_edges} \"\n",
    "                    f\"edges (got {self.edge_feat_mask.size(0)} edges)\",\n",
    "                    raise_on_error)\n",
    "\n",
    "        return status\n",
    "\n",
    "    def get_explanation_subgraph(self) -> 'Explanation':\n",
    "        r\"\"\"Returns the induced subgraph, in which all nodes and edges with\n",
    "        zero attribution are masked out.\"\"\"\n",
    "        return self._apply_masks(\n",
    "            node_mask=self.node_mask > 0 if 'node_mask' in self else None,\n",
    "            edge_mask=self.edge_mask > 0 if 'edge_mask' in self else None,\n",
    "        )\n",
    "\n",
    "    def get_complement_subgraph(self) -> 'Explanation':\n",
    "        r\"\"\"Returns the induced subgraph, in which all nodes and edges with any\n",
    "        attribution are masked out.\"\"\"\n",
    "        return self._apply_masks(\n",
    "            node_mask=self.node_mask == 0 if 'node_mask' in self else None,\n",
    "            edge_mask=self.edge_mask == 0 if 'edge_mask' in self else None,\n",
    "        )\n",
    "\n",
    "    def _apply_masks(\n",
    "        self,\n",
    "        node_mask: Optional[Tensor] = None,\n",
    "        edge_mask: Optional[Tensor] = None,\n",
    "    ) -> 'Explanation':\n",
    "        out = copy.copy(self)\n",
    "\n",
    "        if edge_mask is not None:\n",
    "            for key, value in self.items():\n",
    "                if key == 'edge_index':\n",
    "                    out.edge_index = value[:, edge_mask]\n",
    "                elif self.is_edge_attr(key):\n",
    "                    out[key] = value[edge_mask]\n",
    "\n",
    "        if node_mask is not None:\n",
    "            out = out.subgraph(node_mask)\n",
    "\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['node_mask', 'edge_mask']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = Explanation(data, edge_mask=edge_mask)\n",
    "A.available_explanations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExplainerAlgorithm(torch.nn.Module):\n",
    "    r\"\"\"Abstract base class for explainer algorithms.\"\"\"\n",
    "    @abstractmethod\n",
    "    def forward(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        x = None, \n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        target_index: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ) -> Explanation:\n",
    "        r\"\"\"Computes the explanation.\n",
    "\n",
    "        Args:\n",
    "            model (torch.nn.Module): The model to explain.\n",
    "            x (torch.Tensor): The input node features.\n",
    "            edge_index (torch.Tensor): The input edge indices.\n",
    "            target (torch.Tensor): The target of the model.\n",
    "            index (Union[int, Tensor], optional): The index of the model\n",
    "                output to explain. Can be a single index or a tensor of\n",
    "                indices. (default: :obj:`None`)\n",
    "            target_index (int, optional): The index of the model outputs to\n",
    "                reference in case the model returns a list of tensors, *e.g.*,\n",
    "                in a multi-task learning scenario. Should be kept to\n",
    "                :obj:`None` in case the model only returns a single output\n",
    "                tensor. (default: :obj:`None`)\n",
    "            **kwargs (optional): Additional keyword arguments passed to\n",
    "                :obj:`model`.\n",
    "        \"\"\"\n",
    "\n",
    "    @abstractmethod\n",
    "    def supports(self) -> bool:\n",
    "        r\"\"\"Checks if the explainer supports the user-defined settings provided\n",
    "        in :obj:`self.explainer_config` and :obj:`self.model_config`.\"\"\"\n",
    "        pass\n",
    "\n",
    "    ###########################################################################\n",
    "\n",
    "    @property\n",
    "    def explainer_config(self) -> ExplainerConfig:\n",
    "        r\"\"\"Returns the connected explainer configuration.\"\"\"\n",
    "        if not hasattr(self, '_explainer_config'):\n",
    "            raise ValueError(\n",
    "                f\"The explanation algorithm '{self.__class__.__name__}' is \"\n",
    "                f\"not yet connected to any explainer configuration. Please \"\n",
    "                f\"call `{self.__class__.__name__}.connect(...)` before \"\n",
    "                f\"proceeding.\")\n",
    "        return self._explainer_config\n",
    "\n",
    "    @property\n",
    "    def model_config(self) -> ModelConfig:\n",
    "        r\"\"\"Returns the connected model configuration.\"\"\"\n",
    "        if not hasattr(self, '_model_config'):\n",
    "            raise ValueError(\n",
    "                f\"The explanation algorithm '{self.__class__.__name__}' is \"\n",
    "                f\"not yet connected to any model configuration. Please call \"\n",
    "                f\"`{self.__class__.__name__}.connect(...)` before \"\n",
    "                f\"proceeding.\")\n",
    "        return self._model_config\n",
    "\n",
    "    def connect(\n",
    "        self,\n",
    "        explainer_config: ExplainerConfig,\n",
    "        model_config: ModelConfig,\n",
    "    ):\n",
    "        r\"\"\"Connects an explainer and model configuration to the explainer\n",
    "        algorithm.\"\"\"\n",
    "        self._explainer_config = ExplainerConfig.cast(explainer_config)\n",
    "        self._model_config = ModelConfig.cast(model_config)\n",
    "\n",
    "        if not self.supports():\n",
    "            raise ValueError(\n",
    "                f\"The explanation algorithm '{self.__class__.__name__}' does \"\n",
    "                f\"not support the given explanation settings.\")\n",
    "\n",
    "    # Helper functions ########################################################\n",
    "\n",
    "    @staticmethod\n",
    "    def _post_process_mask(\n",
    "        mask: Optional[Tensor],\n",
    "        num_elems: int,\n",
    "        hard_mask: Optional[Tensor] = None,\n",
    "        apply_sigmoid: bool = True,\n",
    "    ) -> Optional[Tensor]:\n",
    "        r\"\"\"\"Post processes any mask to not include any attributions of\n",
    "        elements not involved during message passing.\"\"\"\n",
    "        if mask is None:\n",
    "            return mask\n",
    "\n",
    "        if mask.size(0) == 1:  # common_attributes:\n",
    "            mask = mask.repeat(num_elems, 1)\n",
    "\n",
    "        mask = mask.detach().squeeze(-1)\n",
    "\n",
    "        if apply_sigmoid:\n",
    "            mask = mask.sigmoid()\n",
    "\n",
    "        if hard_mask is not None:\n",
    "            mask[~hard_mask] = 0.\n",
    "\n",
    "        return mask\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_hard_masks(\n",
    "        model: torch.nn.Module,\n",
    "        index: Optional[Union[int, Tensor]],\n",
    "        edge_index: Tensor,\n",
    "        num_nodes: int,\n",
    "    ) -> Tuple[Optional[Tensor], Optional[Tensor]]:\n",
    "        r\"\"\"Returns hard node and edge masks that only include the nodes and\n",
    "        edges visited during message passing.\"\"\"\n",
    "        if index is None:\n",
    "            return None, None  # Consider all nodes and edges.\n",
    "\n",
    "        index, _, _, edge_mask = k_hop_subgraph(\n",
    "            index,\n",
    "            num_hops=ExplainerAlgorithm._num_hops(model),\n",
    "            edge_index=edge_index,\n",
    "            num_nodes=num_nodes,\n",
    "            flow=ExplainerAlgorithm._flow(model),\n",
    "        )\n",
    "\n",
    "        node_mask = edge_index.new_zeros(num_nodes, dtype=torch.bool)\n",
    "        node_mask[index] = True\n",
    "\n",
    "        return node_mask, edge_mask\n",
    "\n",
    "    @staticmethod\n",
    "    def _num_hops(model: torch.nn.Module) -> int:\n",
    "        r\"\"\"Returns the number of hops the :obj:`model` is aggregating\n",
    "        information from.\n",
    "        \"\"\"\n",
    "        num_hops = 0\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                num_hops += 1\n",
    "        return num_hops\n",
    "\n",
    "    @staticmethod\n",
    "    def _flow(model: torch.nn.Module) -> str:\n",
    "        r\"\"\"Determines the message passing flow of the :obj:`model`.\"\"\"\n",
    "        for module in model.modules():\n",
    "            if isinstance(module, MessagePassing):\n",
    "                return module.flow\n",
    "        return 'source_to_target'\n",
    "\n",
    "    def _to_log_prob(self, y: Tensor) -> Tensor:\n",
    "        r\"\"\"Converts the model output to log-probabilities.\n",
    "\n",
    "        Args:\n",
    "            y (Tensor): The output of the model.\n",
    "        \"\"\"\n",
    "        if self.model_config.return_type == ModelReturnType.probs:\n",
    "            return y.log()\n",
    "        if self.model_config.return_type == ModelReturnType.raw:\n",
    "            return y.log_softmax(dim=-1)\n",
    "        if self.model_config.return_type == ModelReturnType.log_probs:\n",
    "            return y\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNExplainer(ExplainerAlgorithm):\n",
    "    r\"\"\"The GNN-Explainer model from the `\"GNNExplainer: Generating\n",
    "    Explanations for Graph Neural Networks\"\n",
    "    <https://arxiv.org/abs/1903.03894>`_ paper for identifying compact subgraph\n",
    "    structures and node features that play a crucial role in the predictions\n",
    "    made by a GNN.\n",
    "\n",
    "    The following configurations are currently supported:\n",
    "\n",
    "    - :class:`torch_geometric.explain.config.ModelConfig`\n",
    "\n",
    "        - :attr:`task_level`: :obj:`\"node\"`, :obj:`\"edge\"`, or :obj:`\"graph\"`\n",
    "\n",
    "    - :class:`torch_geometric.explain.config.ExplainerConfig`\n",
    "\n",
    "        - :attr:`node_mask_type`: :obj:`\"object\"`, :obj:`\"common_attributes\"`\n",
    "          or :obj:`\"attributes\"`\n",
    "\n",
    "        - :attr:`edge_mask_type`: :obj:`\"object\"` or :obj:`None`\n",
    "\n",
    "    .. note::\n",
    "\n",
    "        For an example of using :class:`GNNExplainer`, see\n",
    "        `examples/gnn_explainer.py <https://github.com/pyg-team/\n",
    "        pytorch_geometric/blob/master/examples/gnn_explainer.py>`_ and\n",
    "        `examples/gnn_explainer_ba_shapes.py <https://github.com/pyg-team/\n",
    "        pytorch_geometric/blob/master/examples/gnn_explainer_ba_shapes.py>`_.\n",
    "\n",
    "    Args:\n",
    "        epochs (int, optional): The number of epochs to train.\n",
    "            (default: :obj:`100`)\n",
    "        lr (float, optional): The learning rate to apply.\n",
    "            (default: :obj:`0.01`)\n",
    "        **kwargs (optional): Additional hyper-parameters to override default\n",
    "            settings in\n",
    "            :attr:`~torch_geometric.explain.algorithm.GNNExplainer.coeffs`.\n",
    "    \"\"\"\n",
    "\n",
    "    coeffs = {\n",
    "        'edge_size': 0.005,\n",
    "        'edge_reduction': 'sum',\n",
    "        'node_feat_size': 1.0,\n",
    "        'node_feat_reduction': 'mean',\n",
    "        'edge_ent': 1.0,\n",
    "        'node_feat_ent': 0.1,\n",
    "        'EPS': 1e-15,\n",
    "    }\n",
    "\n",
    "    def __init__(self, epochs: int = 100, lr: float = 0.01, **kwargs):\n",
    "        super().__init__()\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.coeffs.update(kwargs)\n",
    "        self.Features = False\n",
    "\n",
    "        self.node_mask = self.edge_mask = None\n",
    "\n",
    "    def supports(self) -> bool:\n",
    "        task_level = self.model_config.task_level\n",
    "        if task_level not in [\n",
    "                ModelTaskLevel.node, ModelTaskLevel.edge, ModelTaskLevel.graph\n",
    "        ]:\n",
    "            logging.error(f\"Task level '{task_level.value}' not supported\")\n",
    "            return False\n",
    "\n",
    "        edge_mask_type = self.explainer_config.edge_mask_type\n",
    "        if edge_mask_type not in [MaskType.object, None]:\n",
    "            logging.error(f\"Edge mask type '{edge_mask_type.value}' not \"\n",
    "                          f\"supported\")\n",
    "            return False\n",
    "\n",
    "        node_mask_type = self.explainer_config.node_mask_type\n",
    "        if node_mask_type not in [\n",
    "                MaskType.common_attributes, MaskType.object,\n",
    "                MaskType.attributes\n",
    "        ]:\n",
    "            logging.error(f\"Node mask type '{node_mask_type.value}' not \"\n",
    "                          f\"supported.\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        x: Tensor = None,\n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        target_index: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ) -> Explanation:\n",
    "        hard_node_mask = hard_edge_mask = None\n",
    "        if self.model_config.task_level == ModelTaskLevel.node:\n",
    "            # We need to compute hard masks to properly clean up edges and\n",
    "            # nodes attributions not involved during message passing:\n",
    "            hard_node_mask, hard_edge_mask = self._get_hard_masks(\n",
    "                model, index, edge_index, num_nodes=x.size(0))\n",
    "\n",
    "        self._train(model, x, edge_index, target=target, index=index,\n",
    "                    target_index=target_index, **kwargs)\n",
    "\n",
    "        node_mask = self._post_process_mask(self.node_mask, x.size(0),\n",
    "                                            hard_node_mask, apply_sigmoid=True)\n",
    "        edge_mask = self._post_process_mask(self.edge_mask, edge_index.size(1),\n",
    "                                            hard_edge_mask, apply_sigmoid=True)\n",
    "        print(self.edge_mask)\n",
    "        self._clean_model(model)\n",
    "\n",
    "        # TODO Consider dropping differentiation between `mask` and `feat_mask`\n",
    "        node_feat_mask = None\n",
    "        if self.explainer_config.node_mask_type in {\n",
    "                MaskType.attributes, MaskType.common_attributes\n",
    "        }:\n",
    "            node_feat_mask, node_mask = node_mask, None\n",
    "\n",
    "        return Explanation(x=x, edge_index=edge_index, edge_mask=edge_mask,\n",
    "                           node_mask=node_mask, node_feat_mask=node_feat_mask)\n",
    "\n",
    "    def _train(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        #x: Optional[Tensor],\n",
    "        edge_index: Tensor,\n",
    "        *,\n",
    "        target: Tensor,\n",
    "        x = None, \n",
    "        index: Optional[Union[int, Tensor]] = None,\n",
    "        target_index: Optional[int] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        if self.Features:\n",
    "            self._initialize_masks(x, edge_index, features=True)\n",
    "\n",
    "            parameters = [self.node_mask]  # We always learn a node mask.\n",
    "            if self.explainer_config.edge_mask_type is not None:\n",
    "                set_masks(model, self.edge_mask, edge_index, apply_sigmoid=True)\n",
    "                parameters.append(self.edge_mask)\n",
    "\n",
    "            optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "            for _ in range(self.epochs):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                h = x * self.node_mask.sigmoid()\n",
    "                y_hat, y = model(h, edge_index, **kwargs), target\n",
    "\n",
    "                if target_index is not None:\n",
    "                    y_hat, y = y_hat[target_index], y[target_index]\n",
    "                if index is not None:\n",
    "                    y_hat, y = y_hat[index], y[index]\n",
    "\n",
    "                loss = self._loss(y_hat, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        else:\n",
    "            self._initialize_masks(edge_index) \n",
    "            set_masks(model, self.edge_mask, edge_index, apply_sigmoid=True)\n",
    "            parameters = [self.edge_mask]\n",
    "            optimizer = torch.optim.Adam(parameters, lr=self.lr)\n",
    "\n",
    "            for _ in range(self.epochs):\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                h = x * self.node_mask.sigmoid()\n",
    "                y_hat, y = model(h, edge_index, **kwargs), target\n",
    "\n",
    "                if target_index is not None:\n",
    "                    y_hat, y = y_hat[target_index], y[target_index]\n",
    "                if index is not None:\n",
    "                    y_hat, y = y_hat[index], y[index]\n",
    "\n",
    "                if self.Features:\n",
    "                    loss = self._loss(y_hat, y, Features=True)\n",
    "                else:\n",
    "                    loss = self._loss(y_hat, y)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "\n",
    "    def _initialize_masks(self, edge_index: Tensor, x = None):\n",
    "        if self.Features:\n",
    "        \n",
    "            node_mask_type = self.explainer_config.node_mask_type\n",
    "            node_mask_type = MaskType.object\n",
    "            edge_mask_type = self.explainer_config.edge_mask_type\n",
    "\n",
    "            device = x.device\n",
    "            (N, F), E = x.size(), edge_index.size(1)\n",
    "\n",
    "            std = 0.1\n",
    "            if node_mask_type == MaskType.object:\n",
    "                self.node_mask = Parameter(torch.randn(N, 1, device=device) * std)\n",
    "            elif node_mask_type == MaskType.attributes:\n",
    "                self.node_mask = Parameter(torch.randn(N, F, device=device) * std)\n",
    "            elif node_mask_type == MaskType.common_attributes:\n",
    "                self.node_mask = Parameter(torch.randn(1, F, device=device) * std)\n",
    "            else:\n",
    "                raise NotImplementedError\n",
    "\n",
    "            if edge_mask_type == MaskType.object:\n",
    "                std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "                self.edge_mask = Parameter(torch.randn(E, device=device) * std)\n",
    "            elif edge_mask_type is not None:\n",
    "                raise NotImplementedError\n",
    "        else:\n",
    "            edge_mask_type = self.explainer_config.edge_mask_type\n",
    "            E = edge_index.size(1)\n",
    "            if edge_mask_type == MaskType.object:\n",
    "                std = torch.nn.init.calculate_gain('relu') * sqrt(2.0 / (2 * N))\n",
    "                self.edge_mask = Parameter(torch.randn(E, device=device) * std)\n",
    "                print('edge mask: ', self.edge_mask)\n",
    "            elif edge_mask_type is not None:\n",
    "                raise NotImplementedError\n",
    "\n",
    "\n",
    "\n",
    "    def _loss_regression(self, y_hat: Tensor, y: Tensor) -> Tensor:\n",
    "        return F.mse_loss(y_hat, y)\n",
    "\n",
    "    def _loss_classification(self, y_hat: Tensor, y: Tensor) -> Tensor:\n",
    "        if y.dim() == 0:  # `index` was given as an integer.\n",
    "            y_hat, y = y_hat.unsqueeze(0), y.unsqueeze(0)\n",
    "\n",
    "        y_hat = self._to_log_prob(y_hat)\n",
    "\n",
    "        return (-y_hat).gather(1, y.view(-1, 1)).mean()\n",
    "\n",
    "    def _loss(self, y_hat: Tensor, y: Tensor) -> Tensor:\n",
    "        if self.model_config.mode == ModelMode.regression:\n",
    "            loss = self._loss_regression(y_hat, y)\n",
    "        elif self.model_config.mode == ModelMode.classification:\n",
    "            loss = self._loss_classification(y_hat, y)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        if self.explainer_config.edge_mask_type is not None:\n",
    "            m = self.edge_mask.sigmoid()\n",
    "            edge_reduce = getattr(torch, self.coeffs['edge_reduction'])\n",
    "            loss = loss + self.coeffs['edge_size'] * edge_reduce(m)\n",
    "            ent = -m * torch.log(m + self.coeffs['EPS']) - (\n",
    "                1 - m) * torch.log(1 - m + self.coeffs['EPS'])\n",
    "            loss = loss + self.coeffs['edge_ent'] * ent.mean()\n",
    "\n",
    "        if self.Features:\n",
    "            m = self.node_mask.sigmoid()\n",
    "            node_feat_reduce = getattr(torch, self.coeffs['node_feat_reduction'])\n",
    "            loss = loss + self.coeffs['node_feat_size'] * node_feat_reduce(m)\n",
    "            ent = -m * torch.log(m + self.coeffs['EPS']) - (\n",
    "                1 - m) * torch.log(1 - m + self.coeffs['EPS'])\n",
    "            loss = loss + self.coeffs['node_feat_ent'] * ent.mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def _clean_model(self, model):\n",
    "        clear_masks(model)\n",
    "        self.node_mask = None\n",
    "        self.edge_mask = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GNNExplainer_:\n",
    "    r\"\"\"Deprecated version for :class:`GNNExplainer`.\"\"\"\n",
    "\n",
    "    coeffs = GNNExplainer.coeffs\n",
    "\n",
    "    conversion_node_mask_type = {\n",
    "        'feature': 'common_attributes',\n",
    "        'individual_feature': 'attributes',\n",
    "        'scalar': 'object',\n",
    "    }\n",
    "\n",
    "    conversion_return_type = {\n",
    "        'log_prob': 'log_probs',\n",
    "        'prob': 'probs',\n",
    "        'raw': 'raw',\n",
    "        'regression': 'raw',\n",
    "    }\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: torch.nn.Module,\n",
    "        epochs: int = 100,\n",
    "        lr: float = 0.01,\n",
    "        return_type: str = 'log_prob',\n",
    "        feat_mask_type: str = 'feature',\n",
    "        allow_edge_mask: bool = True,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        assert feat_mask_type in ['feature', 'individual_feature', 'scalar']\n",
    "\n",
    "        explainer_config = ExplainerConfig(\n",
    "            explanation_type='model',\n",
    "            node_mask_type=self.conversion_node_mask_type[feat_mask_type],\n",
    "            edge_mask_type=MaskType.object if allow_edge_mask else None,\n",
    "        )\n",
    "        model_config = ModelConfig(\n",
    "            mode='regression'\n",
    "            if return_type == 'regression' else 'classification',\n",
    "            task_level=ModelTaskLevel.node,\n",
    "            return_type=self.conversion_return_type[return_type],\n",
    "        )\n",
    "\n",
    "        self.model = model\n",
    "        self._explainer = GNNExplainer(epochs=epochs, lr=lr, **kwargs)\n",
    "        self._explainer.connect(explainer_config, model_config)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def get_initial_prediction(self, *args, **kwargs) -> Tensor:\n",
    "\n",
    "        training = self.model.training\n",
    "        self.model.eval()\n",
    "\n",
    "        out = self.model(*args, **kwargs)\n",
    "        if self._explainer.model_config.mode == ModelMode.classification:\n",
    "            out = out.argmax(dim=-1)\n",
    "\n",
    "        self.model.train(training)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def explain_graph(\n",
    "        self,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        self._explainer.model_config.task_level = ModelTaskLevel.graph\n",
    "\n",
    "        explanation = self._explainer(\n",
    "            self.model,\n",
    "            x,\n",
    "            edge_index,\n",
    "            target=self.get_initial_prediction(x, edge_index, **kwargs),\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self._convert_output(explanation, edge_index)\n",
    "\n",
    "    def explain_node(\n",
    "        self,\n",
    "        node_idx: int,\n",
    "        x: Tensor,\n",
    "        edge_index: Tensor,\n",
    "        **kwargs,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        self._explainer.model_config.task_level = ModelTaskLevel.node\n",
    "        explanation = self._explainer(\n",
    "            self.model,\n",
    "            x,\n",
    "            edge_index,\n",
    "            target=self.get_initial_prediction(x, edge_index, **kwargs),\n",
    "            index=node_idx,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self._convert_output(explanation, edge_index, index=node_idx,\n",
    "                                    x=x)\n",
    "    \n",
    "    def explain_rel_node(\n",
    "        self,\n",
    "        node_idx: int,\n",
    "        edge_index: Tensor,\n",
    "        edge_type: Tensor = None, \n",
    "        **kwargs,\n",
    "    ) -> Tuple[Tensor, Tensor]:\n",
    "        self._explainer.model_config.task_level = ModelTaskLevel.node\n",
    "        explanation = self._explainer(\n",
    "            self.model,\n",
    "            x,\n",
    "            edge_index,\n",
    "            target=self.get_initial_prediction(edge_index, edge_type, **kwargs),\n",
    "            index=node_idx,\n",
    "            **kwargs,\n",
    "        )\n",
    "        return self._convert_output(explanation, edge_index, index=node_idx,\n",
    "                                    x=x)\n",
    "\n",
    "    def _convert_output(self, explanation, edge_index, index=None, x=None):\n",
    "        if 'node_mask' in explanation.available_explanations:\n",
    "            node_mask = explanation.node_mask\n",
    "        else:\n",
    "            if (self._explainer.explainer_config.node_mask_type ==\n",
    "                    MaskType.common_attributes):\n",
    "                node_mask = explanation.node_feat_mask[0]\n",
    "            else:\n",
    "                node_mask = explanation.node_feat_mask\n",
    "\n",
    "        edge_mask = None\n",
    "        if 'edge_mask' in explanation.available_explanations:\n",
    "            edge_mask = explanation.edge_mask\n",
    "        else:\n",
    "            if index is not None:\n",
    "                _, edge_mask = self._explainer._get_hard_masks(\n",
    "                    self.model, index, edge_index, num_nodes=x.size(0))\n",
    "                edge_mask = edge_mask.to(x.dtype)\n",
    "            else:\n",
    "                edge_mask = torch.ones(edge_index.shape[1],\n",
    "                                       device=edge_index.device)\n",
    "\n",
    "        return node_mask, edge_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,data):\n",
    "        super().__init__()\n",
    "        self.conv1 = RGCNConv(data.num_nodes, 16, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "        self.conv2 = RGCNConv(16, dataset.num_classes, dataset.num_relations,\n",
    "                              num_bases=30)\n",
    "\n",
    "    def forward(self, edge_index, edge_type):\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "    \n",
    "\n",
    "    def forward(self):\n",
    "        edge_index, edge_type = data.edge_index, data.edge_type\n",
    "        x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "        x = self.conv2(x, edge_index, edge_type)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    # def forward(self, edge_type, edge_index):\n",
    "    #     #edge_type edge_type.unsqueeze(1)\n",
    "    #     x = F.relu(self.conv1(None, edge_index, edge_type))\n",
    "    #     x = self.conv2(x, edge_index, edge_type)\n",
    "    #     return F.log_softmax(x, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')# if args.dataset == 'AM' else device\n",
    "model, data = Net(data).to(device), data.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_node(node_idx, model,data):\n",
    "    explanation = GNNExplainer(\n",
    "            model,\n",
    "            edge_index,\n",
    "            target= model(),\n",
    "            index=node_idx\n",
    "        )\n",
    "    print(explanation)\n",
    "    return _convert_output(explanation, edge_index, data, index=node_idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _convert_output(explanation, edge_index,data,  index=0, x=None):\n",
    "\n",
    "    # node_mask = explanation.node_mask\n",
    "\n",
    "    # edge_mask = explanation.edge_mask\n",
    "    # else:\n",
    "    #if index is not None:\n",
    "    _, edge_mask = _get_hard_masks(\n",
    "            model, index, edge_index, num_nodes=data.num_nodes)\n",
    "        #edge_mask = edge_mask.to(data.num_nodes.dtype)\n",
    "    # else:\n",
    "    #     edge_mask = torch.ones(edge_index.shape[1],\n",
    "    #                             device=edge_index.device)\n",
    "\n",
    "    return edge_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNExplainer(\n",
      "  (epochs): Net(\n",
      "    (conv1): RGCNConv(6909, 16, num_relations=90)\n",
      "    (conv2): RGCNConv(16, 4, num_relations=90)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ True, False, False,  ..., False, False, False])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain_node(0,model,data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c30f2af5f468e7f5b45bcc30fca5f4886c90d54777aed916ed5f6294dfb24bf2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
