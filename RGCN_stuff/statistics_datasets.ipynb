{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "name = 'dbo_gender'\n",
    "if name in ['aifb', 'mutag', 'bgs', 'am', 'mdgenre']:\n",
    "    data = kg.load(name, torch=True, final=False)\n",
    "if 'IMDb' in name:    \n",
    "    data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "if 'dbo' in name:\n",
    "    data = torch.load(f'data/DBO/finals/{name}.pt')\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)\n",
    "print('rel:', data.num_relations, 'ent:', data.num_entities, 'triples:', data.triples.shape)\n",
    "print('training', data.training.shape, 'withheld', data.withheld.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m v \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39m'\u001b[39m\u001b[39mchk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.0005_sizestd_adaptive_ent_1_type_1_killtype_False_break_no/masked_adj/masked_hor_thresh5731\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "v = torch.load('chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.0005_sizestd_adaptive_ent_1_type_1_killtype_False_break_no/masked_adj/masked_hor_thresh5731')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)\n",
    "data.entities = np.append(data.triples[:,0].detach().numpy(),(data.triples[:,2].detach().numpy()))\n",
    "relations = get_relations(data)\n",
    "\n",
    "#d_classes(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = data.withheld[:,0]\n",
    "# most_common_node = {}\n",
    "# for i in val:\n",
    "#     sub_edges, neighborhoods, sub_edges_tensor = find_n_hop_neighbors(data, 2,int(i), adj=True)\n",
    "\n",
    "#     counter = Counter([num for tup in sub_edges for num in tup]).most_common(1)[0][0]\n",
    "#     most_common_node[int(i)] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m female \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtraining[data\u001b[39m.\u001b[39mtraining[:,\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m][:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m male_triples \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mtriples[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtriples[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mif\u001b[39;00m male[i] \u001b[39min\u001b[39;00m  data\u001b[39m.\u001b[39mtriples[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist() ]\n\u001b[0;32m----> 4\u001b[0m female_triples \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mtriples[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtriples[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mif\u001b[39;00m female[i] \u001b[39min\u001b[39;00m  data\u001b[39m.\u001b[39mtriples[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist() ]\n\u001b[1;32m      5\u001b[0m female_triples \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mtriples[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtriples[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mtriples[i][\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m female ]\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrequency_relations\u001b[39m(data, subset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mall\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n",
      "Cell \u001b[0;32mIn[81], line 4\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m female \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mtraining[data\u001b[39m.\u001b[39mtraining[:,\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m][:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      3\u001b[0m male_triples \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mtriples[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtriples[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mif\u001b[39;00m male[i] \u001b[39min\u001b[39;00m  data\u001b[39m.\u001b[39mtriples[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist() ]\n\u001b[0;32m----> 4\u001b[0m female_triples \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mtriples[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtriples[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mif\u001b[39;00m female[i] \u001b[39min\u001b[39;00m  data\u001b[39m.\u001b[39mtriples[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mtolist() ]\n\u001b[1;32m      5\u001b[0m female_triples \u001b[39m=\u001b[39m [data\u001b[39m.\u001b[39mtriples[i][\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mtriples[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mtolist() \u001b[39mif\u001b[39;00m data\u001b[39m.\u001b[39mtriples[i][\u001b[39m0\u001b[39m] \u001b[39min\u001b[39;00m female ]\n\u001b[1;32m      6\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrequency_relations\u001b[39m(data, subset\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39mall\u001b[39m \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m):\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "male = data.training[data.training[:,1] == 0][:,0].tolist()\n",
    "female = data.training[data.training[:,1] == 1][:,0].tolist()\n",
    "male_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if male[i] in  data.triples[:,0].tolist() ]\n",
    "female_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if female[i] in  data.triples[:,0].tolist() ]\n",
    "female_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if data.triples[i][0] in female ]\n",
    "def frequency_relations(data, subset=None, all = True):\n",
    "    if all:\n",
    "        freq = Counter(data.triples[:,1].tolist())\n",
    "        print(freq)\n",
    "    else:\n",
    "        freq = Counter(subset)\n",
    "        print(freq)\n",
    "    sorted_freq = {data.i2r[k]: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_freq\n",
    "#f = frequency_relations(data,male, all = False)\n",
    "f = frequency_relations(data,female_triples, all = False)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if data.triples[i][0] in female ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "male_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if male[i] in  data.triples[:,0].tolist() ]\n",
    "female_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if female[i] in  data.triples[:,0].tolist() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7413)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "female_triples = [data.triples[i][0] for i in data.triples[:,1]if data.triples[i][0] in female ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Node Degree: 2.606 ± 6.427\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import statistics\n",
    "def select_matching_triples(triples_tensor, nodes_to_check):\n",
    "    selected_triples = []\n",
    "\n",
    "    # Iterate over the triples and check if any node matches with nodes_to_check\n",
    "    for triple in triples_tensor:\n",
    "        head, relation, tail = triple.tolist()\n",
    "        if head in nodes_to_check or tail in nodes_to_check:\n",
    "            selected_triples.append(triple)\n",
    "\n",
    "    return torch.stack(selected_triples)\n",
    "val = data.withheld[:,0]\n",
    "\n",
    "selected_triples = select_matching_triples(data.triples, val)\n",
    "\n",
    "def compute_average_node_degree(triples_tensor):\n",
    "    # Create an empty dictionary to store the node degrees\n",
    "    node_degrees = {}\n",
    "\n",
    "    # Iterate over the triples and calculate the node degrees\n",
    "    for triple in triples_tensor:\n",
    "        head, relation, tail = triple.tolist()\n",
    "        # Increment the degree for the head node\n",
    "        node_degrees[head] = node_degrees.get(head, 0) + 1\n",
    "        # Increment the degree for the tail node\n",
    "        node_degrees[tail] = node_degrees.get(tail, 0) + 1\n",
    "\n",
    "    # Compute the average node degree\n",
    "    num_nodes = len(node_degrees)\n",
    "    total_degree = sum(node_degrees.values())\n",
    "    average_degree = total_degree / num_nodes\n",
    "        # Compute the standard deviation of node degrees\n",
    "    degree_values = list(node_degrees.values())\n",
    "    degree_std = statistics.stdev(degree_values)\n",
    "\n",
    "    return average_degree, degree_std\n",
    "\n",
    "\n",
    "# Example usage\n",
    "triples_tensor = torch.tensor([[12264, 20, 19861],\n",
    "                               [22808, 0, 22261],\n",
    "                               [21753, 9, 13458]])\n",
    "\n",
    "average_degree, std_degree = compute_average_node_degree(data.triples)\n",
    "print(\"Average Node Degree:\", np.round(average_degree,3), \"±\", np.round(std_degree,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Degree at 2 Hops: 43.298 ± 93.297\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import statistics\n",
    "\n",
    "def compute_average_degree_at_2_hops(triples_tensor):\n",
    "    # Create an adjacency dictionary to store the neighbors of each node\n",
    "    adjacency_dict = {}\n",
    "\n",
    "    # Iterate over the triples and build the adjacency dictionary\n",
    "    for triple in triples_tensor:\n",
    "        head, relation, tail = triple.tolist()\n",
    "\n",
    "        # Add tail as a neighbor of head\n",
    "        if head not in adjacency_dict:\n",
    "            adjacency_dict[head] = set()\n",
    "        adjacency_dict[head].add(tail)\n",
    "\n",
    "        # Add head as a neighbor of tail\n",
    "        if tail not in adjacency_dict:\n",
    "            adjacency_dict[tail] = set()\n",
    "        adjacency_dict[tail].add(head)\n",
    "\n",
    "    # Compute the average degree at 2 hops for each node\n",
    "    average_degrees_2_hops = []\n",
    "    for node, neighbors in adjacency_dict.items():\n",
    "        two_hop_neighbors = set()\n",
    "        for neighbor in neighbors:\n",
    "            two_hop_neighbors.update(adjacency_dict.get(neighbor, set()))\n",
    "        average_degrees_2_hops.append(len(neighbors) + len(two_hop_neighbors))\n",
    "\n",
    "    # Compute the average degree at 2 hops and its standard deviation\n",
    "    average_degree_2_hops = statistics.mean(average_degrees_2_hops)\n",
    "    degree_std_2_hops = statistics.stdev(average_degrees_2_hops)\n",
    "\n",
    "    return average_degree_2_hops, degree_std_2_hops\n",
    "\n",
    "\n",
    "# Example usage\n",
    "triples_tensor = torch.tensor([[1, 20, 2],\n",
    "                               [2, 0, 3],\n",
    "                               [3, 9, 4],\n",
    "                               [4, 7, 1]])\n",
    "\n",
    "average_degree_2_hops, degree_std_2_hops = compute_average_degree_at_2_hops(data.triples)\n",
    "print(\"Average Degree at 2 Hops:\", np.round(average_degree_2_hops,3),'±', np.round(degree_std_2_hops,3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg num edges 0 hop 16.394 ± 9.23\n",
      "avg num edges 2 hop 213.793 ± 155.405\n"
     ]
    }
   ],
   "source": [
    "import statistics\n",
    "def select_matching_triples(triples_tensor, nodes_to_check):\n",
    "    selected_triples = []\n",
    "\n",
    "    # Iterate over the triples and check if any node matches with nodes_to_check\n",
    "    for triple in triples_tensor:\n",
    "        head, relation, tail = triple.tolist()\n",
    "        if head in nodes_to_check or tail in nodes_to_check:\n",
    "            selected_triples.append(triple)\n",
    "\n",
    "    return torch.stack(selected_triples)\n",
    "val = data.withheld[:,0]\n",
    "\n",
    "selected_triples = select_matching_triples(data.triples, val)\n",
    "\n",
    "def compute_num_edges_to_node(triples_tensor, node):\n",
    "    # Create an adjacency dictionary to store the neighbors of each node\n",
    "    adjacency_dict = {}\n",
    "\n",
    "    # Iterate over the triples and build the adjacency dictionary\n",
    "    for triple in triples_tensor:\n",
    "        head, relation, tail = triple.tolist()\n",
    "\n",
    "        # Add tail as a neighbor of head\n",
    "        if head not in adjacency_dict:\n",
    "            adjacency_dict[head] = set()\n",
    "        adjacency_dict[head].add(tail)\n",
    "\n",
    "        # Add head as a neighbor of tail\n",
    "        if tail not in adjacency_dict:\n",
    "            adjacency_dict[tail] = set()\n",
    "        adjacency_dict[tail].add(head)\n",
    "\n",
    "    # Compute the number of edges to the given node at 0 and 2 hops\n",
    "    num_edges_to_node_0_hop = len(adjacency_dict.get(node, set()))\n",
    "    neighbors_2_hops = set()\n",
    "    if node in adjacency_dict:\n",
    "        neighbors = adjacency_dict[node]\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor in adjacency_dict:\n",
    "                neighbors_2_hops.update(adjacency_dict[neighbor])\n",
    "    num_edges_to_node_2_hops = len(neighbors_2_hops)\n",
    "\n",
    "    return num_edges_to_node_0_hop, num_edges_to_node_2_hops\n",
    "\n",
    "sum_0,sum_2 = [], []\n",
    "for i in val:\n",
    "    #print(int(i))\n",
    "    num_edges_0_hop, num_edges_2_hops = compute_num_edges_to_node(data.triples, int(i))\n",
    "    sum_0.append(num_edges_0_hop)\n",
    "    sum_2.append(num_edges_2_hops)\n",
    "print('avg num edges 0 hop', np.round(np.mean(sum_0),3), '±', np.round(np.std(sum_0),3))\n",
    "print('avg num edges 2 hop', np.round(np.mean(sum_2),3), '±', np.round(np.std(sum_2),3))\n",
    "# Example usage\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_type(v,h,data, relation_id = None,type=True):\n",
    "    ''' Get the object class of a specific relation'''\n",
    "    if type:\n",
    "        relation_id = [i for i in range(data.num_relations) if 'type' in data.i2r[i]][-1]\n",
    "    output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, relation_id)\n",
    "    output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, relation_id)\n",
    "    objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "    list = []\n",
    "    for i in objects_types:\n",
    "        list.append(data.i2e[i[2]][0])#.split('#')[1])\n",
    "    result = Counter(list)\n",
    "    return result\n",
    "\n",
    "for node_idx in data.withheld[:,0]:\n",
    "    h, v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}'), torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "    print(f'node {node_idx}:', object_type(v,h,data, 39))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
