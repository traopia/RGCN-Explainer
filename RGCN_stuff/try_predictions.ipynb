{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import src.kgbench as kg\n",
    "import fire, sys\n",
    "import math\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# #\n",
    "#from torch_geometric.utils import to_networkx\n",
    "# import networkx as nx\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from rgcn_model import RGCN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading dmg777k dataset.\n",
      "loaded data dmg777k (86.54s).\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('dmg777k', torch=True, final=False)\n",
    "data = prunee(data, 2)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([198, 11])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.load('chk/am_chk/models/prediction_am_prune_True')\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 asWKT-RD\n",
      "1 city\n",
      "2 codeNationalMonument\n",
      "3 location\n",
      "4 name\n",
      "5 neighbourhood\n",
      "6 thumbnail\n",
      "7 created\n",
      "8 creator\n",
      "9 description\n",
      "10 isPartOf\n",
      "11 spatial\n",
      "12 dateCreated\n",
      "13 roleName\n",
      "14 alternateName\n",
      "15 countryCode\n",
      "16 featureClass\n",
      "17 featureCode\n",
      "18 locationMap\n",
      "19 name\n",
      "20 nearbyFeatures\n",
      "21 officialName\n",
      "22 parentADM1\n",
      "23 parentADM2\n",
      "24 parentCountry\n",
      "25 parentFeature\n",
      "26 population\n",
      "27 wikipediaArticle\n",
      "28 asWKT\n",
      "29 hasGeometry\n",
      "30 sfWithin\n",
      "31 type\n",
      "32 isDefinedBy\n",
      "33 label\n",
      "34 seeAlso\n",
      "35 sameAs\n",
      "36 alt\n",
      "37 hasStreetAddress\n",
      "38 postal-code\n",
      "39 street-address\n",
      "40 depiction\n",
      "41 depicts\n",
      "42 name\n",
      "43 bouwjaar\n",
      "44 complexnummer\n",
      "45 fotograaf\n",
      "46 graveur\n",
      "47 huisnummer\n",
      "48 huisnummerCompleet\n",
      "49 huisnummerToevoeging\n",
      "50 internComplexNummers\n",
      "51 isFree\n",
      "52 locator\n",
      "53 ontwerper\n",
      "54 reprofotograaf\n",
      "55 rnaSubject\n",
      "56 schilder\n",
      "57 techniek\n",
      "58 tekenaar\n",
      "59 regiocode\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data.i2rel)):\n",
    "    print(i, data.i2rel[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_threshold(sparse_tensor, num_exp):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == num_exp:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "\n",
    "def threshold_mask(h,v ,data, num_exp, equal=True):\n",
    "    ''' Apply a threshold mask to the adjacency matrix'''\n",
    "    t_v, t_h =     find_threshold(v, num_exp), find_threshold(h, num_exp)\n",
    "    #v, h = convert_back(v, data), convert_back(h, data)\n",
    "    v_thresh, h_thresh = convert_binary(v,t_v,equal), convert_binary(h,t_h,equal)\n",
    "    return h_thresh,v_thresh,t_h,t_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[ 23451,  23451,  23451,  ..., 329925, 329926, 329927],\n",
       "                       [  5678,   5743,   5746,  ...,   5230,   5230,   5230]]),\n",
       "       values=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
       "       size=(753935, 8285), nnz=1311, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_binary_num(sparse_tensor, threshold_num ,equal=True):\n",
    "    ''' Converts a sparse tensor to a binary sparse tensor based on a threshold'''\n",
    "    # convert values to either 0 or 1 based on a threshold of 0.5\n",
    "    top_values, top_indices = torch.topk(tensor, k=n)\n",
    "    mask = sparse_tensor._values() >= threshold\n",
    "    if equal==False:\n",
    "        mask = sparse_tensor._values() > threshold\n",
    "\n",
    "    converted_values = torch.zeros_like(sparse_tensor._values())\n",
    "    converted_values[mask] = 1\n",
    "    #print(\"Number of non zero values: \", converted_values.nonzero().size(0))\n",
    "\n",
    "    # create a new sparse tensor with the converted values\n",
    "    converted_sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), converted_values, size=sparse_tensor.size())\n",
    "\n",
    "    return converted_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[23567, 23551, 23458, 23567, 23551, 23458, 23551, 23451,\n",
       "                        23567, 23458, 23567, 23451, 23451, 23451, 23551],\n",
       "                       [ 5678,  5745,  6610,  6683,  5743,  5678,  5746,  5746,\n",
       "                         6404,  6611,  6685,  5678,  5743,  6404,  5678]]),\n",
       "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "                      1.]),\n",
       "       size=(753935, 8285), nnz=15, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_n_highest_sparse(tensor, n):\n",
    "    ''' Get the n highest elements of a sparse tensor'''\n",
    "    # Get the number of non-zero elements in the sparse tensor\n",
    "    nnz = tensor._nnz()\n",
    "\n",
    "    # Check if n is greater than nnz, and handle it accordingly\n",
    "    if n >= nnz:\n",
    "        # If n is greater than or equal to nnz, select all non-zero elements\n",
    "        selected_indices = tensor._indices()\n",
    "        selected_values = tensor._values()\n",
    "    else:\n",
    "        # Get the indices and values of the top n highest elements\n",
    "        values, indices = torch.topk(tensor._values(), n)\n",
    "\n",
    "        # Get the corresponding row and column indices from the original tensor\n",
    "        row_indices = tensor._indices()[0][indices]\n",
    "        col_indices = tensor._indices()[1][indices]\n",
    "\n",
    "        # Combine the row and column indices to form the selected indices\n",
    "        selected_indices = torch.stack((row_indices, col_indices))\n",
    "\n",
    "        # Get the corresponding values from the original tensor\n",
    "        selected_values = tensor._values()[indices]\n",
    "        sel_tensor = torch.sparse_coo_tensor(selected_indices, selected_values, size=tensor.size())\n",
    "        sel_tensor = convert_binary(sel_tensor, 0, equal=False)\n",
    "    return sel_tensor\n",
    "\n",
    "# Example sparse tensor\n",
    "indices = torch.tensor([[0, 1, 1],\n",
    "                        [1, 0, 1]])\n",
    "\n",
    "values = torch.tensor([2, 3, 4], dtype=torch.float32)\n",
    "\n",
    "# Create the sparse tensor\n",
    "sparse_tensor = v#torch.sparse_coo_tensor(indices, values, size=(2, 2))\n",
    "\n",
    "n = 15\n",
    "get_n_highest_sparse(sparse_tensor, n)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "\n",
    "def get_n_highest_sparse_with_specified(tensor, n, specified_value, specified_number):\n",
    "    # Convert the sparse tensor to a dense tensor for indexing\n",
    "    dense_tensor = tensor.to_dense()\n",
    "\n",
    "    # Get the number of non-zero elements in the sparse tensor\n",
    "    nnz = tensor._nnz()\n",
    "\n",
    "    # Check if n is greater than nnz, and handle it accordingly\n",
    "    if n >= nnz:\n",
    "        # If n is greater than or equal to nnz, select all non-zero elements\n",
    "        selected_indices = tensor._indices()\n",
    "        selected_values = tensor._values()\n",
    "    else:\n",
    "        # Get the indices and values of the top n highest elements\n",
    "        values, indices = torch.topk(dense_tensor, n)\n",
    "\n",
    "        # Convert the indices to a sparse tensor\n",
    "        selected_indices = indices.nonzero().t()\n",
    "\n",
    "        # Get the corresponding values from the original tensor\n",
    "        selected_values = tensor[selected_indices[0], selected_indices[1]]\n",
    "\n",
    "        # Create a mask to identify indices with values equal to the specified value\n",
    "        specified_mask = selected_indices[1] == specified_value\n",
    "        specified_indices = selected_indices[:, specified_mask]\n",
    "\n",
    "        # Check if there is at least the specified number of indices with the specified value\n",
    "        if specified_indices.size(1) < specified_number:\n",
    "            # If not, randomly replace indices with the specified value until we have the specified number\n",
    "            replace_indices = torch.randint(0, nnz, (specified_number - specified_indices.size(1),))\n",
    "            selected_indices[:, specified_mask] = tensor._indices()[:, replace_indices]\n",
    "\n",
    "        # Get the corresponding values from the original tensor\n",
    "        selected_values = tensor[selected_indices[0], selected_indices[1]]\n",
    "\n",
    "    # Convert the selected indices and values back to a sparse tensor\n",
    "    selected_sparse_tensor = torch.sparse_coo_tensor(selected_indices, selected_values, size=tensor.size())\n",
    "\n",
    "    return selected_values, selected_sparse_tensor\n",
    "\n",
    "# Your sparse tensor\n",
    "indices = torch.tensor([[23567, 23551, 23458, 23567, 23551, 23458, 23551, 23451,\n",
    "                        23567, 23458, 23567, 23451, 23451, 23451, 23551],\n",
    "                       [ 5678,  5745,  6610,  6683,  5743,  5678,  5746,  5746,\n",
    "                         6404,  6611,  6685,  5678,  5743,  6404,  5678]])\n",
    "\n",
    "values = torch.tensor([0.2, 0.3, 0.2, 0.2, 0.5, 0.4, 0.2, 0.3, 0.2, 0.2, 0.5, 0.4, 0.2, 0.5, 0.5], dtype=torch.float32)\n",
    "\n",
    "# Create the sparse tensor\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(753935, 8285))\n",
    "\n",
    "n = 5\n",
    "specified_value = 5678\n",
    "specified_number = 1\n",
    "selected_values, selected_sparse_tensor = get_n_highest_sparse_with_specified(sparse_tensor, n, specified_value, specified_number)\n",
    "print(\"Selected Values:\", selected_values)\n",
    "print(\"Selected Indices:\", selected_sparse_tensor._indices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = torch.load('chk/aifb_chk/exp/init_const_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_1_type_1_killMFR_False/masked_adj/masked_hor5678')\n",
    "v = torch.load('chk/aifb_chk/exp/init_const_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_1_type_1_killMFR_False/masked_adj/masked_ver5678')\n",
    "# h,v,t_h,t_v = threshold_mask(h,v,data, 25, equal=True)\n",
    "# torch.mean(h.coalesce().values())\n",
    "# v.coalesce().values().count_nonzero()\n",
    "# h.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([[ 23451,  23451,  23451,  ..., 329925, 329926, 329927],\n",
       "                       [  5678,   5743,   5746,  ...,   5230,   5230,   5230]]),\n",
       "       values=tensor([0.9928, 0.9928, 0.9928,  ..., 0.9928, 0.9928, 0.9928]),\n",
       "       size=(753935, 8285), nnz=1311, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_thresh = v.coalesce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BIK': 0, 'CoM': 1, 'Forschungsgebiete': 2, 'Forschungsgruppen': 3, 'Kooperationen': 4, 'Personen': 5, 'Projekte': 6, 'Publications': 7, 'Publikationen': 8, 'WBS': 9, 'eOrganisation': 10, 'fbe': 11, 'kangal': 12, 'mitarbeiter': 13, 'optrek': 14, 'padlr': 15, 'projects': 16, 'prost': 17, 'uli': 18, 'wiki': 19, 'wim': 20, 'ze': 21}\n",
      "35\n"
     ]
    }
   ],
   "source": [
    "dict_classes = d_classes(data)\n",
    "dict_classes\n",
    "min_length = min(len(value) for value in dict_classes.values())\n",
    "num_samples_per_class = 30 if min_length > 30 else min_length \n",
    "total_elements = sum(len(value) for value in dict_classes.values())\n",
    "print(total_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi-Squared Statistic: 24.588578445305824\n",
      "P-value: 0.00016727053987577496\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "\n",
    "\n",
    "# Get the set of common relation names\n",
    "common_relations = set(full_graph_relations.keys()).intersection(explanation_subgraph_relations.keys())\n",
    "\n",
    "# Extract the counts for common relations\n",
    "full_graph_counts = np.array([full_graph_relations[relation] for relation in common_relations])\n",
    "explanation_counts = np.array([explanation_subgraph_relations[relation] for relation in common_relations])\n",
    "\n",
    "# Perform chi-squared test\n",
    "observed = np.array([full_graph_counts, explanation_counts])\n",
    "chi2, p, _, _ = chi2_contingency(observed)\n",
    "\n",
    "print(\"Chi-Squared Statistic:\", chi2)\n",
    "print(\"P-value:\", p)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstract</th>\n",
       "      <th>address</th>\n",
       "      <th>author</th>\n",
       "      <th>booktitle</th>\n",
       "      <th>carriedOutBy</th>\n",
       "      <th>carriesOut</th>\n",
       "      <th>chapter</th>\n",
       "      <th>dealtWithIn</th>\n",
       "      <th>edition</th>\n",
       "      <th>editor</th>\n",
       "      <th>...</th>\n",
       "      <th>volume</th>\n",
       "      <th>worksAtProject</th>\n",
       "      <th>year</th>\n",
       "      <th>type</th>\n",
       "      <th>type</th>\n",
       "      <th>range</th>\n",
       "      <th>subClassOf</th>\n",
       "      <th>allValuesFrom</th>\n",
       "      <th>inverseOf</th>\n",
       "      <th>onProperty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abstract  address  author  booktitle  carriedOutBy  carriesOut  chapter  \\\n",
       "0       NaN      NaN       4        NaN           NaN         NaN      NaN   \n",
       "1       NaN      NaN       1        NaN           NaN         NaN      NaN   \n",
       "2       NaN      NaN      11        NaN           NaN         NaN      NaN   \n",
       "3       NaN      NaN       1        NaN           NaN         NaN      NaN   \n",
       "4       NaN      NaN       4        NaN           NaN         NaN      NaN   \n",
       "5       NaN      NaN       3        NaN           NaN         NaN      NaN   \n",
       "\n",
       "   dealtWithIn  edition  editor  ...  volume  worksAtProject  year  type  \\\n",
       "0          NaN      NaN     NaN  ...     NaN             NaN   NaN   NaN   \n",
       "1          NaN      NaN     NaN  ...     NaN             NaN   NaN   NaN   \n",
       "2          NaN      NaN     NaN  ...     NaN             1.0   NaN   NaN   \n",
       "3          NaN      NaN     NaN  ...     NaN             NaN   NaN   NaN   \n",
       "4          NaN      NaN     NaN  ...     NaN             NaN   NaN   NaN   \n",
       "5          NaN      NaN     NaN  ...     NaN             2.0   NaN   NaN   \n",
       "\n",
       "   type  range  subClassOf  allValuesFrom  inverseOf  onProperty  \n",
       "0   NaN    NaN         NaN            NaN        NaN         NaN  \n",
       "1   NaN    NaN         NaN            NaN        NaN         NaN  \n",
       "2   NaN    NaN         NaN            NaN        NaN         NaN  \n",
       "3   NaN    NaN         NaN            NaN        NaN         NaN  \n",
       "4   NaN    NaN         NaN            NaN        NaN         NaN  \n",
       "5   NaN    NaN         NaN            NaN        NaN         NaN  \n",
       "\n",
       "[6 rows x 45 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('chk/aifb_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_1_type_1_killtype_True_break_no/Relation_Importance/Relations_Important_sample_threshold.csv')\n",
    "df[relations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "full_graph_df = pd.DataFrame(list(full_graph_relations.items()), columns=['Relation Name', 'Count'])\n",
    "explanation_df = pd.DataFrame(list(explanation_subgraph_relations.items()), columns=['Relation Name', 'Count'])\n",
    "\n",
    "# Calculate the total counts for both full graph and explanation subgraph\n",
    "total_full_graph = full_graph_df['Count'].sum()\n",
    "total_explanation = explanation_df['Count'].sum()\n",
    "\n",
    "# Calculate the percentages for each relation in both full graph and explanation subgraph\n",
    "full_graph_df['Percentage'] = full_graph_df['Count'] / total_full_graph * 100\n",
    "explanation_df['Percentage'] = explanation_df['Count'] / total_explanation * 100\n",
    "\n",
    "# Create the bar plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot the full graph data with increased transparency (alpha = 0.7) and blue color\n",
    "plt.bar(full_graph_df['Relation Name'], full_graph_df['Percentage'], alpha=0.7, color='yellow', edgecolor='black', label='Full Graph')\n",
    "\n",
    "# Plot the explanation subgraph data with increased transparency (alpha = 0.7) and green color\n",
    "plt.bar(explanation_df['Relation Name'], explanation_df['Percentage'], alpha=0.7, color='blue', edgecolor='black', label='Explanation Subgraph')\n",
    "\n",
    "plt.xlabel('Relation Name')\n",
    "plt.ylabel('Percentage')\n",
    "plt.title('Distribution of Relations')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5783,\n",
       " 5724,\n",
       " 5678,\n",
       " 5702,\n",
       " 5905,\n",
       " 5731,\n",
       " 5808,\n",
       " 5785,\n",
       " 5861,\n",
       " 5755,\n",
       " 5797,\n",
       " 5831,\n",
       " 5857,\n",
       " 5854,\n",
       " 5798,\n",
       " 5753]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "sampled_data = []\n",
    "for key in dict_classes:\n",
    "    sampled_data.extend(random.sample(dict_classes[key], 4))\n",
    "sampled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5272) tensor(0.5272)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v = torch.load(f'chk/mutag_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no/masked_adj/masked_ver6594')\n",
    "h = torch.load(f'chk/mutag_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no/masked_adj/masked_hor6594')\n",
    "h_t = find_threshold(h,10)\n",
    "v_t = find_threshold(v,10)\n",
    "print(h_t, v_t)\n",
    "h,v,_,_=threshold_mask(h,v,data,10)\n",
    "v.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/src/kgbench.py:247: UserWarning: The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, the correct evaluation is to combine train and validation for the final evaluation run.Set include_val to True when loading the data.\n",
      "  warnings.warn('The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2145s).\n"
     ]
    }
   ],
   "source": [
    "name = 'aifb'\n",
    "data = kg.load(name, torch=True, final=True)\n",
    "data = prunee(data, 2)\n",
    "model = torch.load(f'chk/{name}_chk/models/model_{name}_prune_True')\n",
    "node_idx = 5757\n",
    "init = 'relative_frequency'\n",
    "'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no/masked_adj'\n",
    "#'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no'\n",
    "exp = f'init_{init}_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no'\n",
    "v = torch.load(f'chk/{name}_chk/exp/{exp}/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/{name}_chk/exp/{exp}/masked_adj/masked_hor{node_idx}')\n",
    "masked_ver = v\n",
    "masked_hor = h\n",
    "h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 10)\n",
    "res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8069, 0.0444, 0.1456, 0.0031], grad_fn=<SoftmaxBackward0>)\n",
      "69\n",
      "tensor(75)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while res_threshold.argmax() != 0:\n",
    "    h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 1+i)\n",
    "    i+=1\n",
    "    res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])\n",
    "print(res_threshold)\n",
    "print(1+i)\n",
    "print(v_threshold.coalesce().values().count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0094, 0.0133, 0.9756, 0.0017], grad_fn=<SoftmaxBackward0>)\n",
      "1\n",
      "tensor(79) tensor(87)\n",
      "tensor([0.2189, 0.2325, 0.4891, 0.0596], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while res_threshold.argmax() != 2:\n",
    "    h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 1+i)\n",
    "    i+=1\n",
    "    res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])\n",
    "    if i== masked_hor.shape[0]:\n",
    "        break\n",
    "\n",
    "\n",
    "print(res_threshold)\n",
    "print(1+i)\n",
    "print(v_threshold.coalesce().values().count_nonzero(),masked_ver.coalesce().values().count_nonzero() )\n",
    "res = nn.Softmax(dim=0)(model.forward2(convert_binary(masked_hor,0.5), convert_binary(masked_ver,0.5))[node_idx, :])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(res_full, res_expl,res1_m,label,masked_ver, config):\n",
    "    ''' res_expl: res_binary , res_threshold'''\n",
    "    fidelity_minus = float(1 - (res_full[int(label)] - res_expl[int(label)]))\n",
    "    fidelity_plus = float((res_full[int(label)] - res1_m[int(label)]))\n",
    "    print(fidelity_minus, fidelity_plus)\n",
    "    explanation_lenght = len(masked_ver.coalesce().values()[masked_ver.coalesce().values()>config['threshold'] ])\n",
    "    sparsity = float(1 - explanation_lenght/len(masked_ver.coalesce().values()))\n",
    "\n",
    "    if sparsity == 1:\n",
    "        sparsity_loss = 0\n",
    "    if sparsity == 0:\n",
    "        sparsity_loss = - 1\n",
    "    else:\n",
    "        sparsity_loss = sparsity\n",
    "    score = fidelity_minus + fidelity_plus + sparsity_loss\n",
    "    return fidelity_minus, fidelity_plus, sparsity, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3945, 0.6055], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_ver = v\n",
    "masked_hor = h\n",
    "h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 59)\n",
    "res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])\n",
    "res_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sparse Tensor:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [1, 0, 1]]),\n",
      "       values=tensor([2, 3, 4]),\n",
      "       size=(10, 2), nnz=3, layout=torch.sparse_coo)\n",
      "Sparse Tensor with All Values Set to 0:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [1, 0, 1]]),\n",
      "       values=tensor([0, 0, 0]),\n",
      "       size=(10, 2), nnz=3, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sparse tensor with non-zero values and indices\n",
    "indices = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "values = torch.tensor([2, 3, 4])\n",
    "size = (10, 2)\n",
    "sparse_tensor = torch.sparse.FloatTensor(indices, values, size)\n",
    "\n",
    "print(\"Original Sparse Tensor:\")\n",
    "print(sparse_tensor)\n",
    "\n",
    "# Set all values to zero\n",
    "sparse_tensor._values().zero_()\n",
    "\n",
    "print(\"Sparse Tensor with All Values Set to 0:\")\n",
    "print(sparse_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2276s).\n",
      "29043\n",
      "26666\n",
      "ypred explain tensor([0.4507, 0.1969, 0.2936, 0.0587], grad_fn=<SoftmaxBackward0>)\n",
      "v binary: tensor(indices=tensor([[ 23451,  23451,  23451,  ..., 329925, 329926, 329927],\n",
      "                       [  5678,   5743,   5746,  ...,   5230,   5230,   5230]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
      "       size=(753935, 8285), nnz=1311, layout=torch.sparse_coo) tensor(119)\n",
      "ypred explain binary tensor([0.3810, 0.2180, 0.3542, 0.0468], grad_fn=<SoftmaxBackward0>)\n",
      "ypred true tensor([0])\n",
      "ypred full tensor([9.8647e-01, 5.4700e-04, 1.2982e-02, 1.1929e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 27, 10: 1, 15: 1, 18: 35, 21: 21, 27: 1, 30: 30, 36: 3, 0: 101})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'aifb'\n",
    "\n",
    "data = kg.load(name, torch=True) \n",
    "print(data.triples.shape[0])\n",
    "node_idx = 5678\n",
    "\n",
    "# else:\n",
    "#     data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "print(data.triples.shape[0])\n",
    "data.triples = torch.Tensor(data.triples).to(int)#data.triples.clone().detach()\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)#data.withheld.clone().detach()\n",
    "data.training = torch.Tensor(data.training).to(int)#data.training.clone().detach()\n",
    "#\n",
    "get_relations(data)\n",
    "d_classes(data)\n",
    "dict_classes = {key.item(): data.withheld[:, 0][data.withheld[:, 1] == key].tolist() for key in torch.unique(data.withheld[:, 1])}\n",
    "if name != 'aifb':\n",
    "    node_idx = dict_classes[0][0]\n",
    "\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "# v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "# h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "model = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/model_{name}_prune_True')\n",
    "\n",
    "# h = select_entity(h, 5230)\n",
    "# v = select_entity(v, 5230)\n",
    "\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "# v = torch.sparse_coo_tensor(v.coalesce().indices(), torch.sigmoid(v.coalesce().values()), v.size(), requires_grad=True)\n",
    "# h = torch.sparse_coo_tensor(h.coalesce().indices(), torch.sigmoid(h.coalesce().values()), h.size(), requires_grad=True)\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)\n",
    "# print(v.coalesce().values()[v.coalesce().values()>0.5])\n",
    "# print(h.coalesce().values())\n",
    "\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "print('v binary:',v_bin, torch.count_nonzero(v_bin.coalesce().values()))\n",
    "res = nn.Softmax(dim=0)(model.forward2(h_bin,v_bin)[node_idx, :])\n",
    "print('ypred explain binary', res)\n",
    "\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "v,h = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(v,h,data, node_idx)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5678\n",
    "init = 'normal'\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important relations {'author': 7, 'homepage': 1, 'isWorkedOnBy': 5, 'member': 2, 'publication': 4, 'type': 100}\n",
      "tensor([0.2483, 0.2657, 0.2633, 0.2227], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def random_explanation_baseline(sparse_tensor):\n",
    "    ''' Create a random explanation baseline for a given sparse tensor'''\n",
    "    # Retrieve the indices of non-zero elements\n",
    "    # explanation_lenght = len(sparse_tensor.coalesce().values()[sparse_tensor.coalesce().values()>config['threshold'] ])\n",
    "    explanation_lenght = len(sparse_tensor.coalesce().values()[sparse_tensor.coalesce().values()> 0.5 ])\n",
    "    indices = sparse_tensor._indices()\n",
    "\n",
    "    # Get the total number of non-zero elements\n",
    "    num_nonzero = indices.size(1)\n",
    "\n",
    "    # Specify the number of random indices you want to select\n",
    "    n = explanation_lenght\n",
    "\n",
    "    # Generate 'n' random indices within the range of non-zero indices\n",
    "    random_indices = torch.randperm(num_nonzero)[:n]\n",
    "\n",
    "    # Create a new sparse tensor with the same shape as the original tensor but with all values set to 0\n",
    "    new_sparse_tensor = torch.sparse.FloatTensor(indices, torch.zeros(num_nonzero), size=sparse_tensor.size())\n",
    "\n",
    "    # Assign 1 to the randomly selected indices in the new sparse tensor\n",
    "    new_sparse_tensor._values()[random_indices] = 1\n",
    "\n",
    "    # Print the new sparse tensor\n",
    "    return new_sparse_tensor\n",
    "\n",
    "h_random, v_random = random_explanation_baseline(h), random_explanation_baseline(v)\n",
    "counter = important_relation(h_random, v_random, data,node_idx, 0.5)\n",
    "print('Important relations', counter)\n",
    "res_random = nn.Softmax(dim=0)(model.forward2(h_random, v_random)[node_idx, :])\n",
    "print(res_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.3375s).\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('aifb', torch=True, final=False)\n",
    "data = prunee(data, 2)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "d = d_classes(data)\n",
    "node_idx = d[list(d.keys())[0]][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pv is empty\n"
     ]
    }
   ],
   "source": [
    "#but I want to get the most frequent relations for a given node (2 hops)\n",
    "\n",
    "def most_frequent_relations(data, node_idx, n_hops):\n",
    "    ''' Most frequent relations for a given node (2 hops)'''\n",
    "    hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "    edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "\n",
    "    sub_edges_h, neighbors_h, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "    sub_edges_v, neighbors_v, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "    sub_triples = match_to_triples(sub_edges_tensor_v, sub_edges_tensor_h,data, sparse=False)\n",
    "    sub_h, sub_v = hor_ver_graph(sub_triples, data.num_entities, data.num_relations)\n",
    "    m = match_to_triples(sub_v, sub_h,data, node_idx)\n",
    "    freq = Counter(m[:,1].tolist())\n",
    "    sorted_freq = {data.i2r[k]: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True) if k!=0}\n",
    "\n",
    "    most_freq_rel = list(sorted_freq.keys())[0]\n",
    "    id_most_freq_rel = data.r2i[most_freq_rel]\n",
    "    return most_freq_rel\n",
    "most_freq_rel = most_frequent_relations(data, node_idx, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent relation http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n"
     ]
    }
   ],
   "source": [
    "print('most frequent relation', most_freq_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "23643",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     degree_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(degree)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m degree_mean\n\u001b[0;32m---> 10\u001b[0m degree_distribution(data)\n",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m, in \u001b[0;36mdegree_distribution\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m degree \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data\u001b[39m.\u001b[39mnum_entities):\n\u001b[0;32m----> 5\u001b[0m     _,n,_ \u001b[39m=\u001b[39m find_n_hop_neighbors(edge_index, \u001b[39m0\u001b[39;49m, i)\n\u001b[1;32m      6\u001b[0m     degree\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(n))\n\u001b[1;32m      7\u001b[0m degree_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(degree)\n",
      "File \u001b[0;32m~/Documents/GitHub/RGCN-Explainer/RGCN_stuff/src/rgcn_explainer_utils.py:93\u001b[0m, in \u001b[0;36mfind_n_hop_neighbors\u001b[0;34m(edge_index, n, node)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m edges:\n\u001b[1;32m     92\u001b[0m     src, dst \u001b[39m=\u001b[39m edge\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mif\u001b[39;00m src \u001b[39min\u001b[39;00m neighborhoods[node] \u001b[39mand\u001b[39;00m dst \u001b[39min\u001b[39;00m neighborhoods[node] \u001b[39mor\u001b[39;00m src \u001b[39m==\u001b[39m node \u001b[39mor\u001b[39;00m dst \u001b[39m==\u001b[39m node:\n\u001b[1;32m     94\u001b[0m         sub_edges\u001b[39m.\u001b[39mappend(edge)\n\u001b[1;32m     96\u001b[0m sub_edges_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([sub_edges[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sub_edges))])\u001b[39m.\u001b[39mt()        \n",
      "\u001b[0;31mKeyError\u001b[0m: 23643"
     ]
    }
   ],
   "source": [
    "def degree_distribution(data):\n",
    "    edge_index = edge_index_oneadj(data.triples)\n",
    "    degree = []\n",
    "    for i in range(data.num_entities):\n",
    "        _,n,_ = find_n_hop_neighbors(edge_index, 0, i)\n",
    "        degree.append(len(n))\n",
    "    degree_mean = np.mean(degree)\n",
    "    return degree_mean\n",
    "\n",
    "degree_distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = []\n",
    "for i in data.triples:\n",
    "    if i[0] not in counter:\n",
    "        counter.append(i[0])\n",
    "    if i[2] not in counter:\n",
    "        counter.append(i[2])\n",
    "\n",
    "len(set(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_threshold(sparse_tensor):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == 10:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def convert_back(sparse_tensor, data):\n",
    "    sparse_tensor = torch.sparse_coo_tensor(\n",
    "        sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    )\n",
    "    return sparse_tensor\n",
    "\n",
    "t =     find_threshold(v)\n",
    "v, h = convert_back(v, data), convert_back(h, data)\n",
    "print(sub(v,t),t)\n",
    "v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "print(v.coalesce().values().count_nonzero())\n",
    "v_sub = sub(v,t)\n",
    "if node_idx in v_sub.coalesce().indices():\n",
    "    print('node_idx in v')\n",
    "else:\n",
    "    print('node_idx not in v')\n",
    "\n",
    "#print(t, sub(v,t))\n",
    "\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "\n",
    "masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "counter = dict(Counter(m[:,1].tolist()))\n",
    "counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "print('Important relations', counter)\n",
    "\n",
    "def important_relation(v,h,data):\n",
    "    masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "    m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "    counter = dict(Counter(m[:,1].tolist()))\n",
    "    counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "    print('Important relations', counter)\n",
    "    return counter\n",
    "\n",
    "v,h = threshold_mask(h,v, data, 10)\n",
    "important_relation(v,h,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def is_graph_connected(adjacency_matrix):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    visited = torch.zeros(n, dtype=torch.bool)\n",
    "    stack = [0]  # Start traversal from node 0\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        visited[node] = True\n",
    "\n",
    "        neighbor_indices = adjacency_matrix.coalesce().indices()\n",
    "        neighbor_values = adjacency_matrix.coalesce().values()\n",
    "\n",
    "        node_neighbors = neighbor_indices[0, neighbor_indices[1] == node]\n",
    "        for neighbor in node_neighbors:\n",
    "            if not visited[neighbor]:\n",
    "                stack.append(neighbor)\n",
    "                print(stack)\n",
    "\n",
    "    return visited.all()\n",
    "\n",
    "\n",
    "def remove_disconnected_edges(adjacency_matrix):\n",
    "    if not is_graph_connected(adjacency_matrix):\n",
    "        connected_indices = []\n",
    "        connected_values = []\n",
    "\n",
    "        for node in range(adjacency_matrix.size(0)):\n",
    "            row = adjacency_matrix[node]\n",
    "            node_neighbors = row.coalesce().indices()\n",
    "            node_values = row.coalesce().values()\n",
    "\n",
    "            connected_indices.extend([(node, neighbor) for neighbor in node_neighbors])\n",
    "            connected_values.extend(node_values)\n",
    "\n",
    "        connected_indices = torch.tensor(connected_indices).t()\n",
    "        connected_values = torch.tensor(connected_values)\n",
    "        connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "            connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "        )\n",
    "\n",
    "        return connected_adjacency_matrix\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "is_graph_connected(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "node_idx = 5757\n",
    "v = torch.load(f'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "def select_connected_subgraph(adjacency_matrix, given_node,data):\n",
    "    adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        adjacency_matrix.coalesce().indices()%data.num_entities, adjacency_matrix.coalesce().values(), size=adjacency_matrix.size()\n",
    "    )\n",
    "    sub_adj = sub(adjacency_matrix, 0.5)\n",
    "    print(adjacency_matrix)\n",
    "    num_nodes = sub_adj.size(0)\n",
    "    visited = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    connected_nodes = set()\n",
    "    stack = []\n",
    "\n",
    "    # Starting with the given node\n",
    "    stack.append(given_node)\n",
    "    connected_nodes.add(given_node)\n",
    "    visited[given_node] = True\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        node = stack.pop()\n",
    "        neighbors = sub_adj[node].coalesce().indices()\n",
    "        for i in range(neighbors.size(1)):\n",
    "            neighbor = neighbors[:, i]\n",
    "            if not visited[neighbor[0]]:\n",
    "                stack.append(neighbor[0])\n",
    "                connected_nodes.add(neighbor[0])\n",
    "                visited[neighbor[0]] = True\n",
    "\n",
    "    # Select the indices of the connected nodes\n",
    "    connected_indices = []\n",
    "    for node in connected_nodes:\n",
    "        connected_indices.append([node, node])\n",
    "\n",
    "    # Create the connected adjacency matrix\n",
    "    connected_indices = torch.tensor(connected_indices, dtype=torch.long).t()\n",
    "    #connected_values = adjacency_matrix._values()[connected_indices[0]]\n",
    "    connected_values = torch.ones(connected_indices.size(1))\n",
    "\n",
    "    #torch.ones(connected_indices.size(1))\n",
    "    disconnected_indices = get_non_selected_indices(adjacency_matrix, connected_indices)\n",
    "    disconnected_values = torch.zeros(disconnected_indices.size(1))\n",
    "    connected_indices = torch.cat([connected_indices, disconnected_indices], dim=1)\n",
    "    connected_values = torch.cat([connected_values, disconnected_values])\n",
    "    connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "    )\n",
    "\n",
    "    return connected_adjacency_matrix\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# v, h = sub(v, 0.5), sub(h,0.5)\n",
    "v = select_connected_subgraph(v, node_idx,data)\n",
    "h = select_connected_subgraph(h, node_idx,data)\n",
    "print(v.coalesce().values().count_nonzero(), h.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_non_selected_indices(sparse_tensor, selected_indices):\n",
    "    original_indices = sparse_tensor.coalesce().indices()\n",
    "    selected_set = set(map(tuple, selected_indices.t().tolist()))\n",
    "\n",
    "    non_selected_indices = []\n",
    "    for index in original_indices.t().tolist():\n",
    "        if tuple(index) not in selected_set:\n",
    "            non_selected_indices.append(index)\n",
    "\n",
    "    return torch.tensor(non_selected_indices).t()\n",
    "\n",
    "# Example usage\n",
    "sparse_tensor = torch.sparse_coo_tensor(torch.tensor([[0, 0, 1, 1], [0, 1, 0, 2]]), torch.tensor([2, 3, 4, 5]), size=(2, 3))\n",
    "selected_indices = torch.tensor([[0, 1], [1, 2]])  # Example selected indices\n",
    "\n",
    "non_selected_indices = get_non_selected_indices(sparse_tensor, selected_indices)\n",
    "print(non_selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "v, h = select_on_relation_sparse(v,data, 39), select_on_relation_sparse(h,data, 39)\n",
    "#print(v_.coalesce().values().count_nonzero())\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "\n",
    "print(v_bin.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_bin,v_bin)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse predictions \n",
    "v_inv, h_inv = inverse_tensor(v), inverse_tensor(h)\n",
    "print(v_inv.coalesce().values().count_nonzero())\n",
    "\n",
    "out = model.forward2(h_inv,v_inv)\n",
    "\n",
    "res1_m = nn.Softmax(dim=0)(out[node_idx])\n",
    "res - res1_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_tensor(sparse_tensor):\n",
    "    \"\"\" Convert 0 to 1 and viceversa in sparse tensor\n",
    "    The aim is computing the Fidelity- score\"\"\"\n",
    "    sparse_tensor = convert_binary(sparse_tensor, 0.5)\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices=sparse_tensor._indices(), \n",
    "                                        values=1 - sparse_tensor._values(), \n",
    "                                        size=sparse_tensor.size())\n",
    "    return sparse_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data = prunee(data, 2)\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "object_type(v,h,data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#I want to get the indices of the triples with type relation \n",
    "output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, 39)\n",
    "output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, 39)\n",
    "objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "list = []\n",
    "for i in objects_types:\n",
    "    list.append(data.i2e[i[2]][0].split('#')[1])\n",
    "result = Counter(list)\n",
    "print(result)\n",
    "#probably node person is the most frequent - what about I delete all the triples where Person is the object?????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_entity(sparse_tensor,class_id):\n",
    "    ''' Select the subset of the tensor based on the id of the class to be zeroed out'''\n",
    "    value_indices = torch.where(sparse_tensor.coalesce().indices() == class_id)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices[1]] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "\n",
    "    return masked_sparse_tensor\n",
    "select_entity(h, 5230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation,value =1):\n",
    "    \"\"\" Selects the values of a sparse tensor based on the relation\"\"\"\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = value\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in data.triples:\n",
    "    if i[0] == 5757:\n",
    "        list.append(i[2])\n",
    "    if i[2] == 5757:\n",
    "        list.append(i[0])\n",
    "\n",
    "count = []  \n",
    "for i in data.triples: \n",
    "    for j in list:\n",
    "        if i[0] == j or i[2] == j:\n",
    "            count.append[]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = d_classes(data)\n",
    "count = 0\n",
    "dict_rel_all_classes = {}\n",
    "dict_rel = {}\n",
    "for j in range(len(classes)):\n",
    "    dict_rel = {}\n",
    "    for node_idx in classes[j]:\n",
    "        for i in data.triples:\n",
    "            if i[0] == node_idx or i[2] == node_idx:\n",
    "                count += 1\n",
    "                if data.i2r[int(i[1])] not in dict_rel.keys():\n",
    "                    dict_rel[data.i2r[int(i[1])]] = 1\n",
    "                else:\n",
    "                    dict_rel[data.i2r[int(i[1])]] += 1\n",
    "    dict_rel_all_classes[j] = dict_rel\n",
    "\n",
    "count\n",
    "dict_rel_all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_0 = select_on_relation_sparse(v_bin,data, 30)\n",
    "h_0 = select_on_relation_sparse(h_bin,data, 30)\n",
    "\n",
    "print(v_0.coalesce().values().count_nonzero(),h_0.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_0,v_0)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_on_relation_sparse(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 1\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "#loop over keys of counter\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    # v_ = select_on_relation_sparse(v,data, key)\n",
    "    # h_ = select_on_relation_sparse(h,data, key)\n",
    "    v_ = select_one_relation(v,data, key)\n",
    "    h_ = select_one_relation(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        pass\n",
    "        #print(f'wrong prediction without {data.i2r[key]}')\n",
    "    else:\n",
    "        print(f'correct only with {data.i2r[key]}')\n",
    "        print(f'ypred only with {data.i2r[key]}, {key}', res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a baseline: no use RGCNExplainer - just rule out relations based on prediction of the model\n",
    "\n",
    "#node:\n",
    "node_idx = 5678\n",
    "\n",
    "#label for that node\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "\n",
    "#edge index\n",
    "edge_index = edge_index_oneadj(data.triples)\n",
    "\n",
    "#number of hops\n",
    "n_hops = 2\n",
    "\n",
    "#augment dataset with self loops and inverse relations\n",
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "\n",
    "#get the edge index at 2 hops per node\n",
    "_,_,index_h = find_n_hop_neighbors(hor_graph.coalesce().indices(), n_hops, node_idx)\n",
    "_,_,index_v = find_n_hop_neighbors(ver_graph.coalesce().indices(), n_hops, node_idx)\n",
    "\n",
    "h = torch.sparse_coo_tensor(index_h, torch.ones(index_h.shape[1]), hor_graph.size() )\n",
    "v = torch.sparse_coo_tensor(index_v, torch.ones(index_v.shape[1]), ver_graph.size() )\n",
    "\n",
    "#match to triple\n",
    "m = match_to_triples(v,h, data)\n",
    "\n",
    "#counter of relations in the 2 hops subgraph\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "#forward pass of the model\n",
    "out = model.forward2(h,v)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print(f'ypred explain all subgraph: {torch.argmax(res)} with prediction probability: {res}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(m[:,1].tolist())\n",
    "\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 9)\n",
    "h.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5757\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "m = match_to_triples(ver_graph,hor_graph,data, node_idx)\n",
    "v, h = ver_graph, hor_graph\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'for node {node_idx}, wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_remove = []\n",
    "for i in range(data.num_relations):\n",
    "    if 'genre' in data.i2r[i]:\n",
    "        print(f'{i}: {data.i2r[i]}')\n",
    "        numbers_to_remove.append(i)\n",
    "numbers_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data.triples:\n",
    "#     for j in numbers_to_remove:\n",
    "#         if i[1] == j:\n",
    "#             print(i)\n",
    "for i in data.triples:\n",
    "    if i[0] ==9662:\n",
    "        print(data.i2e[i[0]], data.i2r[i[1]], data.i2e[i[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_most_genre'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.i2e[3599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld[data.withheld[:,0]==10241,1]\n",
    "data.withheld[torch.where(data.withheld[:, 0] == torch.tensor([10112])),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.entities = np.append(data.triples[:,0].detach().numpy(),(data.triples[:,2].detach().numpy()))\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "    \n",
    "relations = ['label', 'node_idx','number_neighbors', 'prediction_explain', 'prediction_full', 'prediction_explain_binary'] + relations\n",
    "df = pd.DataFrame(columns=relations)\n",
    "d = d_classes(data)\n",
    "\n",
    "#count how many nodes per class\n",
    "count = {}\n",
    "for i in range(len(d)):\n",
    "    count[i] = len(d[i])\n",
    "count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the node of the most important relations - the relations with the highest weights\n",
    "\n",
    "tensor_list = (list(v.coalesce().indices()[1][v.coalesce().values()>0.5]) + list(h.coalesce().indices()[0][h.coalesce().values()>0.5]))\n",
    "float_list = [tensor.item() for tensor in tensor_list]\n",
    "len(set(float_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "others = []\n",
    "for i in data.triples:\n",
    "\n",
    "    if i[0] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[2])\n",
    "    if i[2] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[0])\n",
    "\n",
    "count\n",
    "others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "l = []\n",
    "a = []\n",
    "for i in data.triples:\n",
    "    for n in others:\n",
    "        if i[0] == int(n) or i[2] == int(n):\n",
    "            count += 1\n",
    "            l.append(n)\n",
    "            a.append(i)\n",
    "            #print(i)\n",
    "            break\n",
    "res = set(l)\n",
    "resa = set(a)\n",
    "print(len(resa))            \n",
    "print(len(res))\n",
    "count\n",
    "#others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/masked_adj/masked_ver{node_idx}_new')\n",
    "res, weights = visualize(node_idx, 2, data, v, 0, name, result_weights=False, low_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj(data.triples, data.num_entities, data.num_relations, cuda=False, vertical=True)\n",
    "hor_ver_graph(data.triples, data.num_entities, data.num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_h, edge_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "_,_,sub_edges_tensor_h  = find_n_hop_neighbors(edge_h,2, 5699)\n",
    "_,_,sub_edges_tensor_v  = find_n_hop_neighbors(edge_v,2, 5699)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_edges_tensor_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_edges_tensor\n",
    "indexes = sub_edges_tensor%data.num_entities\n",
    "indexes\n",
    "r = sub_edges_tensor//data.num_entities\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,p = torch.div(sub_edges_tensor, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "s,o = sub_edges_tensor%data.num_entities\n",
    "result = torch.stack([s,p,o], dim=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try initialization where the first hop neighborhood gets initialized with 1s and the rest with different methods??\n",
    "def construct_edge_mask(self, num_nodes,sparse_tensor,data, const_val=1.0, relation_id = 2):\n",
    "    \"\"\"\n",
    "    Construct edge mask\n",
    "    \"\"\"\n",
    "    init_strategy = self.init_strategy\n",
    "    # if num_nodes > 1000:\n",
    "    #     init(strategy=\"const\", const_val=0.1)\n",
    "    data = self.data\n",
    "    num_entities = data.num_entities\n",
    "    torch.manual_seed(42)\n",
    "    mask = nn.Parameter(torch.FloatTensor(num_nodes))\n",
    "\n",
    "    if init_strategy == \"normal\":\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "    elif init_strategy == \"const\":\n",
    "        nn.init.constant_(mask, const_val) \n",
    "    elif init_strategy == \"zero_out\":\n",
    "        '''initialize the mask with the zero out strategy: we zero out edges belonging to specific relations'''\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "        output_indices, output_values, value_indices=select_relation(sparse_tensor,relation_id)\n",
    "        _,_,value_indices1=select_relation(sparse_tensor,33)\n",
    "        print(value_indices, value_indices1)\n",
    "        value_indices = torch.cat((value_indices, value_indices1), 0)\n",
    "        mask.data[[value_indices]] = 0\n",
    "    \n",
    "\n",
    "    elif init_strategy == \"overall_frequency\":\n",
    "        '''Initialize the mask with the overall frequency of the relations'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        overall_rel_frequency = dict(Counter(data.triples[:,1].tolist()))#.most_common()\n",
    "\n",
    "        overall_rel_frequency_  = {key: round(value/len(data.triples[:,1].tolist()),5) for key, value in overall_rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = overall_rel_frequency_[i]\n",
    "    \n",
    "    elif init_strategy == \"relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "    elif init_strategy == \"inverse_relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: 1 - round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "\n",
    "    elif init_strategy == \"domain_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = dict_domain[i]\n",
    "\n",
    "    elif init_strategy == \"range_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "                _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "                mask.data[[value_indices]] = dict_range[i]\n",
    "    elif init_strategy == \"rdf\":\n",
    "        rdf = [i for i in range(data.num_relations) if 'rdf' in data.i2r[i]]\n",
    "        for i in rdf:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    elif init_strategy == \"owl\":\n",
    "        owl = [i for i in range(data.num_relations) if 'owl' in data.i2r[i]]\n",
    "        for i in owl:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    print(f'mask initialized with {init_strategy} strategy: {mask}')   \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 3).to_sparse().requires_grad_(True)\n",
    "print(a)\n",
    "#a.values = torch.ones_like(a.values())\n",
    "values = torch.ones(a._nnz())\n",
    "#len(a.values)\n",
    "a.indices()\n",
    "sparse_tensor = torch.sparse_coo_tensor(a.indices(), torch.ones(a._nnz()), a.size(), requires_grad=True)\n",
    "sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > 0.7]\n",
    "nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "nonzero_values = v.coalesce().values()[v.coalesce().values() > 0.7]\n",
    "sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "sel_masked_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() < 0.5]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() < 0.5]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "sub(v, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result\n",
    "\n",
    "m = match_to_triples(v,h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v, data, sparse=True):\n",
    "    if sparse:\n",
    "        # p,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        # s,o = v.coalesce().indices()%data.num_entities\n",
    "        # result = torch.stack([s,p,o], dim=1)\n",
    "        matching = []\n",
    "        indexes = v.coalesce().indices()%data.num_entities\n",
    "        for j in range(indexes.size()[1]):\n",
    "            for triple in data.triples:\n",
    "                if triple[0] == indexes[0][j] and triple[2] == indexes[1][j]:\n",
    "                    matching.append(triple)\n",
    "        result = torch.stack(matching)\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        matching = []\n",
    "        for i,i2 in zip(v[:,0],v[:,1]):\n",
    "            for j,j1,j2, index in zip(data[:,0],data[:,1],  data[:,2], range(len(data[:,0]))):\n",
    "                if i == j and i2 == j2:\n",
    "                    matching.append(data[index])\n",
    "                    \n",
    "\n",
    "        result = torch.stack(matching)\n",
    "    \n",
    "    return result\n",
    "m = match_to_triples(h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "\n",
    "def visualize(node_idx, n_hop, data, masked_ver,masked_hor, threshold,name, result_weights=True, low_threshold=False,experiment_name=None ):\n",
    "    \"\"\" \n",
    "    Visualize important nodes for node idx prediction\n",
    "    \"\"\"\n",
    "    dict_index = dict_index_classes(data,masked_ver)\n",
    "    mask = torch.vstack((masked_ver, masked_hor.t()))\n",
    "    mask = sub(mask, threshold)\n",
    "    print(mask)\n",
    "    #select only nodes with a certain threshold\n",
    "    sel_masked_ver = sub(masked_ver, threshold)\n",
    "    sel_masked_hor = sub(masked_hor, threshold)\n",
    "    if len(sel_masked_ver)==0:\n",
    "        sel_masked_ver=sub_sparse_tensor(masked_ver, 0,data, low_threshold)\n",
    "    #mask = torch.vstack((sel_masked_ver, sel_masked_hor.t()))\n",
    "    print('sel masked ver',mask)\n",
    "    indices_nodes = mask.coalesce().indices().detach().numpy()\n",
    "    new_index = np.transpose(np.stack((indices_nodes[0], indices_nodes[1]))) #original edge indexes\n",
    "\n",
    "    \n",
    "    \n",
    "    G = nx.Graph()\n",
    "    if result_weights:\n",
    "        values = mask.coalesce().values().detach().numpy()\n",
    "        for s,p,o in zip(indices_nodes[0],values , indices_nodes[1]):\n",
    "            G.add_edge(int(s), int(o), weight=np.round(p, 2))\n",
    "\n",
    "    else:\n",
    "\n",
    "        triples_matched = match_to_triples(sel_masked_ver,sel_masked_hor, data)\n",
    "        l = []\n",
    "        for i in triples_matched[:,1]:\n",
    "            l.append(data.i2rel[int(i)][0])\n",
    "        triples_matched = find_repeating_sublists(triples_matched.numpy())\n",
    "        print(triples_matched)\n",
    "        for s,p,o in triples_matched:\n",
    "            G.add_edge(int(s), int(o), weight=p)\n",
    "\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    weights = [[item] if not isinstance(item, list) else item for item in weights]\n",
    "\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    ordered_dict = {}\n",
    "    for item in list(G.nodes):\n",
    "        if item in ordered_dict:\n",
    "            ordered_dict[item].append(dict_index[item])\n",
    "        # else:\n",
    "        #     ordered_dict[item] =  dict_index[item]\n",
    "\n",
    "    dict_index = ordered_dict\n",
    "\n",
    "    labeldict = {}\n",
    "    for node in G.nodes:\n",
    "        labeldict[int(node)] = int(node)  \n",
    "\n",
    "\n",
    "    dict = {}\n",
    "    for k,v in dict_index.items():\n",
    "        for k1,v1 in data.entities_classes.items():\n",
    "            if v==k1: \n",
    "\n",
    "                dict[k] = v1\n",
    "            else:\n",
    "                if k not in dict:\n",
    "                    dict[k] = 0\n",
    "                \n",
    "\n",
    "    color_list = list(dict.values())\n",
    "    color_list = list(encode_dict(dict_index).values())\n",
    "\n",
    "\n",
    "    col_weights = [weights[i][0] for i in range(len(weights))]\n",
    "    if result_weights:\n",
    "        \n",
    "        nx.draw(G, pos,labels = labeldict,  edgelist=edges, edge_color=col_weights, node_color =  color_list, cmap=\"Set2\",edge_cmap=plt.cm.Reds,font_size=8)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=nx.get_edge_attributes(G,'weight'),font_size=8,font_color='red')\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        sm.set_array(weights)\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.set_title('Weight')\n",
    "        plt.title(\"Node {}'s {}-hop neighborhood important nodes\".format(node_idx, n_hop))\n",
    "    else:\n",
    "        rel = nx.get_edge_attributes(G,'weight')\n",
    "        rel = {k: [data.i2rel[i][0] for i in v] for k,v in rel.items()}\n",
    "        col_weights = [sum(weights[i], 3) if len(weights[i]) > 1 else weights[i][0] for i in range(len(weights))]\n",
    "        nx.draw(G, pos,labels = labeldict, edge_color=col_weights,edgelist=edges,node_color =  color_list, cmap=\"Set2\",font_size=7, arrows = True)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=rel,font_size=8,font_color='red')\n",
    "        \n",
    "        res = Counter(unnest_list(rel.values()))\n",
    "        print(res)\n",
    "    if result_weights:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}â„graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}â„graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}â„graphs/Explanation_{node_idx}_weights.png')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}â„graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}â„graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}â„graphs/Explanation_{node_idx}_relations.png')    \n",
    "        #plt.show()\n",
    "        return res, weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.vstack((v,h.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(node_idx, 2, data, v,h, 0.5,name, result_weights=False, low_threshold=False,experiment_name=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "\n",
    "        _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "\n",
    "        pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "n_hops = 0\n",
    "node_idx = 5678\n",
    "#hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "sub_edges, neighbors, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "\n",
    "sub_edges, neighbors, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "print(len(list(neighbors)))\n",
    "print('shape sub',sub_edges_tensor_h.shape, sub_edges_tensor_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5677\n",
    "count = 0\n",
    "\n",
    "\n",
    "\n",
    "for m in data.triples:\n",
    "    if m[0] == node_idx or m[2] == node_idx:\n",
    "        print(m)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the mask to give priority to the 1st hop relations\n",
    "neighbors_h, neighbors_v = list((1,1)), list((2,3))\n",
    "neighbors = len(set(neighbors_v + neighbors_h))\n",
    "len(neighbors)\n",
    "#set(list((neighbors_h, neighbors_v)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the graph into subgraphs per relation \n",
    "#create dictionary where each key is a relation and each value is a list of the triples with that relation\n",
    "#each value is a tensor with the edge indices of the triples with that relation\n",
    "\n",
    "dict_rel = {}\n",
    "for i in range(data.num_relations):\n",
    "    dict_rel[i] = []\n",
    "for i in range(len(data.triples)):\n",
    "\n",
    "    dict_rel[int(data.triples[i][1])].append(torch.tensor([data.triples[i][0], data.triples[i][2]]))\n",
    "\n",
    "dict_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.3058s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [5678,\n",
       "  5724,\n",
       "  5699,\n",
       "  5688,\n",
       "  5702,\n",
       "  5714,\n",
       "  5708,\n",
       "  5843,\n",
       "  5873,\n",
       "  5697,\n",
       "  5783,\n",
       "  5701,\n",
       "  5845,\n",
       "  5778],\n",
       " 1: [5731, 5905, 5808, 5785],\n",
       " 2: [5757, 5797, 5900, 5677, 5791, 5811, 5831, 5839, 5755, 5844, 5861],\n",
       " 3: [5857, 5752, 5795, 5753, 5798, 5854]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = kg.load('aifb', torch=True, final=False)\n",
    "d_classes(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
