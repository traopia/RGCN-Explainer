{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import src.kgbench as kg\n",
    "import fire, sys\n",
    "import math\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# #\n",
    "#from torch_geometric.utils import to_networkx\n",
    "# import networkx as nx\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from rgcn_model import RGCN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.3363s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/kgbench/load.py:123: UserWarning: The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, the correct evaluation is to combine train and validation for the final evaluation run.Set include_val to True when loading the data.\n",
      "  warnings.warn('The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, '\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('aifb', torch=True, final=True)\n",
    "data = prunee(data, 2)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2276s).\n",
      "29043\n",
      "26666\n",
      "ypred explain tensor([0.4507, 0.1969, 0.2936, 0.0587], grad_fn=<SoftmaxBackward0>)\n",
      "v binary: tensor(indices=tensor([[ 23451,  23451,  23451,  ..., 329925, 329926, 329927],\n",
      "                       [  5678,   5743,   5746,  ...,   5230,   5230,   5230]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
      "       size=(753935, 8285), nnz=1311, layout=torch.sparse_coo) tensor(119)\n",
      "ypred explain binary tensor([0.3810, 0.2180, 0.3542, 0.0468], grad_fn=<SoftmaxBackward0>)\n",
      "ypred true tensor([0])\n",
      "ypred full tensor([9.8647e-01, 5.4700e-04, 1.2982e-02, 1.1929e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 27, 10: 1, 15: 1, 18: 35, 21: 21, 27: 1, 30: 30, 36: 3, 0: 101})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'aifb'\n",
    "\n",
    "data = kg.load(name, torch=True) \n",
    "print(data.triples.shape[0])\n",
    "node_idx = 5678\n",
    "\n",
    "# else:\n",
    "#     data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "print(data.triples.shape[0])\n",
    "data.triples = torch.Tensor(data.triples).to(int)#data.triples.clone().detach()\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)#data.withheld.clone().detach()\n",
    "data.training = torch.Tensor(data.training).to(int)#data.training.clone().detach()\n",
    "#\n",
    "get_relations(data)\n",
    "d_classes(data)\n",
    "dict_classes = {key.item(): data.withheld[:, 0][data.withheld[:, 1] == key].tolist() for key in torch.unique(data.withheld[:, 1])}\n",
    "if name != 'aifb':\n",
    "    node_idx = dict_classes[0][0]\n",
    "\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "# v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "# h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "model = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/model_{name}_prune_True')\n",
    "\n",
    "# h = select_entity(h, 5230)\n",
    "# v = select_entity(v, 5230)\n",
    "\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "# v = torch.sparse_coo_tensor(v.coalesce().indices(), torch.sigmoid(v.coalesce().values()), v.size(), requires_grad=True)\n",
    "# h = torch.sparse_coo_tensor(h.coalesce().indices(), torch.sigmoid(h.coalesce().values()), h.size(), requires_grad=True)\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)\n",
    "# print(v.coalesce().values()[v.coalesce().values()>0.5])\n",
    "# print(h.coalesce().values())\n",
    "\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "print('v binary:',v_bin, torch.count_nonzero(v_bin.coalesce().values()))\n",
    "res = nn.Softmax(dim=0)(model.forward2(h_bin,v_bin)[node_idx, :])\n",
    "print('ypred explain binary', res)\n",
    "\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "v,h = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(v,h,data, node_idx)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5678\n",
    "init = 'normal'\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important relations {'author': 7, 'homepage': 1, 'isWorkedOnBy': 5, 'member': 2, 'publication': 4, 'type': 100}\n",
      "tensor([0.2483, 0.2657, 0.2633, 0.2227], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def random_explanation_baseline(sparse_tensor):\n",
    "    ''' Create a random explanation baseline for a given sparse tensor'''\n",
    "    # Retrieve the indices of non-zero elements\n",
    "    # explanation_lenght = len(sparse_tensor.coalesce().values()[sparse_tensor.coalesce().values()>config['threshold'] ])\n",
    "    explanation_lenght = len(sparse_tensor.coalesce().values()[sparse_tensor.coalesce().values()> 0.5 ])\n",
    "    indices = sparse_tensor._indices()\n",
    "\n",
    "    # Get the total number of non-zero elements\n",
    "    num_nonzero = indices.size(1)\n",
    "\n",
    "    # Specify the number of random indices you want to select\n",
    "    n = explanation_lenght\n",
    "\n",
    "    # Generate 'n' random indices within the range of non-zero indices\n",
    "    random_indices = torch.randperm(num_nonzero)[:n]\n",
    "\n",
    "    # Create a new sparse tensor with the same shape as the original tensor but with all values set to 0\n",
    "    new_sparse_tensor = torch.sparse.FloatTensor(indices, torch.zeros(num_nonzero), size=sparse_tensor.size())\n",
    "\n",
    "    # Assign 1 to the randomly selected indices in the new sparse tensor\n",
    "    new_sparse_tensor._values()[random_indices] = 1\n",
    "\n",
    "    # Print the new sparse tensor\n",
    "    return new_sparse_tensor\n",
    "\n",
    "h_random, v_random = random_explanation_baseline(h), random_explanation_baseline(v)\n",
    "counter = important_relation(h_random, v_random, data,node_idx, 0.5)\n",
    "print('Important relations', counter)\n",
    "res_random = nn.Softmax(dim=0)(model.forward2(h_random, v_random)[node_idx, :])\n",
    "print(res_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'http://swrc.ontoware.org/ontology#publication': 4139, 'http://swrc.ontoware.org/ontology#author': 3962, 'http://www.w3.org/1999/02/22-rdf-syntax-ns#type': 3785, 'http://swrc.ontoware.org/ontology#isAbout': 2475, 'http://swrc.ontoware.org/ontology#publishes': 1217, 'http://swrc.ontoware.org/ontology#year': 1210, 'http://swrc.ontoware.org/ontology#title': 1136, 'http://swrc.ontoware.org/ontology#projectInfo': 952, 'http://swrc.ontoware.org/ontology#hasProject': 952, 'http://swrc.ontoware.org/ontology#month': 746, 'http://swrc.ontoware.org/ontology#booktitle': 721, 'http://swrc.ontoware.org/ontology#isWorkedOnBy': 567, 'http://swrc.ontoware.org/ontology#pages': 514, 'http://swrc.ontoware.org/ontology#abstract': 492, 'http://swrc.ontoware.org/ontology#dealtWithIn': 355, 'http://swrc.ontoware.org/ontology#member': 338, 'http://swrc.ontoware.org/ontology#name': 335, 'http://swrc.ontoware.org/ontology#volume': 298, 'http://swrc.ontoware.org/ontology#series': 282, 'http://swrc.ontoware.org/ontology#fax': 219, 'http://swrc.ontoware.org/ontology#worksAtProject': 200, 'http://swrc.ontoware.org/ontology#address': 194, 'http://swrc.ontoware.org/ontology#editor': 190, 'http://swrc.ontoware.org/ontology#phone': 185, 'http://swrc.ontoware.org/ontology#journal': 155, 'http://swrc.ontoware.org/ontology#number': 143, 'http://www.aifb.uni-karlsruhe.de/WBS/dvr/owltools/merge/type': 129, 'http://swrc.ontoware.org/ontology#homepage': 122, 'http://swrc.ontoware.org/ontology#note': 105, 'http://swrc.ontoware.org/ontology#photo': 89, 'http://swrc.ontoware.org/ontology#carriesOut': 79, 'http://swrc.ontoware.org/ontology#carriedOutBy': 79, 'http://swrc.ontoware.org/ontology#finances': 64, 'http://swrc.ontoware.org/ontology#financedBy': 64, 'http://swrc.ontoware.org/ontology#type': 49, 'http://swrc.ontoware.org/ontology#howpublished': 42, 'http://www.w3.org/2000/01/rdf-schema#subClassOf': 35, 'http://www.w3.org/2002/07/owl#allValuesFrom': 23, 'http://swrc.ontoware.org/ontology#isbn': 15, 'http://swrc.ontoware.org/ontology#chapter': 14, 'http://swrc.ontoware.org/ontology#edition': 11, 'http://swrc.ontoware.org/ontology#head': 5}\n"
     ]
    }
   ],
   "source": [
    "def frequency_relations(data):\n",
    "    freq = Counter(data.triples[:,1].tolist())\n",
    "    sorted_freq = {data.i2r[k]: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return sorted_freq\n",
    "f = frequency_relations(data)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/kgbench/load.py:123: UserWarning: The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, the correct evaluation is to combine train and validation for the final evaluation run.Set include_val to True when loading the data.\n",
      "  warnings.warn('The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.777s).\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('aifb', torch=True, final=True)\n",
    "data = prunee(data, 2)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "d = d_classes(data)\n",
    "node_idx = d[list(d.keys())[0]][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pv is empty\n"
     ]
    }
   ],
   "source": [
    "#but I want to get the most frequent relations for a given node (2 hops)\n",
    "\n",
    "def most_frequent_relations(data, node_idx, n_hops):\n",
    "    ''' Most frequent relations for a given node (2 hops)'''\n",
    "    hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "    edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "\n",
    "    sub_edges_h, neighbors_h, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "    sub_edges_v, neighbors_v, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "    sub_triples = match_to_triples(sub_edges_tensor_v, sub_edges_tensor_h,data, sparse=False)\n",
    "    sub_h, sub_v = hor_ver_graph(sub_triples, data.num_entities, data.num_relations)\n",
    "    m = match_to_triples(sub_v, sub_h,data, node_idx)\n",
    "    freq = Counter(m[:,1].tolist())\n",
    "    sorted_freq = {data.i2r[k]: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True) if k!=0}\n",
    "\n",
    "    most_freq_rel = list(sorted_freq.keys())[0]\n",
    "    id_most_freq_rel = data.r2i[most_freq_rel]\n",
    "    return most_freq_rel\n",
    "most_freq_rel = most_frequent_relations(data, node_idx, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent relation http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n"
     ]
    }
   ],
   "source": [
    "print('most frequent relation', most_freq_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "23643",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     degree_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(degree)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m degree_mean\n\u001b[0;32m---> 10\u001b[0m degree_distribution(data)\n",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m, in \u001b[0;36mdegree_distribution\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m degree \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data\u001b[39m.\u001b[39mnum_entities):\n\u001b[0;32m----> 5\u001b[0m     _,n,_ \u001b[39m=\u001b[39m find_n_hop_neighbors(edge_index, \u001b[39m0\u001b[39;49m, i)\n\u001b[1;32m      6\u001b[0m     degree\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(n))\n\u001b[1;32m      7\u001b[0m degree_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(degree)\n",
      "File \u001b[0;32m~/Documents/GitHub/RGCN-Explainer/RGCN_stuff/src/rgcn_explainer_utils.py:93\u001b[0m, in \u001b[0;36mfind_n_hop_neighbors\u001b[0;34m(edge_index, n, node)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m edges:\n\u001b[1;32m     92\u001b[0m     src, dst \u001b[39m=\u001b[39m edge\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mif\u001b[39;00m src \u001b[39min\u001b[39;00m neighborhoods[node] \u001b[39mand\u001b[39;00m dst \u001b[39min\u001b[39;00m neighborhoods[node] \u001b[39mor\u001b[39;00m src \u001b[39m==\u001b[39m node \u001b[39mor\u001b[39;00m dst \u001b[39m==\u001b[39m node:\n\u001b[1;32m     94\u001b[0m         sub_edges\u001b[39m.\u001b[39mappend(edge)\n\u001b[1;32m     96\u001b[0m sub_edges_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([sub_edges[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sub_edges))])\u001b[39m.\u001b[39mt()        \n",
      "\u001b[0;31mKeyError\u001b[0m: 23643"
     ]
    }
   ],
   "source": [
    "def degree_distribution(data):\n",
    "    edge_index = edge_index_oneadj(data.triples)\n",
    "    degree = []\n",
    "    for i in range(data.num_entities):\n",
    "        _,n,_ = find_n_hop_neighbors(edge_index, 0, i)\n",
    "        degree.append(len(n))\n",
    "    degree_mean = np.mean(degree)\n",
    "    return degree_mean\n",
    "\n",
    "degree_distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(4945),\n",
       " tensor(5230),\n",
       " tensor(4946),\n",
       " tensor(4951),\n",
       " tensor(4973),\n",
       " tensor(4974),\n",
       " tensor(4987),\n",
       " tensor(4988),\n",
       " tensor(4998),\n",
       " tensor(4999),\n",
       " tensor(5005),\n",
       " tensor(5010),\n",
       " tensor(5014),\n",
       " tensor(5016),\n",
       " tensor(5231),\n",
       " tensor(5022),\n",
       " tensor(5034),\n",
       " tensor(5238),\n",
       " tensor(5035),\n",
       " tensor(5200),\n",
       " tensor(5036),\n",
       " tensor(5235),\n",
       " tensor(5042),\n",
       " tensor(5053),\n",
       " tensor(5063),\n",
       " tensor(5078),\n",
       " tensor(5081),\n",
       " tensor(5085),\n",
       " tensor(8176),\n",
       " tensor(5211),\n",
       " tensor(5202),\n",
       " tensor(5203),\n",
       " tensor(5215),\n",
       " tensor(5206),\n",
       " tensor(5216),\n",
       " tensor(5217),\n",
       " tensor(5246),\n",
       " tensor(5219),\n",
       " tensor(5220),\n",
       " tensor(5223),\n",
       " tensor(5228),\n",
       " tensor(5027),\n",
       " tensor(5028),\n",
       " tensor(5029),\n",
       " tensor(5030),\n",
       " tensor(5031),\n",
       " tensor(5032),\n",
       " tensor(5033),\n",
       " tensor(5233),\n",
       " tensor(5240),\n",
       " tensor(5242),\n",
       " tensor(5247),\n",
       " tensor(5349),\n",
       " tensor(5950),\n",
       " tensor(5964),\n",
       " tensor(5970),\n",
       " tensor(5977),\n",
       " tensor(5679),\n",
       " tensor(5732),\n",
       " tensor(5748),\n",
       " tensor(5791),\n",
       " tensor(5855),\n",
       " tensor(5886),\n",
       " tensor(5900),\n",
       " tensor(8281),\n",
       " tensor(5243),\n",
       " tensor(5350),\n",
       " tensor(5921),\n",
       " tensor(5932),\n",
       " tensor(5990),\n",
       " tensor(5843),\n",
       " tensor(5845),\n",
       " tensor(5894),\n",
       " tensor(5906),\n",
       " tensor(8279),\n",
       " tensor(5351),\n",
       " tensor(5915),\n",
       " tensor(5937),\n",
       " tensor(5940),\n",
       " tensor(5942),\n",
       " tensor(5948),\n",
       " tensor(5954),\n",
       " tensor(5960),\n",
       " tensor(5971),\n",
       " tensor(5974),\n",
       " tensor(5983),\n",
       " tensor(5680),\n",
       " tensor(5740),\n",
       " tensor(5760),\n",
       " tensor(5775),\n",
       " tensor(5782),\n",
       " tensor(5811),\n",
       " tensor(5835),\n",
       " tensor(5853),\n",
       " tensor(5861),\n",
       " tensor(5862),\n",
       " tensor(5876),\n",
       " tensor(5878),\n",
       " tensor(5897),\n",
       " tensor(5904),\n",
       " tensor(5913),\n",
       " tensor(8204),\n",
       " tensor(5352),\n",
       " tensor(8205),\n",
       " tensor(5353),\n",
       " tensor(5966),\n",
       " tensor(5772),\n",
       " tensor(5803),\n",
       " tensor(5871),\n",
       " tensor(5872),\n",
       " tensor(8209),\n",
       " tensor(5354),\n",
       " tensor(5985),\n",
       " tensor(5989),\n",
       " tensor(5779),\n",
       " tensor(5789),\n",
       " tensor(8208),\n",
       " tensor(5355),\n",
       " tensor(5986),\n",
       " tensor(5698),\n",
       " tensor(5717),\n",
       " tensor(5759),\n",
       " tensor(5767),\n",
       " tensor(5769),\n",
       " tensor(5814),\n",
       " tensor(5852),\n",
       " tensor(5859),\n",
       " tensor(5865),\n",
       " tensor(5879),\n",
       " tensor(8280),\n",
       " tensor(5356),\n",
       " tensor(5918),\n",
       " tensor(5953),\n",
       " tensor(5982),\n",
       " tensor(5783),\n",
       " tensor(5892),\n",
       " tensor(5910),\n",
       " tensor(8200),\n",
       " tensor(5357),\n",
       " tensor(5939),\n",
       " tensor(5678),\n",
       " tensor(5737),\n",
       " tensor(5743),\n",
       " tensor(5744),\n",
       " tensor(5745),\n",
       " tensor(5746),\n",
       " tensor(5747),\n",
       " tensor(5777),\n",
       " tensor(8219),\n",
       " tensor(5358),\n",
       " tensor(1676),\n",
       " tensor(5359),\n",
       " tensor(5874),\n",
       " tensor(5103),\n",
       " tensor(5360),\n",
       " tensor(5755),\n",
       " tensor(3130),\n",
       " tensor(5361),\n",
       " tensor(5912),\n",
       " tensor(5362),\n",
       " tensor(5944),\n",
       " tensor(5363),\n",
       " tensor(5972),\n",
       " tensor(5973),\n",
       " tensor(1615),\n",
       " tensor(5364),\n",
       " tensor(5773),\n",
       " tensor(5774),\n",
       " tensor(5365),\n",
       " tensor(5366),\n",
       " tensor(5961),\n",
       " tensor(1835),\n",
       " tensor(5367),\n",
       " tensor(5957),\n",
       " tensor(5762),\n",
       " tensor(5908),\n",
       " tensor(4156),\n",
       " tensor(5368),\n",
       " tensor(5761),\n",
       " tensor(5907),\n",
       " tensor(5104),\n",
       " tensor(5369),\n",
       " tensor(5790),\n",
       " tensor(5815),\n",
       " tensor(5860),\n",
       " tensor(5903),\n",
       " tensor(2199),\n",
       " tensor(5370),\n",
       " tensor(5371),\n",
       " tensor(5979),\n",
       " tensor(5800),\n",
       " tensor(5850),\n",
       " tensor(5864),\n",
       " tensor(3435),\n",
       " tensor(5372),\n",
       " tensor(5770),\n",
       " tensor(5809),\n",
       " tensor(5824),\n",
       " tensor(5825),\n",
       " tensor(3479),\n",
       " tensor(5373),\n",
       " tensor(8240),\n",
       " tensor(5374),\n",
       " tensor(5984),\n",
       " tensor(2357),\n",
       " tensor(5375),\n",
       " tensor(2358),\n",
       " tensor(5376),\n",
       " tensor(5115),\n",
       " tensor(5377),\n",
       " tensor(5969),\n",
       " tensor(8213),\n",
       " tensor(5378),\n",
       " tensor(5917),\n",
       " tensor(5754),\n",
       " tensor(5849),\n",
       " tensor(5106),\n",
       " tensor(5379),\n",
       " tensor(8226),\n",
       " tensor(5380),\n",
       " tensor(8225),\n",
       " tensor(5381),\n",
       " tensor(5797),\n",
       " tensor(5126),\n",
       " tensor(5382),\n",
       " tensor(8273),\n",
       " tensor(5383),\n",
       " tensor(5935),\n",
       " tensor(5819),\n",
       " tensor(8218),\n",
       " tensor(5384),\n",
       " tensor(5895),\n",
       " tensor(3038),\n",
       " tensor(5385),\n",
       " tensor(5808),\n",
       " tensor(4797),\n",
       " tensor(5386),\n",
       " tensor(8255),\n",
       " tensor(5387),\n",
       " tensor(5388),\n",
       " tensor(5951),\n",
       " tensor(5752),\n",
       " tensor(5753),\n",
       " tensor(5795),\n",
       " tensor(5854),\n",
       " tensor(5857),\n",
       " tensor(5112),\n",
       " tensor(5389),\n",
       " tensor(5881),\n",
       " tensor(5390),\n",
       " tensor(5391),\n",
       " tensor(5392),\n",
       " tensor(5394),\n",
       " tensor(5396),\n",
       " tensor(5988),\n",
       " tensor(3335),\n",
       " tensor(5397),\n",
       " tensor(5681),\n",
       " tensor(5806),\n",
       " tensor(3364),\n",
       " tensor(5398),\n",
       " tensor(5831),\n",
       " tensor(2470),\n",
       " tensor(5399),\n",
       " tensor(3106),\n",
       " tensor(5400),\n",
       " tensor(5401),\n",
       " tensor(5402),\n",
       " tensor(5403),\n",
       " tensor(5785),\n",
       " tensor(1610),\n",
       " tensor(5405),\n",
       " tensor(5916),\n",
       " tensor(5920),\n",
       " tensor(5926),\n",
       " tensor(5947),\n",
       " tensor(5116),\n",
       " tensor(5406),\n",
       " tensor(5117),\n",
       " tensor(5407),\n",
       " tensor(5120),\n",
       " tensor(5408),\n",
       " tensor(5131),\n",
       " tensor(5409),\n",
       " tensor(5928),\n",
       " tensor(5096),\n",
       " tensor(5410),\n",
       " tensor(5923),\n",
       " tensor(5934),\n",
       " tensor(5941),\n",
       " tensor(5958),\n",
       " tensor(5963),\n",
       " tensor(5976),\n",
       " tensor(5987),\n",
       " tensor(5127),\n",
       " tensor(5411),\n",
       " tensor(5412),\n",
       " tensor(5946),\n",
       " tensor(5731),\n",
       " tensor(5869),\n",
       " tensor(5140),\n",
       " tensor(5413),\n",
       " tensor(5952),\n",
       " tensor(5141),\n",
       " tensor(5414),\n",
       " tensor(5142),\n",
       " tensor(5415),\n",
       " tensor(5417),\n",
       " tensor(5119),\n",
       " tensor(5418),\n",
       " tensor(5122),\n",
       " tensor(5419),\n",
       " tensor(8259),\n",
       " tensor(5420),\n",
       " tensor(5925),\n",
       " tensor(5965),\n",
       " tensor(5742),\n",
       " tensor(5882),\n",
       " tensor(5889),\n",
       " tensor(5144),\n",
       " tensor(5421),\n",
       " tensor(5145),\n",
       " tensor(5422),\n",
       " tensor(5146),\n",
       " tensor(5423),\n",
       " tensor(2033),\n",
       " tensor(5424),\n",
       " tensor(5147),\n",
       " tensor(5425),\n",
       " tensor(5967),\n",
       " tensor(5426),\n",
       " tensor(5827),\n",
       " tensor(5151),\n",
       " tensor(5427),\n",
       " tensor(5428),\n",
       " tensor(5153),\n",
       " tensor(5429),\n",
       " tensor(5154),\n",
       " tensor(5430),\n",
       " tensor(8260),\n",
       " tensor(5431),\n",
       " tensor(5105),\n",
       " tensor(5432),\n",
       " tensor(5107),\n",
       " tensor(5433),\n",
       " tensor(5108),\n",
       " tensor(5434),\n",
       " tensor(5919),\n",
       " tensor(5155),\n",
       " tensor(5435),\n",
       " tensor(5156),\n",
       " tensor(5436),\n",
       " tensor(5437),\n",
       " tensor(5158),\n",
       " tensor(5438),\n",
       " tensor(8194),\n",
       " tensor(5439),\n",
       " tensor(5936),\n",
       " tensor(8199),\n",
       " tensor(5440),\n",
       " tensor(5442),\n",
       " tensor(8203),\n",
       " tensor(5443),\n",
       " tensor(8206),\n",
       " tensor(5444),\n",
       " tensor(5927),\n",
       " tensor(5945),\n",
       " tensor(8207),\n",
       " tensor(5445),\n",
       " tensor(5446),\n",
       " tensor(5978),\n",
       " tensor(1351),\n",
       " tensor(5447),\n",
       " tensor(8264),\n",
       " tensor(5448),\n",
       " tensor(8210),\n",
       " tensor(5449),\n",
       " tensor(8212),\n",
       " tensor(5450),\n",
       " tensor(8217),\n",
       " tensor(5451),\n",
       " tensor(5771),\n",
       " tensor(5858),\n",
       " tensor(5098),\n",
       " tensor(5452),\n",
       " tensor(8193),\n",
       " tensor(5453),\n",
       " tensor(8221),\n",
       " tensor(5454),\n",
       " tensor(5455),\n",
       " tensor(5924),\n",
       " tensor(5930),\n",
       " tensor(5682),\n",
       " tensor(8222),\n",
       " tensor(5456),\n",
       " tensor(5949),\n",
       " tensor(8223),\n",
       " tensor(5457),\n",
       " tensor(8224),\n",
       " tensor(5458),\n",
       " tensor(8228),\n",
       " tensor(5459),\n",
       " tensor(5914),\n",
       " tensor(5938),\n",
       " tensor(8232),\n",
       " tensor(5460),\n",
       " tensor(8230),\n",
       " tensor(5462),\n",
       " tensor(5929),\n",
       " tensor(5931),\n",
       " tensor(3309),\n",
       " tensor(5463),\n",
       " tensor(8231),\n",
       " tensor(5464),\n",
       " tensor(8233),\n",
       " tensor(5465),\n",
       " tensor(5922),\n",
       " tensor(5867),\n",
       " tensor(8234),\n",
       " tensor(5466),\n",
       " tensor(8241),\n",
       " tensor(5467),\n",
       " tensor(5113),\n",
       " tensor(5468),\n",
       " tensor(8245),\n",
       " tensor(5469),\n",
       " tensor(8244),\n",
       " tensor(5470),\n",
       " tensor(8247),\n",
       " tensor(5471),\n",
       " tensor(5933),\n",
       " tensor(5956),\n",
       " tensor(5975),\n",
       " tensor(5821),\n",
       " tensor(8253),\n",
       " tensor(5472),\n",
       " tensor(5473),\n",
       " tensor(8254),\n",
       " tensor(5474),\n",
       " tensor(8252),\n",
       " tensor(5475),\n",
       " tensor(8249),\n",
       " tensor(5476),\n",
       " tensor(4092),\n",
       " tensor(5477),\n",
       " tensor(8256),\n",
       " tensor(5478),\n",
       " tensor(8257),\n",
       " tensor(5479),\n",
       " tensor(8258),\n",
       " tensor(5480),\n",
       " tensor(5481),\n",
       " tensor(8265),\n",
       " tensor(5483),\n",
       " tensor(5484),\n",
       " tensor(8266),\n",
       " tensor(5485),\n",
       " tensor(8267),\n",
       " tensor(5486),\n",
       " tensor(8269),\n",
       " tensor(5487),\n",
       " tensor(8270),\n",
       " tensor(5488),\n",
       " tensor(5489),\n",
       " tensor(5491),\n",
       " tensor(5492),\n",
       " tensor(5959),\n",
       " tensor(8276),\n",
       " tensor(5493),\n",
       " tensor(8277),\n",
       " tensor(5494),\n",
       " tensor(8229),\n",
       " tensor(5502),\n",
       " tensor(5495),\n",
       " tensor(5765),\n",
       " tensor(5766),\n",
       " tensor(5778),\n",
       " tensor(5837),\n",
       " tensor(5863),\n",
       " tensor(1499),\n",
       " tensor(6814),\n",
       " tensor(6833),\n",
       " tensor(6841),\n",
       " tensor(6843),\n",
       " tensor(6844),\n",
       " tensor(6846),\n",
       " tensor(6847),\n",
       " tensor(6881),\n",
       " tensor(6882),\n",
       " tensor(6883),\n",
       " tensor(6884),\n",
       " tensor(6886),\n",
       " tensor(6887),\n",
       " tensor(6888),\n",
       " tensor(6890),\n",
       " tensor(6891),\n",
       " tensor(6917),\n",
       " tensor(6930),\n",
       " tensor(6935),\n",
       " tensor(6951),\n",
       " tensor(6981),\n",
       " tensor(6983),\n",
       " tensor(6987),\n",
       " tensor(6988),\n",
       " tensor(6989),\n",
       " tensor(6997),\n",
       " tensor(7001),\n",
       " tensor(7002),\n",
       " tensor(7007),\n",
       " tensor(7045),\n",
       " tensor(7047),\n",
       " tensor(7052),\n",
       " tensor(7066),\n",
       " tensor(7068),\n",
       " tensor(7070),\n",
       " tensor(7078),\n",
       " tensor(7079),\n",
       " tensor(7080),\n",
       " tensor(7081),\n",
       " tensor(7084),\n",
       " tensor(7085),\n",
       " tensor(7093),\n",
       " tensor(7094),\n",
       " tensor(7095),\n",
       " tensor(7100),\n",
       " tensor(7110),\n",
       " tensor(7111),\n",
       " tensor(7130),\n",
       " tensor(7132),\n",
       " tensor(7136),\n",
       " tensor(7157),\n",
       " tensor(7158),\n",
       " tensor(7159),\n",
       " tensor(7193),\n",
       " tensor(7195),\n",
       " tensor(7204),\n",
       " tensor(7250),\n",
       " tensor(7254),\n",
       " tensor(7258),\n",
       " tensor(7260),\n",
       " tensor(7279),\n",
       " tensor(7287),\n",
       " tensor(7290),\n",
       " tensor(7296),\n",
       " tensor(7297),\n",
       " tensor(7298),\n",
       " tensor(7314),\n",
       " tensor(7315),\n",
       " tensor(7327),\n",
       " tensor(7329),\n",
       " tensor(7377),\n",
       " tensor(7378),\n",
       " tensor(7379),\n",
       " tensor(7384),\n",
       " tensor(7392),\n",
       " tensor(7393),\n",
       " tensor(7394),\n",
       " tensor(7429),\n",
       " tensor(7430),\n",
       " tensor(7431),\n",
       " tensor(7432),\n",
       " tensor(7439),\n",
       " tensor(7440),\n",
       " tensor(7442),\n",
       " tensor(7443),\n",
       " tensor(7452),\n",
       " tensor(7456),\n",
       " tensor(7458),\n",
       " tensor(7459),\n",
       " tensor(7461),\n",
       " tensor(7467),\n",
       " tensor(7477),\n",
       " tensor(7478),\n",
       " tensor(7479),\n",
       " tensor(7578),\n",
       " tensor(7600),\n",
       " tensor(7611),\n",
       " tensor(7613),\n",
       " tensor(7614),\n",
       " tensor(7620),\n",
       " tensor(7632),\n",
       " tensor(7677),\n",
       " tensor(7688),\n",
       " tensor(7733),\n",
       " tensor(7734),\n",
       " tensor(7736),\n",
       " tensor(7797),\n",
       " tensor(7798),\n",
       " tensor(7800),\n",
       " tensor(7801),\n",
       " tensor(7802),\n",
       " tensor(7803),\n",
       " tensor(7815),\n",
       " tensor(7818),\n",
       " tensor(7819),\n",
       " tensor(7821),\n",
       " tensor(7822),\n",
       " tensor(7823),\n",
       " tensor(7828),\n",
       " tensor(7829),\n",
       " tensor(7830),\n",
       " tensor(7832),\n",
       " tensor(7848),\n",
       " tensor(7849),\n",
       " tensor(7850),\n",
       " tensor(7856),\n",
       " tensor(7861),\n",
       " tensor(7866),\n",
       " tensor(7872),\n",
       " tensor(7873),\n",
       " tensor(7886),\n",
       " tensor(7911),\n",
       " tensor(7927),\n",
       " tensor(7930),\n",
       " tensor(7941),\n",
       " tensor(7952),\n",
       " tensor(7953),\n",
       " tensor(7954),\n",
       " tensor(7955),\n",
       " tensor(7956),\n",
       " tensor(7957),\n",
       " tensor(7959),\n",
       " tensor(7961),\n",
       " tensor(7963),\n",
       " tensor(7968),\n",
       " tensor(7981),\n",
       " tensor(7985),\n",
       " tensor(7986),\n",
       " tensor(7987),\n",
       " tensor(7988),\n",
       " tensor(7989),\n",
       " tensor(7991),\n",
       " tensor(7992),\n",
       " tensor(7994),\n",
       " tensor(7995),\n",
       " tensor(7996),\n",
       " tensor(7997),\n",
       " tensor(7998),\n",
       " tensor(7999),\n",
       " tensor(8003),\n",
       " tensor(8010),\n",
       " tensor(8012),\n",
       " tensor(8013),\n",
       " tensor(8014),\n",
       " tensor(8015),\n",
       " tensor(8023),\n",
       " tensor(8031),\n",
       " tensor(8034),\n",
       " tensor(8041),\n",
       " tensor(5503),\n",
       " tensor(5943),\n",
       " tensor(5991),\n",
       " tensor(5497),\n",
       " tensor(5749),\n",
       " tensor(5807),\n",
       " tensor(1929),\n",
       " tensor(6816),\n",
       " tensor(6826),\n",
       " tensor(6832),\n",
       " tensor(6842),\n",
       " tensor(6852),\n",
       " tensor(6862),\n",
       " tensor(6873),\n",
       " tensor(6895),\n",
       " tensor(6896),\n",
       " tensor(6897),\n",
       " tensor(6898),\n",
       " tensor(6899),\n",
       " tensor(6900),\n",
       " tensor(6901),\n",
       " tensor(6903),\n",
       " tensor(6904),\n",
       " tensor(6905),\n",
       " tensor(6906),\n",
       " tensor(6907),\n",
       " tensor(6908),\n",
       " tensor(6909),\n",
       " tensor(6910),\n",
       " tensor(6911),\n",
       " tensor(6918),\n",
       " tensor(6921),\n",
       " tensor(6927),\n",
       " tensor(6929),\n",
       " tensor(6931),\n",
       " tensor(6933),\n",
       " tensor(6934),\n",
       " tensor(6953),\n",
       " tensor(6960),\n",
       " tensor(6963),\n",
       " tensor(6966),\n",
       " tensor(6967),\n",
       " tensor(6968),\n",
       " tensor(6969),\n",
       " tensor(6970),\n",
       " tensor(6971),\n",
       " tensor(6972),\n",
       " tensor(6973),\n",
       " tensor(6982),\n",
       " tensor(6993),\n",
       " tensor(7057),\n",
       " tensor(7069),\n",
       " tensor(7071),\n",
       " tensor(7073),\n",
       " tensor(7092),\n",
       " tensor(7120),\n",
       " tensor(7127),\n",
       " tensor(7147),\n",
       " tensor(7148),\n",
       " tensor(7149),\n",
       " tensor(7150),\n",
       " tensor(7152),\n",
       " tensor(7153),\n",
       " tensor(7154),\n",
       " tensor(7155),\n",
       " tensor(7156),\n",
       " tensor(7163),\n",
       " tensor(7252),\n",
       " tensor(7253),\n",
       " tensor(7255),\n",
       " tensor(7256),\n",
       " tensor(7257),\n",
       " tensor(7261),\n",
       " tensor(7263),\n",
       " tensor(7266),\n",
       " tensor(7269),\n",
       " tensor(7272),\n",
       " tensor(7274),\n",
       " tensor(7288),\n",
       " tensor(7289),\n",
       " tensor(7291),\n",
       " tensor(7306),\n",
       " tensor(7326),\n",
       " tensor(7330),\n",
       " tensor(7332),\n",
       " tensor(7356),\n",
       " tensor(7357),\n",
       " tensor(7358),\n",
       " tensor(7359),\n",
       " tensor(7360),\n",
       " tensor(7361),\n",
       " tensor(7363),\n",
       " tensor(7364),\n",
       " tensor(7365),\n",
       " tensor(7366),\n",
       " tensor(7437),\n",
       " tensor(7448),\n",
       " tensor(7449),\n",
       " tensor(7466),\n",
       " tensor(7556),\n",
       " tensor(7567),\n",
       " tensor(7644),\n",
       " tensor(7655),\n",
       " tensor(7666),\n",
       " tensor(7693),\n",
       " tensor(7694),\n",
       " tensor(7785),\n",
       " tensor(7786),\n",
       " tensor(7796),\n",
       " tensor(7826),\n",
       " tensor(7840),\n",
       " tensor(7874),\n",
       " tensor(7875),\n",
       " tensor(7876),\n",
       " tensor(7877),\n",
       " tensor(7879),\n",
       " tensor(7880),\n",
       " tensor(7881),\n",
       " tensor(7882),\n",
       " tensor(7887),\n",
       " tensor(7893),\n",
       " tensor(7894),\n",
       " tensor(7895),\n",
       " tensor(7896),\n",
       " tensor(7897),\n",
       " tensor(7898),\n",
       " tensor(7899),\n",
       " tensor(7900),\n",
       " tensor(7901),\n",
       " tensor(7902),\n",
       " tensor(8029),\n",
       " tensor(8030),\n",
       " tensor(5504),\n",
       " tensor(5955),\n",
       " tensor(5962),\n",
       " tensor(5501),\n",
       " tensor(5820),\n",
       " tensor(5834),\n",
       " tensor(5839),\n",
       " tensor(5842),\n",
       " tensor(2760),\n",
       " tensor(6813),\n",
       " tensor(6815),\n",
       " tensor(6817),\n",
       " tensor(6818),\n",
       " tensor(6819),\n",
       " tensor(6820),\n",
       " tensor(6821),\n",
       " tensor(6822),\n",
       " tensor(6823),\n",
       " tensor(6824),\n",
       " tensor(6825),\n",
       " tensor(6827),\n",
       " tensor(6828),\n",
       " tensor(6829),\n",
       " tensor(6830),\n",
       " tensor(6831),\n",
       " tensor(6834),\n",
       " tensor(6835),\n",
       " tensor(6836),\n",
       " tensor(6837),\n",
       " tensor(6838),\n",
       " tensor(6839),\n",
       " tensor(6840),\n",
       " tensor(6845),\n",
       " tensor(6848),\n",
       " tensor(6849),\n",
       " tensor(6850),\n",
       " tensor(6851),\n",
       " tensor(6853),\n",
       " tensor(6854),\n",
       " tensor(6855),\n",
       " tensor(6856),\n",
       " tensor(6857),\n",
       " tensor(6858),\n",
       " tensor(6859),\n",
       " tensor(6860),\n",
       " tensor(6861),\n",
       " tensor(6863),\n",
       " tensor(6864),\n",
       " tensor(6865),\n",
       " tensor(6866),\n",
       " tensor(6867),\n",
       " tensor(6868),\n",
       " tensor(6869),\n",
       " tensor(6870),\n",
       " tensor(6871),\n",
       " tensor(6872),\n",
       " tensor(6874),\n",
       " tensor(6875),\n",
       " tensor(6876),\n",
       " tensor(6877),\n",
       " tensor(6878),\n",
       " tensor(6879),\n",
       " tensor(6880),\n",
       " tensor(6885),\n",
       " tensor(6889),\n",
       " tensor(6892),\n",
       " tensor(6893),\n",
       " tensor(6902),\n",
       " tensor(6913),\n",
       " tensor(6914),\n",
       " tensor(6919),\n",
       " tensor(6920),\n",
       " tensor(6922),\n",
       " tensor(6923),\n",
       " tensor(6924),\n",
       " tensor(6925),\n",
       " tensor(6926),\n",
       " tensor(6928),\n",
       " tensor(6932),\n",
       " tensor(6936),\n",
       " tensor(6937),\n",
       " tensor(6939),\n",
       " tensor(6940),\n",
       " tensor(6941),\n",
       " tensor(6942),\n",
       " tensor(6944),\n",
       " tensor(6945),\n",
       " tensor(6946),\n",
       " tensor(6950),\n",
       " tensor(6952),\n",
       " tensor(6954),\n",
       " tensor(6955),\n",
       " tensor(6957),\n",
       " tensor(6958),\n",
       " tensor(6959),\n",
       " tensor(6961),\n",
       " tensor(6962),\n",
       " tensor(6964),\n",
       " tensor(6965),\n",
       " tensor(6974),\n",
       " tensor(6975),\n",
       " tensor(6976),\n",
       " tensor(6977),\n",
       " tensor(6978),\n",
       " tensor(6979),\n",
       " tensor(6980),\n",
       " tensor(6984),\n",
       " tensor(6985),\n",
       " tensor(6986),\n",
       " tensor(6991),\n",
       " tensor(6992),\n",
       " tensor(6994),\n",
       " tensor(6995),\n",
       " tensor(6998),\n",
       " tensor(6999),\n",
       " tensor(7000),\n",
       " tensor(7004),\n",
       " tensor(7005),\n",
       " tensor(7006),\n",
       " tensor(7010),\n",
       " tensor(7011),\n",
       " tensor(7012),\n",
       " tensor(7013),\n",
       " tensor(7014),\n",
       " tensor(7015),\n",
       " tensor(7018),\n",
       " tensor(7019),\n",
       " tensor(7020),\n",
       " tensor(7021),\n",
       " tensor(7022),\n",
       " tensor(7023),\n",
       " tensor(7024),\n",
       " tensor(7025),\n",
       " tensor(7026),\n",
       " tensor(7027),\n",
       " tensor(7028),\n",
       " tensor(7029),\n",
       " tensor(7030),\n",
       " tensor(7031),\n",
       " tensor(7032),\n",
       " tensor(7033),\n",
       " tensor(7034),\n",
       " tensor(7035),\n",
       " tensor(7036),\n",
       " tensor(7037),\n",
       " tensor(7038),\n",
       " tensor(7039),\n",
       " tensor(7040),\n",
       " tensor(7041),\n",
       " tensor(7042),\n",
       " tensor(7043),\n",
       " tensor(7046),\n",
       " tensor(7048),\n",
       " tensor(7049),\n",
       " tensor(7050),\n",
       " tensor(7051),\n",
       " tensor(7053),\n",
       " tensor(7054),\n",
       " tensor(7055),\n",
       " tensor(7056),\n",
       " tensor(7058),\n",
       " tensor(7059),\n",
       " tensor(7060),\n",
       " tensor(7061),\n",
       " tensor(7062),\n",
       " tensor(7063),\n",
       " tensor(7065),\n",
       " tensor(7072),\n",
       " tensor(7075),\n",
       " tensor(7076),\n",
       " tensor(7077),\n",
       " tensor(7082),\n",
       " tensor(7083),\n",
       " tensor(7086),\n",
       " tensor(7087),\n",
       " tensor(7088),\n",
       " tensor(7089),\n",
       " tensor(7090),\n",
       " tensor(7091),\n",
       " tensor(7096),\n",
       " tensor(7097),\n",
       " tensor(7098),\n",
       " tensor(7099),\n",
       " tensor(7101),\n",
       " tensor(7102),\n",
       " tensor(7103),\n",
       " tensor(7104),\n",
       " tensor(7105),\n",
       " tensor(7106),\n",
       " tensor(7107),\n",
       " tensor(7108),\n",
       " tensor(7109),\n",
       " tensor(7112),\n",
       " tensor(7113),\n",
       " tensor(7114),\n",
       " tensor(7115),\n",
       " tensor(7116),\n",
       " tensor(7117),\n",
       " tensor(7118),\n",
       " tensor(7119),\n",
       " tensor(7121),\n",
       " tensor(7123),\n",
       " tensor(7124),\n",
       " tensor(7125),\n",
       " tensor(7126),\n",
       " tensor(7128),\n",
       " tensor(7129),\n",
       " tensor(7131),\n",
       " tensor(7137),\n",
       " tensor(7138),\n",
       " tensor(7141),\n",
       " tensor(7143),\n",
       " tensor(7144),\n",
       " tensor(7145),\n",
       " tensor(7146),\n",
       " tensor(7151),\n",
       " tensor(7160),\n",
       " tensor(7161),\n",
       " tensor(7162),\n",
       " ...]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = []\n",
    "for i in data.triples:\n",
    "    if i[0] not in counter:\n",
    "        counter.append(i[0])\n",
    "    if i[2] not in counter:\n",
    "        counter.append(i[2])\n",
    "\n",
    "len(set(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.coalesce().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_threshold(sparse_tensor):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == 10:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def convert_back(sparse_tensor, data):\n",
    "    sparse_tensor = torch.sparse_coo_tensor(\n",
    "        sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    )\n",
    "    return sparse_tensor\n",
    "\n",
    "t =     find_threshold(v)\n",
    "v, h = convert_back(v, data), convert_back(h, data)\n",
    "print(sub(v,t),t)\n",
    "v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "print(v.coalesce().values().count_nonzero())\n",
    "v_sub = sub(v,t)\n",
    "if node_idx in v_sub.coalesce().indices():\n",
    "    print('node_idx in v')\n",
    "else:\n",
    "    print('node_idx not in v')\n",
    "\n",
    "#print(t, sub(v,t))\n",
    "\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "def find_threshold(sparse_tensor, num_exp):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == num_exp:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "\n",
    "def threshold_mask(h,v ,data, num_exp):\n",
    "    ''' Apply a threshold mask to the adjacency matrix'''\n",
    "    t =     find_threshold(v, num_exp)\n",
    "    #v, h = convert_back(v, data), convert_back(h, data)\n",
    "    v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "    return h,v\n",
    "\n",
    "h,v = threshold_mask(h,v, data, 10)\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)    \n",
    "\n",
    "v.coalesce().values().count_nonzero()\n",
    "masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "print(masked_hor_sub.coalesce().values().count_nonzero())\n",
    "m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "\n",
    "masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "counter = dict(Counter(m[:,1].tolist()))\n",
    "counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "print('Important relations', counter)\n",
    "\n",
    "def important_relation(v,h,data):\n",
    "    masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "    m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "    counter = dict(Counter(m[:,1].tolist()))\n",
    "    counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "    print('Important relations', counter)\n",
    "    return counter\n",
    "\n",
    "v,h = threshold_mask(h,v, data, 10)\n",
    "important_relation(v,h,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# def find_threshold_sparse_tensor(sparse_tensor, index, n):\n",
    "#     # Get the values and indices of the sparse tensor\n",
    "#     values = sparse_tensor.coalesce().values()\n",
    "#     indices = sparse_tensor.coalesce().indices()\n",
    "\n",
    "#     # Filter the values and indices based on the specified index\n",
    "#     selected_values = values[indices[1] == index]\n",
    "\n",
    "#     # Sort the selected values in descending order\n",
    "#     sorted_values, _ = torch.sort(selected_values, descending=True)\n",
    "\n",
    "#     # Find the threshold value\n",
    "#     if n < sorted_values.size(0):\n",
    "#         threshold = sorted_values[n - 1]\n",
    "#     else:\n",
    "#         threshold = sorted_values[-1]\n",
    "\n",
    "#     return threshold\n",
    "def find_threshold_sparse_tensor(sparse_tensor, index, n):\n",
    "    # Get the values and indices of the sparse tensor\n",
    "    values = sparse_tensor.coalesce().values()\n",
    "    indices = sparse_tensor.coalesce().indices()\n",
    "\n",
    "    # Filter the values and indices based on the specified index\n",
    "    selected_values = values[indices[0] == index]\n",
    "\n",
    "    # Sort the selected values in descending order\n",
    "    sorted_values, _ = torch.sort(selected_values, descending=True)\n",
    "\n",
    "    # Find the threshold value\n",
    "    if n <= sorted_values.size(0):\n",
    "        threshold = sorted_values[n - 1]\n",
    "    else:\n",
    "        threshold = sorted_values[-1]\n",
    "\n",
    "    return threshold\n",
    "\n",
    "# Example sparse tensor\n",
    "sparse_tensor = h\n",
    "\n",
    "# Specify the index and maximum number of values\n",
    "index = 5757\n",
    "n = 10\n",
    "# Find the threshold\n",
    "t = find_threshold_sparse_tensor(sparse_tensor, index, n)\n",
    "\n",
    "v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "sub(h,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def is_graph_connected(adjacency_matrix):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    visited = torch.zeros(n, dtype=torch.bool)\n",
    "    stack = [0]  # Start traversal from node 0\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        visited[node] = True\n",
    "\n",
    "        neighbor_indices = adjacency_matrix.coalesce().indices()\n",
    "        neighbor_values = adjacency_matrix.coalesce().values()\n",
    "\n",
    "        node_neighbors = neighbor_indices[0, neighbor_indices[1] == node]\n",
    "        for neighbor in node_neighbors:\n",
    "            if not visited[neighbor]:\n",
    "                stack.append(neighbor)\n",
    "                print(stack)\n",
    "\n",
    "    return visited.all()\n",
    "\n",
    "\n",
    "def remove_disconnected_edges(adjacency_matrix):\n",
    "    if not is_graph_connected(adjacency_matrix):\n",
    "        connected_indices = []\n",
    "        connected_values = []\n",
    "\n",
    "        for node in range(adjacency_matrix.size(0)):\n",
    "            row = adjacency_matrix[node]\n",
    "            node_neighbors = row.coalesce().indices()\n",
    "            node_values = row.coalesce().values()\n",
    "\n",
    "            connected_indices.extend([(node, neighbor) for neighbor in node_neighbors])\n",
    "            connected_values.extend(node_values)\n",
    "\n",
    "        connected_indices = torch.tensor(connected_indices).t()\n",
    "        connected_values = torch.tensor(connected_values)\n",
    "        connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "            connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "        )\n",
    "\n",
    "        return connected_adjacency_matrix\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "is_graph_connected(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "node_idx = 5757\n",
    "v = torch.load(f'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "def select_connected_subgraph(adjacency_matrix, given_node,data):\n",
    "    adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        adjacency_matrix.coalesce().indices()%data.num_entities, adjacency_matrix.coalesce().values(), size=adjacency_matrix.size()\n",
    "    )\n",
    "    sub_adj = sub(adjacency_matrix, 0.5)\n",
    "    print(adjacency_matrix)\n",
    "    num_nodes = sub_adj.size(0)\n",
    "    visited = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    connected_nodes = set()\n",
    "    stack = []\n",
    "\n",
    "    # Starting with the given node\n",
    "    stack.append(given_node)\n",
    "    connected_nodes.add(given_node)\n",
    "    visited[given_node] = True\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        node = stack.pop()\n",
    "        neighbors = sub_adj[node].coalesce().indices()\n",
    "        for i in range(neighbors.size(1)):\n",
    "            neighbor = neighbors[:, i]\n",
    "            if not visited[neighbor[0]]:\n",
    "                stack.append(neighbor[0])\n",
    "                connected_nodes.add(neighbor[0])\n",
    "                visited[neighbor[0]] = True\n",
    "\n",
    "    # Select the indices of the connected nodes\n",
    "    connected_indices = []\n",
    "    for node in connected_nodes:\n",
    "        connected_indices.append([node, node])\n",
    "\n",
    "    # Create the connected adjacency matrix\n",
    "    connected_indices = torch.tensor(connected_indices, dtype=torch.long).t()\n",
    "    #connected_values = adjacency_matrix._values()[connected_indices[0]]\n",
    "    connected_values = torch.ones(connected_indices.size(1))\n",
    "\n",
    "    #torch.ones(connected_indices.size(1))\n",
    "    disconnected_indices = get_non_selected_indices(adjacency_matrix, connected_indices)\n",
    "    disconnected_values = torch.zeros(disconnected_indices.size(1))\n",
    "    connected_indices = torch.cat([connected_indices, disconnected_indices], dim=1)\n",
    "    connected_values = torch.cat([connected_values, disconnected_values])\n",
    "    connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "    )\n",
    "\n",
    "    return connected_adjacency_matrix\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# v, h = sub(v, 0.5), sub(h,0.5)\n",
    "v = select_connected_subgraph(v, node_idx,data)\n",
    "h = select_connected_subgraph(h, node_idx,data)\n",
    "print(v.coalesce().values().count_nonzero(), h.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Example sparse tensor\n",
    "indices = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "values = torch.tensor([2, 4, 6])\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(2, 2))\n",
    "\n",
    "# Example selected indices\n",
    "selected_indices = torch.tensor([[0, 1], [1, 1]])\n",
    "\n",
    "# Convert selected indices to a boolean mask\n",
    "mask = torch.sparse_coo_tensor(selected_indices, torch.ones(selected_indices.size(1)), size=(2, 2)).to_dense().bool()\n",
    "\n",
    "# Use torch.where to select values based on the mask\n",
    "selected_values = torch.where(mask, sparse_tensor.coalesce().values(), torch.zeros(mask.sum()))\n",
    "\n",
    "print(selected_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_non_selected_indices(sparse_tensor, selected_indices):\n",
    "    original_indices = sparse_tensor.coalesce().indices()\n",
    "    selected_set = set(map(tuple, selected_indices.t().tolist()))\n",
    "\n",
    "    non_selected_indices = []\n",
    "    for index in original_indices.t().tolist():\n",
    "        if tuple(index) not in selected_set:\n",
    "            non_selected_indices.append(index)\n",
    "\n",
    "    return torch.tensor(non_selected_indices).t()\n",
    "\n",
    "# Example usage\n",
    "sparse_tensor = torch.sparse_coo_tensor(torch.tensor([[0, 0, 1, 1], [0, 1, 0, 2]]), torch.tensor([2, 3, 4, 5]), size=(2, 3))\n",
    "selected_indices = torch.tensor([[0, 1], [1, 2]])  # Example selected indices\n",
    "\n",
    "non_selected_indices = get_non_selected_indices(sparse_tensor, selected_indices)\n",
    "print(non_selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv,ov = v_bin.coalesce().indices()%data.num_entities\n",
    "sh,oh = h_bin.coalesce().indices()%data.num_entities\n",
    "\n",
    "v = torch.sparse_coo_tensor(torch.stack([sv,ov]), v_bin.coalesce().values(), v_bin.size())\n",
    "h = torch.sparse_coo_tensor(torch.stack([sh,oh]), h_bin.coalesce().values(), h_bin.size())\n",
    "\n",
    "for i in v.coalesce().indices():\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "v, h = select_on_relation_sparse(v,data, 39), select_on_relation_sparse(h,data, 39)\n",
    "#print(v_.coalesce().values().count_nonzero())\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "\n",
    "print(v_bin.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_bin,v_bin)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse predictions \n",
    "v_inv, h_inv = inverse_tensor(v), inverse_tensor(h)\n",
    "print(v_inv.coalesce().values().count_nonzero())\n",
    "\n",
    "out = model.forward2(h_inv,v_inv)\n",
    "\n",
    "res1_m = nn.Softmax(dim=0)(out[node_idx])\n",
    "res - res1_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_tensor(sparse_tensor):\n",
    "    \"\"\" Convert 0 to 1 and viceversa in sparse tensor\n",
    "    The aim is computing the Fidelity- score\"\"\"\n",
    "    sparse_tensor = convert_binary(sparse_tensor, 0.5)\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices=sparse_tensor._indices(), \n",
    "                                        values=1 - sparse_tensor._values(), \n",
    "                                        size=sparse_tensor.size())\n",
    "    return sparse_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data = prunee(data, 2)\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "object_type(v,h,data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.num_relations):\n",
    "    print(i, data.i2r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#I want to get the indices of the triples with type relation \n",
    "output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, 39)\n",
    "output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, 39)\n",
    "objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "list = []\n",
    "for i in objects_types:\n",
    "    list.append(data.i2e[i[2]][0].split('#')[1])\n",
    "result = Counter(list)\n",
    "print(result)\n",
    "#probably node person is the most frequent - what about I delete all the triples where Person is the object?????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_entity(sparse_tensor,class_id):\n",
    "    ''' Select the subset of the tensor based on the id of the class to be zeroed out'''\n",
    "    value_indices = torch.where(sparse_tensor.coalesce().indices() == class_id)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices[1]] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "\n",
    "    return masked_sparse_tensor\n",
    "select_entity(h, 5230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5230*39%5230 \n",
    "#class_id = 5230\n",
    "#value_indices = torch.where(v.coalesce().indices() == class_id or v.coalesce().indices()%class_id == 0)\n",
    "v.coalesce().indices()\n",
    "154915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation,value =1):\n",
    "    \"\"\" Selects the values of a sparse tensor based on the relation\"\"\"\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = value\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(h.coalesce().indices() == torch.tensor(5230))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_type(v,h,data, relation_id = None,type=True):\n",
    "    ''' Get the object class of a specific relation'''\n",
    "    if type:\n",
    "        relation_id = [i for i in range(data.num_relations) if 'type' in data.i2r[i]][-1]\n",
    "    output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, relation_id)\n",
    "    output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, relation_id)\n",
    "    objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "    list = []\n",
    "    for i in objects_types:\n",
    "        list.append(data.i2e[i[2]][0])#.split('#')[1])\n",
    "    result = Counter(list)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "for node_idx in data.withheld[:,0]:\n",
    "    h, v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}'), torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "    print(f'node {node_idx}:', object_type(v,h,data, 39))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "relation_id = [i for i in range(data.num_relations) if 'type' in data.i2r[i]]\n",
    "relation_id\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation,value =1):\n",
    "    \"\"\" Selects the values of a sparse tensor based on the relation\"\"\"\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = value\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e,n,x = find_n_hop_neighbors(edge_index_oneadj(data.triples) ,2, 5757)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in data.triples:\n",
    "    if i[0] == 5757:\n",
    "        list.append(i[2])\n",
    "    if i[2] == 5757:\n",
    "        list.append(i[0])\n",
    "\n",
    "count = []  \n",
    "for i in data.triples: \n",
    "    for j in list:\n",
    "        if i[0] == j or i[2] == j:\n",
    "            count.append[]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld[torch.where(data.withheld[:, 0] == torch.tensor([5757])),1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = d_classes(data)\n",
    "for c in classes:\n",
    "    for node in c:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = d_classes(data)\n",
    "count = 0\n",
    "dict_rel_all_classes = {}\n",
    "dict_rel = {}\n",
    "for j in range(len(classes)):\n",
    "    dict_rel = {}\n",
    "    for node_idx in classes[j]:\n",
    "        for i in data.triples:\n",
    "            if i[0] == node_idx or i[2] == node_idx:\n",
    "                count += 1\n",
    "                if data.i2r[int(i[1])] not in dict_rel.keys():\n",
    "                    dict_rel[data.i2r[int(i[1])]] = 1\n",
    "                else:\n",
    "                    dict_rel[data.i2r[int(i[1])]] += 1\n",
    "    dict_rel_all_classes[j] = dict_rel\n",
    "\n",
    "count\n",
    "dict_rel_all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_0 = select_on_relation_sparse(v_bin,data, 30)\n",
    "h_0 = select_on_relation_sparse(h_bin,data, 30)\n",
    "\n",
    "print(v_0.coalesce().values().count_nonzero(),h_0.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_0,v_0)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_on_relation_sparse(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 1\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "types = []\n",
    "for i in data.triples:\n",
    "    if i[1]==34:\n",
    "        types.append(int(i[2]))\n",
    "        count+=1\n",
    "count\n",
    "types = set(types)\n",
    "types = [data.i2e[i] for i in types]\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "#loop over keys of counter\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    # v_ = select_on_relation_sparse(v,data, key)\n",
    "    # h_ = select_on_relation_sparse(h,data, key)\n",
    "    v_ = select_one_relation(v,data, key)\n",
    "    h_ = select_one_relation(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        pass\n",
    "        #print(f'wrong prediction without {data.i2r[key]}')\n",
    "    else:\n",
    "        print(f'correct only with {data.i2r[key]}')\n",
    "        print(f'ypred only with {data.i2r[key]}, {key}', res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a baseline: no use RGCNExplainer - just rule out relations based on prediction of the model\n",
    "\n",
    "#node:\n",
    "node_idx = 5678\n",
    "\n",
    "#label for that node\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "\n",
    "#edge index\n",
    "edge_index = edge_index_oneadj(data.triples)\n",
    "\n",
    "#number of hops\n",
    "n_hops = 2\n",
    "\n",
    "#augment dataset with self loops and inverse relations\n",
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "\n",
    "#get the edge index at 2 hops per node\n",
    "_,_,index_h = find_n_hop_neighbors(hor_graph.coalesce().indices(), n_hops, node_idx)\n",
    "_,_,index_v = find_n_hop_neighbors(ver_graph.coalesce().indices(), n_hops, node_idx)\n",
    "\n",
    "h = torch.sparse_coo_tensor(index_h, torch.ones(index_h.shape[1]), hor_graph.size() )\n",
    "v = torch.sparse_coo_tensor(index_v, torch.ones(index_v.shape[1]), ver_graph.size() )\n",
    "\n",
    "#match to triple\n",
    "m = match_to_triples(v,h, data)\n",
    "\n",
    "#counter of relations in the 2 hops subgraph\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "#forward pass of the model\n",
    "out = model.forward2(h,v)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print(f'ypred explain all subgraph: {torch.argmax(res)} with prediction probability: {res}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(m[:,1].tolist())\n",
    "\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 9)\n",
    "h.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5757\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "m = match_to_triples(ver_graph,hor_graph,data, node_idx)\n",
    "v, h = ver_graph, hor_graph\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'for node {node_idx}, wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_remove = []\n",
    "for i in range(data.num_relations):\n",
    "    if 'genre' in data.i2r[i]:\n",
    "        print(f'{i}: {data.i2r[i]}')\n",
    "        numbers_to_remove.append(i)\n",
    "numbers_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data.triples:\n",
    "#     for j in numbers_to_remove:\n",
    "#         if i[1] == j:\n",
    "#             print(i)\n",
    "for i in data.triples:\n",
    "    if i[0] ==9662:\n",
    "        print(data.i2e[i[0]], data.i2r[i[1]], data.i2e[i[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_most_genre'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.i2e[3599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld[data.withheld[:,0]==10241,1]\n",
    "data.withheld[torch.where(data.withheld[:, 0] == torch.tensor([10112])),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.entities = np.append(data.triples[:,0].detach().numpy(),(data.triples[:,2].detach().numpy()))\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "    \n",
    "relations = ['label', 'node_idx','number_neighbors', 'prediction_explain', 'prediction_full', 'prediction_explain_binary'] + relations\n",
    "df = pd.DataFrame(columns=relations)\n",
    "d = d_classes(data)\n",
    "\n",
    "#count how many nodes per class\n",
    "count = {}\n",
    "for i in range(len(d)):\n",
    "    count[i] = len(d[i])\n",
    "count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the node of the most important relations - the relations with the highest weights\n",
    "\n",
    "tensor_list = (list(v.coalesce().indices()[1][v.coalesce().values()>0.5]) + list(h.coalesce().indices()[0][h.coalesce().values()>0.5]))\n",
    "float_list = [tensor.item() for tensor in tensor_list]\n",
    "len(set(float_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "others = []\n",
    "for i in data.triples:\n",
    "\n",
    "    if i[0] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[2])\n",
    "    if i[2] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[0])\n",
    "\n",
    "count\n",
    "others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "l = []\n",
    "a = []\n",
    "for i in data.triples:\n",
    "    for n in others:\n",
    "        if i[0] == int(n) or i[2] == int(n):\n",
    "            count += 1\n",
    "            l.append(n)\n",
    "            a.append(i)\n",
    "            #print(i)\n",
    "            break\n",
    "res = set(l)\n",
    "resa = set(a)\n",
    "print(len(resa))            \n",
    "print(len(res))\n",
    "count\n",
    "#others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repeating_sublists(sublists):\n",
    "    repeating_elements = {}\n",
    "\n",
    "    for sublist in sublists:\n",
    "        key1 = (sublist[0], sublist[2])\n",
    "        key2 = (sublist[2], sublist[0])\n",
    "\n",
    "        if key1 in repeating_elements:\n",
    "            repeating_elements[key1].append(sublist[1])\n",
    "        elif key2 in repeating_elements:\n",
    "            repeating_elements[key2].append(sublist[1])\n",
    "        else:\n",
    "            repeating_elements[key1] = [sublist[1]]\n",
    "\n",
    "    result_array = []\n",
    "    for key, values in repeating_elements.items():\n",
    "        if len(values) > 1:\n",
    "            result_array.append([key[0], values, key[1]])\n",
    "        else:\n",
    "            result_array.append([key[0], [values[0]], key[1]])\n",
    "\n",
    "    return result_array\n",
    "\n",
    "def unnest_list(nested_list):\n",
    "    return [item for sublist in nested_list for item in (unnest_list(sublist) if isinstance(sublist, list) else [sublist])]\n",
    "\n",
    "def visualize(node_idx, n_hop, data, masked_ver,threshold,name, result_weights=True, low_threshold=False ):\n",
    "    \"\"\" \n",
    "    Visualize important nodes for node idx prediction\n",
    "    \"\"\"\n",
    "    dict_index = dict_index_classes(data,masked_ver)\n",
    "    \n",
    "    #select only nodes with a certain threshold\n",
    "    sel_masked_ver = sub_sparse_tensor(masked_ver, threshold,data, low_threshold)\n",
    "    if len(sel_masked_ver)==0:\n",
    "        sel_masked_ver=sub_sparse_tensor(masked_ver, 0,data, low_threshold)\n",
    "    print('sel masked ver',sel_masked_ver)\n",
    "    indices_nodes = sel_masked_ver.coalesce().indices().detach().numpy()\n",
    "    new_index = np.transpose(np.stack((indices_nodes[0], indices_nodes[1]))) #original edge indexes\n",
    "\n",
    "    \n",
    "    \n",
    "    G = nx.Graph()\n",
    "    if result_weights:\n",
    "        values = sel_masked_ver.coalesce().values().detach().numpy()\n",
    "        for s,p,o in zip(indices_nodes[0],values , indices_nodes[1]):\n",
    "            G.add_edge(int(s), int(o), weight=np.round(p, 2))\n",
    "\n",
    "    else:\n",
    "\n",
    "        triples_matched = match_to_triples(sel_masked_ver, data)\n",
    "        l = []\n",
    "        for i in triples_matched[:,1]:\n",
    "            l.append(data.i2rel[int(i)][0])\n",
    "        triples_matched = find_repeating_sublists(triples_matched.numpy())\n",
    "        for s,p,o in triples_matched:\n",
    "            G.add_edge(int(s), int(o), weight=p)\n",
    "\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    weights = [[item] if not isinstance(item, list) else item for item in weights]\n",
    "\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    ordered_dict = {}\n",
    "    for item in list(G.nodes):\n",
    "        if item in ordered_dict:\n",
    "            ordered_dict[item].append(dict_index[item])\n",
    "        else:\n",
    "            ordered_dict[item] =  dict_index[item]\n",
    "\n",
    "    dict_index = ordered_dict\n",
    "\n",
    "    labeldict = {}\n",
    "    for node in G.nodes:\n",
    "        labeldict[int(node)] = int(node)  \n",
    "\n",
    "\n",
    "    dict = {}\n",
    "    for k,v in dict_index.items():\n",
    "        for k1,v1 in data.entities_classes.items():\n",
    "            if v==k1: \n",
    "\n",
    "                dict[k] = v1\n",
    "            else:\n",
    "                if k not in dict:\n",
    "                    dict[k] = 0\n",
    "                \n",
    "\n",
    "    color_list = list(dict.values())\n",
    "    color_list = list(encode_dict(dict_index).values())\n",
    "\n",
    "\n",
    "    col_weights = [weights[i][0] for i in range(len(weights))]\n",
    "    if result_weights:\n",
    "        \n",
    "        nx.draw(G, pos,labels = labeldict,  edgelist=edges, edge_color=col_weights, node_color =  color_list, cmap=\"Set2\",edge_cmap=plt.cm.Reds,font_size=8)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=nx.get_edge_attributes(G,'weight'),font_size=8,font_color='red')\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        sm.set_array(weights)\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.set_title('Weight')\n",
    "        plt.title(\"Node {}'s {}-hop neighborhood important nodes\".format(node_idx, n_hop))\n",
    "    else:\n",
    "        rel = nx.get_edge_attributes(G,'weight')\n",
    "        rel = {k: [data.i2rel[i][0] for i in v] for k,v in rel.items()}\n",
    "        col_weights = [sum(weights[i], 3) if len(weights[i]) > 1 else weights[i][0] for i in range(len(weights))]\n",
    "        nx.draw(G, pos,labels = labeldict, edge_color=col_weights,edgelist=edges,node_color =  color_list, cmap=\"Set2\",font_size=7, arrows = True)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=rel,font_size=8,font_color='red')\n",
    "        \n",
    "        res = Counter(unnest_list(rel.values()))\n",
    "    if result_weights:\n",
    "        if not os.path.exists(f'chk/{name}_chk/graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/graphs/Explanation_{node_idx}_{n_hop}_weights.png')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(f'chk/{name}_chk/graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/graphs/Explanation_{node_idx}_{n_hop}_relations.png')    \n",
    "        #plt.show()\n",
    "        return res, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/masked_adj/masked_ver{node_idx}_new')\n",
    "res, weights = visualize(node_idx, 2, data, v, 0, name, result_weights=False, low_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def hor_ver_graph(triples, n, r):\n",
    "    \"\"\"\n",
    "    input: triples, number of nodes, number of relations\n",
    "    output: hor_graph, ver_graph : horizontally and vertically stacked adjacency matrix\n",
    "    \"\"\"\n",
    "\n",
    "    hor_ind, hor_size = adj(triples, n, 2*r+1, vertical=False)\n",
    "    ver_ind, ver_size = adj(triples, n, 2*r+1, vertical=True)\n",
    "\n",
    "    rn, _ = hor_size  # horizontally stacked adjacency matrix size\n",
    "    r = rn // n  # number of relations enriched divided by number of nodes\n",
    "\n",
    "    vals = torch.ones(ver_ind.size(0), dtype=torch.float)  # number of enriched triples\n",
    "\n",
    "    hor_graph = torch.sparse.FloatTensor(hor_ind.t(), vals, hor_size)  # size: n, r, emb\n",
    "    ver_graph = torch.sparse.FloatTensor(ver_ind.t(), vals, ver_size)\n",
    "\n",
    "    return hor_graph, ver_graph\n",
    "\n",
    "def adj(triples, num_nodes, num_rels, cuda=False, vertical=True):\n",
    "    \"\"\"\n",
    "     Computes a sparse adjacency matrix for the given graph (the adjacency matrices of all\n",
    "     relations are stacked vertically).\n",
    "\n",
    "     :param edges: List representing the triples\n",
    "     :param i2r: list of relations\n",
    "     :param i2n: list of nodes\n",
    "     :return: sparse tensor\n",
    "    \"\"\"\n",
    "    r, n = num_rels, num_nodes\n",
    "    size = (r * n, n) if vertical else (n, r * n)\n",
    "\n",
    "    from_indices = []\n",
    "    upto_indices = []\n",
    "\n",
    "    for s, p, o in triples:\n",
    "        offset = p.item() * n\n",
    "        s = offset + s.item() if vertical else s.item()\n",
    "        o = offset + o.item() if not vertical else o.item()\n",
    "        from_indices.append(s)\n",
    "        upto_indices.append(o)\n",
    "\n",
    "    indices = torch.tensor([from_indices, upto_indices], dtype=torch.long, device=d(cuda))\n",
    "\n",
    "    return indices.t(), size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj(data.triples, data.num_entities, data.num_relations, cuda=False, vertical=True)\n",
    "hor_ver_graph(data.triples, data.num_entities, data.num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_h, edge_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "_,_,sub_edges_tensor_h  = find_n_hop_neighbors(edge_h,2, 5699)\n",
    "_,_,sub_edges_tensor_v  = find_n_hop_neighbors(edge_v,2, 5699)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_edges_tensor_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_edges_tensor\n",
    "indexes = sub_edges_tensor%data.num_entities\n",
    "indexes\n",
    "r = sub_edges_tensor//data.num_entities\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,p = torch.div(sub_edges_tensor, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "s,o = sub_edges_tensor%data.num_entities\n",
    "result = torch.stack([s,p,o], dim=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try initialization where the first hop neighborhood gets initialized with 1s and the rest with different methods??\n",
    "def construct_edge_mask(self, num_nodes,sparse_tensor,data, const_val=1.0, relation_id = 2):\n",
    "    \"\"\"\n",
    "    Construct edge mask\n",
    "    \"\"\"\n",
    "    init_strategy = self.init_strategy\n",
    "    # if num_nodes > 1000:\n",
    "    #     init(strategy=\"const\", const_val=0.1)\n",
    "    data = self.data\n",
    "    num_entities = data.num_entities\n",
    "    torch.manual_seed(42)\n",
    "    mask = nn.Parameter(torch.FloatTensor(num_nodes))\n",
    "\n",
    "    if init_strategy == \"normal\":\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "    elif init_strategy == \"const\":\n",
    "        nn.init.constant_(mask, const_val) \n",
    "    elif init_strategy == \"zero_out\":\n",
    "        '''initialize the mask with the zero out strategy: we zero out edges belonging to specific relations'''\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "        output_indices, output_values, value_indices=select_relation(sparse_tensor,relation_id)\n",
    "        _,_,value_indices1=select_relation(sparse_tensor,33)\n",
    "        print(value_indices, value_indices1)\n",
    "        value_indices = torch.cat((value_indices, value_indices1), 0)\n",
    "        mask.data[[value_indices]] = 0\n",
    "    \n",
    "\n",
    "    elif init_strategy == \"overall_frequency\":\n",
    "        '''Initialize the mask with the overall frequency of the relations'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        overall_rel_frequency = dict(Counter(data.triples[:,1].tolist()))#.most_common()\n",
    "\n",
    "        overall_rel_frequency_  = {key: round(value/len(data.triples[:,1].tolist()),5) for key, value in overall_rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = overall_rel_frequency_[i]\n",
    "    \n",
    "    elif init_strategy == \"relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "    elif init_strategy == \"inverse_relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: 1 - round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "\n",
    "    elif init_strategy == \"domain_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = dict_domain[i]\n",
    "\n",
    "    elif init_strategy == \"range_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "                _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "                mask.data[[value_indices]] = dict_range[i]\n",
    "    elif init_strategy == \"rdf\":\n",
    "        rdf = [i for i in range(data.num_relations) if 'rdf' in data.i2r[i]]\n",
    "        for i in rdf:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    elif init_strategy == \"owl\":\n",
    "        owl = [i for i in range(data.num_relations) if 'owl' in data.i2r[i]]\n",
    "        for i in owl:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    print(f'mask initialized with {init_strategy} strategy: {mask}')   \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 3).to_sparse().requires_grad_(True)\n",
    "print(a)\n",
    "#a.values = torch.ones_like(a.values())\n",
    "values = torch.ones(a._nnz())\n",
    "#len(a.values)\n",
    "a.indices()\n",
    "sparse_tensor = torch.sparse_coo_tensor(a.indices(), torch.ones(a._nnz()), a.size(), requires_grad=True)\n",
    "sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v  = torch.load('chk/aifb_chk/size_0.05_lr_0.1_epochs_30_threshold_0.7_init_normal/masked_adj/masked_ver5757')\n",
    "h = torch.load('chk/aifb_chk/size_0.05_lr_0.1_epochs_30_threshold_0.7_init_normal/masked_adj/masked_hor5757')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > 0.7]\n",
    "nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "nonzero_values = v.coalesce().values()[v.coalesce().values() > 0.7]\n",
    "sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "sel_masked_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = sub_sparse_tensor(v, 0.5, data, low_threshold=False)\n",
    "h = sub_sparse_tensor(h, 0.5, data, low_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() < 0.5]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() < 0.5]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "sub(v, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result\n",
    "\n",
    "m = match_to_triples(v,h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v, data, sparse=True):\n",
    "    if sparse:\n",
    "        # p,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        # s,o = v.coalesce().indices()%data.num_entities\n",
    "        # result = torch.stack([s,p,o], dim=1)\n",
    "        matching = []\n",
    "        indexes = v.coalesce().indices()%data.num_entities\n",
    "        for j in range(indexes.size()[1]):\n",
    "            for triple in data.triples:\n",
    "                if triple[0] == indexes[0][j] and triple[2] == indexes[1][j]:\n",
    "                    matching.append(triple)\n",
    "        result = torch.stack(matching)\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        matching = []\n",
    "        for i,i2 in zip(v[:,0],v[:,1]):\n",
    "            for j,j1,j2, index in zip(data[:,0],data[:,1],  data[:,2], range(len(data[:,0]))):\n",
    "                if i == j and i2 == j2:\n",
    "                    matching.append(data[index])\n",
    "                    \n",
    "\n",
    "        result = torch.stack(matching)\n",
    "    \n",
    "    return result\n",
    "m = match_to_triples(h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "\n",
    "def visualize(node_idx, n_hop, data, masked_ver,masked_hor, threshold,name, result_weights=True, low_threshold=False,experiment_name=None ):\n",
    "    \"\"\" \n",
    "    Visualize important nodes for node idx prediction\n",
    "    \"\"\"\n",
    "    dict_index = dict_index_classes(data,masked_ver)\n",
    "    mask = torch.vstack((masked_ver, masked_hor.t()))\n",
    "    mask = sub(mask, threshold)\n",
    "    print(mask)\n",
    "    #select only nodes with a certain threshold\n",
    "    sel_masked_ver = sub(masked_ver, threshold)\n",
    "    sel_masked_hor = sub(masked_hor, threshold)\n",
    "    if len(sel_masked_ver)==0:\n",
    "        sel_masked_ver=sub_sparse_tensor(masked_ver, 0,data, low_threshold)\n",
    "    #mask = torch.vstack((sel_masked_ver, sel_masked_hor.t()))\n",
    "    print('sel masked ver',mask)\n",
    "    indices_nodes = mask.coalesce().indices().detach().numpy()\n",
    "    new_index = np.transpose(np.stack((indices_nodes[0], indices_nodes[1]))) #original edge indexes\n",
    "\n",
    "    \n",
    "    \n",
    "    G = nx.Graph()\n",
    "    if result_weights:\n",
    "        values = mask.coalesce().values().detach().numpy()\n",
    "        for s,p,o in zip(indices_nodes[0],values , indices_nodes[1]):\n",
    "            G.add_edge(int(s), int(o), weight=np.round(p, 2))\n",
    "\n",
    "    else:\n",
    "\n",
    "        triples_matched = match_to_triples(sel_masked_ver,sel_masked_hor, data)\n",
    "        l = []\n",
    "        for i in triples_matched[:,1]:\n",
    "            l.append(data.i2rel[int(i)][0])\n",
    "        triples_matched = find_repeating_sublists(triples_matched.numpy())\n",
    "        print(triples_matched)\n",
    "        for s,p,o in triples_matched:\n",
    "            G.add_edge(int(s), int(o), weight=p)\n",
    "\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    weights = [[item] if not isinstance(item, list) else item for item in weights]\n",
    "\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    ordered_dict = {}\n",
    "    for item in list(G.nodes):\n",
    "        if item in ordered_dict:\n",
    "            ordered_dict[item].append(dict_index[item])\n",
    "        # else:\n",
    "        #     ordered_dict[item] =  dict_index[item]\n",
    "\n",
    "    dict_index = ordered_dict\n",
    "\n",
    "    labeldict = {}\n",
    "    for node in G.nodes:\n",
    "        labeldict[int(node)] = int(node)  \n",
    "\n",
    "\n",
    "    dict = {}\n",
    "    for k,v in dict_index.items():\n",
    "        for k1,v1 in data.entities_classes.items():\n",
    "            if v==k1: \n",
    "\n",
    "                dict[k] = v1\n",
    "            else:\n",
    "                if k not in dict:\n",
    "                    dict[k] = 0\n",
    "                \n",
    "\n",
    "    color_list = list(dict.values())\n",
    "    color_list = list(encode_dict(dict_index).values())\n",
    "\n",
    "\n",
    "    col_weights = [weights[i][0] for i in range(len(weights))]\n",
    "    if result_weights:\n",
    "        \n",
    "        nx.draw(G, pos,labels = labeldict,  edgelist=edges, edge_color=col_weights, node_color =  color_list, cmap=\"Set2\",edge_cmap=plt.cm.Reds,font_size=8)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=nx.get_edge_attributes(G,'weight'),font_size=8,font_color='red')\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        sm.set_array(weights)\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.set_title('Weight')\n",
    "        plt.title(\"Node {}'s {}-hop neighborhood important nodes\".format(node_idx, n_hop))\n",
    "    else:\n",
    "        rel = nx.get_edge_attributes(G,'weight')\n",
    "        rel = {k: [data.i2rel[i][0] for i in v] for k,v in rel.items()}\n",
    "        col_weights = [sum(weights[i], 3) if len(weights[i]) > 1 else weights[i][0] for i in range(len(weights))]\n",
    "        nx.draw(G, pos,labels = labeldict, edge_color=col_weights,edgelist=edges,node_color =  color_list, cmap=\"Set2\",font_size=7, arrows = True)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=rel,font_size=8,font_color='red')\n",
    "        \n",
    "        res = Counter(unnest_list(rel.values()))\n",
    "        print(res)\n",
    "    if result_weights:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}graphs/Explanation_{node_idx}_weights.png')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}graphs/Explanation_{node_idx}_relations.png')    \n",
    "        #plt.show()\n",
    "        return res, weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.vstack((v,h.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(node_idx, 2, data, v,h, 0.5,name, result_weights=False, low_threshold=False,experiment_name=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "\n",
    "        _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "\n",
    "        pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "n_hops = 0\n",
    "node_idx = 5678\n",
    "#hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "sub_edges, neighbors, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "\n",
    "sub_edges, neighbors, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "print(len(list(neighbors)))\n",
    "print('shape sub',sub_edges_tensor_h.shape, sub_edges_tensor_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5677\n",
    "count = 0\n",
    "\n",
    "\n",
    "\n",
    "for m in data.triples:\n",
    "    if m[0] == node_idx or m[2] == node_idx:\n",
    "        print(m)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the mask to give priority to the 1st hop relations\n",
    "neighbors_h, neighbors_v = list((1,1)), list((2,3))\n",
    "neighbors = len(set(neighbors_v + neighbors_h))\n",
    "len(neighbors)\n",
    "#set(list((neighbors_h, neighbors_v)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the graph into subgraphs per relation \n",
    "#create dictionary where each key is a relation and each value is a list of the triples with that relation\n",
    "#each value is a tensor with the edge indices of the triples with that relation\n",
    "\n",
    "dict_rel = {}\n",
    "for i in range(data.num_relations):\n",
    "    dict_rel[i] = []\n",
    "for i in range(len(data.triples)):\n",
    "\n",
    "    dict_rel[int(data.triples[i][1])].append(torch.tensor([data.triples[i][0], data.triples[i][2]]))\n",
    "\n",
    "dict_rel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
