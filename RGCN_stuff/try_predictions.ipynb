{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import kgbench as kg\n",
    "import fire, sys\n",
    "import math\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# #\n",
    "#from torch_geometric.utils import to_networkx\n",
    "# import networkx as nx\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from rgcn_model import RGCN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.3288s).\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('aifb', torch=True, final=False)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def convert_binary(sparse_tensor, threshold):\n",
    "#     # convert values to either 0 or 1 based on a threshold of 0.5\n",
    "#     mask = sparse_tensor._values() > threshold\n",
    "#     converted_values = torch.zeros_like(sparse_tensor._values())\n",
    "#     converted_values[mask] = 1\n",
    "#     #print number of non zero values\n",
    "#     print(\"Number of non zero values: \", converted_values.nonzero().size(0))\n",
    "\n",
    "#     # create a new sparse tensor with the converted values\n",
    "#     converted_sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), converted_values, size=sparse_tensor.size())\n",
    "#     return converted_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2924s).\n",
      "29043\n",
      "26666\n",
      "ypred explain tensor([0.4507, 0.1969, 0.2936, 0.0587], grad_fn=<SoftmaxBackward0>)\n",
      "v binary: tensor(indices=tensor([[ 23451,  23451,  23451,  ..., 329925, 329926, 329927],\n",
      "                       [  5678,   5743,   5746,  ...,   5230,   5230,   5230]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
      "       size=(753935, 8285), nnz=1311, layout=torch.sparse_coo) tensor(119)\n",
      "ypred explain binary tensor([0.3810, 0.2180, 0.3542, 0.0468], grad_fn=<SoftmaxBackward0>)\n",
      "ypred true tensor([0])\n",
      "ypred full tensor([9.8647e-01, 5.4700e-04, 1.2982e-02, 1.1929e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 27, 10: 1, 15: 1, 18: 35, 21: 21, 27: 1, 30: 30, 36: 3, 0: 101})"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'aifb'\n",
    "\n",
    "data = kg.load(name, torch=True) \n",
    "print(data.triples.shape[0])\n",
    "node_idx = 5678\n",
    "\n",
    "# else:\n",
    "#     data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "print(data.triples.shape[0])\n",
    "data.triples = torch.Tensor(data.triples).to(int)#data.triples.clone().detach()\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)#data.withheld.clone().detach()\n",
    "data.training = torch.Tensor(data.training).to(int)#data.training.clone().detach()\n",
    "#\n",
    "get_relations(data)\n",
    "d_classes(data)\n",
    "dict_classes = {key.item(): data.withheld[:, 0][data.withheld[:, 1] == key].tolist() for key in torch.unique(data.withheld[:, 1])}\n",
    "if name != 'aifb':\n",
    "    node_idx = dict_classes[0][0]\n",
    "\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "# v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "# h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "model = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/model_{name}_prune_True')\n",
    "v = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "# h = select_entity(h, 5230)\n",
    "# v = select_entity(v, 5230)\n",
    "\n",
    "\n",
    "\n",
    "# v = torch.sparse_coo_tensor(v.coalesce().indices(), torch.sigmoid(v.coalesce().values()), v.size(), requires_grad=True)\n",
    "# h = torch.sparse_coo_tensor(h.coalesce().indices(), torch.sigmoid(h.coalesce().values()), h.size(), requires_grad=True)\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)\n",
    "# print(v.coalesce().values()[v.coalesce().values()>0.5])\n",
    "# print(h.coalesce().values())\n",
    "\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "print('v binary:',v_bin, torch.count_nonzero(v_bin.coalesce().values()))\n",
    "res = nn.Softmax(dim=0)(model.forward2(h_bin,v_bin)[node_idx, :])\n",
    "print('ypred explain binary', res)\n",
    "\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "    \n",
    "from r_exp import hor_ver_graph\n",
    "model.eval()\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "v,h = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(v,h,data, node_idx)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5678\n",
    "init = 'normal'\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5168, 0.5132, 0.5084,  ..., 0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.coalesce().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[5357, 5357, 5502, 5746, 6404, 6881, 7100, 7968, 8013],\n",
      "                       [5743, 5777, 5837, 7068, 8013, 5678, 5746, 6404, 5743]]),\n",
      "       values=tensor([1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
      "       size=(8014, 8014), nnz=9, layout=torch.sparse_coo) tensor(0.)\n",
      "tensor(9)\n",
      "node_idx in v\n",
      "ypred explain tensor([0.2730, 0.2465, 0.2477, 0.2329], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "def find_threshold(sparse_tensor):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == 10:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def convert_back(sparse_tensor, data):\n",
    "    sparse_tensor = torch.sparse_coo_tensor(\n",
    "        sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    )\n",
    "    return sparse_tensor\n",
    "\n",
    "t =     find_threshold(v)\n",
    "v, h = convert_back(v, data), convert_back(h, data)\n",
    "print(sub(v,t),t)\n",
    "v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "print(v.coalesce().values().count_nonzero())\n",
    "v_sub = sub(v,t)\n",
    "if node_idx in v_sub.coalesce().indices():\n",
    "    print('node_idx in v')\n",
    "else:\n",
    "    print('node_idx not in v')\n",
    "\n",
    "#print(t, sub(v,t))\n",
    "\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ypred explain tensor([0.2730, 0.2465, 0.2477, 0.2329], grad_fn=<SoftmaxBackward0>)\n",
      "tensor(12)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[6881,    2, 5678],\n",
       "        [7100,    2, 5746],\n",
       "        [7968,    2, 6404],\n",
       "        [8013,    2, 5743],\n",
       "        [5357,   18, 5743],\n",
       "        [5357,   18, 5777],\n",
       "        [5502,   21, 5837],\n",
       "        [5746,   30, 7068],\n",
       "        [6404,   30, 8013],\n",
       "        [5357,    0, 5678],\n",
       "        [5431,    0, 5879],\n",
       "        [5494,    0, 5745],\n",
       "        [5494,    0, 5824],\n",
       "        [5502,    0, 5767],\n",
       "        [5502,    0, 5814],\n",
       "        [5743,    0, 8014],\n",
       "        [5746,    0, 8010],\n",
       "        [5747,    0, 5939],\n",
       "        [6611,    0, 6888],\n",
       "        [6981,    0, 5678],\n",
       "        [7045,    0, 5743]])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "def find_threshold(sparse_tensor, num_exp):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == num_exp:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "\n",
    "def threshold_mask(h,v ,data, num_exp):\n",
    "    ''' Apply a threshold mask to the adjacency matrix'''\n",
    "    t =     find_threshold(v, num_exp)\n",
    "    #v, h = convert_back(v, data), convert_back(h, data)\n",
    "    v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "    return h,v\n",
    "\n",
    "h,v = threshold_mask(h,v, data, 10)\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)    \n",
    "\n",
    "v.coalesce().values().count_nonzero()\n",
    "masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "print(masked_hor_sub.coalesce().values().count_nonzero())\n",
    "m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important relations {'author': 27, 'fax': 1, 'homepage': 1, 'isWorkedOnBy': 35, 'member': 21, 'phone': 1, 'publication': 30, 'worksAtProject': 3}\n",
      "Important relations {'author': 4, 'isWorkedOnBy': 2, 'member': 1, 'publication': 2}\n"
     ]
    }
   ],
   "source": [
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "\n",
    "masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "counter = dict(Counter(m[:,1].tolist()))\n",
    "counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "print('Important relations', counter)\n",
    "\n",
    "def important_relation(v,h,data):\n",
    "    masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "    m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "    counter = dict(Counter(m[:,1].tolist()))\n",
    "    counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "    print('Important relations', counter)\n",
    "    return counter\n",
    "\n",
    "v,h = threshold_mask(h,v, data, 10)\n",
    "important_relation(v,h,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(indices=tensor([], size=(2, 0)),\n",
       "       values=tensor([], size=(0,)),\n",
       "       size=(0, 0), nnz=0, layout=torch.sparse_coo)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# def find_threshold_sparse_tensor(sparse_tensor, index, n):\n",
    "#     # Get the values and indices of the sparse tensor\n",
    "#     values = sparse_tensor.coalesce().values()\n",
    "#     indices = sparse_tensor.coalesce().indices()\n",
    "\n",
    "#     # Filter the values and indices based on the specified index\n",
    "#     selected_values = values[indices[1] == index]\n",
    "\n",
    "#     # Sort the selected values in descending order\n",
    "#     sorted_values, _ = torch.sort(selected_values, descending=True)\n",
    "\n",
    "#     # Find the threshold value\n",
    "#     if n < sorted_values.size(0):\n",
    "#         threshold = sorted_values[n - 1]\n",
    "#     else:\n",
    "#         threshold = sorted_values[-1]\n",
    "\n",
    "#     return threshold\n",
    "def find_threshold_sparse_tensor(sparse_tensor, index, n):\n",
    "    # Get the values and indices of the sparse tensor\n",
    "    values = sparse_tensor.coalesce().values()\n",
    "    indices = sparse_tensor.coalesce().indices()\n",
    "\n",
    "    # Filter the values and indices based on the specified index\n",
    "    selected_values = values[indices[0] == index]\n",
    "\n",
    "    # Sort the selected values in descending order\n",
    "    sorted_values, _ = torch.sort(selected_values, descending=True)\n",
    "\n",
    "    # Find the threshold value\n",
    "    if n <= sorted_values.size(0):\n",
    "        threshold = sorted_values[n - 1]\n",
    "    else:\n",
    "        threshold = sorted_values[-1]\n",
    "\n",
    "    return threshold\n",
    "\n",
    "# Example sparse tensor\n",
    "sparse_tensor = h\n",
    "\n",
    "# Specify the index and maximum number of values\n",
    "index = 5757\n",
    "n = 10\n",
    "# Find the threshold\n",
    "t = find_threshold_sparse_tensor(sparse_tensor, index, n)\n",
    "\n",
    "v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "sub(h,t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def is_graph_connected(adjacency_matrix):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    visited = torch.zeros(n, dtype=torch.bool)\n",
    "    stack = [0]  # Start traversal from node 0\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        visited[node] = True\n",
    "\n",
    "        neighbor_indices = adjacency_matrix.coalesce().indices()\n",
    "        neighbor_values = adjacency_matrix.coalesce().values()\n",
    "\n",
    "        node_neighbors = neighbor_indices[0, neighbor_indices[1] == node]\n",
    "        for neighbor in node_neighbors:\n",
    "            if not visited[neighbor]:\n",
    "                stack.append(neighbor)\n",
    "                print(stack)\n",
    "\n",
    "    return visited.all()\n",
    "\n",
    "\n",
    "def remove_disconnected_edges(adjacency_matrix):\n",
    "    if not is_graph_connected(adjacency_matrix):\n",
    "        connected_indices = []\n",
    "        connected_values = []\n",
    "\n",
    "        for node in range(adjacency_matrix.size(0)):\n",
    "            row = adjacency_matrix[node]\n",
    "            node_neighbors = row.coalesce().indices()\n",
    "            node_values = row.coalesce().values()\n",
    "\n",
    "            connected_indices.extend([(node, neighbor) for neighbor in node_neighbors])\n",
    "            connected_values.extend(node_values)\n",
    "\n",
    "        connected_indices = torch.tensor(connected_indices).t()\n",
    "        connected_values = torch.tensor(connected_values)\n",
    "        connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "            connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "        )\n",
    "\n",
    "        return connected_adjacency_matrix\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "is_graph_connected(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(indices=tensor([[6860, 6860, 6860,  ..., 6810, 6811, 6812],\n",
      "                       [5757, 5789, 5791,  ..., 5230, 5230, 5230]]),\n",
      "       values=tensor([0.4919, 0.4875, 0.4830,  ..., 0.4982, 0.4813, 0.4802]),\n",
      "       size=(753935, 8285), nnz=1132, layout=torch.sparse_coo)\n",
      "tensor(indices=tensor([[ 908, 1002, 2227,  ..., 7973, 7973, 7973],\n",
      "                       [ 908, 1002, 2227,  ..., 5791, 5900, 7973]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 0., 0., 1.]),\n",
      "       size=(753935, 8285), nnz=1157, layout=torch.sparse_coo)\n",
      "tensor(25) tensor(25)\n",
      "ypred explain tensor([0.2719, 0.2475, 0.2517, 0.2289], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "node_idx = 5757\n",
    "v = torch.load(f'chk/aifb_chk/experiments/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_normal_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/experiments/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_normal_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "def select_connected_subgraph(adjacency_matrix, given_node,data):\n",
    "    adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        adjacency_matrix.coalesce().indices()%data.num_entities, adjacency_matrix.coalesce().values(), size=adjacency_matrix.size()\n",
    "    )\n",
    "    #adjacency_matrix = sub(adjacency_matrix, 0.5)\n",
    "    print(adjacency_matrix)\n",
    "    num_nodes = adjacency_matrix.size(0)\n",
    "    visited = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    connected_nodes = set()\n",
    "    stack = []\n",
    "\n",
    "    # Starting with the given node\n",
    "    stack.append(given_node)\n",
    "    connected_nodes.add(given_node)\n",
    "    visited[given_node] = True\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        node = stack.pop()\n",
    "        neighbors = adjacency_matrix[node].coalesce().indices()\n",
    "        for i in range(neighbors.size(1)):\n",
    "            neighbor = neighbors[:, i]\n",
    "            if not visited[neighbor[0]]:\n",
    "                stack.append(neighbor[0])\n",
    "                connected_nodes.add(neighbor[0])\n",
    "                visited[neighbor[0]] = True\n",
    "\n",
    "    # Select the indices of the connected nodes\n",
    "    connected_indices = []\n",
    "    for node in connected_nodes:\n",
    "        connected_indices.append([node, node])\n",
    "\n",
    "    # Create the connected adjacency matrix\n",
    "    connected_indices = torch.tensor(connected_indices, dtype=torch.long).t()\n",
    "\n",
    "    # if adjacency_matrix.shape[0] > adjacency_matrix.shape[1]:\n",
    "        \n",
    "    #     connected_values = v.coalesce().values()[torch.where(connected_indices)[1]]\n",
    "    # else:\n",
    "    #     connected_values = v.coalesce().values()[torch.where(connected_indices)[0]]\n",
    "\n",
    "    connected_values = torch.ones(connected_indices.size(1))\n",
    "    #torch.ones(connected_indices.size(1))\n",
    "    disconnected_indices = get_non_selected_indices(adjacency_matrix, connected_indices)\n",
    "    disconnected_values = torch.zeros(disconnected_indices.size(1))\n",
    "    connected_indices = torch.cat([connected_indices, disconnected_indices], dim=1)\n",
    "    connected_values = torch.cat([connected_values, disconnected_values])\n",
    "    connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "    )\n",
    "\n",
    "    return connected_adjacency_matrix\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "v = select_connected_subgraph(v, node_idx,data)\n",
    "h = select_connected_subgraph(v, node_idx,data).t()\n",
    "print(v.coalesce().values().count_nonzero(), h.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "where() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n * (Tensor condition, Tensor input, Number other)\n * (Tensor condition, Number self, Number other)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[92], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m selected_indexes \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([[\u001b[39m6805\u001b[39m, \u001b[39m7933\u001b[39m, \u001b[39m5230\u001b[39m, \u001b[39m6860\u001b[39m, \u001b[39m7731\u001b[39m, \u001b[39m5791\u001b[39m, \u001b[39m1002\u001b[39m, \u001b[39m2227\u001b[39m, \u001b[39m6598\u001b[39m,  \u001b[39m908\u001b[39m, \u001b[39m6874\u001b[39m, \u001b[39m7837\u001b[39m,\n\u001b[1;32m      3\u001b[0m          \u001b[39m7973\u001b[39m, \u001b[39m5789\u001b[39m, \u001b[39m5900\u001b[39m, \u001b[39m6603\u001b[39m, \u001b[39m6604\u001b[39m, \u001b[39m6920\u001b[39m, \u001b[39m7857\u001b[39m, \u001b[39m6599\u001b[39m, \u001b[39m5886\u001b[39m, \u001b[39m6582\u001b[39m, \u001b[39m6976\u001b[39m, \u001b[39m7905\u001b[39m,\n\u001b[1;32m      4\u001b[0m          \u001b[39m5757\u001b[39m],\n\u001b[1;32m      5\u001b[0m         [\u001b[39m6805\u001b[39m, \u001b[39m7933\u001b[39m, \u001b[39m5230\u001b[39m, \u001b[39m6860\u001b[39m, \u001b[39m7731\u001b[39m, \u001b[39m5791\u001b[39m, \u001b[39m1002\u001b[39m, \u001b[39m2227\u001b[39m, \u001b[39m6598\u001b[39m,  \u001b[39m908\u001b[39m, \u001b[39m6874\u001b[39m, \u001b[39m7837\u001b[39m,\n\u001b[1;32m      6\u001b[0m          \u001b[39m7973\u001b[39m, \u001b[39m5789\u001b[39m, \u001b[39m5900\u001b[39m, \u001b[39m6603\u001b[39m, \u001b[39m6604\u001b[39m, \u001b[39m6920\u001b[39m, \u001b[39m7857\u001b[39m, \u001b[39m6599\u001b[39m, \u001b[39m5886\u001b[39m, \u001b[39m6582\u001b[39m, \u001b[39m6976\u001b[39m, \u001b[39m7905\u001b[39m,\n\u001b[1;32m      7\u001b[0m          \u001b[39m5757\u001b[39m]])\n\u001b[1;32m      8\u001b[0m \u001b[39m#v = torch.sparse_coo_tensor(v.coalesce().indices(), v.coalesce().values(), v.size())\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m values_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mwhere(selected_indexes[\u001b[39m0\u001b[39;49m],v)\n\u001b[1;32m     10\u001b[0m \u001b[39mprint\u001b[39m(values_index)\n\u001b[1;32m     11\u001b[0m values \u001b[39m=\u001b[39m v\u001b[39m.\u001b[39mcoalesce()\u001b[39m.\u001b[39mvalues()[values_index]\n",
      "\u001b[0;31mTypeError\u001b[0m: where() received an invalid combination of arguments - got (Tensor, Tensor), but expected one of:\n * (Tensor condition)\n * (Tensor condition, Tensor input, Tensor other, *, Tensor out)\n * (Tensor condition, Number self, Tensor other)\n * (Tensor condition, Tensor input, Number other)\n * (Tensor condition, Number self, Number other)\n"
     ]
    }
   ],
   "source": [
    "v \n",
    "selected_indexes = torch.tensor([[6805, 7933, 5230, 6860, 7731, 5791, 1002, 2227, 6598,  908, 6874, 7837,\n",
    "         7973, 5789, 5900, 6603, 6604, 6920, 7857, 6599, 5886, 6582, 6976, 7905,\n",
    "         5757],\n",
    "        [6805, 7933, 5230, 6860, 7731, 5791, 1002, 2227, 6598,  908, 6874, 7837,\n",
    "         7973, 5789, 5900, 6603, 6604, 6920, 7857, 6599, 5886, 6582, 6976, 7905,\n",
    "         5757]])\n",
    "#v = torch.sparse_coo_tensor(v.coalesce().indices(), v.coalesce().values(), v.size())\n",
    "values_index = torch.where(selected_indexes[0],v)\n",
    "print(values_index)\n",
    "values = v.coalesce().values()[values_index]\n",
    "values.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39msparse_coo_tensor(selected_indices, torch\u001b[39m.\u001b[39mones(selected_indices\u001b[39m.\u001b[39msize(\u001b[39m1\u001b[39m)), size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m))\u001b[39m.\u001b[39mto_dense()\u001b[39m.\u001b[39mbool()\n\u001b[1;32m     14\u001b[0m \u001b[39m# Use torch.where to select values based on the mask\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m selected_values \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mwhere(mask, sparse_tensor\u001b[39m.\u001b[39;49mcoalesce()\u001b[39m.\u001b[39;49mvalues(), torch\u001b[39m.\u001b[39;49mzeros(mask\u001b[39m.\u001b[39;49msum()))\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(selected_values)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Example sparse tensor\n",
    "indices = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "values = torch.tensor([2, 4, 6])\n",
    "sparse_tensor = torch.sparse_coo_tensor(indices, values, size=(2, 2))\n",
    "\n",
    "# Example selected indices\n",
    "selected_indices = torch.tensor([[0, 1], [1, 1]])\n",
    "\n",
    "# Convert selected indices to a boolean mask\n",
    "mask = torch.sparse_coo_tensor(selected_indices, torch.ones(selected_indices.size(1)), size=(2, 2)).to_dense().bool()\n",
    "\n",
    "# Use torch.where to select values based on the mask\n",
    "selected_values = torch.where(mask, sparse_tensor.coalesce().values(), torch.zeros(mask.sum()))\n",
    "\n",
    "print(selected_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [0, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_non_selected_indices(sparse_tensor, selected_indices):\n",
    "    original_indices = sparse_tensor.coalesce().indices()\n",
    "    selected_set = set(map(tuple, selected_indices.t().tolist()))\n",
    "\n",
    "    non_selected_indices = []\n",
    "    for index in original_indices.t().tolist():\n",
    "        if tuple(index) not in selected_set:\n",
    "            non_selected_indices.append(index)\n",
    "\n",
    "    return torch.tensor(non_selected_indices).t()\n",
    "\n",
    "# Example usage\n",
    "sparse_tensor = torch.sparse_coo_tensor(torch.tensor([[0, 0, 1, 1], [0, 1, 0, 2]]), torch.tensor([2, 3, 4, 5]), size=(2, 3))\n",
    "selected_indices = torch.tensor([[0, 1], [1, 2]])  # Example selected indices\n",
    "\n",
    "non_selected_indices = get_non_selected_indices(sparse_tensor, selected_indices)\n",
    "print(non_selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sv,ov = v_bin.coalesce().indices()%data.num_entities\n",
    "sh,oh = h_bin.coalesce().indices()%data.num_entities\n",
    "\n",
    "v = torch.sparse_coo_tensor(torch.stack([sv,ov]), v_bin.coalesce().values(), v_bin.size())\n",
    "h = torch.sparse_coo_tensor(torch.stack([sh,oh]), h_bin.coalesce().values(), h_bin.size())\n",
    "\n",
    "for i in v.coalesce().indices():\n",
    "    if "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kgbench.load.Data at 0x7fee3d3bb580>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(756)\n",
      "ypred explain tensor([0.3810, 0.2180, 0.3542, 0.0468], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "v = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "v, h = select_on_relation_sparse(v,data, 39), select_on_relation_sparse(h,data, 39)\n",
    "#print(v_.coalesce().values().count_nonzero())\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "\n",
    "print(v_bin.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_bin,v_bin)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(555)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0789,  0.0464,  0.0738, -0.0413], grad_fn=<SubBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#inverse predictions \n",
    "v_inv, h_inv = inverse_tensor(v), inverse_tensor(h)\n",
    "print(v_inv.coalesce().values().count_nonzero())\n",
    "\n",
    "out = model.forward2(h_inv,v_inv)\n",
    "\n",
    "res1_m = nn.Softmax(dim=0)(out[node_idx])\n",
    "res - res1_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_tensor(sparse_tensor):\n",
    "    \"\"\" Convert 0 to 1 and viceversa in sparse tensor\n",
    "    The aim is computing the Fidelity- score\"\"\"\n",
    "    sparse_tensor = convert_binary(sparse_tensor, 0.5)\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices=sparse_tensor._indices(), \n",
    "                                        values=1 - sparse_tensor._values(), \n",
    "                                        size=sparse_tensor.size())\n",
    "    return sparse_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data = prunee(data, 2)\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "object_type(v,h,data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(data.num_relations):\n",
    "    print(i, data.i2r[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#I want to get the indices of the triples with type relation \n",
    "output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, 39)\n",
    "output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, 39)\n",
    "objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "list = []\n",
    "for i in objects_types:\n",
    "    list.append(data.i2e[i[2]][0].split('#')[1])\n",
    "result = Counter(list)\n",
    "print(result)\n",
    "#probably node person is the most frequent - what about I delete all the triples where Person is the object?????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_entity(sparse_tensor,class_id):\n",
    "    ''' Select the subset of the tensor based on the id of the class to be zeroed out'''\n",
    "    value_indices = torch.where(sparse_tensor.coalesce().indices() == class_id)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices[1]] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "\n",
    "    return masked_sparse_tensor\n",
    "select_entity(h, 5230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5230*39%5230 \n",
    "#class_id = 5230\n",
    "#value_indices = torch.where(v.coalesce().indices() == class_id or v.coalesce().indices()%class_id == 0)\n",
    "v.coalesce().indices()\n",
    "154915"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation,value =1):\n",
    "    \"\"\" Selects the values of a sparse tensor based on the relation\"\"\"\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = value\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.where(h.coalesce().indices() == torch.tensor(5230))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_type(v,h,data, relation_id = None,type=True):\n",
    "    ''' Get the object class of a specific relation'''\n",
    "    if type:\n",
    "        relation_id = [i for i in range(data.num_relations) if 'type' in data.i2r[i]][-1]\n",
    "    output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, relation_id)\n",
    "    output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, relation_id)\n",
    "    objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "    list = []\n",
    "    for i in objects_types:\n",
    "        list.append(data.i2e[i[2]][0])#.split('#')[1])\n",
    "    result = Counter(list)\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "for node_idx in data.withheld[:,0]:\n",
    "    h, v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}'), torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "    print(f'node {node_idx}:', object_type(v,h,data, 39))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "relation_id = [i for i in range(data.num_relations) if 'type' in data.i2r[i]]\n",
    "relation_id\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation,value =1):\n",
    "    \"\"\" Selects the values of a sparse tensor based on the relation\"\"\"\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = value\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e,n,x = find_n_hop_neighbors(edge_index_oneadj(data.triples) ,2, 5757)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in data.triples:\n",
    "    if i[0] == 5757:\n",
    "        list.append(i[2])\n",
    "    if i[2] == 5757:\n",
    "        list.append(i[0])\n",
    "\n",
    "count = []  \n",
    "for i in data.triples: \n",
    "    for j in list:\n",
    "        if i[0] == j or i[2] == j:\n",
    "            count.append[]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld[torch.where(data.withheld[:, 0] == torch.tensor([5757])),1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = d_classes(data)\n",
    "for c in classes:\n",
    "    for node in c:\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = d_classes(data)\n",
    "count = 0\n",
    "dict_rel_all_classes = {}\n",
    "dict_rel = {}\n",
    "for j in range(len(classes)):\n",
    "    dict_rel = {}\n",
    "    for node_idx in classes[j]:\n",
    "        for i in data.triples:\n",
    "            if i[0] == node_idx or i[2] == node_idx:\n",
    "                count += 1\n",
    "                if data.i2r[int(i[1])] not in dict_rel.keys():\n",
    "                    dict_rel[data.i2r[int(i[1])]] = 1\n",
    "                else:\n",
    "                    dict_rel[data.i2r[int(i[1])]] += 1\n",
    "    dict_rel_all_classes[j] = dict_rel\n",
    "\n",
    "count\n",
    "dict_rel_all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_0 = select_on_relation_sparse(v_bin,data, 30)\n",
    "h_0 = select_on_relation_sparse(h_bin,data, 30)\n",
    "\n",
    "print(v_0.coalesce().values().count_nonzero(),h_0.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_0,v_0)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_on_relation_sparse(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 1\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "types = []\n",
    "for i in data.triples:\n",
    "    if i[1]==34:\n",
    "        types.append(int(i[2]))\n",
    "        count+=1\n",
    "count\n",
    "types = set(types)\n",
    "types = [data.i2e[i] for i in types]\n",
    "types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "#loop over keys of counter\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    # v_ = select_on_relation_sparse(v,data, key)\n",
    "    # h_ = select_on_relation_sparse(h,data, key)\n",
    "    v_ = select_one_relation(v,data, key)\n",
    "    h_ = select_one_relation(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        pass\n",
    "        #print(f'wrong prediction without {data.i2r[key]}')\n",
    "    else:\n",
    "        print(f'correct only with {data.i2r[key]}')\n",
    "        print(f'ypred only with {data.i2r[key]}, {key}', res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a baseline: no use RGCNExplainer - just rule out relations based on prediction of the model\n",
    "\n",
    "#node:\n",
    "node_idx = 5678\n",
    "\n",
    "#label for that node\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "\n",
    "#edge index\n",
    "edge_index = edge_index_oneadj(data.triples)\n",
    "\n",
    "#number of hops\n",
    "n_hops = 2\n",
    "\n",
    "#augment dataset with self loops and inverse relations\n",
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "\n",
    "#get the edge index at 2 hops per node\n",
    "_,_,index_h = find_n_hop_neighbors(hor_graph.coalesce().indices(), n_hops, node_idx)\n",
    "_,_,index_v = find_n_hop_neighbors(ver_graph.coalesce().indices(), n_hops, node_idx)\n",
    "\n",
    "h = torch.sparse_coo_tensor(index_h, torch.ones(index_h.shape[1]), hor_graph.size() )\n",
    "v = torch.sparse_coo_tensor(index_v, torch.ones(index_v.shape[1]), ver_graph.size() )\n",
    "\n",
    "#match to triple\n",
    "m = match_to_triples(v,h, data)\n",
    "\n",
    "#counter of relations in the 2 hops subgraph\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "#forward pass of the model\n",
    "out = model.forward2(h,v)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print(f'ypred explain all subgraph: {torch.argmax(res)} with prediction probability: {res}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(m[:,1].tolist())\n",
    "\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 9)\n",
    "h.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5757\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "m = match_to_triples(ver_graph,hor_graph,data, node_idx)\n",
    "v, h = ver_graph, hor_graph\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'for node {node_idx}, wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_remove = []\n",
    "for i in range(data.num_relations):\n",
    "    if 'genre' in data.i2r[i]:\n",
    "        print(f'{i}: {data.i2r[i]}')\n",
    "        numbers_to_remove.append(i)\n",
    "numbers_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data.triples:\n",
    "#     for j in numbers_to_remove:\n",
    "#         if i[1] == j:\n",
    "#             print(i)\n",
    "for i in data.triples:\n",
    "    if i[0] ==9662:\n",
    "        print(data.i2e[i[0]], data.i2r[i[1]], data.i2e[i[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_most_genre'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.i2e[3599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld[data.withheld[:,0]==10241,1]\n",
    "data.withheld[torch.where(data.withheld[:, 0] == torch.tensor([10112])),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.entities = np.append(data.triples[:,0].detach().numpy(),(data.triples[:,2].detach().numpy()))\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "    \n",
    "relations = ['label', 'node_idx','number_neighbors', 'prediction_explain', 'prediction_full', 'prediction_explain_binary'] + relations\n",
    "df = pd.DataFrame(columns=relations)\n",
    "d = d_classes(data)\n",
    "\n",
    "#count how many nodes per class\n",
    "count = {}\n",
    "for i in range(len(d)):\n",
    "    count[i] = len(d[i])\n",
    "count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the node of the most important relations - the relations with the highest weights\n",
    "\n",
    "tensor_list = (list(v.coalesce().indices()[1][v.coalesce().values()>0.5]) + list(h.coalesce().indices()[0][h.coalesce().values()>0.5]))\n",
    "float_list = [tensor.item() for tensor in tensor_list]\n",
    "len(set(float_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "others = []\n",
    "for i in data.triples:\n",
    "\n",
    "    if i[0] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[2])\n",
    "    if i[2] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[0])\n",
    "\n",
    "count\n",
    "others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "l = []\n",
    "a = []\n",
    "for i in data.triples:\n",
    "    for n in others:\n",
    "        if i[0] == int(n) or i[2] == int(n):\n",
    "            count += 1\n",
    "            l.append(n)\n",
    "            a.append(i)\n",
    "            #print(i)\n",
    "            break\n",
    "res = set(l)\n",
    "resa = set(a)\n",
    "print(len(resa))            \n",
    "print(len(res))\n",
    "count\n",
    "#others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_repeating_sublists(sublists):\n",
    "    repeating_elements = {}\n",
    "\n",
    "    for sublist in sublists:\n",
    "        key1 = (sublist[0], sublist[2])\n",
    "        key2 = (sublist[2], sublist[0])\n",
    "\n",
    "        if key1 in repeating_elements:\n",
    "            repeating_elements[key1].append(sublist[1])\n",
    "        elif key2 in repeating_elements:\n",
    "            repeating_elements[key2].append(sublist[1])\n",
    "        else:\n",
    "            repeating_elements[key1] = [sublist[1]]\n",
    "\n",
    "    result_array = []\n",
    "    for key, values in repeating_elements.items():\n",
    "        if len(values) > 1:\n",
    "            result_array.append([key[0], values, key[1]])\n",
    "        else:\n",
    "            result_array.append([key[0], [values[0]], key[1]])\n",
    "\n",
    "    return result_array\n",
    "\n",
    "def unnest_list(nested_list):\n",
    "    return [item for sublist in nested_list for item in (unnest_list(sublist) if isinstance(sublist, list) else [sublist])]\n",
    "\n",
    "def visualize(node_idx, n_hop, data, masked_ver,threshold,name, result_weights=True, low_threshold=False ):\n",
    "    \"\"\" \n",
    "    Visualize important nodes for node idx prediction\n",
    "    \"\"\"\n",
    "    dict_index = dict_index_classes(data,masked_ver)\n",
    "    \n",
    "    #select only nodes with a certain threshold\n",
    "    sel_masked_ver = sub_sparse_tensor(masked_ver, threshold,data, low_threshold)\n",
    "    if len(sel_masked_ver)==0:\n",
    "        sel_masked_ver=sub_sparse_tensor(masked_ver, 0,data, low_threshold)\n",
    "    print('sel masked ver',sel_masked_ver)\n",
    "    indices_nodes = sel_masked_ver.coalesce().indices().detach().numpy()\n",
    "    new_index = np.transpose(np.stack((indices_nodes[0], indices_nodes[1]))) #original edge indexes\n",
    "\n",
    "    \n",
    "    \n",
    "    G = nx.Graph()\n",
    "    if result_weights:\n",
    "        values = sel_masked_ver.coalesce().values().detach().numpy()\n",
    "        for s,p,o in zip(indices_nodes[0],values , indices_nodes[1]):\n",
    "            G.add_edge(int(s), int(o), weight=np.round(p, 2))\n",
    "\n",
    "    else:\n",
    "\n",
    "        triples_matched = match_to_triples(sel_masked_ver, data)\n",
    "        l = []\n",
    "        for i in triples_matched[:,1]:\n",
    "            l.append(data.i2rel[int(i)][0])\n",
    "        triples_matched = find_repeating_sublists(triples_matched.numpy())\n",
    "        for s,p,o in triples_matched:\n",
    "            G.add_edge(int(s), int(o), weight=p)\n",
    "\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    weights = [[item] if not isinstance(item, list) else item for item in weights]\n",
    "\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    ordered_dict = {}\n",
    "    for item in list(G.nodes):\n",
    "        if item in ordered_dict:\n",
    "            ordered_dict[item].append(dict_index[item])\n",
    "        else:\n",
    "            ordered_dict[item] =  dict_index[item]\n",
    "\n",
    "    dict_index = ordered_dict\n",
    "\n",
    "    labeldict = {}\n",
    "    for node in G.nodes:\n",
    "        labeldict[int(node)] = int(node)  \n",
    "\n",
    "\n",
    "    dict = {}\n",
    "    for k,v in dict_index.items():\n",
    "        for k1,v1 in data.entities_classes.items():\n",
    "            if v==k1: \n",
    "\n",
    "                dict[k] = v1\n",
    "            else:\n",
    "                if k not in dict:\n",
    "                    dict[k] = 0\n",
    "                \n",
    "\n",
    "    color_list = list(dict.values())\n",
    "    color_list = list(encode_dict(dict_index).values())\n",
    "\n",
    "\n",
    "    col_weights = [weights[i][0] for i in range(len(weights))]\n",
    "    if result_weights:\n",
    "        \n",
    "        nx.draw(G, pos,labels = labeldict,  edgelist=edges, edge_color=col_weights, node_color =  color_list, cmap=\"Set2\",edge_cmap=plt.cm.Reds,font_size=8)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=nx.get_edge_attributes(G,'weight'),font_size=8,font_color='red')\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        sm.set_array(weights)\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.set_title('Weight')\n",
    "        plt.title(\"Node {}'s {}-hop neighborhood important nodes\".format(node_idx, n_hop))\n",
    "    else:\n",
    "        rel = nx.get_edge_attributes(G,'weight')\n",
    "        rel = {k: [data.i2rel[i][0] for i in v] for k,v in rel.items()}\n",
    "        col_weights = [sum(weights[i], 3) if len(weights[i]) > 1 else weights[i][0] for i in range(len(weights))]\n",
    "        nx.draw(G, pos,labels = labeldict, edge_color=col_weights,edgelist=edges,node_color =  color_list, cmap=\"Set2\",font_size=7, arrows = True)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=rel,font_size=8,font_color='red')\n",
    "        \n",
    "        res = Counter(unnest_list(rel.values()))\n",
    "    if result_weights:\n",
    "        if not os.path.exists(f'chk/{name}_chk/graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/graphs/Explanation_{node_idx}_{n_hop}_weights.png')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(f'chk/{name}_chk/graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/graphs/Explanation_{node_idx}_{n_hop}_relations.png')    \n",
    "        #plt.show()\n",
    "        return res, weights\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/masked_adj/masked_ver{node_idx}_new')\n",
    "res, weights = visualize(node_idx, 2, data, v, 0, name, result_weights=False, low_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def hor_ver_graph(triples, n, r):\n",
    "    \"\"\"\n",
    "    input: triples, number of nodes, number of relations\n",
    "    output: hor_graph, ver_graph : horizontally and vertically stacked adjacency matrix\n",
    "    \"\"\"\n",
    "\n",
    "    hor_ind, hor_size = adj(triples, n, 2*r+1, vertical=False)\n",
    "    ver_ind, ver_size = adj(triples, n, 2*r+1, vertical=True)\n",
    "\n",
    "    rn, _ = hor_size  # horizontally stacked adjacency matrix size\n",
    "    r = rn // n  # number of relations enriched divided by number of nodes\n",
    "\n",
    "    vals = torch.ones(ver_ind.size(0), dtype=torch.float)  # number of enriched triples\n",
    "\n",
    "    hor_graph = torch.sparse.FloatTensor(hor_ind.t(), vals, hor_size)  # size: n, r, emb\n",
    "    ver_graph = torch.sparse.FloatTensor(ver_ind.t(), vals, ver_size)\n",
    "\n",
    "    return hor_graph, ver_graph\n",
    "\n",
    "def adj(triples, num_nodes, num_rels, cuda=False, vertical=True):\n",
    "    \"\"\"\n",
    "     Computes a sparse adjacency matrix for the given graph (the adjacency matrices of all\n",
    "     relations are stacked vertically).\n",
    "\n",
    "     :param edges: List representing the triples\n",
    "     :param i2r: list of relations\n",
    "     :param i2n: list of nodes\n",
    "     :return: sparse tensor\n",
    "    \"\"\"\n",
    "    r, n = num_rels, num_nodes\n",
    "    size = (r * n, n) if vertical else (n, r * n)\n",
    "\n",
    "    from_indices = []\n",
    "    upto_indices = []\n",
    "\n",
    "    for s, p, o in triples:\n",
    "        offset = p.item() * n\n",
    "        s = offset + s.item() if vertical else s.item()\n",
    "        o = offset + o.item() if not vertical else o.item()\n",
    "        from_indices.append(s)\n",
    "        upto_indices.append(o)\n",
    "\n",
    "    indices = torch.tensor([from_indices, upto_indices], dtype=torch.long, device=d(cuda))\n",
    "\n",
    "    return indices.t(), size\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj(data.triples, data.num_entities, data.num_relations, cuda=False, vertical=True)\n",
    "hor_ver_graph(data.triples, data.num_entities, data.num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_h, edge_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "_,_,sub_edges_tensor_h  = find_n_hop_neighbors(edge_h,2, 5699)\n",
    "_,_,sub_edges_tensor_v  = find_n_hop_neighbors(edge_v,2, 5699)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_edges_tensor_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_edges_tensor\n",
    "indexes = sub_edges_tensor%data.num_entities\n",
    "indexes\n",
    "r = sub_edges_tensor//data.num_entities\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,p = torch.div(sub_edges_tensor, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "s,o = sub_edges_tensor%data.num_entities\n",
    "result = torch.stack([s,p,o], dim=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try initialization where the first hop neighborhood gets initialized with 1s and the rest with different methods??\n",
    "def construct_edge_mask(self, num_nodes,sparse_tensor,data, const_val=1.0, relation_id = 2):\n",
    "    \"\"\"\n",
    "    Construct edge mask\n",
    "    \"\"\"\n",
    "    init_strategy = self.init_strategy\n",
    "    # if num_nodes > 1000:\n",
    "    #     init(strategy=\"const\", const_val=0.1)\n",
    "    data = self.data\n",
    "    num_entities = data.num_entities\n",
    "    torch.manual_seed(42)\n",
    "    mask = nn.Parameter(torch.FloatTensor(num_nodes))\n",
    "\n",
    "    if init_strategy == \"normal\":\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "    elif init_strategy == \"const\":\n",
    "        nn.init.constant_(mask, const_val) \n",
    "    elif init_strategy == \"zero_out\":\n",
    "        '''initialize the mask with the zero out strategy: we zero out edges belonging to specific relations'''\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "        output_indices, output_values, value_indices=select_relation(sparse_tensor,relation_id)\n",
    "        _,_,value_indices1=select_relation(sparse_tensor,33)\n",
    "        print(value_indices, value_indices1)\n",
    "        value_indices = torch.cat((value_indices, value_indices1), 0)\n",
    "        mask.data[[value_indices]] = 0\n",
    "    \n",
    "\n",
    "    elif init_strategy == \"overall_frequency\":\n",
    "        '''Initialize the mask with the overall frequency of the relations'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        overall_rel_frequency = dict(Counter(data.triples[:,1].tolist()))#.most_common()\n",
    "\n",
    "        overall_rel_frequency_  = {key: round(value/len(data.triples[:,1].tolist()),5) for key, value in overall_rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = overall_rel_frequency_[i]\n",
    "    \n",
    "    elif init_strategy == \"relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "    elif init_strategy == \"inverse_relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: 1 - round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "\n",
    "    elif init_strategy == \"domain_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = dict_domain[i]\n",
    "\n",
    "    elif init_strategy == \"range_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "                _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "                mask.data[[value_indices]] = dict_range[i]\n",
    "    elif init_strategy == \"rdf\":\n",
    "        rdf = [i for i in range(data.num_relations) if 'rdf' in data.i2r[i]]\n",
    "        for i in rdf:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    elif init_strategy == \"owl\":\n",
    "        owl = [i for i in range(data.num_relations) if 'owl' in data.i2r[i]]\n",
    "        for i in owl:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    print(f'mask initialized with {init_strategy} strategy: {mask}')   \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 3).to_sparse().requires_grad_(True)\n",
    "print(a)\n",
    "#a.values = torch.ones_like(a.values())\n",
    "values = torch.ones(a._nnz())\n",
    "#len(a.values)\n",
    "a.indices()\n",
    "sparse_tensor = torch.sparse_coo_tensor(a.indices(), torch.ones(a._nnz()), a.size(), requires_grad=True)\n",
    "sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v  = torch.load('chk/aifb_chk/size_0.05_lr_0.1_epochs_30_threshold_0.7_init_normal/masked_adj/masked_ver5757')\n",
    "h = torch.load('chk/aifb_chk/size_0.05_lr_0.1_epochs_30_threshold_0.7_init_normal/masked_adj/masked_hor5757')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > 0.7]\n",
    "nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "nonzero_values = v.coalesce().values()[v.coalesce().values() > 0.7]\n",
    "sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "sel_masked_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = sub_sparse_tensor(v, 0.5, data, low_threshold=False)\n",
    "h = sub_sparse_tensor(h, 0.5, data, low_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() < 0.5]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() < 0.5]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "sub(v, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result\n",
    "\n",
    "m = match_to_triples(v,h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v, data, sparse=True):\n",
    "    if sparse:\n",
    "        # p,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        # s,o = v.coalesce().indices()%data.num_entities\n",
    "        # result = torch.stack([s,p,o], dim=1)\n",
    "        matching = []\n",
    "        indexes = v.coalesce().indices()%data.num_entities\n",
    "        for j in range(indexes.size()[1]):\n",
    "            for triple in data.triples:\n",
    "                if triple[0] == indexes[0][j] and triple[2] == indexes[1][j]:\n",
    "                    matching.append(triple)\n",
    "        result = torch.stack(matching)\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        matching = []\n",
    "        for i,i2 in zip(v[:,0],v[:,1]):\n",
    "            for j,j1,j2, index in zip(data[:,0],data[:,1],  data[:,2], range(len(data[:,0]))):\n",
    "                if i == j and i2 == j2:\n",
    "                    matching.append(data[index])\n",
    "                    \n",
    "\n",
    "        result = torch.stack(matching)\n",
    "    \n",
    "    return result\n",
    "m = match_to_triples(h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "\n",
    "def visualize(node_idx, n_hop, data, masked_ver,masked_hor, threshold,name, result_weights=True, low_threshold=False,experiment_name=None ):\n",
    "    \"\"\" \n",
    "    Visualize important nodes for node idx prediction\n",
    "    \"\"\"\n",
    "    dict_index = dict_index_classes(data,masked_ver)\n",
    "    mask = torch.vstack((masked_ver, masked_hor.t()))\n",
    "    mask = sub(mask, threshold)\n",
    "    print(mask)\n",
    "    #select only nodes with a certain threshold\n",
    "    sel_masked_ver = sub(masked_ver, threshold)\n",
    "    sel_masked_hor = sub(masked_hor, threshold)\n",
    "    if len(sel_masked_ver)==0:\n",
    "        sel_masked_ver=sub_sparse_tensor(masked_ver, 0,data, low_threshold)\n",
    "    #mask = torch.vstack((sel_masked_ver, sel_masked_hor.t()))\n",
    "    print('sel masked ver',mask)\n",
    "    indices_nodes = mask.coalesce().indices().detach().numpy()\n",
    "    new_index = np.transpose(np.stack((indices_nodes[0], indices_nodes[1]))) #original edge indexes\n",
    "\n",
    "    \n",
    "    \n",
    "    G = nx.Graph()\n",
    "    if result_weights:\n",
    "        values = mask.coalesce().values().detach().numpy()\n",
    "        for s,p,o in zip(indices_nodes[0],values , indices_nodes[1]):\n",
    "            G.add_edge(int(s), int(o), weight=np.round(p, 2))\n",
    "\n",
    "    else:\n",
    "\n",
    "        triples_matched = match_to_triples(sel_masked_ver,sel_masked_hor, data)\n",
    "        l = []\n",
    "        for i in triples_matched[:,1]:\n",
    "            l.append(data.i2rel[int(i)][0])\n",
    "        triples_matched = find_repeating_sublists(triples_matched.numpy())\n",
    "        print(triples_matched)\n",
    "        for s,p,o in triples_matched:\n",
    "            G.add_edge(int(s), int(o), weight=p)\n",
    "\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    weights = [[item] if not isinstance(item, list) else item for item in weights]\n",
    "\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    ordered_dict = {}\n",
    "    for item in list(G.nodes):\n",
    "        if item in ordered_dict:\n",
    "            ordered_dict[item].append(dict_index[item])\n",
    "        # else:\n",
    "        #     ordered_dict[item] =  dict_index[item]\n",
    "\n",
    "    dict_index = ordered_dict\n",
    "\n",
    "    labeldict = {}\n",
    "    for node in G.nodes:\n",
    "        labeldict[int(node)] = int(node)  \n",
    "\n",
    "\n",
    "    dict = {}\n",
    "    for k,v in dict_index.items():\n",
    "        for k1,v1 in data.entities_classes.items():\n",
    "            if v==k1: \n",
    "\n",
    "                dict[k] = v1\n",
    "            else:\n",
    "                if k not in dict:\n",
    "                    dict[k] = 0\n",
    "                \n",
    "\n",
    "    color_list = list(dict.values())\n",
    "    color_list = list(encode_dict(dict_index).values())\n",
    "\n",
    "\n",
    "    col_weights = [weights[i][0] for i in range(len(weights))]\n",
    "    if result_weights:\n",
    "        \n",
    "        nx.draw(G, pos,labels = labeldict,  edgelist=edges, edge_color=col_weights, node_color =  color_list, cmap=\"Set2\",edge_cmap=plt.cm.Reds,font_size=8)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=nx.get_edge_attributes(G,'weight'),font_size=8,font_color='red')\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        sm.set_array(weights)\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.set_title('Weight')\n",
    "        plt.title(\"Node {}'s {}-hop neighborhood important nodes\".format(node_idx, n_hop))\n",
    "    else:\n",
    "        rel = nx.get_edge_attributes(G,'weight')\n",
    "        rel = {k: [data.i2rel[i][0] for i in v] for k,v in rel.items()}\n",
    "        col_weights = [sum(weights[i], 3) if len(weights[i]) > 1 else weights[i][0] for i in range(len(weights))]\n",
    "        nx.draw(G, pos,labels = labeldict, edge_color=col_weights,edgelist=edges,node_color =  color_list, cmap=\"Set2\",font_size=7, arrows = True)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=rel,font_size=8,font_color='red')\n",
    "        \n",
    "        res = Counter(unnest_list(rel.values()))\n",
    "        print(res)\n",
    "    if result_weights:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}graphs/Explanation_{node_idx}_weights.png')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}graphs/Explanation_{node_idx}_relations.png')    \n",
    "        #plt.show()\n",
    "        return res, weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.vstack((v,h.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(node_idx, 2, data, v,h, 0.5,name, result_weights=False, low_threshold=False,experiment_name=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "\n",
    "        _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "\n",
    "        pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "n_hops = 0\n",
    "node_idx = 5678\n",
    "#hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "sub_edges, neighbors, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "\n",
    "sub_edges, neighbors, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "print(len(list(neighbors)))\n",
    "print('shape sub',sub_edges_tensor_h.shape, sub_edges_tensor_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5677\n",
    "count = 0\n",
    "\n",
    "\n",
    "\n",
    "for m in data.triples:\n",
    "    if m[0] == node_idx or m[2] == node_idx:\n",
    "        print(m)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the mask to give priority to the 1st hop relations\n",
    "neighbors_h, neighbors_v = list((1,1)), list((2,3))\n",
    "neighbors = len(set(neighbors_v + neighbors_h))\n",
    "len(neighbors)\n",
    "#set(list((neighbors_h, neighbors_v)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the graph into subgraphs per relation \n",
    "#create dictionary where each key is a relation and each value is a list of the triples with that relation\n",
    "#each value is a tensor with the edge indices of the triples with that relation\n",
    "\n",
    "dict_rel = {}\n",
    "for i in range(data.num_relations):\n",
    "    dict_rel[i] = []\n",
    "for i in range(len(data.triples)):\n",
    "\n",
    "    dict_rel[int(data.triples[i][1])].append(torch.tensor([data.triples[i][0], data.triples[i][2]]))\n",
    "\n",
    "dict_rel"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
