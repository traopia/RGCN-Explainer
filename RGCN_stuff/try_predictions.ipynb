{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import src.kgbench as kg\n",
    "import fire, sys\n",
    "import math\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "\n",
    "# #\n",
    "#from torch_geometric.utils import to_networkx\n",
    "# import networkx as nx\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "from rgcn_model import RGCN\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/kgbench/load.py:123: UserWarning: The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, the correct evaluation is to combine train and validation for the final evaluation run.Set include_val to True when loading the data.\n",
      "  warnings.warn('The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data mutag (0.4233s).\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('mutag', torch=True, final=True)\n",
    "data = prunee(data, 2)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5272) tensor(0.5272)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "v = torch.load(f'chk/mutag_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no/masked_adj/masked_ver6594')\n",
    "h = torch.load(f'chk/mutag_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no/masked_adj/masked_hor6594')\n",
    "h_t = find_threshold(h,10)\n",
    "v_t = find_threshold(v,10)\n",
    "print(h_t, v_t)\n",
    "h,v,_,_=threshold_mask(h,v,data,10)\n",
    "v.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/src/kgbench.py:247: UserWarning: The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, the correct evaluation is to combine train and validation for the final evaluation run.Set include_val to True when loading the data.\n",
      "  warnings.warn('The validation data is not added to the training data. For AIFB, MUTAG, BGS and AM, '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2145s).\n"
     ]
    }
   ],
   "source": [
    "name = 'aifb'\n",
    "data = kg.load(name, torch=True, final=True)\n",
    "data = prunee(data, 2)\n",
    "model = torch.load(f'chk/{name}_chk/models/model_{name}_prune_True')\n",
    "node_idx = 5757\n",
    "init = 'relative_frequency'\n",
    "'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no/masked_adj'\n",
    "#'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no'\n",
    "exp = f'init_{init}_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-1_type_-1_killtype_True_break_no'\n",
    "v = torch.load(f'chk/{name}_chk/exp/{exp}/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/{name}_chk/exp/{exp}/masked_adj/masked_hor{node_idx}')\n",
    "masked_ver = v\n",
    "masked_hor = h\n",
    "h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 10)\n",
    "res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8069, 0.0444, 0.1456, 0.0031], grad_fn=<SoftmaxBackward0>)\n",
      "69\n",
      "tensor(75)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "i = 0\n",
    "while res_threshold.argmax() != 0:\n",
    "    h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 1+i)\n",
    "    i+=1\n",
    "    res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])\n",
    "print(res_threshold)\n",
    "print(1+i)\n",
    "print(v_threshold.coalesce().values().count_nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0094, 0.0133, 0.9756, 0.0017], grad_fn=<SoftmaxBackward0>)\n",
      "1\n",
      "tensor(79) tensor(87)\n",
      "tensor([0.2189, 0.2325, 0.4891, 0.0596], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while res_threshold.argmax() != 2:\n",
    "    h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 1+i)\n",
    "    i+=1\n",
    "    res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])\n",
    "    if i== masked_hor.shape[0]:\n",
    "        break\n",
    "\n",
    "\n",
    "print(res_threshold)\n",
    "print(1+i)\n",
    "print(v_threshold.coalesce().values().count_nonzero(),masked_ver.coalesce().values().count_nonzero() )\n",
    "res = nn.Softmax(dim=0)(model.forward2(convert_binary(masked_hor,0.5), convert_binary(masked_ver,0.5))[node_idx, :])\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(res_full, res_expl,res1_m,label,masked_ver, config):\n",
    "    ''' res_expl: res_binary , res_threshold'''\n",
    "    fidelity_minus = float(1 - (res_full[int(label)] - res_expl[int(label)]))\n",
    "    fidelity_plus = float((res_full[int(label)] - res1_m[int(label)]))\n",
    "    print(fidelity_minus, fidelity_plus)\n",
    "    explanation_lenght = len(masked_ver.coalesce().values()[masked_ver.coalesce().values()>config['threshold'] ])\n",
    "    sparsity = float(1 - explanation_lenght/len(masked_ver.coalesce().values()))\n",
    "\n",
    "    if sparsity == 1:\n",
    "        sparsity_loss = 0\n",
    "    if sparsity == 0:\n",
    "        sparsity_loss = - 1\n",
    "    else:\n",
    "        sparsity_loss = sparsity\n",
    "    score = fidelity_minus + fidelity_plus + sparsity_loss\n",
    "    return fidelity_minus, fidelity_plus, sparsity, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3945, 0.6055], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_ver = v\n",
    "masked_hor = h\n",
    "h_threshold, v_threshold,t_h, t_v = threshold_mask(masked_hor, masked_ver, data, 59)\n",
    "res_threshold = nn.Softmax(dim=0)(model.forward2(h_threshold, v_threshold)[node_idx, :])\n",
    "res_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Sparse Tensor:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [1, 0, 1]]),\n",
      "       values=tensor([2, 3, 4]),\n",
      "       size=(10, 2), nnz=3, layout=torch.sparse_coo)\n",
      "Sparse Tensor with All Values Set to 0:\n",
      "tensor(indices=tensor([[0, 1, 1],\n",
      "                       [1, 0, 1]]),\n",
      "       values=tensor([0, 0, 0]),\n",
      "       size=(10, 2), nnz=3, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Create a sparse tensor with non-zero values and indices\n",
    "indices = torch.tensor([[0, 1, 1], [1, 0, 1]])\n",
    "values = torch.tensor([2, 3, 4])\n",
    "size = (10, 2)\n",
    "sparse_tensor = torch.sparse.FloatTensor(indices, values, size)\n",
    "\n",
    "print(\"Original Sparse Tensor:\")\n",
    "print(sparse_tensor)\n",
    "\n",
    "# Set all values to zero\n",
    "sparse_tensor._values().zero_()\n",
    "\n",
    "print(\"Sparse Tensor with All Values Set to 0:\")\n",
    "print(sparse_tensor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2276s).\n",
      "29043\n",
      "26666\n",
      "ypred explain tensor([0.4507, 0.1969, 0.2936, 0.0587], grad_fn=<SoftmaxBackward0>)\n",
      "v binary: tensor(indices=tensor([[ 23451,  23451,  23451,  ..., 329925, 329926, 329927],\n",
      "                       [  5678,   5743,   5746,  ...,   5230,   5230,   5230]]),\n",
      "       values=tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
      "       size=(753935, 8285), nnz=1311, layout=torch.sparse_coo) tensor(119)\n",
      "ypred explain binary tensor([0.3810, 0.2180, 0.3542, 0.0468], grad_fn=<SoftmaxBackward0>)\n",
      "ypred true tensor([0])\n",
      "ypred full tensor([9.8647e-01, 5.4700e-04, 1.2982e-02, 1.1929e-06],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({2: 27, 10: 1, 15: 1, 18: 35, 21: 21, 27: 1, 30: 30, 36: 3, 0: 101})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = 'aifb'\n",
    "\n",
    "data = kg.load(name, torch=True) \n",
    "print(data.triples.shape[0])\n",
    "node_idx = 5678\n",
    "\n",
    "# else:\n",
    "#     data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "print(data.triples.shape[0])\n",
    "data.triples = torch.Tensor(data.triples).to(int)#data.triples.clone().detach()\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)#data.withheld.clone().detach()\n",
    "data.training = torch.Tensor(data.training).to(int)#data.training.clone().detach()\n",
    "#\n",
    "get_relations(data)\n",
    "d_classes(data)\n",
    "dict_classes = {key.item(): data.withheld[:, 0][data.withheld[:, 1] == key].tolist() for key in torch.unique(data.withheld[:, 1])}\n",
    "if name != 'aifb':\n",
    "    node_idx = dict_classes[0][0]\n",
    "\n",
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "# v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "# h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "model = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/model_{name}_prune_True')\n",
    "\n",
    "# h = select_entity(h, 5230)\n",
    "# v = select_entity(v, 5230)\n",
    "\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "# v = torch.sparse_coo_tensor(v.coalesce().indices(), torch.sigmoid(v.coalesce().values()), v.size(), requires_grad=True)\n",
    "# h = torch.sparse_coo_tensor(h.coalesce().indices(), torch.sigmoid(h.coalesce().values()), h.size(), requires_grad=True)\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)\n",
    "# print(v.coalesce().values()[v.coalesce().values()>0.5])\n",
    "# print(h.coalesce().values())\n",
    "\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "print('v binary:',v_bin, torch.count_nonzero(v_bin.coalesce().values()))\n",
    "res = nn.Softmax(dim=0)(model.forward2(h_bin,v_bin)[node_idx, :])\n",
    "print('ypred explain binary', res)\n",
    "\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "    \n",
    "\n",
    "model.eval()\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "v,h = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(v,h,data, node_idx)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5678\n",
    "init = 'normal'\n",
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important relations {'author': 7, 'homepage': 1, 'isWorkedOnBy': 5, 'member': 2, 'publication': 4, 'type': 100}\n",
      "tensor([0.2483, 0.2657, 0.2633, 0.2227], grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def random_explanation_baseline(sparse_tensor):\n",
    "    ''' Create a random explanation baseline for a given sparse tensor'''\n",
    "    # Retrieve the indices of non-zero elements\n",
    "    # explanation_lenght = len(sparse_tensor.coalesce().values()[sparse_tensor.coalesce().values()>config['threshold'] ])\n",
    "    explanation_lenght = len(sparse_tensor.coalesce().values()[sparse_tensor.coalesce().values()> 0.5 ])\n",
    "    indices = sparse_tensor._indices()\n",
    "\n",
    "    # Get the total number of non-zero elements\n",
    "    num_nonzero = indices.size(1)\n",
    "\n",
    "    # Specify the number of random indices you want to select\n",
    "    n = explanation_lenght\n",
    "\n",
    "    # Generate 'n' random indices within the range of non-zero indices\n",
    "    random_indices = torch.randperm(num_nonzero)[:n]\n",
    "\n",
    "    # Create a new sparse tensor with the same shape as the original tensor but with all values set to 0\n",
    "    new_sparse_tensor = torch.sparse.FloatTensor(indices, torch.zeros(num_nonzero), size=sparse_tensor.size())\n",
    "\n",
    "    # Assign 1 to the randomly selected indices in the new sparse tensor\n",
    "    new_sparse_tensor._values()[random_indices] = 1\n",
    "\n",
    "    # Print the new sparse tensor\n",
    "    return new_sparse_tensor\n",
    "\n",
    "h_random, v_random = random_explanation_baseline(h), random_explanation_baseline(v)\n",
    "counter = important_relation(h_random, v_random, data,node_idx, 0.5)\n",
    "print('Important relations', counter)\n",
    "res_random = nn.Softmax(dim=0)(model.forward2(h_random, v_random)[node_idx, :])\n",
    "print(res_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.3375s).\n"
     ]
    }
   ],
   "source": [
    "import kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "\n",
    "data = kg.load('aifb', torch=True, final=False)\n",
    "data = prunee(data, 2)\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "d = d_classes(data)\n",
    "node_idx = d[list(d.keys())[0]][0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pv is empty\n"
     ]
    }
   ],
   "source": [
    "#but I want to get the most frequent relations for a given node (2 hops)\n",
    "\n",
    "def most_frequent_relations(data, node_idx, n_hops):\n",
    "    ''' Most frequent relations for a given node (2 hops)'''\n",
    "    hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "    edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "\n",
    "    sub_edges_h, neighbors_h, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "    sub_edges_v, neighbors_v, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "    sub_triples = match_to_triples(sub_edges_tensor_v, sub_edges_tensor_h,data, sparse=False)\n",
    "    sub_h, sub_v = hor_ver_graph(sub_triples, data.num_entities, data.num_relations)\n",
    "    m = match_to_triples(sub_v, sub_h,data, node_idx)\n",
    "    freq = Counter(m[:,1].tolist())\n",
    "    sorted_freq = {data.i2r[k]: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True) if k!=0}\n",
    "\n",
    "    most_freq_rel = list(sorted_freq.keys())[0]\n",
    "    id_most_freq_rel = data.r2i[most_freq_rel]\n",
    "    return most_freq_rel\n",
    "most_freq_rel = most_frequent_relations(data, node_idx, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most frequent relation http://www.w3.org/1999/02/22-rdf-syntax-ns#type\n"
     ]
    }
   ],
   "source": [
    "print('most frequent relation', most_freq_rel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "23643",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m     degree_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(degree)\n\u001b[1;32m      8\u001b[0m     \u001b[39mreturn\u001b[39;00m degree_mean\n\u001b[0;32m---> 10\u001b[0m degree_distribution(data)\n",
      "Cell \u001b[0;32mIn[55], line 5\u001b[0m, in \u001b[0;36mdegree_distribution\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m      3\u001b[0m degree \u001b[39m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(data\u001b[39m.\u001b[39mnum_entities):\n\u001b[0;32m----> 5\u001b[0m     _,n,_ \u001b[39m=\u001b[39m find_n_hop_neighbors(edge_index, \u001b[39m0\u001b[39;49m, i)\n\u001b[1;32m      6\u001b[0m     degree\u001b[39m.\u001b[39mappend(\u001b[39mlen\u001b[39m(n))\n\u001b[1;32m      7\u001b[0m degree_mean \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(degree)\n",
      "File \u001b[0;32m~/Documents/GitHub/RGCN-Explainer/RGCN_stuff/src/rgcn_explainer_utils.py:93\u001b[0m, in \u001b[0;36mfind_n_hop_neighbors\u001b[0;34m(edge_index, n, node)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mfor\u001b[39;00m edge \u001b[39min\u001b[39;00m edges:\n\u001b[1;32m     92\u001b[0m     src, dst \u001b[39m=\u001b[39m edge\n\u001b[0;32m---> 93\u001b[0m     \u001b[39mif\u001b[39;00m src \u001b[39min\u001b[39;00m neighborhoods[node] \u001b[39mand\u001b[39;00m dst \u001b[39min\u001b[39;00m neighborhoods[node] \u001b[39mor\u001b[39;00m src \u001b[39m==\u001b[39m node \u001b[39mor\u001b[39;00m dst \u001b[39m==\u001b[39m node:\n\u001b[1;32m     94\u001b[0m         sub_edges\u001b[39m.\u001b[39mappend(edge)\n\u001b[1;32m     96\u001b[0m sub_edges_tensor \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtensor([sub_edges[i] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(sub_edges))])\u001b[39m.\u001b[39mt()        \n",
      "\u001b[0;31mKeyError\u001b[0m: 23643"
     ]
    }
   ],
   "source": [
    "def degree_distribution(data):\n",
    "    edge_index = edge_index_oneadj(data.triples)\n",
    "    degree = []\n",
    "    for i in range(data.num_entities):\n",
    "        _,n,_ = find_n_hop_neighbors(edge_index, 0, i)\n",
    "        degree.append(len(n))\n",
    "    degree_mean = np.mean(degree)\n",
    "    return degree_mean\n",
    "\n",
    "degree_distribution(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6575"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = []\n",
    "for i in data.triples:\n",
    "    if i[0] not in counter:\n",
    "        counter.append(i[0])\n",
    "    if i[2] not in counter:\n",
    "        counter.append(i[2])\n",
    "\n",
    "len(set(counter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def find_threshold(sparse_tensor):\n",
    "    ''' Find the threshold value for the sparse tensor'''\n",
    "    # sparse_tensor = torch.sparse_coo_tensor(\n",
    "    #     sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    # )\n",
    "    numbers = sparse_tensor.coalesce().values()\n",
    "    sorted_numbers = sorted(numbers, reverse=True)\n",
    "    count = 0\n",
    "    threshold = None\n",
    "    \n",
    "    for num in sorted_numbers:\n",
    "        if count == 10:\n",
    "            break\n",
    "        threshold = num\n",
    "        count += 1\n",
    "    \n",
    "    return threshold\n",
    "\n",
    "def convert_back(sparse_tensor, data):\n",
    "    sparse_tensor = torch.sparse_coo_tensor(\n",
    "        sparse_tensor.coalesce().indices()%data.num_entities, sparse_tensor.coalesce().values(), size=sparse_tensor.size()\n",
    "    )\n",
    "    return sparse_tensor\n",
    "\n",
    "t =     find_threshold(v)\n",
    "v, h = convert_back(v, data), convert_back(h, data)\n",
    "print(sub(v,t),t)\n",
    "v, h =convert_binary(v,t), convert_binary(h,t)\n",
    "print(v.coalesce().values().count_nonzero())\n",
    "v_sub = sub(v,t)\n",
    "if node_idx in v_sub.coalesce().indices():\n",
    "    print('node_idx in v')\n",
    "else:\n",
    "    print('node_idx not in v')\n",
    "\n",
    "#print(t, sub(v,t))\n",
    "\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/old_all/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "\n",
    "masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "counter = dict(Counter(m[:,1].tolist()))\n",
    "counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "print('Important relations', counter)\n",
    "\n",
    "def important_relation(v,h,data):\n",
    "    masked_ver_sub, masked_hor_sub = sub(v, 0.5), sub(h,0.5)\n",
    "    m = match_to_triples(masked_ver_sub, masked_hor_sub, data, node_idx)\n",
    "    counter = dict(Counter(m[:,1].tolist()))\n",
    "    counter = {data.i2rel[k][0]:v for k,v in counter.items() if k!=0}\n",
    "    print('Important relations', counter)\n",
    "    return counter\n",
    "\n",
    "v,h = threshold_mask(h,v, data, 10)\n",
    "important_relation(v,h,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def is_graph_connected(adjacency_matrix):\n",
    "    n = adjacency_matrix.shape[0]\n",
    "    visited = torch.zeros(n, dtype=torch.bool)\n",
    "    stack = [0]  # Start traversal from node 0\n",
    "\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        visited[node] = True\n",
    "\n",
    "        neighbor_indices = adjacency_matrix.coalesce().indices()\n",
    "        neighbor_values = adjacency_matrix.coalesce().values()\n",
    "\n",
    "        node_neighbors = neighbor_indices[0, neighbor_indices[1] == node]\n",
    "        for neighbor in node_neighbors:\n",
    "            if not visited[neighbor]:\n",
    "                stack.append(neighbor)\n",
    "                print(stack)\n",
    "\n",
    "    return visited.all()\n",
    "\n",
    "\n",
    "def remove_disconnected_edges(adjacency_matrix):\n",
    "    if not is_graph_connected(adjacency_matrix):\n",
    "        connected_indices = []\n",
    "        connected_values = []\n",
    "\n",
    "        for node in range(adjacency_matrix.size(0)):\n",
    "            row = adjacency_matrix[node]\n",
    "            node_neighbors = row.coalesce().indices()\n",
    "            node_values = row.coalesce().values()\n",
    "\n",
    "            connected_indices.extend([(node, neighbor) for neighbor in node_neighbors])\n",
    "            connected_values.extend(node_values)\n",
    "\n",
    "        connected_indices = torch.tensor(connected_indices).t()\n",
    "        connected_values = torch.tensor(connected_values)\n",
    "        connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "            connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "        )\n",
    "\n",
    "        return connected_adjacency_matrix\n",
    "\n",
    "    return adjacency_matrix\n",
    "\n",
    "\n",
    "\n",
    "is_graph_connected(v)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "node_idx = 5757\n",
    "v = torch.load(f'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/masked_adj/masked_hor{node_idx}')\n",
    "\n",
    "def select_connected_subgraph(adjacency_matrix, given_node,data):\n",
    "    adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        adjacency_matrix.coalesce().indices()%data.num_entities, adjacency_matrix.coalesce().values(), size=adjacency_matrix.size()\n",
    "    )\n",
    "    sub_adj = sub(adjacency_matrix, 0.5)\n",
    "    print(adjacency_matrix)\n",
    "    num_nodes = sub_adj.size(0)\n",
    "    visited = torch.zeros(num_nodes, dtype=torch.bool)\n",
    "    connected_nodes = set()\n",
    "    stack = []\n",
    "\n",
    "    # Starting with the given node\n",
    "    stack.append(given_node)\n",
    "    connected_nodes.add(given_node)\n",
    "    visited[given_node] = True\n",
    "\n",
    "    while len(stack) > 0:\n",
    "        node = stack.pop()\n",
    "        neighbors = sub_adj[node].coalesce().indices()\n",
    "        for i in range(neighbors.size(1)):\n",
    "            neighbor = neighbors[:, i]\n",
    "            if not visited[neighbor[0]]:\n",
    "                stack.append(neighbor[0])\n",
    "                connected_nodes.add(neighbor[0])\n",
    "                visited[neighbor[0]] = True\n",
    "\n",
    "    # Select the indices of the connected nodes\n",
    "    connected_indices = []\n",
    "    for node in connected_nodes:\n",
    "        connected_indices.append([node, node])\n",
    "\n",
    "    # Create the connected adjacency matrix\n",
    "    connected_indices = torch.tensor(connected_indices, dtype=torch.long).t()\n",
    "    #connected_values = adjacency_matrix._values()[connected_indices[0]]\n",
    "    connected_values = torch.ones(connected_indices.size(1))\n",
    "\n",
    "    #torch.ones(connected_indices.size(1))\n",
    "    disconnected_indices = get_non_selected_indices(adjacency_matrix, connected_indices)\n",
    "    disconnected_values = torch.zeros(disconnected_indices.size(1))\n",
    "    connected_indices = torch.cat([connected_indices, disconnected_indices], dim=1)\n",
    "    connected_values = torch.cat([connected_values, disconnected_values])\n",
    "    connected_adjacency_matrix = torch.sparse_coo_tensor(\n",
    "        connected_indices, connected_values, size=adjacency_matrix.size()\n",
    "    )\n",
    "\n",
    "    return connected_adjacency_matrix\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# v, h = sub(v, 0.5), sub(h,0.5)\n",
    "v = select_connected_subgraph(v, node_idx,data)\n",
    "h = select_connected_subgraph(h, node_idx,data)\n",
    "print(v.coalesce().values().count_nonzero(), h.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h,v)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def get_non_selected_indices(sparse_tensor, selected_indices):\n",
    "    original_indices = sparse_tensor.coalesce().indices()\n",
    "    selected_set = set(map(tuple, selected_indices.t().tolist()))\n",
    "\n",
    "    non_selected_indices = []\n",
    "    for index in original_indices.t().tolist():\n",
    "        if tuple(index) not in selected_set:\n",
    "            non_selected_indices.append(index)\n",
    "\n",
    "    return torch.tensor(non_selected_indices).t()\n",
    "\n",
    "# Example usage\n",
    "sparse_tensor = torch.sparse_coo_tensor(torch.tensor([[0, 0, 1, 1], [0, 1, 0, 2]]), torch.tensor([2, 3, 4, 5]), size=(2, 3))\n",
    "selected_indices = torch.tensor([[0, 1], [1, 2]])  # Example selected indices\n",
    "\n",
    "non_selected_indices = get_non_selected_indices(sparse_tensor, selected_indices)\n",
    "print(non_selected_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_1_ent_1_type_1_killtype_False_init_normal_break_wrong_pred_exp_/masked_adj/masked_hor{node_idx}')\n",
    "v, h = select_on_relation_sparse(v,data, 39), select_on_relation_sparse(h,data, 39)\n",
    "#print(v_.coalesce().values().count_nonzero())\n",
    "v_bin,h_bin = convert_binary(v, 0.5), convert_binary(h,0.5)\n",
    "\n",
    "print(v_bin.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_bin,v_bin)\n",
    "\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print('ypred explain', res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inverse predictions \n",
    "v_inv, h_inv = inverse_tensor(v), inverse_tensor(h)\n",
    "print(v_inv.coalesce().values().count_nonzero())\n",
    "\n",
    "out = model.forward2(h_inv,v_inv)\n",
    "\n",
    "res1_m = nn.Softmax(dim=0)(out[node_idx])\n",
    "res - res1_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_tensor(sparse_tensor):\n",
    "    \"\"\" Convert 0 to 1 and viceversa in sparse tensor\n",
    "    The aim is computing the Fidelity- score\"\"\"\n",
    "    sparse_tensor = convert_binary(sparse_tensor, 0.5)\n",
    "    sparse_tensor = torch.sparse_coo_tensor(indices=sparse_tensor._indices(), \n",
    "                                        values=1 - sparse_tensor._values(), \n",
    "                                        size=sparse_tensor.size())\n",
    "    return sparse_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/data/IMDB/finals/{name}.pt')\n",
    "data = prunee(data, 2)\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "object_type(v,h,data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "#I want to get the indices of the triples with type relation \n",
    "output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, 39)\n",
    "output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, 39)\n",
    "objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "list = []\n",
    "for i in objects_types:\n",
    "    list.append(data.i2e[i[2]][0].split('#')[1])\n",
    "result = Counter(list)\n",
    "print(result)\n",
    "#probably node person is the most frequent - what about I delete all the triples where Person is the object?????\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_entity(sparse_tensor,class_id):\n",
    "    ''' Select the subset of the tensor based on the id of the class to be zeroed out'''\n",
    "    value_indices = torch.where(sparse_tensor.coalesce().indices() == class_id)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices[1]] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "\n",
    "    return masked_sparse_tensor\n",
    "select_entity(h, 5230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation,value =1):\n",
    "    \"\"\" Selects the values of a sparse tensor based on the relation\"\"\"\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = value\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = []\n",
    "for i in data.triples:\n",
    "    if i[0] == 5757:\n",
    "        list.append(i[2])\n",
    "    if i[2] == 5757:\n",
    "        list.append(i[0])\n",
    "\n",
    "count = []  \n",
    "for i in data.triples: \n",
    "    for j in list:\n",
    "        if i[0] == j or i[2] == j:\n",
    "            count.append[]\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = d_classes(data)\n",
    "count = 0\n",
    "dict_rel_all_classes = {}\n",
    "dict_rel = {}\n",
    "for j in range(len(classes)):\n",
    "    dict_rel = {}\n",
    "    for node_idx in classes[j]:\n",
    "        for i in data.triples:\n",
    "            if i[0] == node_idx or i[2] == node_idx:\n",
    "                count += 1\n",
    "                if data.i2r[int(i[1])] not in dict_rel.keys():\n",
    "                    dict_rel[data.i2r[int(i[1])]] = 1\n",
    "                else:\n",
    "                    dict_rel[data.i2r[int(i[1])]] += 1\n",
    "    dict_rel_all_classes[j] = dict_rel\n",
    "\n",
    "count\n",
    "dict_rel_all_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_0 = select_on_relation_sparse(v_bin,data, 30)\n",
    "h_0 = select_on_relation_sparse(h_bin,data, 30)\n",
    "\n",
    "print(v_0.coalesce().values().count_nonzero(),h_0.coalesce().values().count_nonzero())\n",
    "out = model.forward2(h_0,v_0)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_on_relation_sparse(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 0\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_one_relation(sparse_tensor,data, relation):\n",
    "    ''' Selects the values of a sparse tensor based on the relation'''\n",
    "    sparse_tensor = torch.sparse_coo_tensor(sparse_tensor._indices(), torch.zeros(sparse_tensor._indices().shape[1]), sparse_tensor.size() )\n",
    "    output_indices, output_values, value_indices=select_relation(sparse_tensor,data.num_entities,relation)\n",
    "    coalesced_tensor = sparse_tensor.coalesce()\n",
    "    coalesced_values = coalesced_tensor._values()\n",
    "    coalesced_indices = coalesced_tensor._indices()\n",
    "    coalesced_values[value_indices] = 1\n",
    "    masked_sparse_tensor = torch.sparse_coo_tensor(coalesced_indices, coalesced_values, sparse_tensor.size())\n",
    "    return masked_sparse_tensor\n",
    "v, h = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 39)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_ver{node_idx}')\n",
    "h = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/size_0.005_lr_0.1_epochs_30_threshold_0.5_init_normal/masked_adj/masked_hor{node_idx}')\n",
    "#loop over keys of counter\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    # v_ = select_on_relation_sparse(v,data, key)\n",
    "    # h_ = select_on_relation_sparse(h,data, key)\n",
    "    v_ = select_one_relation(v,data, key)\n",
    "    h_ = select_one_relation(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        pass\n",
    "        #print(f'wrong prediction without {data.i2r[key]}')\n",
    "    else:\n",
    "        print(f'correct only with {data.i2r[key]}')\n",
    "        print(f'ypred only with {data.i2r[key]}, {key}', res)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a baseline: no use RGCNExplainer - just rule out relations based on prediction of the model\n",
    "\n",
    "#node:\n",
    "node_idx = 5678\n",
    "\n",
    "#label for that node\n",
    "if node_idx in data.withheld[:,0]:\n",
    "    print('ypred true', data.withheld[data.withheld[:,0]==node_idx,1])\n",
    "\n",
    "#edge index\n",
    "edge_index = edge_index_oneadj(data.triples)\n",
    "\n",
    "#number of hops\n",
    "n_hops = 2\n",
    "\n",
    "#augment dataset with self loops and inverse relations\n",
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "\n",
    "#get the edge index at 2 hops per node\n",
    "_,_,index_h = find_n_hop_neighbors(hor_graph.coalesce().indices(), n_hops, node_idx)\n",
    "_,_,index_v = find_n_hop_neighbors(ver_graph.coalesce().indices(), n_hops, node_idx)\n",
    "\n",
    "h = torch.sparse_coo_tensor(index_h, torch.ones(index_h.shape[1]), hor_graph.size() )\n",
    "v = torch.sparse_coo_tensor(index_v, torch.ones(index_v.shape[1]), ver_graph.size() )\n",
    "\n",
    "#match to triple\n",
    "m = match_to_triples(v,h, data)\n",
    "\n",
    "#counter of relations in the 2 hops subgraph\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "#forward pass of the model\n",
    "out = model.forward2(h,v)\n",
    "res = nn.Softmax(dim=0)(out[node_idx])\n",
    "print(f'ypred explain all subgraph: {torch.argmax(res)} with prediction probability: {res}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(m[:,1].tolist())\n",
    "\n",
    "v = select_one_relation(v,data, 39)\n",
    "h = select_one_relation(h,data, 9)\n",
    "h.coalesce().values().count_nonzero()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5757\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "y_full = model.forward2(hor_graph, ver_graph)\n",
    "node_pred_full = y_full[node_idx, :]\n",
    "res_full = nn.Softmax(dim=0)(node_pred_full)\n",
    "print('ypred full', res_full)\n",
    "\n",
    "m = match_to_triples(ver_graph,hor_graph,data, node_idx)\n",
    "v, h = ver_graph, hor_graph\n",
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    #print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'for node {node_idx}, wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_us'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers_to_remove = []\n",
    "for i in range(data.num_relations):\n",
    "    if 'genre' in data.i2r[i]:\n",
    "        print(f'{i}: {data.i2r[i]}')\n",
    "        numbers_to_remove.append(i)\n",
    "numbers_to_remove"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in data.triples:\n",
    "#     for j in numbers_to_remove:\n",
    "#         if i[1] == j:\n",
    "#             print(i)\n",
    "for i in data.triples:\n",
    "    if i[0] ==9662:\n",
    "        print(data.i2e[i[0]], data.i2r[i[1]], data.i2e[i[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'IMDb_most_genre'\n",
    "data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "\n",
    "data = prunee(data, 2)\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.i2e[3599]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.withheld[data.withheld[:,0]==10241,1]\n",
    "data.withheld[torch.where(data.withheld[:, 0] == torch.tensor([10112])),1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.entities = np.append(data.triples[:,0].detach().numpy(),(data.triples[:,2].detach().numpy()))\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "    \n",
    "relations = ['label', 'node_idx','number_neighbors', 'prediction_explain', 'prediction_full', 'prediction_explain_binary'] + relations\n",
    "df = pd.DataFrame(columns=relations)\n",
    "d = d_classes(data)\n",
    "\n",
    "#count how many nodes per class\n",
    "count = {}\n",
    "for i in range(len(d)):\n",
    "    count[i] = len(d[i])\n",
    "count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in Counter(m[:,1].tolist()).keys():\n",
    "    v_ = select_on_relation_sparse(v,data, key)\n",
    "    h_ = select_on_relation_sparse(h,data, key)\n",
    "    out = model.forward2(h_,v_)\n",
    "    res = nn.Softmax(dim=0)(out[node_idx])\n",
    "    print(f'ypred explain no {data.i2r[key]}, {key}', res)\n",
    "    if torch.argmax(res)!=torch.argmax(res_full):\n",
    "        print(f'wrong prediction without {data.i2r[key]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the node of the most important relations - the relations with the highest weights\n",
    "\n",
    "tensor_list = (list(v.coalesce().indices()[1][v.coalesce().values()>0.5]) + list(h.coalesce().indices()[0][h.coalesce().values()>0.5]))\n",
    "float_list = [tensor.item() for tensor in tensor_list]\n",
    "len(set(float_list))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "others = []\n",
    "for i in data.triples:\n",
    "\n",
    "    if i[0] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[2])\n",
    "    if i[2] == 5857:\n",
    "        print(i)\n",
    "        count += 1\n",
    "        others.append(i[0])\n",
    "\n",
    "count\n",
    "others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "l = []\n",
    "a = []\n",
    "for i in data.triples:\n",
    "    for n in others:\n",
    "        if i[0] == int(n) or i[2] == int(n):\n",
    "            count += 1\n",
    "            l.append(n)\n",
    "            a.append(i)\n",
    "            #print(i)\n",
    "            break\n",
    "res = set(l)\n",
    "resa = set(a)\n",
    "print(len(resa))            \n",
    "print(len(res))\n",
    "count\n",
    "#others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "v = torch.load(f'/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/chk/{name}_chk/masked_adj/masked_ver{node_idx}_new')\n",
    "res, weights = visualize(node_idx, 2, data, v, 0, name, result_weights=False, low_threshold=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj(data.triples, data.num_entities, data.num_relations, cuda=False, vertical=True)\n",
    "hor_ver_graph(data.triples, data.num_entities, data.num_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_h, edge_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "_,_,sub_edges_tensor_h  = find_n_hop_neighbors(edge_h,2, 5699)\n",
    "_,_,sub_edges_tensor_v  = find_n_hop_neighbors(edge_v,2, 5699)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sub_edges_tensor_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_edges_tensor\n",
    "indexes = sub_edges_tensor%data.num_entities\n",
    "indexes\n",
    "r = sub_edges_tensor//data.num_entities\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_,p = torch.div(sub_edges_tensor, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "s,o = sub_edges_tensor%data.num_entities\n",
    "result = torch.stack([s,p,o], dim=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try initialization where the first hop neighborhood gets initialized with 1s and the rest with different methods??\n",
    "def construct_edge_mask(self, num_nodes,sparse_tensor,data, const_val=1.0, relation_id = 2):\n",
    "    \"\"\"\n",
    "    Construct edge mask\n",
    "    \"\"\"\n",
    "    init_strategy = self.init_strategy\n",
    "    # if num_nodes > 1000:\n",
    "    #     init(strategy=\"const\", const_val=0.1)\n",
    "    data = self.data\n",
    "    num_entities = data.num_entities\n",
    "    torch.manual_seed(42)\n",
    "    mask = nn.Parameter(torch.FloatTensor(num_nodes))\n",
    "\n",
    "    if init_strategy == \"normal\":\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "    elif init_strategy == \"const\":\n",
    "        nn.init.constant_(mask, const_val) \n",
    "    elif init_strategy == \"zero_out\":\n",
    "        '''initialize the mask with the zero out strategy: we zero out edges belonging to specific relations'''\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "        output_indices, output_values, value_indices=select_relation(sparse_tensor,relation_id)\n",
    "        _,_,value_indices1=select_relation(sparse_tensor,33)\n",
    "        print(value_indices, value_indices1)\n",
    "        value_indices = torch.cat((value_indices, value_indices1), 0)\n",
    "        mask.data[[value_indices]] = 0\n",
    "    \n",
    "\n",
    "    elif init_strategy == \"overall_frequency\":\n",
    "        '''Initialize the mask with the overall frequency of the relations'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        overall_rel_frequency = dict(Counter(data.triples[:,1].tolist()))#.most_common()\n",
    "\n",
    "        overall_rel_frequency_  = {key: round(value/len(data.triples[:,1].tolist()),5) for key, value in overall_rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = overall_rel_frequency_[i]\n",
    "    \n",
    "    elif init_strategy == \"relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "    elif init_strategy == \"inverse_relative_frequency\":\n",
    "        ''' Initialize the mask with the relative frequency of the relations-relative for the node to be explained'''\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        rel_frequency = dict(Counter(p))\n",
    "        rel_frequency_  = {key: 1 - round(value/len(p),5) for key, value in rel_frequency.items()}\n",
    "        for i in p:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = rel_frequency_[i]\n",
    "\n",
    "\n",
    "    elif init_strategy == \"domain_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = dict_domain[i]\n",
    "\n",
    "    elif init_strategy == \"range_frequency\":\n",
    "        _ ,p = torch.div(sparse_tensor.coalesce().indices(), num_entities, rounding_mode='floor').tolist()\n",
    "        dict_domain, dict_range = domain_range_freq(data, len(d_classes(data)))\n",
    "        for i in p:\n",
    "                _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "                mask.data[[value_indices]] = dict_range[i]\n",
    "    elif init_strategy == \"rdf\":\n",
    "        rdf = [i for i in range(data.num_relations) if 'rdf' in data.i2r[i]]\n",
    "        for i in rdf:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    elif init_strategy == \"owl\":\n",
    "        owl = [i for i in range(data.num_relations) if 'owl' in data.i2r[i]]\n",
    "        for i in owl:\n",
    "            _,_,value_indices=select_relation(sparse_tensor,num_entities,i)\n",
    "            mask.data[[value_indices]] = 0\n",
    "    print(f'mask initialized with {init_strategy} strategy: {mask}')   \n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.randn(2, 3).to_sparse().requires_grad_(True)\n",
    "print(a)\n",
    "#a.values = torch.ones_like(a.values())\n",
    "values = torch.ones(a._nnz())\n",
    "#len(a.values)\n",
    "a.indices()\n",
    "sparse_tensor = torch.sparse_coo_tensor(a.indices(), torch.ones(a._nnz()), a.size(), requires_grad=True)\n",
    "sparse_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > 0.7]\n",
    "nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "nonzero_values = v.coalesce().values()[v.coalesce().values() > 0.7]\n",
    "sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "sel_masked_ver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() < 0.5]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() < 0.5]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "sub(v, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result\n",
    "\n",
    "m = match_to_triples(v,h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v, data, sparse=True):\n",
    "    if sparse:\n",
    "        # p,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        # s,o = v.coalesce().indices()%data.num_entities\n",
    "        # result = torch.stack([s,p,o], dim=1)\n",
    "        matching = []\n",
    "        indexes = v.coalesce().indices()%data.num_entities\n",
    "        for j in range(indexes.size()[1]):\n",
    "            for triple in data.triples:\n",
    "                if triple[0] == indexes[0][j] and triple[2] == indexes[1][j]:\n",
    "                    matching.append(triple)\n",
    "        result = torch.stack(matching)\n",
    "\n",
    "                    \n",
    "    else:\n",
    "        matching = []\n",
    "        for i,i2 in zip(v[:,0],v[:,1]):\n",
    "            for j,j1,j2, index in zip(data[:,0],data[:,1],  data[:,2], range(len(data[:,0]))):\n",
    "                if i == j and i2 == j2:\n",
    "                    matching.append(data[index])\n",
    "                    \n",
    "\n",
    "        result = torch.stack(matching)\n",
    "    \n",
    "    return result\n",
    "m = match_to_triples(h, data, sparse=True)\n",
    "Counter(m[:,1].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sub(v, threshold):\n",
    "    nonzero_indices = v.coalesce().indices()[:, v.coalesce().values() > threshold]\n",
    "    nonzero_indices[0] = nonzero_indices[0]#%data.num_entities\n",
    "    nonzero_values = v.coalesce().values()[v.coalesce().values() > threshold]\n",
    "    sel_masked_ver = torch.sparse_coo_tensor(nonzero_indices, nonzero_values)\n",
    "    return sel_masked_ver\n",
    "\n",
    "def visualize(node_idx, n_hop, data, masked_ver,masked_hor, threshold,name, result_weights=True, low_threshold=False,experiment_name=None ):\n",
    "    \"\"\" \n",
    "    Visualize important nodes for node idx prediction\n",
    "    \"\"\"\n",
    "    dict_index = dict_index_classes(data,masked_ver)\n",
    "    mask = torch.vstack((masked_ver, masked_hor.t()))\n",
    "    mask = sub(mask, threshold)\n",
    "    print(mask)\n",
    "    #select only nodes with a certain threshold\n",
    "    sel_masked_ver = sub(masked_ver, threshold)\n",
    "    sel_masked_hor = sub(masked_hor, threshold)\n",
    "    if len(sel_masked_ver)==0:\n",
    "        sel_masked_ver=sub_sparse_tensor(masked_ver, 0,data, low_threshold)\n",
    "    #mask = torch.vstack((sel_masked_ver, sel_masked_hor.t()))\n",
    "    print('sel masked ver',mask)\n",
    "    indices_nodes = mask.coalesce().indices().detach().numpy()\n",
    "    new_index = np.transpose(np.stack((indices_nodes[0], indices_nodes[1]))) #original edge indexes\n",
    "\n",
    "    \n",
    "    \n",
    "    G = nx.Graph()\n",
    "    if result_weights:\n",
    "        values = mask.coalesce().values().detach().numpy()\n",
    "        for s,p,o in zip(indices_nodes[0],values , indices_nodes[1]):\n",
    "            G.add_edge(int(s), int(o), weight=np.round(p, 2))\n",
    "\n",
    "    else:\n",
    "\n",
    "        triples_matched = match_to_triples(sel_masked_ver,sel_masked_hor, data)\n",
    "        l = []\n",
    "        for i in triples_matched[:,1]:\n",
    "            l.append(data.i2rel[int(i)][0])\n",
    "        triples_matched = find_repeating_sublists(triples_matched.numpy())\n",
    "        print(triples_matched)\n",
    "        for s,p,o in triples_matched:\n",
    "            G.add_edge(int(s), int(o), weight=p)\n",
    "\n",
    "\n",
    "    edges,weights = zip(*nx.get_edge_attributes(G,'weight').items())\n",
    "    \n",
    "    weights = [[item] if not isinstance(item, list) else item for item in weights]\n",
    "\n",
    "\n",
    "    pos = nx.circular_layout(G)\n",
    "\n",
    "    ordered_dict = {}\n",
    "    for item in list(G.nodes):\n",
    "        if item in ordered_dict:\n",
    "            ordered_dict[item].append(dict_index[item])\n",
    "        # else:\n",
    "        #     ordered_dict[item] =  dict_index[item]\n",
    "\n",
    "    dict_index = ordered_dict\n",
    "\n",
    "    labeldict = {}\n",
    "    for node in G.nodes:\n",
    "        labeldict[int(node)] = int(node)  \n",
    "\n",
    "\n",
    "    dict = {}\n",
    "    for k,v in dict_index.items():\n",
    "        for k1,v1 in data.entities_classes.items():\n",
    "            if v==k1: \n",
    "\n",
    "                dict[k] = v1\n",
    "            else:\n",
    "                if k not in dict:\n",
    "                    dict[k] = 0\n",
    "                \n",
    "\n",
    "    color_list = list(dict.values())\n",
    "    color_list = list(encode_dict(dict_index).values())\n",
    "\n",
    "\n",
    "    col_weights = [weights[i][0] for i in range(len(weights))]\n",
    "    if result_weights:\n",
    "        \n",
    "        nx.draw(G, pos,labels = labeldict,  edgelist=edges, edge_color=col_weights, node_color =  color_list, cmap=\"Set2\",edge_cmap=plt.cm.Reds,font_size=8)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=nx.get_edge_attributes(G,'weight'),font_size=8,font_color='red')\n",
    "        sm = plt.cm.ScalarMappable(cmap=plt.cm.Reds, norm=plt.Normalize(vmin=0, vmax=1))\n",
    "        sm.set_array(weights)\n",
    "        cbar = plt.colorbar(sm)\n",
    "        cbar.ax.set_title('Weight')\n",
    "        plt.title(\"Node {}'s {}-hop neighborhood important nodes\".format(node_idx, n_hop))\n",
    "    else:\n",
    "        rel = nx.get_edge_attributes(G,'weight')\n",
    "        rel = {k: [data.i2rel[i][0] for i in v] for k,v in rel.items()}\n",
    "        col_weights = [sum(weights[i], 3) if len(weights[i]) > 1 else weights[i][0] for i in range(len(weights))]\n",
    "        nx.draw(G, pos,labels = labeldict, edge_color=col_weights,edgelist=edges,node_color =  color_list, cmap=\"Set2\",font_size=7, arrows = True)\n",
    "        nx.draw_networkx_edge_labels( G, pos,edge_labels=rel,font_size=8,font_color='red')\n",
    "        \n",
    "        res = Counter(unnest_list(rel.values()))\n",
    "        print(res)\n",
    "    if result_weights:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}⁄graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}⁄graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}⁄graphs/Explanation_{node_idx}_weights.png')\n",
    "\n",
    "        #plt.show()\n",
    "\n",
    "    else:\n",
    "        if not os.path.exists(f'chk/{name}_chk/{experiment_name}⁄graphs'):\n",
    "            os.makedirs(f'chk/{name}_chk/{experiment_name}⁄graphs')  \n",
    "        plt.savefig(f'chk/{name}_chk/{experiment_name}⁄graphs/Explanation_{node_idx}_relations.png')    \n",
    "        #plt.show()\n",
    "        return res, weights\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.vstack((v,h.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(node_idx, 2, data, v,h, 0.5,name, result_weights=False, low_threshold=False,experiment_name=None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "\n",
    "        _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h%data.num_entities\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "\n",
    "        pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v%data.num_entities\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h%data.num_entities\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v%data.num_entities\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            print(pv,ph)\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print(pv)\n",
    "        if len(v) == 0:\n",
    "            result = result_h\n",
    "            print(ph)\n",
    "        \n",
    "\n",
    "                    \n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "n_hops = 0\n",
    "node_idx = 5678\n",
    "#hor_graph, ver_graph = hor_ver_graph(data.triples, data.num_entities, data.num_relations)\n",
    "edge_index_h, edge_index_v = hor_graph.coalesce().indices(), ver_graph.coalesce().indices()\n",
    "sub_edges, neighbors, sub_edges_tensor_h  = find_n_hop_neighbors(edge_index_h, n=n_hops, node=node_idx)\n",
    "\n",
    "sub_edges, neighbors, sub_edges_tensor_v  = find_n_hop_neighbors(edge_index_v, n=n_hops, node=node_idx)\n",
    "print(len(list(neighbors)))\n",
    "print('shape sub',sub_edges_tensor_h.shape, sub_edges_tensor_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_idx = 5677\n",
    "count = 0\n",
    "\n",
    "\n",
    "\n",
    "for m in data.triples:\n",
    "    if m[0] == node_idx or m[2] == node_idx:\n",
    "        print(m)\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize the mask to give priority to the 1st hop relations\n",
    "neighbors_h, neighbors_v = list((1,1)), list((2,3))\n",
    "neighbors = len(set(neighbors_v + neighbors_h))\n",
    "len(neighbors)\n",
    "#set(list((neighbors_h, neighbors_v)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separate the graph into subgraphs per relation \n",
    "#create dictionary where each key is a relation and each value is a list of the triples with that relation\n",
    "#each value is a tensor with the edge indices of the triples with that relation\n",
    "\n",
    "dict_rel = {}\n",
    "for i in range(data.num_relations):\n",
    "    dict_rel[i] = []\n",
    "for i in range(len(data.triples)):\n",
    "\n",
    "    dict_rel[int(data.triples[i][1])].append(torch.tensor([data.triples[i][0], data.triples[i][2]]))\n",
    "\n",
    "dict_rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.3058s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: [5678,\n",
       "  5724,\n",
       "  5699,\n",
       "  5688,\n",
       "  5702,\n",
       "  5714,\n",
       "  5708,\n",
       "  5843,\n",
       "  5873,\n",
       "  5697,\n",
       "  5783,\n",
       "  5701,\n",
       "  5845,\n",
       "  5778],\n",
       " 1: [5731, 5905, 5808, 5785],\n",
       " 2: [5757, 5797, 5900, 5677, 5791, 5811, 5831, 5839, 5755, 5844, 5861],\n",
       " 3: [5857, 5752, 5795, 5753, 5798, 5854]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = kg.load('aifb', torch=True, final=False)\n",
    "d_classes(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
