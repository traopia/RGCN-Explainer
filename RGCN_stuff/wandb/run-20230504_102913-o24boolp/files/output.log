
wandb: WARNING Calling wandb.login() after wandb.init() has no effect.
masked_adj tensor([0.7773, 0.7672, 0.7534, 0.6742, 0.7480, 0.6985, 0.7300, 0.6883, 0.7115,
        0.7710, 0.7209, 0.6938, 0.7121, 0.7166, 0.7110, 0.7500, 0.7708, 0.7270,
        0.7182, 0.7421, 0.7113, 0.7576, 0.7510, 0.7717, 0.7624, 0.7628, 0.7463,
        0.7637, 0.7251, 0.7321, 0.7246, 0.7524, 0.6943, 0.7083, 0.7253, 0.7725,
        0.7391, 0.7201, 0.7388, 0.7109, 0.6896, 0.7557, 0.7081, 0.7155, 0.6974,
        0.7816, 0.6985, 0.7184, 0.7071, 0.7140, 0.7330, 0.7442, 0.7184, 0.7603,
        0.7098, 0.7119, 0.6938, 0.7320, 0.7294, 0.7479, 0.7286, 0.7754, 0.6998,
        0.7648, 0.7663, 0.7523, 0.7837, 0.7442, 0.7398, 0.7260, 0.7033, 0.7624,
        0.7266, 0.7442, 0.7325, 0.7418, 0.7455, 0.7144, 0.6713, 0.7115, 0.7313,
        0.7223, 0.6955, 0.7159, 0.7445, 0.7442, 0.7591, 0.7324, 0.7496, 0.7186,
        0.7035, 0.7462, 0.6850, 0.7094, 0.7637, 0.7432, 0.6625, 0.7433, 0.7506,
        0.7318, 0.7471, 0.7457, 0.7574, 0.7443, 0.7565, 0.7127, 0.7561, 0.7225,
        0.7440, 0.7408, 0.7160, 0.7414, 0.7162, 0.7438, 0.7188, 0.7183, 0.7379,
        0.7165, 0.7480], grad_fn=<MulBackward0>)
res: tensor([9.9855e-01, 6.6735e-04, 9.8767e-05, 6.8133e-04],
       grad_fn=<SoftmaxBackward0>)
num_high 119 len(mask) 119
mask_without_small tensor([0.7773, 0.7672, 0.7534, 0.6742, 0.7480, 0.6985, 0.7300, 0.6883, 0.7115,
        0.7710, 0.7209, 0.6938, 0.7121, 0.7166, 0.7110, 0.7500, 0.7708, 0.7270,
        0.7182, 0.7421, 0.7113, 0.7576, 0.7510, 0.7717, 0.7624, 0.7628, 0.7463,
        0.7637, 0.7251, 0.7321, 0.7246, 0.7524, 0.6943, 0.7083, 0.7253, 0.7725,
        0.7391, 0.7201, 0.7388, 0.7109, 0.6896, 0.7557, 0.7081, 0.7155, 0.6974,
        0.7816, 0.6985, 0.7184, 0.7071, 0.7140, 0.7330, 0.7442, 0.7184, 0.7603,
        0.7098, 0.7119, 0.6938, 0.7320, 0.7294, 0.7479, 0.7286, 0.7754, 0.6998,
        0.7648, 0.7663, 0.7523, 0.7837, 0.7442, 0.7398, 0.7260, 0.7033, 0.7624,
        0.7266, 0.7442, 0.7325, 0.7418, 0.7455, 0.7144, 0.6713, 0.7115, 0.7313,
        0.7223, 0.6955, 0.7159, 0.7445, 0.7442, 0.7591, 0.7324, 0.7496, 0.7186,
        0.7035, 0.7462, 0.6850, 0.7094, 0.7637, 0.7432, 0.6625, 0.7433, 0.7506,
        0.7318, 0.7471, 0.7457, 0.7574, 0.7443, 0.7565, 0.7127, 0.7561, 0.7225,
        0.7440, 0.7408, 0.7160, 0.7414, 0.7162, 0.7438, 0.7188, 0.7183, 0.7379,
        0.7165, 0.7480], grad_fn=<IndexBackward0>)
pred_loss tensor([0.0014], grad_fn=<MulBackward0>)
size_loss tensor(-1.6366, grad_fn=<AddBackward0>)
size_num_loss 11.9
loss: tensor([10.8447], grad_fn=<AddBackward0>)
0
epoch:  0 ; loss:  10.844664573669434 ; pred:  tensor([9.9855e-01, 6.6735e-04, 9.8767e-05, 6.8133e-04],
       grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.8519, 0.8446, 0.8343, 0.5565, 0.6429, 0.5842, 0.6211, 0.5725, 0.5993,
        0.8473, 0.6104, 0.5788, 0.6000, 0.6053, 0.5988, 0.8319, 0.8472, 0.6176,
        0.6072, 0.6358, 0.5991, 0.8375, 0.8326, 0.8479, 0.8410, 0.8413, 0.6409,
        0.8420, 0.6154, 0.6237, 0.6148, 0.8336, 0.5794, 0.5956, 0.6156, 0.8485,
        0.6321, 0.6094, 0.6317, 0.5986, 0.5740, 0.8360, 0.5953, 0.6040, 0.5829,
        0.8551, 0.5842, 0.6075, 0.5942, 0.6022, 0.6248, 0.6383, 0.6075, 0.8395,
        0.5974, 0.5998, 0.5789, 0.6236, 0.6205, 0.6428, 0.6195, 0.8506, 0.5858,
        0.8428, 0.8439, 0.8336, 0.8566, 0.6383, 0.6330, 0.6164, 0.5898, 0.8410,
        0.6172, 0.6383, 0.6242, 0.6354, 0.6398, 0.6027, 0.5533, 0.5993, 0.6228,
        0.6121, 0.5808, 0.6045, 0.6387, 0.6383, 0.8386, 0.6240, 0.8315, 0.6077,
        0.5900, 0.6407, 0.5687, 0.5969, 0.8420, 0.6371, 0.5436, 0.6372, 0.8323,
        0.6233, 0.6418, 0.6401, 0.8373, 0.6384, 0.8367, 0.6008, 0.8364, 0.6123,
        0.6381, 0.6342, 0.6046, 0.6349, 0.6048, 0.6378, 0.6079, 0.6074, 0.6307,
        0.6052, 0.6429], grad_fn=<MulBackward0>)
res: tensor([9.9426e-01, 2.6345e-03, 5.7197e-04, 2.5344e-03],
       grad_fn=<SoftmaxBackward0>)
num_high 63 len(mask) 119
mask_without_small tensor([0.8519, 0.8446, 0.8343, 0.5565, 0.6429, 0.5842, 0.6211, 0.5725, 0.5993,
        0.8473, 0.6104, 0.5788, 0.6000, 0.6053, 0.5988, 0.8319, 0.8472, 0.6176,
        0.6072, 0.6358, 0.5991, 0.8375, 0.8326, 0.8479, 0.8410, 0.8413, 0.6409,
        0.8420, 0.6154, 0.6237, 0.6148, 0.8336, 0.5794, 0.5956, 0.6156, 0.8485,
        0.6321, 0.6094, 0.6317, 0.5986, 0.5740, 0.8360, 0.5953, 0.6040, 0.5829,
        0.8551, 0.5842, 0.6075, 0.5942, 0.6022, 0.6248, 0.6383, 0.6075, 0.8395,
        0.5974, 0.5998, 0.5789, 0.6236, 0.6205, 0.6428, 0.6195, 0.8506, 0.5858,
        0.8428, 0.8439, 0.8336, 0.8566, 0.6383, 0.6330, 0.6164, 0.5898, 0.8410,
        0.6172, 0.6383, 0.6242, 0.6354, 0.6398, 0.6027, 0.5533, 0.5993, 0.6228,
        0.6121, 0.5808, 0.6045, 0.6387, 0.6383, 0.8386, 0.6240, 0.8315, 0.6077,
        0.5900, 0.6407, 0.5687, 0.5969, 0.8420, 0.6371, 0.5436, 0.6372, 0.8323,
        0.6233, 0.6418, 0.6401, 0.8373, 0.6384, 0.8367, 0.6008, 0.8364, 0.6123,
        0.6381, 0.6342, 0.6046, 0.6349, 0.6048, 0.6378, 0.6079, 0.6074, 0.6307,
        0.6052, 0.6429], grad_fn=<IndexBackward0>)
pred_loss tensor([0.0058], grad_fn=<MulBackward0>)
size_loss tensor(-9.4273, grad_fn=<AddBackward0>)
size_num_loss 6.300000000000001
loss: tensor([-2.5124], grad_fn=<AddBackward0>)
1
epoch:  1 ; loss:  -2.5123822689056396 ; pred:  tensor([9.9426e-01, 2.6345e-03, 5.7197e-04, 2.5344e-03],
       grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.8934, 0.8913, 0.8926, 0.4402, 0.5493, 0.4643, 0.4988, 0.4542, 0.4774,
        0.8918, 0.4875, 0.4597, 0.4780, 0.4827, 0.4769, 0.8833, 0.8918, 0.4947,
        0.4844, 0.5248, 0.4772, 0.8924, 0.8877, 0.8920, 0.8913, 0.8913, 0.5412,
        0.8912, 0.4923, 0.5021, 0.4917, 0.8914, 0.4602, 0.4741, 0.4926, 0.8921,
        0.5162, 0.4865, 0.5153, 0.4768, 0.4555, 0.8929, 0.4739, 0.4815, 0.4632,
        0.8949, 0.4643, 0.4847, 0.4730, 0.4800, 0.5036, 0.5324, 0.4847, 0.8916,
        0.4757, 0.4778, 0.4597, 0.5018, 0.4980, 0.5490, 0.4968, 0.8929, 0.4657,
        0.8912, 0.8912, 0.8913, 0.8956, 0.5322, 0.5180, 0.4934, 0.4692, 0.8914,
        0.4943, 0.5322, 0.5027, 0.5238, 0.5374, 0.4804, 0.4374, 0.4774, 0.5008,
        0.4890, 0.4614, 0.4820, 0.5334, 0.5323, 0.8921, 0.5025, 0.8808, 0.4849,
        0.4694, 0.5405, 0.4510, 0.4754, 0.8914, 0.5285, 0.4288, 0.5289, 0.8861,
        0.5015, 0.5447, 0.5383, 0.8925, 0.5326, 0.8928, 0.4787, 0.8929, 0.4893,
        0.5317, 0.5209, 0.4821, 0.5226, 0.4823, 0.5306, 0.4851, 0.4846, 0.5130,
        0.4826, 0.5495], grad_fn=<MulBackward0>)
res: tensor([0.9765, 0.0105, 0.0034, 0.0096], grad_fn=<SoftmaxBackward0>)
num_high 30 len(mask) 119
mask_without_small tensor([0.8934, 0.8913, 0.8926, 0.5493, 0.8918, 0.8833, 0.8918, 0.5248, 0.8924,
        0.8877, 0.8920, 0.8913, 0.8913, 0.5412, 0.8912, 0.5021, 0.8914, 0.8921,
        0.5162, 0.5153, 0.8929, 0.8949, 0.5036, 0.5324, 0.8916, 0.5018, 0.5490,
        0.8929, 0.8912, 0.8912, 0.8913, 0.8956, 0.5322, 0.5180, 0.8914, 0.5322,
        0.5027, 0.5238, 0.5374, 0.5008, 0.5334, 0.5323, 0.8921, 0.5025, 0.8808,
        0.5405, 0.8914, 0.5285, 0.5289, 0.8861, 0.5015, 0.5447, 0.5383, 0.8925,
        0.5326, 0.8928, 0.8929, 0.5317, 0.5209, 0.5226, 0.5306, 0.5130, 0.5495],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.0238], grad_fn=<MulBackward0>)
size_loss tensor(-1845.3788, grad_fn=<MulBackward0>)
size_num_loss 3.0
loss: tensor([-1841.7511], grad_fn=<AddBackward0>)
2
epoch:  2 ; loss:  -1841.7510986328125 ; pred:  tensor([0.9765, 0.0105, 0.0034, 0.0096], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9204, 0.9187, 0.9196, 0.3571, 0.4694, 0.3765, 0.4037, 0.3685, 0.3865,
        0.9192, 0.3943, 0.3729, 0.3870, 0.3906, 0.3862, 0.9125, 0.9191, 0.4001,
        0.3919, 0.4449, 0.3864, 0.9195, 0.9159, 0.9193, 0.9187, 0.9187, 0.4613,
        0.9187, 0.3982, 0.4225, 0.3977, 0.9188, 0.3733, 0.3841, 0.3984, 0.9194,
        0.4363, 0.3935, 0.4355, 0.3861, 0.3695, 0.9199, 0.3839, 0.3897, 0.3756,
        0.9216, 0.3765, 0.3921, 0.3832, 0.3885, 0.4240, 0.4525, 0.3921, 0.9190,
        0.3853, 0.3869, 0.3729, 0.4222, 0.4030, 0.4691, 0.4020, 0.9200, 0.3778,
        0.9186, 0.9187, 0.9187, 0.9221, 0.4522, 0.4381, 0.3993, 0.3805, 0.9188,
        0.4001, 0.4523, 0.4231, 0.4439, 0.4574, 0.3892, 0.3549, 0.3866, 0.4213,
        0.3958, 0.3747, 0.3907, 0.4535, 0.4524, 0.9193, 0.4228, 0.9105, 0.3935,
        0.3811, 0.4606, 0.3668, 0.3855, 0.9188, 0.4486, 0.3481, 0.4490, 0.9146,
        0.4219, 0.4648, 0.4583, 0.9196, 0.4527, 0.9198, 0.3880, 0.9199, 0.3961,
        0.4517, 0.4410, 0.3905, 0.4427, 0.3905, 0.4507, 0.3927, 0.3924, 0.4332,
        0.3911, 0.4696], grad_fn=<MulBackward0>)
res: tensor([0.9417, 0.0251, 0.0105, 0.0227], grad_fn=<SoftmaxBackward0>)
num_high 30 len(mask) 119
mask_without_small tensor([0.9204, 0.9187, 0.9196, 0.9192, 0.9125, 0.9191, 0.9195, 0.9159, 0.9193,
        0.9187, 0.9187, 0.9187, 0.9188, 0.9194, 0.9199, 0.9216, 0.9190, 0.9200,
        0.9186, 0.9187, 0.9187, 0.9221, 0.9188, 0.9193, 0.9105, 0.9188, 0.9146,
        0.9196, 0.9198, 0.9199], grad_fn=<IndexBackward0>)
pred_loss tensor([0.0600], grad_fn=<MulBackward0>)
size_loss tensor(-23.7235, grad_fn=<MulBackward0>)
size_num_loss 3.0
loss: tensor([-20.0883], grad_fn=<AddBackward0>)
3
epoch:  3 ; loss:  -20.088281631469727 ; pred:  tensor([0.9417, 0.0251, 0.0105, 0.0227], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9448, 0.9373, 0.9436, 0.3012, 0.4050, 0.3185, 0.3454, 0.3113, 0.3278,
        0.9414, 0.3354, 0.3152, 0.3282, 0.3317, 0.3274, 0.8928, 0.9412, 0.3416,
        0.3330, 0.3814, 0.3276, 0.9433, 0.9047, 0.9421, 0.9373, 0.9369, 0.3971,
        0.9366, 0.3395, 0.3600, 0.3389, 0.9378, 0.3156, 0.3254, 0.3397, 0.9429,
        0.3732, 0.3347, 0.3724, 0.3273, 0.3122, 0.9443, 0.3253, 0.3308, 0.3177,
        0.9450, 0.3185, 0.3332, 0.3246, 0.3297, 0.3614, 0.3886, 0.3332, 0.9399,
        0.3266, 0.3281, 0.3152, 0.3598, 0.3446, 0.4046, 0.3435, 0.9444, 0.3201,
        0.9361, 0.9367, 0.9365, 0.9450, 0.3884, 0.3749, 0.3410, 0.3226, 0.9378,
        0.3422, 0.3885, 0.3606, 0.3804, 0.3934, 0.3310, 0.2995, 0.3278, 0.3589,
        0.3378, 0.3177, 0.3332, 0.3896, 0.3885, 0.9422, 0.3604, 0.8887, 0.3380,
        0.3244, 0.3964, 0.3120, 0.3282, 0.9379, 0.3849, 0.2941, 0.3853, 0.8990,
        0.3595, 0.4005, 0.3942, 0.9436, 0.3888, 0.9441, 0.3303, 0.9442, 0.3384,
        0.3879, 0.3776, 0.3323, 0.3793, 0.3322, 0.3869, 0.3346, 0.3342, 0.3703,
        0.3337, 0.4051], grad_fn=<MulBackward0>)
res: tensor([0.8956, 0.0434, 0.0220, 0.0390], grad_fn=<SoftmaxBackward0>)
num_high 30 len(mask) 119
mask_without_small tensor([0.9448, 0.9373, 0.9436, 0.9414, 0.8928, 0.9412, 0.9433, 0.9047, 0.9421,
        0.9373, 0.9369, 0.9366, 0.9378, 0.9429, 0.9443, 0.9450, 0.9399, 0.9444,
        0.9361, 0.9367, 0.9365, 0.9450, 0.9378, 0.9422, 0.8887, 0.9379, 0.8990,
        0.9436, 0.9441, 0.9442], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1103], grad_fn=<MulBackward0>)
size_loss tensor(-158.6875, grad_fn=<MulBackward0>)
size_num_loss 3.0
loss: tensor([-155.0352], grad_fn=<AddBackward0>)
4
epoch:  4 ; loss:  -155.03518676757812 ; pred:  tensor([0.8956, 0.0434, 0.0220, 0.0390], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9628, 0.9518, 0.9619, 0.2662, 0.3529, 0.2846, 0.3203, 0.2766, 0.2960,
        0.9590, 0.3064, 0.2809, 0.2967, 0.3013, 0.2956, 0.8568, 0.9588, 0.3151,
        0.3031, 0.3307, 0.2959, 0.9615, 0.8764, 0.9600, 0.9518, 0.9509, 0.3455,
        0.9502, 0.3122, 0.3107, 0.3114, 0.9529, 0.2813, 0.2930, 0.3125, 0.9610,
        0.3230, 0.3054, 0.3223, 0.2954, 0.2776, 0.9625, 0.2928, 0.3001, 0.2837,
        0.9620, 0.2846, 0.3034, 0.2920, 0.2985, 0.3120, 0.3375, 0.3034, 0.9568,
        0.2944, 0.2964, 0.2809, 0.3105, 0.3193, 0.3526, 0.3177, 0.9627, 0.2870,
        0.9492, 0.9504, 0.9500, 0.9615, 0.3373, 0.3246, 0.3145, 0.2901, 0.9529,
        0.3167, 0.3373, 0.3112, 0.3297, 0.3420, 0.3011, 0.2648, 0.2961, 0.3096,
        0.3105, 0.2848, 0.3046, 0.3384, 0.3374, 0.9602, 0.3110, 0.8506, 0.3139,
        0.2939, 0.3448, 0.2807, 0.2982, 0.9530, 0.3340, 0.2603, 0.3344, 0.8668,
        0.3102, 0.3487, 0.3428, 0.9618, 0.3377, 0.9623, 0.3009, 0.9625, 0.3116,
        0.3368, 0.3272, 0.3027, 0.3287, 0.3025, 0.3359, 0.3061, 0.3054, 0.3204,
        0.3060, 0.3531], grad_fn=<MulBackward0>)
res: tensor([0.8518, 0.0602, 0.0342, 0.0537], grad_fn=<SoftmaxBackward0>)
num_high 30 len(mask) 119
mask_without_small tensor([0.9628, 0.9518, 0.9619, 0.9590, 0.8568, 0.9588, 0.9615, 0.8764, 0.9600,
        0.9518, 0.9509, 0.9502, 0.9529, 0.9610, 0.9625, 0.9620, 0.9568, 0.9627,
        0.9492, 0.9504, 0.9500, 0.9615, 0.9529, 0.9602, 0.8506, 0.9530, 0.8668,
        0.9618, 0.9623, 0.9625], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1604], grad_fn=<MulBackward0>)
size_loss tensor(-332.7892, grad_fn=<MulBackward0>)
size_num_loss 3.0
loss: tensor([-329.1148], grad_fn=<AddBackward0>)
5
epoch:  5 ; loss:  -329.11480712890625 ; pred:  tensor([0.8518, 0.0602, 0.0342, 0.0537], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9749, 0.9633, 0.9744, 0.2468, 0.3107, 0.2693, 0.3204, 0.2591, 0.2851,
        0.9718, 0.3004, 0.2645, 0.2860, 0.2928, 0.2845, 0.8026, 0.9715, 0.3130,
        0.2955, 0.2900, 0.2849, 0.9741, 0.8315, 0.9728, 0.9632, 0.9621, 0.3038,
        0.9611, 0.3088, 0.2714, 0.3077, 0.9647, 0.2650, 0.2808, 0.3093, 0.9736,
        0.2828, 0.2989, 0.2822, 0.2843, 0.2603, 0.9749, 0.2805, 0.2911, 0.2681,
        0.9735, 0.2693, 0.2960, 0.2794, 0.2887, 0.2726, 0.2963, 0.2960, 0.9694,
        0.2829, 0.2857, 0.2645, 0.2712, 0.3190, 0.3104, 0.3168, 0.9750, 0.2729,
        0.9595, 0.9614, 0.9608, 0.9728, 0.2961, 0.2843, 0.3121, 0.2773, 0.9647,
        0.3157, 0.2962, 0.2719, 0.2891, 0.3005, 0.2928, 0.2457, 0.2853, 0.2704,
        0.3067, 0.2703, 0.2981, 0.2972, 0.2963, 0.9729, 0.2718, 0.7938, 0.3141,
        0.2834, 0.3032, 0.2674, 0.2892, 0.9649, 0.2931, 0.2414, 0.2934, 0.8173,
        0.2710, 0.3068, 0.3013, 0.9743, 0.2965, 0.9748, 0.2934, 0.9749, 0.3084,
        0.2957, 0.2867, 0.2952, 0.2882, 0.2948, 0.2949, 0.3002, 0.2992, 0.2806,
        0.3010, 0.3109], grad_fn=<MulBackward0>)
res: tensor([0.8172, 0.0733, 0.0447, 0.0648], grad_fn=<SoftmaxBackward0>)
num_high 30 len(mask) 119
mask_without_small tensor([0.9749, 0.9633, 0.9744, 0.9718, 0.8026, 0.9715, 0.9741, 0.8315, 0.9728,
        0.9632, 0.9621, 0.9611, 0.9647, 0.9736, 0.9749, 0.9735, 0.9694, 0.9750,
        0.9595, 0.9614, 0.9608, 0.9728, 0.9647, 0.9729, 0.7938, 0.9649, 0.8173,
        0.9743, 0.9748, 0.9749], grad_fn=<IndexBackward0>)
pred_loss tensor([0.2019], grad_fn=<MulBackward0>)
size_loss tensor(-551.4848, grad_fn=<MulBackward0>)
size_num_loss 3.0
loss: tensor([-547.7878], grad_fn=<AddBackward0>)
6
epoch:  6 ; loss:  -547.7877807617188 ; pred:  tensor([0.8172, 0.0733, 0.0447, 0.0648], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9828, 0.9723, 0.9826, 0.2394, 0.2764, 0.2683, 0.3390, 0.2548, 0.2902,
        0.9805, 0.3118, 0.2619, 0.2915, 0.3011, 0.2894, 0.7276, 0.9803, 0.3291,
        0.3049, 0.2571, 0.2899, 0.9824, 0.7673, 0.9813, 0.9722, 0.9710, 0.2699,
        0.9698, 0.3234, 0.2399, 0.3219, 0.9738, 0.2626, 0.2842, 0.3241, 0.9821,
        0.2504, 0.3096, 0.2499, 0.2891, 0.2564, 0.9829, 0.2838, 0.2986, 0.2668,
        0.9812, 0.2683, 0.3055, 0.2822, 0.2953, 0.2410, 0.2630, 0.3055, 0.9784,
        0.2871, 0.2911, 0.2619, 0.2397, 0.3372, 0.2761, 0.3343, 0.9830, 0.2735,
        0.9680, 0.9702, 0.9695, 0.9804, 0.2628, 0.2518, 0.3275, 0.2795, 0.9738,
        0.3329, 0.2629, 0.2403, 0.2563, 0.2669, 0.3012, 0.2384, 0.2905, 0.2389,
        0.3206, 0.2700, 0.3084, 0.2638, 0.2630, 0.9814, 0.2403, 0.7157, 0.3330,
        0.2885, 0.2694, 0.2681, 0.2963, 0.9740, 0.2600, 0.2340, 0.2603, 0.7477,
        0.2395, 0.2728, 0.2676, 0.9826, 0.2632, 0.9829, 0.3027, 0.9829, 0.3230,
        0.2624, 0.2541, 0.3046, 0.2554, 0.3039, 0.2616, 0.3115, 0.3101, 0.2486,
        0.3135, 0.2766], grad_fn=<MulBackward0>)
res: tensor([0.7927, 0.0827, 0.0525, 0.0721], grad_fn=<SoftmaxBackward0>)
num_high 30 len(mask) 119
mask_without_small tensor([0.9828, 0.9723, 0.9826, 0.9805, 0.7276, 0.9803, 0.9824, 0.7673, 0.9813,
        0.9722, 0.9710, 0.9698, 0.9738, 0.9821, 0.9829, 0.9812, 0.9784, 0.9830,
        0.9680, 0.9702, 0.9695, 0.9804, 0.9738, 0.9814, 0.7157, 0.9740, 0.7477,
        0.9826, 0.9829, 0.9829], grad_fn=<IndexBackward0>)
pred_loss tensor([0.2323], grad_fn=<MulBackward0>)
size_loss tensor(-828.3203, grad_fn=<MulBackward0>)
size_num_loss 3.0
loss: tensor([-824.6030], grad_fn=<AddBackward0>)
7
epoch:  7 ; loss:  -824.60302734375 ; pred:  tensor([0.7927, 0.0827, 0.0525, 0.0721], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9879, 0.9792, 0.9879, 0.2416, 0.2483, 0.2789, 0.3713, 0.2613, 0.3081,
        0.9863, 0.3366, 0.2704, 0.3098, 0.3225, 0.3069, 0.6316, 0.9861, 0.3590,
        0.3275, 0.2303, 0.3077, 0.9878, 0.6823, 0.9870, 0.9791, 0.9779, 0.2423,
        0.9767, 0.3517, 0.2143, 0.3497, 0.9805, 0.2713, 0.3001, 0.3525, 0.9875,
        0.2241, 0.3338, 0.2237, 0.3065, 0.2633, 0.9881, 0.2995, 0.3192, 0.2768,
        0.9864, 0.2789, 0.3283, 0.2973, 0.3149, 0.2154, 0.2358, 0.3283, 0.9846,
        0.3038, 0.3092, 0.2704, 0.2142, 0.3691, 0.2481, 0.3654, 0.9882, 0.2857,
        0.9749, 0.9771, 0.9764, 0.9855, 0.2356, 0.2255, 0.3564, 0.2940, 0.9805,
        0.3638, 0.2357, 0.2148, 0.2296, 0.2394, 0.3228, 0.2406, 0.3085, 0.2135,
        0.3484, 0.2813, 0.3321, 0.2365, 0.2359, 0.9871, 0.2148, 0.6169, 0.3669,
        0.3060, 0.2418, 0.2803, 0.3163, 0.9807, 0.2331, 0.2358, 0.2334, 0.6571,
        0.2140, 0.2449, 0.2401, 0.9879, 0.2360, 0.9881, 0.3257, 0.9881, 0.3512,
        0.2353, 0.2275, 0.3272, 0.2288, 0.3263, 0.2346, 0.3363, 0.3344, 0.2226,
        0.3398, 0.2486], grad_fn=<MulBackward0>)
res: tensor([0.7769, 0.0890, 0.0577, 0.0764], grad_fn=<SoftmaxBackward0>)
num_high 29 len(mask) 119
mask_without_small tensor([0.9879, 0.9792, 0.9879, 0.9863, 0.6316, 0.9861, 0.9878, 0.6823, 0.9870,
        0.9791, 0.9779, 0.9767, 0.9805, 0.9875, 0.9881, 0.9864, 0.9846, 0.9882,
        0.9749, 0.9771, 0.9764, 0.9855, 0.9805, 0.9871, 0.6169, 0.9807, 0.6571,
        0.9879, 0.9881, 0.9881], grad_fn=<IndexBackward0>)
pred_loss tensor([0.2524], grad_fn=<MulBackward0>)
size_loss tensor(-1168.9091, grad_fn=<MulBackward0>)
size_num_loss 2.9000000000000004
loss: tensor([-1165.2756], grad_fn=<AddBackward0>)
8
epoch:  8 ; loss:  -1165.275634765625 ; pred:  tensor([0.7769, 0.0890, 0.0577, 0.0764], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9913, 0.9843, 0.9914, 0.2520, 0.2252, 0.2991, 0.4131, 0.2767, 0.3363,
        0.9902, 0.3717, 0.2883, 0.3384, 0.3543, 0.3348, 0.5195, 0.9901, 0.3987,
        0.3606, 0.2084, 0.3357, 0.9913, 0.5782, 0.9907, 0.9842, 0.9831, 0.2195,
        0.9820, 0.3900, 0.1935, 0.3877, 0.9854, 0.2895, 0.3261, 0.3910, 0.9911,
        0.2026, 0.3683, 0.2022, 0.3343, 0.2793, 0.9915, 0.3254, 0.3503, 0.2965,
        0.9898, 0.2991, 0.3616, 0.3226, 0.3448, 0.1945, 0.2135, 0.3616, 0.9888,
        0.3309, 0.3377, 0.2883, 0.1933, 0.4106, 0.2249, 0.4063, 0.9915, 0.3078,
        0.9804, 0.9824, 0.9818, 0.9890, 0.2133, 0.2038, 0.3950, 0.3186, 0.9854,
        0.4047, 0.2134, 0.1939, 0.2077, 0.2169, 0.3550, 0.2510, 0.3368, 0.1927,
        0.3867, 0.3024, 0.3664, 0.2141, 0.2136, 0.9908, 0.1940, 0.5028, 0.4127,
        0.3338, 0.2191, 0.3022, 0.3465, 0.9856, 0.2110, 0.2455, 0.2112, 0.5487,
        0.1932, 0.2220, 0.2175, 0.9914, 0.2137, 0.9915, 0.3598, 0.9915, 0.3897,
        0.2130, 0.2058, 0.3604, 0.2069, 0.3592, 0.2123, 0.3714, 0.3691, 0.2014,
        0.3768, 0.2255], grad_fn=<MulBackward0>)
res: tensor([0.7681, 0.0931, 0.0605, 0.0784], grad_fn=<SoftmaxBackward0>)
num_high 26 len(mask) 119
mask_without_small tensor([0.9913, 0.9843, 0.9914, 0.9902, 0.5195, 0.9901, 0.9913, 0.5782, 0.9907,
        0.9842, 0.9831, 0.9820, 0.9854, 0.9911, 0.9915, 0.9898, 0.9888, 0.9915,
        0.9804, 0.9824, 0.9818, 0.9890, 0.9854, 0.9908, 0.5028, 0.9856, 0.5487,
        0.9914, 0.9915, 0.9915], grad_fn=<IndexBackward0>)
pred_loss tensor([0.2639], grad_fn=<MulBackward0>)
size_loss tensor(-1562.1674, grad_fn=<MulBackward0>)
size_num_loss 2.6
loss: tensor([-1558.8235], grad_fn=<AddBackward0>)
9
epoch:  9 ; loss:  -1558.823486328125 ; pred:  tensor([0.7681, 0.0931, 0.0605, 0.0784], grad_fn=<SoftmaxBackward0>)
Finished Training
sel masked ver tensor(indices=tensor([[6881, 6888, 6981, 7911, 8015, 5937, 5408, 5413, 5431,
                        5450, 5494, 5678, 6997, 8013, 5939, 6881, 7393, 5408,
                        5431, 5450, 5494, 5502, 5678, 5678, 5678, 5678, 5678,
                        5502, 5502, 5502],
                       [5678, 5678, 5678, 5678, 5678, 5502, 5939, 5939, 5937,
                        5939, 5937,   22, 5939, 5939, 5357, 5357, 5450, 5678,
                        5678, 5678, 5678, 5678, 5535, 6997, 7068, 8010, 8015,
                        6981, 7045, 7100]]),
       values=tensor([0.9913, 0.9843, 0.9914, 0.9902, 0.5195, 0.9901, 0.9913,
                      0.5782, 0.9907, 0.9842, 0.9831, 0.9820, 0.9854, 0.9911,
                      0.9915, 0.9898, 0.9888, 0.9915, 0.9804, 0.9824, 0.9818,
                      0.9890, 0.9854, 0.9908, 0.5028, 0.9856, 0.5487, 0.9914,
                      0.9915, 0.9915]),
       size=(8016, 8016), nnz=30, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
Counter({'dealtWithIn': 5, 'author': 5, 'isWorkedOnBy': 4, 'publication': 4, 'publishes': 3, 'isAbout': 3, 'hasProject': 2, 'member': 1, 'fax': 1, 'photo': 1, 'carriedOutBy': 1})
dict index: {}
Traceback (most recent call last):
  File "r_exp.py", line 514, in <module>
    main('aifb',node_idx= 5791, prune= True, explain_all =True, train=True)
  File "r_exp.py", line 443, in main
    h_floats = selected(masked_ver, threshold=0.5,data=data, low_threshold=False,float=True)
  File "/home/tliberatore/RGCN-Explainer/RGCN_stuff/src/rgcn_explainer_utils.py", line 266, in selected
    l[data.i2rel[int(i)][0]] += j
RuntimeError: Output 1 of UnbindBackward0 is a view and is being modified inplace. This view is the output of a function that returns multiple views. Such functions do not allow the output views to be modified inplace. You should replace the inplace operation by an out-of-place one.