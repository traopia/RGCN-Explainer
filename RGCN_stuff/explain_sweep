wandb: Agent Starting Run: gfq6oid7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: W&B API key is configured. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124549-gfq6oid7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-1
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gfq6oid7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 1
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92551
wandb:       num_high 24
wandb:      pred_loss 1.36578
wandb:          score 1.99912
wandb:      size_loss 0.02741
wandb:  size_std_loss -7.72511
wandb:     wrong_pred 1
wandb: 
wandb:  View run happy-sweep-1 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gfq6oid7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124549-gfq6oid7/logs
wandb: Agent Starting Run: unepn8qy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: Currently logged in as: t-liberatore. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124611-unepn8qy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-2
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/unepn8qy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 1
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92551
wandb:       num_high 26
wandb:      pred_loss 1.36578
wandb:          score 1.99912
wandb:      size_loss 0.02741
wandb:  size_std_loss -7.74998
wandb:     wrong_pred 1
wandb: 
wandb:  View run pretty-sweep-2 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/unepn8qy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124611-unepn8qy/logs
wandb: Agent Starting Run: 8o52iufn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124632-8o52iufn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-3
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8o52iufn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 40
wandb:           loss 0.0
wandb:  mask_ent_loss -6.82366
wandb:       num_high 494
wandb:      pred_loss 0.56427
wandb:          score 1.96466
wandb:      size_loss 0.02922
wandb:  size_std_loss -76.63004
wandb:     wrong_pred 0
wandb: 
wandb:  View run comfy-sweep-3 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8o52iufn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124632-8o52iufn/logs
wandb: Agent Starting Run: 478y061z with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124653-478y061z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-4
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/478y061z
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.0
wandb:  mask_ent_loss -6.10227
wandb:       num_high 1049
wandb:      pred_loss 3e-05
wandb:          score 1.92845
wandb:      size_loss 0.03713
wandb:  size_std_loss -130.46294
wandb:     wrong_pred 0
wandb: 
wandb:  View run dashing-sweep-4 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/478y061z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124653-478y061z/logs
wandb: Agent Starting Run: b4t4wuyd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124713-b4t4wuyd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-5
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/b4t4wuyd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79915
wandb:     wrong_pred 0
wandb: 
wandb:  View run dainty-sweep-5 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/b4t4wuyd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124713-b4t4wuyd/logs
wandb: Agent Starting Run: pf9qpkca with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124733-pf9qpkca
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-6
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pf9qpkca
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79915
wandb:     wrong_pred 0
wandb: 
wandb:  View run pretty-sweep-6 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pf9qpkca
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124733-pf9qpkca/logs
wandb: Agent Starting Run: bcpmkbqh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124755-bcpmkbqh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-7
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bcpmkbqh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79916
wandb:     wrong_pred 0
wandb: 
wandb:  View run youthful-sweep-7 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bcpmkbqh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124755-bcpmkbqh/logs
wandb: Agent Starting Run: 4o0neudc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124816-4o0neudc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-8
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4o0neudc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79916
wandb:     wrong_pred 0
wandb: 
wandb:  View run earnest-sweep-8 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4o0neudc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124816-4o0neudc/logs
wandb: Agent Starting Run: gajg4ul7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124837-gajg4ul7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-9
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gajg4ul7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.32437
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.92308
wandb:     wrong_pred 0
wandb: 
wandb:  View run apricot-sweep-9 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gajg4ul7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124837-gajg4ul7/logs
wandb: Agent Starting Run: y0hsjlmy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124857-y0hsjlmy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-10
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/y0hsjlmy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.32437
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.92306
wandb:     wrong_pred 0
wandb: 
wandb:  View run ancient-sweep-10 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/y0hsjlmy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124857-y0hsjlmy/logs
wandb: Agent Starting Run: 35h5uing with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124918-35h5uing
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-11
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/35h5uing
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2e-05
wandb:  mask_ent_loss -6.09535
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03963
wandb:  size_std_loss -23.24191
wandb:     wrong_pred 0
wandb: 
wandb:  View run solar-sweep-11 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/35h5uing
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124918-35h5uing/logs
wandb: Agent Starting Run: rvmaja9i with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_124939-rvmaja9i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-12
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rvmaja9i
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2e-05
wandb:  mask_ent_loss -5.88087
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04097
wandb:  size_std_loss -23.69866
wandb:     wrong_pred 0
wandb: 
wandb:  View run eternal-sweep-12 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rvmaja9i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_124939-rvmaja9i/logs
wandb: Agent Starting Run: r467748v with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125000-r467748v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-13
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r467748v
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1864978.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run scarlet-sweep-13 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r467748v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125000-r467748v/logs
wandb: Agent Starting Run: xjlf7fup with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125021-xjlf7fup
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-14
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xjlf7fup
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1864978.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run charmed-sweep-14 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xjlf7fup
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125021-xjlf7fup/logs
wandb: Agent Starting Run: ipk6x33q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125041-ipk6x33q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-15
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ipk6x33q
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 30702657601536.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run colorful-sweep-15 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ipk6x33q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125041-ipk6x33q/logs
wandb: Agent Starting Run: d276q8uc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125102-d276q8uc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-16
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d276q8uc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 30702657601536.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run worldly-sweep-16 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d276q8uc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125102-d276q8uc/logs
wandb: Agent Starting Run: eof5enz8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125123-eof5enz8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-17
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eof5enz8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.29903
wandb:  mask_ent_loss -0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run divine-sweep-17 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eof5enz8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125123-eof5enz8/logs
wandb: Agent Starting Run: t4r839uh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125144-t4r839uh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-18
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t4r839uh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.29903
wandb:  mask_ent_loss -0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run golden-sweep-18 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t4r839uh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125144-t4r839uh/logs
wandb: Agent Starting Run: dhoucy07 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125204-dhoucy07
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-19
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dhoucy07
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 109519992.0
wandb:  mask_ent_loss -0.00757
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00032
wandb:     wrong_pred 0
wandb: 
wandb:  View run lemon-sweep-19 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dhoucy07
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125204-dhoucy07/logs
wandb: Agent Starting Run: 5pbxuiy0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125225-5pbxuiy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-20
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5pbxuiy0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110017656.0
wandb:  mask_ent_loss -0.00329
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run solar-sweep-20 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5pbxuiy0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125225-5pbxuiy0/logs
wandb: Agent Starting Run: 6rx74134 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125245-6rx74134
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-21
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6rx74134
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run generous-sweep-21 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6rx74134
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125245-6rx74134/logs
wandb: Agent Starting Run: ojerzn0u with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125306-ojerzn0u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-22
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ojerzn0u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run rare-sweep-22 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ojerzn0u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125306-ojerzn0u/logs
wandb: Agent Starting Run: 47ad2s9y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125327-47ad2s9y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run upbeat-sweep-23
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/47ad2s9y
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run upbeat-sweep-23 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/47ad2s9y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125327-47ad2s9y/logs
wandb: Agent Starting Run: rxauyb41 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125348-rxauyb41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-24
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rxauyb41
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run dry-sweep-24 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rxauyb41
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125348-rxauyb41/logs
wandb: Agent Starting Run: xuj9v75o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125419-xuj9v75o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-25
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xuj9v75o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.66143
wandb:  mask_ent_loss -0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run whole-sweep-25 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xuj9v75o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125419-xuj9v75o/logs
wandb: Agent Starting Run: htbjuoyb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125440-htbjuoyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-26
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/htbjuoyb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.66143
wandb:  mask_ent_loss -0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run peachy-sweep-26 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/htbjuoyb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125440-htbjuoyb/logs
wandb: Agent Starting Run: 5o5nf6ry with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125501-5o5nf6ry
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-27
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5o5nf6ry
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 109850536.0
wandb:  mask_ent_loss -0.00488
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.0
wandb:     wrong_pred 0
wandb: 
wandb:  View run efficient-sweep-27 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5o5nf6ry
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125501-5o5nf6ry/logs
wandb: Agent Starting Run: ydffnzpz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125522-ydffnzpz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-28
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ydffnzpz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 109826656.0
wandb:  mask_ent_loss -0.0049
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run robust-sweep-28 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ydffnzpz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125522-ydffnzpz/logs
wandb: Agent Starting Run: k7a1pcwj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125543-k7a1pcwj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-29
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/k7a1pcwj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run giddy-sweep-29 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/k7a1pcwj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125543-k7a1pcwj/logs
wandb: Agent Starting Run: bqat755u with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125603-bqat755u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-30
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bqat755u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run giddy-sweep-30 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bqat755u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125603-bqat755u/logs
wandb: Agent Starting Run: e2tkzcfn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125624-e2tkzcfn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-31
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/e2tkzcfn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run azure-sweep-31 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/e2tkzcfn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125624-e2tkzcfn/logs
wandb: Agent Starting Run: z6bafq8m with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125645-z6bafq8m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rosy-sweep-32
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z6bafq8m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run rosy-sweep-32 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z6bafq8m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125645-z6bafq8m/logs
wandb: Agent Starting Run: m1zzfeag with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125706-m1zzfeag
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-33
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m1zzfeag
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00186
wandb:  mask_ent_loss -6.93104
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02804
wandb:  size_std_loss -0.75194
wandb:     wrong_pred 1
wandb: 
wandb:  View run fresh-sweep-33 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m1zzfeag
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125706-m1zzfeag/logs
wandb: Agent Starting Run: xbqdjrif with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125726-xbqdjrif
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-34
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xbqdjrif
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00086
wandb:  mask_ent_loss -6.93099
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02803
wandb:  size_std_loss -1.52309
wandb:     wrong_pred 1
wandb: 
wandb:  View run glad-sweep-34 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xbqdjrif
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125726-xbqdjrif/logs
wandb: Agent Starting Run: tluyoy5t with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125747-tluyoy5t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-35
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tluyoy5t
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.69025
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02366
wandb:  size_std_loss -77.99466
wandb:     wrong_pred 1
wandb: 
wandb:  View run legendary-sweep-35 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tluyoy5t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125747-tluyoy5t/logs
wandb: Agent Starting Run: wofpqifn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125807-wofpqifn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-36
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wofpqifn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67944
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02351
wandb:  size_std_loss -78.83733
wandb:     wrong_pred 1
wandb: 
wandb:  View run clean-sweep-36 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wofpqifn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125807-wofpqifn/logs
wandb: Agent Starting Run: o7nwz2ga with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125829-o7nwz2ga
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-37
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o7nwz2ga
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run polar-sweep-37 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o7nwz2ga
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125829-o7nwz2ga/logs
wandb: Agent Starting Run: wexs63wn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125849-wexs63wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-38
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wexs63wn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run rose-sweep-38 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wexs63wn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125849-wexs63wn/logs
wandb: Agent Starting Run: syabgz25 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125910-syabgz25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-39
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/syabgz25
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run ruby-sweep-39 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/syabgz25
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125910-syabgz25/logs
wandb: Agent Starting Run: ap4v1606 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125931-ap4v1606
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-40
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ap4v1606
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run sandy-sweep-40 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ap4v1606
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125931-ap4v1606/logs
wandb: Agent Starting Run: 37m98szs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_125951-37m98szs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-41
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/37m98szs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.0024
wandb:  mask_ent_loss -6.93059
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02793
wandb:  size_std_loss -0.49698
wandb:     wrong_pred 1
wandb: 
wandb:  View run decent-sweep-41 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/37m98szs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_125951-37m98szs/logs
wandb: Agent Starting Run: i81bxnpv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130012-i81bxnpv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-42
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i81bxnpv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00193
wandb:  mask_ent_loss -6.93059
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02793
wandb:  size_std_loss -0.71299
wandb:     wrong_pred 1
wandb: 
wandb:  View run worthy-sweep-42 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i81bxnpv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130012-i81bxnpv/logs
wandb: Agent Starting Run: 763ogudt with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130033-763ogudt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-43
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/763ogudt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.04767
wandb:  mask_ent_loss -6.92379
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.61166
wandb:     wrong_pred 0
wandb: 
wandb:  View run cool-sweep-43 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/763ogudt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130033-763ogudt/logs
wandb: Agent Starting Run: 34i7h1tg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130054-34i7h1tg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-44
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/34i7h1tg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: / 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.04805
wandb:  mask_ent_loss -6.92378
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.60385
wandb:     wrong_pred 0
wandb: 
wandb:  View run brisk-sweep-44 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/34i7h1tg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130054-34i7h1tg/logs
wandb: Agent Starting Run: ngu38sb0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130115-ngu38sb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-45
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ngu38sb0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25144.10156
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run electric-sweep-45 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ngu38sb0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130115-ngu38sb0/logs
wandb: Agent Starting Run: vh66kl2o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130135-vh66kl2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-46
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vh66kl2o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25144.10156
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run atomic-sweep-46 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vh66kl2o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130135-vh66kl2o/logs
wandb: Agent Starting Run: megh4imb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130157-megh4imb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-47
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/megh4imb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 413942513664.0
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run laced-sweep-47 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/megh4imb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130157-megh4imb/logs
wandb: Agent Starting Run: ankcpcf1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130218-ankcpcf1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-48
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ankcpcf1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 413942513664.0
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run eager-sweep-48 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ankcpcf1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130218-ankcpcf1/logs
wandb: Agent Starting Run: nemfe5ys with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130238-nemfe5ys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-49
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nemfe5ys
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00219
wandb:  mask_ent_loss -6.93136
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02817
wandb:  size_std_loss -0.58801
wandb:     wrong_pred 1
wandb: 
wandb:  View run happy-sweep-49 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nemfe5ys
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130238-nemfe5ys/logs
wandb: Agent Starting Run: decdjcgy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130259-decdjcgy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-50
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/decdjcgy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00186
wandb:  mask_ent_loss -6.93136
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02817
wandb:  size_std_loss -0.75039
wandb:     wrong_pred 1
wandb: 
wandb:  View run generous-sweep-50 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/decdjcgy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130259-decdjcgy/logs
wandb: Agent Starting Run: 4enoo9eb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130320-4enoo9eb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-51
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4enoo9eb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.9229
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02786
wandb:  size_std_loss -20.66013
wandb:     wrong_pred 1
wandb: 
wandb:  View run fiery-sweep-51 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4enoo9eb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130320-4enoo9eb/logs
wandb: Agent Starting Run: 255t5mub with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130340-255t5mub
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-52
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/255t5mub
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.90994
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02759
wandb:  size_std_loss -32.59633
wandb:     wrong_pred 1
wandb: 
wandb:  View run lyric-sweep-52 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/255t5mub
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130340-255t5mub/logs
wandb: Agent Starting Run: 093ww2hr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130401-093ww2hr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-53
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/093ww2hr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.90221
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 27.08175
wandb:  size_std_loss -33.90592
wandb:     wrong_pred 1
wandb: 
wandb:  View run whole-sweep-53 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/093ww2hr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130401-093ww2hr/logs
wandb: Agent Starting Run: sco33iqx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130421-sco33iqx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-54
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sco33iqx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.90534
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 27.35807
wandb:  size_std_loss -34.43969
wandb:     wrong_pred 1
wandb: 
wandb:  View run colorful-sweep-54 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sco33iqx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130421-sco33iqx/logs
wandb: Agent Starting Run: 9ptu5we2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130443-9ptu5we2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-55
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ptu5we2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.89902
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 27.58485
wandb:  size_std_loss -41.00499
wandb:     wrong_pred 1
wandb: 
wandb:  View run ethereal-sweep-55 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ptu5we2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130443-9ptu5we2/logs
wandb: Agent Starting Run: rmyk3eu1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130504-rmyk3eu1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cosmic-sweep-56
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rmyk3eu1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00857
wandb:  mask_ent_loss -6.89544
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.56163
wandb:  size_std_loss -45.31958
wandb:     wrong_pred 1
wandb: 
wandb:  View run cosmic-sweep-56 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rmyk3eu1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130504-rmyk3eu1/logs
wandb: Agent Starting Run: lsatorx0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130525-lsatorx0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-57
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/lsatorx0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run still-sweep-57 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/lsatorx0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130525-lsatorx0/logs
wandb: Agent Starting Run: 7ivzqhkh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130545-7ivzqhkh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-58
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7ivzqhkh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run robust-sweep-58 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7ivzqhkh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130545-7ivzqhkh/logs
wandb: Agent Starting Run: 40jurera with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130607-40jurera
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-59
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/40jurera
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run gallant-sweep-59 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/40jurera
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130607-40jurera/logs
wandb: Agent Starting Run: n9fb3ev2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130628-n9fb3ev2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-60
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/n9fb3ev2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run mild-sweep-60 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/n9fb3ev2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130628-n9fb3ev2/logs
wandb: Agent Starting Run: nuj604g2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130648-nuj604g2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-61
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nuj604g2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 1e-05
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.40144
wandb:  size_std_loss -45.01017
wandb:     wrong_pred 1
wandb: 
wandb:  View run fresh-sweep-61 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nuj604g2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130648-nuj604g2/logs
wandb: Agent Starting Run: onyxuj2w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130709-onyxuj2w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-62
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/onyxuj2w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 1e-05
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.40143
wandb:  size_std_loss -45.01087
wandb:     wrong_pred 1
wandb: 
wandb:  View run avid-sweep-62 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/onyxuj2w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130709-onyxuj2w/logs
wandb: Agent Starting Run: ix67wjzl with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130730-ix67wjzl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-63
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ix67wjzl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.13602
wandb:  mask_ent_loss -6.47867
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.3173
wandb:  size_std_loss -50.72807
wandb:     wrong_pred 1
wandb: 
wandb:  View run silver-sweep-63 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ix67wjzl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130730-ix67wjzl/logs
wandb: Agent Starting Run: 1rmup8km with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130750-1rmup8km
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-64
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1rmup8km
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.01625
wandb:  mask_ent_loss -6.47802
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.28658
wandb:  size_std_loss -52.82242
wandb:     wrong_pred 1
wandb: 
wandb:  View run misty-sweep-64 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1rmup8km
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130750-1rmup8km/logs
wandb: Agent Starting Run: 1aq0xucp with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130812-1aq0xucp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-65
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1aq0xucp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00068
wandb:  mask_ent_loss -6.93126
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02836
wandb:  size_std_loss -3.3029
wandb:     wrong_pred 1
wandb: 
wandb:  View run lyric-sweep-65 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1aq0xucp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130812-1aq0xucp/logs
wandb: Agent Starting Run: coo3glg8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130832-coo3glg8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-66
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/coo3glg8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00068
wandb:  mask_ent_loss -6.93126
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02836
wandb:  size_std_loss -3.29825
wandb:     wrong_pred 1
wandb: 
wandb:  View run deep-sweep-66 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/coo3glg8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130832-coo3glg8/logs
wandb: Agent Starting Run: h6if89ly with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130853-h6if89ly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-67
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h6if89ly
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.90197
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02988
wandb:  size_std_loss -28.53528
wandb:     wrong_pred 1
wandb: 
wandb:  View run devout-sweep-67 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h6if89ly
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130853-h6if89ly/logs
wandb: Agent Starting Run: u1z2qrv7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130913-u1z2qrv7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-68
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u1z2qrv7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss -6.76691
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.0242
wandb:  size_std_loss -58.63078
wandb:     wrong_pred 1
wandb: 
wandb:  View run ancient-sweep-68 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u1z2qrv7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130913-u1z2qrv7/logs
wandb: Agent Starting Run: vjqttobo with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130934-vjqttobo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-69
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vjqttobo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.18602
wandb:  mask_ent_loss -6.92102
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.39061
wandb:  size_std_loss -24.58704
wandb:     wrong_pred 1
wandb: 
wandb:  View run glamorous-sweep-69 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vjqttobo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130934-vjqttobo/logs
wandb: Agent Starting Run: 9no2fqs6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_130955-9no2fqs6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-70
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9no2fqs6
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.25268
wandb:  mask_ent_loss -6.91063
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.51961
wandb:  size_std_loss -25.83091
wandb:     wrong_pred 0
wandb: 
wandb:  View run still-sweep-70 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9no2fqs6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_130955-9no2fqs6/logs
wandb: Agent Starting Run: ayp6sl6m with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131016-ayp6sl6m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-71
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ayp6sl6m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss -6.64232
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.64638
wandb:  size_std_loss -93.5095
wandb:     wrong_pred 1
wandb: 
wandb:  View run volcanic-sweep-71 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ayp6sl6m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131016-ayp6sl6m/logs
wandb: Agent Starting Run: zednqzi5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131037-zednqzi5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-72
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zednqzi5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss -6.63963
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.61423
wandb:  size_std_loss -93.74755
wandb:     wrong_pred 1
wandb: 
wandb:  View run sparkling-sweep-72 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zednqzi5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131037-zednqzi5/logs
wandb: Agent Starting Run: 3sgia4co with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131058-3sgia4co
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-73
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3sgia4co
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run robust-sweep-73 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3sgia4co
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131058-3sgia4co/logs
wandb: Agent Starting Run: 3mws25kt with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131118-3mws25kt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-74
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3mws25kt
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run magic-sweep-74 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3mws25kt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131118-3mws25kt/logs
wandb: Agent Starting Run: 18tn77zh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131139-18tn77zh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-75
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/18tn77zh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run skilled-sweep-75 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/18tn77zh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131139-18tn77zh/logs
wandb: Agent Starting Run: zllx8sec with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131200-zllx8sec
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-76
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zllx8sec
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run vague-sweep-76 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zllx8sec
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131200-zllx8sec/logs
wandb: Agent Starting Run: il17hxjw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131220-il17hxjw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-77
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/il17hxjw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run helpful-sweep-77 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/il17hxjw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131220-il17hxjw/logs
wandb: Agent Starting Run: stqa2gss with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131241-stqa2gss
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-78
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/stqa2gss
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run comic-sweep-78 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/stqa2gss
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131241-stqa2gss/logs
wandb: Agent Starting Run: s68s308x with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131301-s68s308x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-79
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s68s308x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00249
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12131
wandb:  size_std_loss -46.68871
wandb:     wrong_pred 0
wandb: 
wandb:  View run brisk-sweep-79 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s68s308x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131301-s68s308x/logs
wandb: Agent Starting Run: u30cel6n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131323-u30cel6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-80
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u30cel6n
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00248
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12033
wandb:  size_std_loss -46.69538
wandb:     wrong_pred 0
wandb: 
wandb:  View run confused-sweep-80 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u30cel6n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131323-u30cel6n/logs
wandb: Agent Starting Run: xw0g7eng with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131344-xw0g7eng
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run likely-sweep-81
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xw0g7eng
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 7
wandb:           loss 0.0
wandb:  mask_ent_loss -6.84378
wandb:       num_high 86
wandb:      pred_loss 1.36578
wandb:          score 1.99382
wandb:      size_loss 0.02473
wandb:  size_std_loss -21.4463
wandb:     wrong_pred 1
wandb: 
wandb:  View run likely-sweep-81 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xw0g7eng
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131344-xw0g7eng/logs
wandb: Agent Starting Run: qv9su3ue with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131404-qv9su3ue
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-82
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qv9su3ue
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 7
wandb:           loss 0.0
wandb:  mask_ent_loss -6.84378
wandb:       num_high 86
wandb:      pred_loss 1.36578
wandb:          score 1.99382
wandb:      size_loss 0.02473
wandb:  size_std_loss -21.44036
wandb:     wrong_pred 1
wandb: 
wandb:  View run polished-sweep-82 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qv9su3ue
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131404-qv9su3ue/logs
wandb: Agent Starting Run: bpla2rcv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131425-bpla2rcv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-83
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bpla2rcv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 2
wandb:           loss 0.0
wandb:  mask_ent_loss -6.8742
wandb:       num_high 44
wandb:      pred_loss 1.36578
wandb:          score 1.99823
wandb:      size_loss 0.0258
wandb:  size_std_loss -32.28941
wandb:     wrong_pred 1
wandb: 
wandb:  View run glad-sweep-83 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bpla2rcv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131425-bpla2rcv/logs
wandb: Agent Starting Run: 765l48lt with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131446-765l48lt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run faithful-sweep-84
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/765l48lt
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88923
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02614
wandb:  size_std_loss -27.39698
wandb:     wrong_pred 1
wandb: 
wandb:  View run faithful-sweep-84 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/765l48lt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131446-765l48lt/logs
wandb: Agent Starting Run: gnj6jp33 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131507-gnj6jp33
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-85
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gnj6jp33
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.8511
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 25.16254
wandb:  size_std_loss -32.4847
wandb:     wrong_pred 1
wandb: 
wandb:  View run colorful-sweep-85 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gnj6jp33
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131507-gnj6jp33/logs
wandb: Agent Starting Run: 7egxjb7r with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131527-7egxjb7r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-86
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7egxjb7r
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.87105
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 25.93071
wandb:  size_std_loss -37.83315
wandb:     wrong_pred 1
wandb: 
wandb:  View run autumn-sweep-86 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7egxjb7r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131527-7egxjb7r/logs
wandb: Agent Starting Run: enxpbod8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131550-enxpbod8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-87
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/enxpbod8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.83353
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.80236
wandb:  size_std_loss -34.5574
wandb:     wrong_pred 1
wandb: 
wandb:  View run sparkling-sweep-87 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/enxpbod8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131550-enxpbod8/logs
wandb: Agent Starting Run: 250v6kc8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131611-250v6kc8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fanciful-sweep-88
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/250v6kc8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.85367
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 25.43709
wandb:  size_std_loss -38.62383
wandb:     wrong_pred 1
wandb: 
wandb:  View run fanciful-sweep-88 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/250v6kc8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131611-250v6kc8/logs
wandb: Agent Starting Run: nq5e65bq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131632-nq5e65bq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-89
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nq5e65bq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run mild-sweep-89 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nq5e65bq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131632-nq5e65bq/logs
wandb: Agent Starting Run: uhom4w8j with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131652-uhom4w8j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-90
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uhom4w8j
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run toasty-sweep-90 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uhom4w8j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131652-uhom4w8j/logs
wandb: Agent Starting Run: wazlbvx6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131713-wazlbvx6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-91
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wazlbvx6
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run wild-sweep-91 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wazlbvx6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131713-wazlbvx6/logs
wandb: Agent Starting Run: 5wksm5xe with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131733-5wksm5xe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-92
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5wksm5xe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run vital-sweep-92 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5wksm5xe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131733-5wksm5xe/logs
wandb: Agent Starting Run: 7sn4wkk8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131755-7sn4wkk8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-93
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7sn4wkk8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run effortless-sweep-93 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7sn4wkk8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131755-7sn4wkk8/logs
wandb: Agent Starting Run: 2tfwg376 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131816-2tfwg376
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-94
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2tfwg376
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run elated-sweep-94 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2tfwg376
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131816-2tfwg376/logs
wandb: Agent Starting Run: chvig5jz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131836-chvig5jz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-95
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/chvig5jz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49449
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6055
wandb:  size_std_loss -69.77669
wandb:     wrong_pred 0
wandb: 
wandb:  View run gallant-sweep-95 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/chvig5jz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131836-chvig5jz/logs
wandb: Agent Starting Run: bwjmfnpb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131857-bwjmfnpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-96
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bwjmfnpb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49449
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.60638
wandb:  size_std_loss -69.71101
wandb:     wrong_pred 0
wandb: 
wandb:  View run feasible-sweep-96 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bwjmfnpb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131857-bwjmfnpb/logs
wandb: Agent Starting Run: 68el1xoe with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131918-68el1xoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-97
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/68el1xoe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00119
wandb:  mask_ent_loss -6.93131
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02843
wandb:  size_std_loss -1.67425
wandb:     wrong_pred 0
wandb: 
wandb:  View run genial-sweep-97 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/68el1xoe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131918-68el1xoe/logs
wandb: Agent Starting Run: qztvlk1v with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131939-qztvlk1v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-98
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qztvlk1v
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00113
wandb:  mask_ent_loss -6.93131
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02843
wandb:  size_std_loss -1.73017
wandb:     wrong_pred 0
wandb: 
wandb:  View run floral-sweep-98 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qztvlk1v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131939-qztvlk1v/logs
wandb: Agent Starting Run: 18szb9pi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_131959-18szb9pi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run soft-sweep-99
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/18szb9pi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.77231
wandb:       num_high 1090
wandb:      pred_loss 1.12945
wandb:          score 1.92314
wandb:      size_loss 0.03274
wandb:  size_std_loss -45.42536
wandb:     wrong_pred 1
wandb: 
wandb:  View run soft-sweep-99 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/18szb9pi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_131959-18szb9pi/logs
wandb: Agent Starting Run: qtysedjb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132020-qtysedjb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-100
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qtysedjb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92481
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02753
wandb:  size_std_loss -13.14553
wandb:     wrong_pred 1
wandb: 
wandb:  View run glamorous-sweep-100 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qtysedjb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132020-qtysedjb/logs
wandb: Agent Starting Run: 1xolrkth with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132041-1xolrkth
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-101
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1xolrkth
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.76309
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48542
wandb:  size_std_loss -66.18763
wandb:     wrong_pred 1
wandb: 
wandb:  View run ruby-sweep-101 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1xolrkth
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132041-1xolrkth/logs
wandb: Agent Starting Run: cydc9te3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132102-cydc9te3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-102
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cydc9te3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.76309
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.4853
wandb:  size_std_loss -66.18817
wandb:     wrong_pred 1
wandb: 
wandb:  View run bright-sweep-102 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cydc9te3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132102-cydc9te3/logs
wandb: Agent Starting Run: b9istdx3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132123-b9istdx3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-103
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/b9istdx3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.76309
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48529
wandb:  size_std_loss -66.18828
wandb:     wrong_pred 1
wandb: 
wandb:  View run deep-sweep-103 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/b9istdx3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132123-b9istdx3/logs
wandb: Agent Starting Run: 8st2fgt7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132144-8st2fgt7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-104
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8st2fgt7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss -6.76309
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48529
wandb:  size_std_loss -66.18828
wandb:     wrong_pred 1
wandb: 
wandb:  View run valiant-sweep-104 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8st2fgt7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132144-8st2fgt7/logs
wandb: Agent Starting Run: wgeagak7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132205-wgeagak7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-105
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wgeagak7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92894
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.09085
wandb:     wrong_pred 0
wandb: 
wandb:  View run devoted-sweep-105 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wgeagak7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132205-wgeagak7/logs
wandb: Agent Starting Run: eteyjk4o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132225-eteyjk4o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-106
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eteyjk4o
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92894
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.09086
wandb:     wrong_pred 0
wandb: 
wandb:  View run gentle-sweep-106 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eteyjk4o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132225-eteyjk4o/logs
wandb: Agent Starting Run: sho62rzy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132246-sho62rzy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-107
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sho62rzy
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.19199
wandb:  mask_ent_loss -6.928
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02857
wandb:  size_std_loss -13.2138
wandb:     wrong_pred 0
wandb: 
wandb:  View run stilted-sweep-107 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sho62rzy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132246-sho62rzy/logs
wandb: Agent Starting Run: bnrnevb0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132306-bnrnevb0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-108
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bnrnevb0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1e-05
wandb:  mask_ent_loss -6.91938
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02894
wandb:  size_std_loss -23.44587
wandb:     wrong_pred 0
wandb: 
wandb:  View run deep-sweep-108 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bnrnevb0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132306-bnrnevb0/logs
wandb: Agent Starting Run: wqgymjof with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132327-wqgymjof
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-109
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wqgymjof
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 251.34628
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88343
wandb:  size_std_loss -20.32042
wandb:     wrong_pred 0
wandb: 
wandb:  View run northern-sweep-109 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wqgymjof
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132327-wqgymjof/logs
wandb: Agent Starting Run: ow1kog35 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132348-ow1kog35
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-110
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ow1kog35
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 251.36115
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88344
wandb:  size_std_loss -20.32037
wandb:     wrong_pred 0
wandb: 
wandb:  View run warm-sweep-110 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ow1kog35
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132348-ow1kog35/logs
wandb: Agent Starting Run: 8o6hbigw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132409-8o6hbigw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hopeful-sweep-111
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8o6hbigw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4138086656.0
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88344
wandb:  size_std_loss -20.32037
wandb:     wrong_pred 0
wandb: 
wandb:  View run hopeful-sweep-111 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8o6hbigw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132409-8o6hbigw/logs
wandb: Agent Starting Run: pc3u9do1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132430-pc3u9do1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-112
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pc3u9do1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4138086656.0
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88344
wandb:  size_std_loss -20.32037
wandb:     wrong_pred 0
wandb: 
wandb:  View run iconic-sweep-112 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pc3u9do1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132430-pc3u9do1/logs
wandb: Agent Starting Run: 1cdsbusm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132451-1cdsbusm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-113
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1cdsbusm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.07188
wandb:  mask_ent_loss 0.6926
wandb:       num_high 8
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.0274
wandb:  size_std_loss -4.73176
wandb:     wrong_pred 1
wandb: 
wandb:  View run robust-sweep-113 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1cdsbusm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132451-1cdsbusm/logs
wandb: Agent Starting Run: zjfpe183 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132521-zjfpe183
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-114
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zjfpe183
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0226
wandb:  mask_ent_loss 0.69258
wandb:       num_high 8
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.0274
wandb:  size_std_loss -5.88898
wandb:     wrong_pred 1
wandb: 
wandb:  View run woven-sweep-114 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zjfpe183
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132521-zjfpe183/logs
wandb: Agent Starting Run: a79vtxdl with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132541-a79vtxdl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-115
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a79vtxdl
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56224
wandb:       num_high 1128
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0405
wandb:  size_std_loss -127.47887
wandb:     wrong_pred 0
wandb: 
wandb:  View run atomic-sweep-115 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a79vtxdl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132541-a79vtxdl/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 2ou5ynho with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132623-2ou5ynho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-116
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2ou5ynho
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56074
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0406
wandb:  size_std_loss -127.07828
wandb:     wrong_pred 0
wandb: 
wandb:  View run good-sweep-116 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2ou5ynho
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132623-2ou5ynho/logs
wandb: Agent Starting Run: b6wlgdb7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132648-b6wlgdb7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-117
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/b6wlgdb7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56555
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.31503
wandb:  size_std_loss -126.84858
wandb:     wrong_pred 0
wandb: 
wandb:  View run eager-sweep-117 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/b6wlgdb7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132648-b6wlgdb7/logs
wandb: Agent Starting Run: 4ia1k102 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132709-4ia1k102
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-118
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4ia1k102
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56555
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.31503
wandb:  size_std_loss -126.84858
wandb:     wrong_pred 0
wandb: 
wandb:  View run genial-sweep-118 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4ia1k102
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132709-4ia1k102/logs
wandb: Agent Starting Run: 6g7rm4nd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132730-6g7rm4nd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-119
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6g7rm4nd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 168172736.0
wandb:  mask_ent_loss 0.57826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.38657
wandb:  size_std_loss -41.48724
wandb:     wrong_pred 0
wandb: 
wandb:  View run zany-sweep-119 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6g7rm4nd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132730-6g7rm4nd/logs
wandb: Agent Starting Run: eoigldxg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132751-eoigldxg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run different-sweep-120
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eoigldxg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 168172736.0
wandb:  mask_ent_loss 0.57826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.38657
wandb:  size_std_loss -41.48724
wandb:     wrong_pred 0
wandb: 
wandb:  View run different-sweep-120 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eoigldxg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132751-eoigldxg/logs
wandb: Agent Starting Run: wucn8wr6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132811-wucn8wr6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-121
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wucn8wr6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00061
wandb:  mask_ent_loss 0.63244
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.9222
wandb:     wrong_pred 0
wandb: 
wandb:  View run volcanic-sweep-121 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wucn8wr6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132811-wucn8wr6/logs
wandb: Agent Starting Run: 0pemf4km with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132833-0pemf4km
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-122
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0pemf4km
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00061
wandb:  mask_ent_loss 0.63244
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.91512
wandb:     wrong_pred 0
wandb: 
wandb:  View run splendid-sweep-122 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0pemf4km
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132833-0pemf4km/logs
wandb: Agent Starting Run: gphgmsm1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132854-gphgmsm1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-123
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gphgmsm1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02147
wandb:  mask_ent_loss 0.58132
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04136
wandb:  size_std_loss -22.92682
wandb:     wrong_pred 0
wandb: 
wandb:  View run helpful-sweep-123 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gphgmsm1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132854-gphgmsm1/logs
wandb: Agent Starting Run: ojj3kfwc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132914-ojj3kfwc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-124
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ojj3kfwc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02138
wandb:  mask_ent_loss 0.58121
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04137
wandb:  size_std_loss -22.93077
wandb:     wrong_pred 0
wandb: 
wandb:  View run neat-sweep-124 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ojj3kfwc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132914-ojj3kfwc/logs
wandb: Agent Starting Run: rm0tinnt with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132934-rm0tinnt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-125
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rm0tinnt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1129259136.0
wandb:  mask_ent_loss 0.58187
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.33206
wandb:  size_std_loss -22.9154
wandb:     wrong_pred 0
wandb: 
wandb:  View run celestial-sweep-125 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rm0tinnt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132934-rm0tinnt/logs
wandb: Agent Starting Run: uxgvw49j with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_132955-uxgvw49j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-126
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uxgvw49j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1129259136.0
wandb:  mask_ent_loss 0.58187
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.33206
wandb:  size_std_loss -22.9154
wandb:     wrong_pred 0
wandb: 
wandb:  View run floral-sweep-126 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uxgvw49j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_132955-uxgvw49j/logs
wandb: Agent Starting Run: h6yjylpa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133016-h6yjylpa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-127
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h6yjylpa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.1852920054681287e+22
wandb:  mask_ent_loss 0.58202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37823
wandb:  size_std_loss -8.98454
wandb:     wrong_pred 0
wandb: 
wandb:  View run eternal-sweep-127 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h6yjylpa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133016-h6yjylpa/logs
wandb: Agent Starting Run: 3p1uq3cx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133037-3p1uq3cx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-128
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3p1uq3cx
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.1852920054681287e+22
wandb:  mask_ent_loss 0.58202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37823
wandb:  size_std_loss -8.98454
wandb:     wrong_pred 0
wandb: 
wandb:  View run glorious-sweep-128 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3p1uq3cx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133037-3p1uq3cx/logs
wandb: Agent Starting Run: tybo7sch with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133058-tybo7sch
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-129
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tybo7sch
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74608
wandb:  mask_ent_loss 0.00623
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run worthy-sweep-129 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tybo7sch
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133058-tybo7sch/logs
wandb: Agent Starting Run: thp1b1va with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133119-thp1b1va
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-130
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/thp1b1va
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74608
wandb:  mask_ent_loss 0.00623
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run scarlet-sweep-130 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/thp1b1va
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133119-thp1b1va/logs
wandb: Agent Starting Run: nia6m29h with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133142-nia6m29h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-131
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nia6m29h
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110393704.0
wandb:  mask_ent_loss 0.00025
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run feasible-sweep-131 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nia6m29h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133142-nia6m29h/logs
wandb: Agent Starting Run: 9jg5x44a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133203-9jg5x44a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-132
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9jg5x44a
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110385280.0
wandb:  mask_ent_loss 0.00017
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run fresh-sweep-132 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9jg5x44a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133203-9jg5x44a/logs
wandb: Agent Starting Run: pajjnwf5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133224-pajjnwf5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-133
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pajjnwf5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run driven-sweep-133 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pajjnwf5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133224-pajjnwf5/logs
wandb: Agent Starting Run: m9iw8c9j with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133245-m9iw8c9j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-134
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m9iw8c9j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run lyric-sweep-134 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m9iw8c9j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133245-m9iw8c9j/logs
wandb: Agent Starting Run: 1zdgojr5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133306-1zdgojr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-135
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1zdgojr5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run playful-sweep-135 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1zdgojr5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133306-1zdgojr5/logs
wandb: Agent Starting Run: zah29k4f with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133326-zah29k4f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-136
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zah29k4f
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run earthy-sweep-136 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zah29k4f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133326-zah29k4f/logs
wandb: Agent Starting Run: 056nlgwv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133347-056nlgwv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-137
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/056nlgwv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.70922
wandb:  mask_ent_loss 0.00065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run peach-sweep-137 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/056nlgwv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133347-056nlgwv/logs
wandb: Agent Starting Run: yct6rlly with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133408-yct6rlly
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-138
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yct6rlly
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.70922
wandb:  mask_ent_loss 0.00065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run misunderstood-sweep-138 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yct6rlly
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133408-yct6rlly/logs
wandb: Agent Starting Run: cruibtir with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133429-cruibtir
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-139
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cruibtir
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110410976.0
wandb:  mask_ent_loss 0.00047
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00026
wandb:     wrong_pred 0
wandb: 
wandb:  View run neat-sweep-139 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cruibtir
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133429-cruibtir/logs
wandb: Agent Starting Run: fiybhpu6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133450-fiybhpu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-140
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fiybhpu6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110404864.0
wandb:  mask_ent_loss 0.00048
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00032
wandb:     wrong_pred 0
wandb: 
wandb:  View run generous-sweep-140 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fiybhpu6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133450-fiybhpu6/logs
wandb: Agent Starting Run: vo3xppdv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133510-vo3xppdv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-141
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vo3xppdv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run eager-sweep-141 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vo3xppdv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133510-vo3xppdv/logs
wandb: Agent Starting Run: txf5b8nm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133531-txf5b8nm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-142
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/txf5b8nm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run ruby-sweep-142 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/txf5b8nm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133531-txf5b8nm/logs
wandb: Agent Starting Run: 8jcge7uy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133552-8jcge7uy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-143
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8jcge7uy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run vivid-sweep-143 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8jcge7uy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133552-8jcge7uy/logs
wandb: Agent Starting Run: ltgohr5r with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133613-ltgohr5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-144
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ltgohr5r
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run fancy-sweep-144 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ltgohr5r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133613-ltgohr5r/logs
wandb: Agent Starting Run: ouh0qdmb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133633-ouh0qdmb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-145
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ouh0qdmb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.03852
wandb:  mask_ent_loss 0.69309
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02823
wandb:  size_std_loss -5.41359
wandb:     wrong_pred 1
wandb: 
wandb:  View run absurd-sweep-145 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ouh0qdmb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133633-ouh0qdmb/logs
wandb: Agent Starting Run: 86le7gux with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133654-86le7gux
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-146
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/86le7gux
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00035
wandb:  mask_ent_loss 0.6929
wandb:       num_high 1087
wandb:      pred_loss 1.12945
wandb:          score 1.9258
wandb:      size_loss 0.02845
wandb:  size_std_loss -11.62895
wandb:     wrong_pred 1
wandb: 
wandb:  View run absurd-sweep-146 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/86le7gux
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133654-86le7gux/logs
wandb: Agent Starting Run: dg1ohtxv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133715-dg1ohtxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-147
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dg1ohtxv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.94307
wandb:     wrong_pred 1
wandb: 
wandb:  View run dashing-sweep-147 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dg1ohtxv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133715-dg1ohtxv/logs
wandb: Agent Starting Run: ge90wkfz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133735-ge90wkfz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-148
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ge90wkfz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.9435
wandb:     wrong_pred 1
wandb: 
wandb:  View run earthy-sweep-148 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ge90wkfz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133735-ge90wkfz/logs
wandb: Agent Starting Run: g2pkfhzw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133756-g2pkfhzw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-149
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g2pkfhzw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run curious-sweep-149 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g2pkfhzw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133756-g2pkfhzw/logs
wandb: Agent Starting Run: 7khs4vmd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133817-7khs4vmd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-150
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7khs4vmd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run fine-sweep-150 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7khs4vmd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133817-7khs4vmd/logs
wandb: Agent Starting Run: beknb1ns with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133838-beknb1ns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-151
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/beknb1ns
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66791
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.51577
wandb:  size_std_loss -79.03844
wandb:     wrong_pred 1
wandb: 
wandb:  View run helpful-sweep-151 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/beknb1ns
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133838-beknb1ns/logs
wandb: Agent Starting Run: bd54x621 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133859-bd54x621
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run daily-sweep-152
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bd54x621
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66791
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.51577
wandb:  size_std_loss -79.03844
wandb:     wrong_pred 1
wandb: 
wandb:  View run daily-sweep-152 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bd54x621
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133859-bd54x621/logs
wandb: Agent Starting Run: wk4gkvz0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133919-wk4gkvz0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-153
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wk4gkvz0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.01272
wandb:  mask_ent_loss 0.69302
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02802
wandb:  size_std_loss -6.52119
wandb:     wrong_pred 1
wandb: 
wandb:  View run sage-sweep-153 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wk4gkvz0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133919-wk4gkvz0/logs
wandb: Agent Starting Run: wnfjn5d5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_133940-wnfjn5d5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-154
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wnfjn5d5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69268
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02835
wandb:  size_std_loss -16.46758
wandb:     wrong_pred 1
wandb: 
wandb:  View run unique-sweep-154 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wnfjn5d5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_133940-wnfjn5d5/logs
wandb: Agent Starting Run: v4m680dm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134001-v4m680dm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-155
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v4m680dm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 96.30389
wandb:  mask_ent_loss 0.69238
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.61688
wandb:     wrong_pred 0
wandb: 
wandb:  View run wise-sweep-155 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v4m680dm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134001-v4m680dm/logs
wandb: Agent Starting Run: 7qpzaqxr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134022-7qpzaqxr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-156
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7qpzaqxr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 96.30389
wandb:  mask_ent_loss 0.69238
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.61688
wandb:     wrong_pred 0
wandb: 
wandb:  View run vibrant-sweep-156 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7qpzaqxr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134022-7qpzaqxr/logs
wandb: Agent Starting Run: bj96kk19 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134043-bj96kk19
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-157
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bj96kk19
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 50090956.0
wandb:  mask_ent_loss 0.69233
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18021
wandb:  size_std_loss -13.98948
wandb:     wrong_pred 0
wandb: 
wandb:  View run dauntless-sweep-157 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bj96kk19
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134043-bj96kk19/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: jxk9ii87 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134121-jxk9ii87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-158
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jxk9ii87
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 50090956.0
wandb:  mask_ent_loss 0.69233
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18021
wandb:  size_std_loss -13.98948
wandb:     wrong_pred 0
wandb: 
wandb:  View run misunderstood-sweep-158 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jxk9ii87
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134121-jxk9ii87/logs
wandb: Agent Starting Run: fpglc63y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134143-fpglc63y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-159
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fpglc63y
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 751856640851968.0
wandb:  mask_ent_loss 0.69234
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.16689
wandb:  size_std_loss -14.06857
wandb:     wrong_pred 0
wandb: 
wandb:  View run misunderstood-sweep-159 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fpglc63y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134143-fpglc63y/logs
wandb: Agent Starting Run: 2omoxssb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134203-2omoxssb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-160
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2omoxssb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 751856640851968.0
wandb:  mask_ent_loss 0.69234
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.16689
wandb:  size_std_loss -14.06857
wandb:     wrong_pred 0
wandb: 
wandb:  View run misunderstood-sweep-160 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2omoxssb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134203-2omoxssb/logs
wandb: Agent Starting Run: 6t97v66q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134225-6t97v66q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-161
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6t97v66q
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69273
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02803
wandb:  size_std_loss -14.69638
wandb:     wrong_pred 1
wandb: 
wandb:  View run sandy-sweep-161 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6t97v66q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134225-6t97v66q/logs
wandb: Agent Starting Run: ragdqss4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134246-ragdqss4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-162
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ragdqss4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69233
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02793
wandb:  size_std_loss -20.63988
wandb:     wrong_pred 1
wandb: 
wandb:  View run astral-sweep-162 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ragdqss4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134246-ragdqss4/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 12hyio99 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134314-12hyio99
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-163
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/12hyio99
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69013
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02721
wandb:  size_std_loss -36.17137
wandb:     wrong_pred 1
wandb: 
wandb:  View run glad-sweep-163 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/12hyio99
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134314-12hyio99/logs
wandb: Agent Starting Run: qnij10gs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134334-qnij10gs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-164
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qnij10gs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.6903
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02706
wandb:  size_std_loss -32.90776
wandb:     wrong_pred 1
wandb: 
wandb:  View run volcanic-sweep-164 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qnij10gs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134334-qnij10gs/logs
wandb: Agent Starting Run: y8rseara with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134354-y8rseara
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-165
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/y8rseara
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.99084
wandb:  mask_ent_loss 0.68924
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 26.29747
wandb:  size_std_loss -28.36168
wandb:     wrong_pred 1
wandb: 
wandb:  View run ancient-sweep-165 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/y8rseara
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134354-y8rseara/logs
wandb: Agent Starting Run: izofwdd4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134416-izofwdd4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-166
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/izofwdd4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 1e-05
wandb:  mask_ent_loss 0.6896
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 27.28931
wandb:  size_std_loss -40.81876
wandb:     wrong_pred 1
wandb: 
wandb:  View run brisk-sweep-166 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/izofwdd4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134416-izofwdd4/logs
wandb: Agent Starting Run: wd9w5o0d with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134437-wd9w5o0d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-167
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wd9w5o0d
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68602
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.56195
wandb:  size_std_loss -63.50681
wandb:     wrong_pred 1
wandb: 
wandb:  View run woven-sweep-167 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wd9w5o0d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134437-wd9w5o0d/logs
wandb: Agent Starting Run: 78g5rcyt with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134457-78g5rcyt
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-168
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/78g5rcyt
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 5265670.0
wandb:  mask_ent_loss 0.69133
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.12465
wandb:  size_std_loss -32.23374
wandb:     wrong_pred 1
wandb: 
wandb:  View run zany-sweep-168 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/78g5rcyt
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134457-78g5rcyt/logs
wandb: Agent Starting Run: j6zawniy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134518-j6zawniy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-169
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j6zawniy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run polar-sweep-169 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j6zawniy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134518-j6zawniy/logs
wandb: Agent Starting Run: 9ckvwf87 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134539-9ckvwf87
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-170
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ckvwf87
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run golden-sweep-170 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ckvwf87
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134539-9ckvwf87/logs
wandb: Agent Starting Run: odlm88ys with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134559-odlm88ys
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-171
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/odlm88ys
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run zany-sweep-171 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/odlm88ys
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134559-odlm88ys/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 3sulyxil with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134628-3sulyxil
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-172
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3sulyxil
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run laced-sweep-172 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3sulyxil
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134628-3sulyxil/logs
wandb: Agent Starting Run: 31wvmuv0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134649-31wvmuv0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-173
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/31wvmuv0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00576
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.39994
wandb:  size_std_loss -45.11077
wandb:     wrong_pred 1
wandb: 
wandb:  View run dark-sweep-173 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/31wvmuv0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134649-31wvmuv0/logs
wandb: Agent Starting Run: d9a17mk1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134709-d9a17mk1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-174
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d9a17mk1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00289
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.38976
wandb:  size_std_loss -45.79141
wandb:     wrong_pred 1
wandb: 
wandb:  View run earthy-sweep-174 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d9a17mk1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134709-d9a17mk1/logs
wandb: Agent Starting Run: cilp9lyz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134731-cilp9lyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-175
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cilp9lyz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.27697
wandb:  mask_ent_loss 0.64768
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.21912
wandb:  size_std_loss -57.04512
wandb:     wrong_pred 1
wandb: 
wandb:  View run valiant-sweep-175 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cilp9lyz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134731-cilp9lyz/logs
wandb: Agent Starting Run: w4ezp3hg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134751-w4ezp3hg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-176
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w4ezp3hg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.14402
wandb:  mask_ent_loss 0.64813
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.16342
wandb:  size_std_loss -57.64378
wandb:     wrong_pred 1
wandb: 
wandb:  View run colorful-sweep-176 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w4ezp3hg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134751-w4ezp3hg/logs
wandb: Agent Starting Run: w2fc4off with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134812-w2fc4off
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-177
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w2fc4off
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00223
wandb:  mask_ent_loss 0.69268
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02755
wandb:  size_std_loss -8.19193
wandb:     wrong_pred 1
wandb: 
wandb:  View run astral-sweep-177 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w2fc4off
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134812-w2fc4off/logs
wandb: Agent Starting Run: 6g5bgk8u with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134833-6g5bgk8u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-178
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6g5bgk8u
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69256
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0286
wandb:  size_std_loss -17.53472
wandb:     wrong_pred 0
wandb: 
wandb:  View run dark-sweep-178 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6g5bgk8u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134833-6g5bgk8u/logs
wandb: Agent Starting Run: ds6kwik1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134853-ds6kwik1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-179
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ds6kwik1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69208
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02848
wandb:  size_std_loss -24.70963
wandb:     wrong_pred 1
wandb: 
wandb:  View run snowy-sweep-179 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ds6kwik1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134853-ds6kwik1/logs
wandb: Agent Starting Run: rwg2mhu6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134914-rwg2mhu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-180
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rwg2mhu6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68962
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02826
wandb:  size_std_loss -45.09116
wandb:     wrong_pred 1
wandb: 
wandb:  View run glowing-sweep-180 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rwg2mhu6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134914-rwg2mhu6/logs
wandb: Agent Starting Run: jq58m0fq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134935-jq58m0fq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-181
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jq58m0fq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68749
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 27.73402
wandb:  size_std_loss -55.96975
wandb:     wrong_pred 1
wandb: 
wandb:  View run desert-sweep-181 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jq58m0fq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134935-jq58m0fq/logs
wandb: Agent Starting Run: a0x4f11t with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_134957-a0x4f11t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sparkling-sweep-182
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a0x4f11t
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68924
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 27.7933
wandb:  size_std_loss -46.48561
wandb:     wrong_pred 1
wandb: 
wandb:  View run sparkling-sweep-182 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a0x4f11t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_134957-a0x4f11t/logs
wandb: Agent Starting Run: dzqi6f13 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135017-dzqi6f13
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-183
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dzqi6f13
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66393
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.61011
wandb:  size_std_loss -93.77776
wandb:     wrong_pred 1
wandb: 
wandb:  View run dutiful-sweep-183 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dzqi6f13
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135017-dzqi6f13/logs
wandb: Agent Starting Run: im8k9iip with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135038-im8k9iip
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-184
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/im8k9iip
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66392
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.60923
wandb:  size_std_loss -93.7823
wandb:     wrong_pred 1
wandb: 
wandb:  View run feasible-sweep-184 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/im8k9iip
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135038-im8k9iip/logs
wandb: Agent Starting Run: npovwezm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135058-npovwezm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-185
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/npovwezm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run stellar-sweep-185 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/npovwezm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135058-npovwezm/logs
wandb: Agent Starting Run: rhel0mmm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135119-rhel0mmm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-186
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rhel0mmm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run spring-sweep-186 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rhel0mmm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135119-rhel0mmm/logs
wandb: Agent Starting Run: mohvdi7c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135140-mohvdi7c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-187
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mohvdi7c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run silver-sweep-187 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mohvdi7c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135140-mohvdi7c/logs
wandb: Agent Starting Run: 36awatx4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135201-36awatx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-188
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/36awatx4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run polished-sweep-188 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/36awatx4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135201-36awatx4/logs
wandb: Agent Starting Run: 0n72fpfb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135221-0n72fpfb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-189
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0n72fpfb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run autumn-sweep-189 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0n72fpfb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135221-0n72fpfb/logs
wandb: Agent Starting Run: x9qurabe with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135242-x9qurabe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-190
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x9qurabe
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run sweepy-sweep-190 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x9qurabe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135242-x9qurabe/logs
wandb: Agent Starting Run: icum2apm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135304-icum2apm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-191
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/icum2apm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68887
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.96906
wandb:  size_std_loss -47.80079
wandb:     wrong_pred 1
wandb: 
wandb:  View run silvery-sweep-191 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/icum2apm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135304-icum2apm/logs
wandb: Agent Starting Run: zmwn13kv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135324-zmwn13kv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sandy-sweep-192
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zmwn13kv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68874
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.90196
wandb:  size_std_loss -48.88729
wandb:     wrong_pred 1
wandb: 
wandb:  View run sandy-sweep-192 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zmwn13kv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135324-zmwn13kv/logs
wandb: Agent Starting Run: 24sqdtqg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135346-24sqdtqg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-193
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/24sqdtqg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68437
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.0247
wandb:  size_std_loss -19.88787
wandb:     wrong_pred 1
wandb: 
wandb:  View run honest-sweep-193 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/24sqdtqg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135346-24sqdtqg/logs
wandb: Agent Starting Run: qdfddsu4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135405-qdfddsu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-194
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qdfddsu4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 2
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68434
wandb:       num_high 44
wandb:      pred_loss 1.36578
wandb:          score 1.99823
wandb:      size_loss 0.02472
wandb:  size_std_loss -20.97792
wandb:     wrong_pred 1
wandb: 
wandb:  View run giddy-sweep-194 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qdfddsu4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135405-qdfddsu4/logs
wandb: Agent Starting Run: 9dyixk9w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135426-9dyixk9w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-195
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9dyixk9w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68935
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02669
wandb:  size_std_loss -35.32254
wandb:     wrong_pred 1
wandb: 
wandb:  View run fresh-sweep-195 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9dyixk9w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135426-9dyixk9w/logs
wandb: Agent Starting Run: ua5r64gq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135447-ua5r64gq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-196
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ua5r64gq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68846
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02651
wandb:  size_std_loss -39.14789
wandb:     wrong_pred 1
wandb: 
wandb:  View run peach-sweep-196 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ua5r64gq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135447-ua5r64gq/logs
wandb: Agent Starting Run: ric19nqs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135508-ric19nqs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-197
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ric19nqs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68953
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.28325
wandb:  size_std_loss -45.585
wandb:     wrong_pred 1
wandb: 
wandb:  View run good-sweep-197 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ric19nqs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135508-ric19nqs/logs
wandb: Agent Starting Run: sybtv6pe with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135529-sybtv6pe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-198
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sybtv6pe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68936
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.84265
wandb:  size_std_loss -45.75451
wandb:     wrong_pred 1
wandb: 
wandb:  View run electric-sweep-198 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sybtv6pe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135529-sybtv6pe/logs
wandb: Agent Starting Run: wnzmco3y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135549-wnzmco3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-199
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wnzmco3y
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00077
wandb:  mask_ent_loss 0.68237
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.56498
wandb:  size_std_loss -33.77753
wandb:     wrong_pred 1
wandb: 
wandb:  View run lilac-sweep-199 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wnzmco3y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135549-wnzmco3y/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: miydjban with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135620-miydjban
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-200
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/miydjban
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.08601
wandb:  mask_ent_loss 0.68229
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.43251
wandb:  size_std_loss -28.93387
wandb:     wrong_pred 1
wandb: 
wandb:  View run snowy-sweep-200 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/miydjban
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135620-miydjban/logs
wandb: Agent Starting Run: 4lgkaf7q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135641-4lgkaf7q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-201
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4lgkaf7q
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run sunny-sweep-201 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4lgkaf7q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135641-4lgkaf7q/logs
wandb: Agent Starting Run: djz5ulbp with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135701-djz5ulbp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-202
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/djz5ulbp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run rose-sweep-202 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/djz5ulbp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135701-djz5ulbp/logs
wandb: Agent Starting Run: gt29gp0t with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135722-gt29gp0t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-203
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gt29gp0t
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run smart-sweep-203 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gt29gp0t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135722-gt29gp0t/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: dt97i9f5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135751-dt97i9f5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-204
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dt97i9f5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run rural-sweep-204 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dt97i9f5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135751-dt97i9f5/logs
wandb: Agent Starting Run: 1k7gvbgq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135812-1k7gvbgq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-205
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1k7gvbgq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run comic-sweep-205 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1k7gvbgq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135812-1k7gvbgq/logs
wandb: Agent Starting Run: qlqxfnob with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135833-qlqxfnob
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polished-sweep-206
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qlqxfnob
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run polished-sweep-206 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qlqxfnob
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135833-qlqxfnob/logs
wandb: Agent Starting Run: fk3f9qwg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135854-fk3f9qwg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-207
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fk3f9qwg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0014
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.62623
wandb:  size_std_loss -68.20956
wandb:     wrong_pred 0
wandb: 
wandb:  View run curious-sweep-207 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fk3f9qwg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135854-fk3f9qwg/logs
wandb: Agent Starting Run: 27hbc95i with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135914-27hbc95i
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-208
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/27hbc95i
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02951
wandb:  mask_ent_loss 0.5496
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.65834
wandb:  size_std_loss -65.19399
wandb:     wrong_pred 0
wandb: 
wandb:  View run apricot-sweep-208 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/27hbc95i
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135914-27hbc95i/logs
wandb: Agent Starting Run: 6h7gbv48 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135935-6h7gbv48
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run skilled-sweep-209
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6h7gbv48
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00561
wandb:  mask_ent_loss 0.69305
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02834
wandb:  size_std_loss -7.30806
wandb:     wrong_pred 1
wandb: 
wandb:  View run skilled-sweep-209 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6h7gbv48
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135935-6h7gbv48/logs
wandb: Agent Starting Run: d54xd1nz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_135955-d54xd1nz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silvery-sweep-210
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d54xd1nz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.01713
wandb:  mask_ent_loss 0.69307
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02816
wandb:  size_std_loss -6.19098
wandb:     wrong_pred 1
wandb: 
wandb:  View run silvery-sweep-210 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d54xd1nz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_135955-d54xd1nz/logs
wandb: Agent Starting Run: x66d17lo with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140017-x66d17lo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-211
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x66d17lo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.67858
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02489
wandb:  size_std_loss -64.35772
wandb:     wrong_pred 1
wandb: 
wandb:  View run earnest-sweep-211 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x66d17lo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140017-x66d17lo/logs
wandb: Agent Starting Run: fyem9j45 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140038-fyem9j45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-212
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fyem9j45
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.67658
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02453
wandb:  size_std_loss -65.98226
wandb:     wrong_pred 1
wandb: 
wandb:  View run exalted-sweep-212 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fyem9j45
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140038-fyem9j45/logs
wandb: Agent Starting Run: sj3t5cmr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140058-sj3t5cmr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-213
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sj3t5cmr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.67631
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48529
wandb:  size_std_loss -66.18832
wandb:     wrong_pred 1
wandb: 
wandb:  View run fiery-sweep-213 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sj3t5cmr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140058-sj3t5cmr/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: v1mqsw6n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140126-v1mqsw6n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-214
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v1mqsw6n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.67631
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48529
wandb:  size_std_loss -66.18832
wandb:     wrong_pred 1
wandb: 
wandb:  View run frosty-sweep-214 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v1mqsw6n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140126-v1mqsw6n/logs
wandb: Agent Starting Run: qxmb4z4b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140146-qxmb4z4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-215
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qxmb4z4b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.67631
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48529
wandb:  size_std_loss -66.18832
wandb:     wrong_pred 1
wandb: 
wandb:  View run vague-sweep-215 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qxmb4z4b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140146-qxmb4z4b/logs
wandb: Agent Starting Run: jvo15f2o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140207-jvo15f2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-216
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jvo15f2o
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 0.67631
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48529
wandb:  size_std_loss -66.18832
wandb:     wrong_pred 1
wandb: 
wandb:  View run solar-sweep-216 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jvo15f2o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140207-jvo15f2o/logs
wandb: Agent Starting Run: mkpdi9xl with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140228-mkpdi9xl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-217
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mkpdi9xl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0002
wandb:  mask_ent_loss 0.69289
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.0913
wandb:     wrong_pred 0
wandb: 
wandb:  View run fluent-sweep-217 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mkpdi9xl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140228-mkpdi9xl/logs
wandb: Agent Starting Run: tq9njnm7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140249-tq9njnm7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-218
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tq9njnm7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0002
wandb:  mask_ent_loss 0.69289
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.09482
wandb:     wrong_pred 0
wandb: 
wandb:  View run earnest-sweep-218 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tq9njnm7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140249-tq9njnm7/logs
wandb: Agent Starting Run: nucvlwy4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140309-nucvlwy4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-219
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nucvlwy4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.17451
wandb:  mask_ent_loss 0.68854
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03078
wandb:  size_std_loss -20.92798
wandb:     wrong_pred 0
wandb: 
wandb:  View run glowing-sweep-219 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nucvlwy4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140309-nucvlwy4/logs
wandb: Agent Starting Run: dr6u5xls with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140330-dr6u5xls
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-220
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dr6u5xls
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.19808
wandb:  mask_ent_loss 0.68843
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03082
wandb:  size_std_loss -20.80125
wandb:     wrong_pred 0
wandb: 
wandb:  View run morning-sweep-220 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dr6u5xls
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140330-dr6u5xls/logs
wandb: Agent Starting Run: 3b37wias with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140351-3b37wias
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-221
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3b37wias
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 477757.9375
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.8809
wandb:  size_std_loss -20.3386
wandb:     wrong_pred 0
wandb: 
wandb:  View run peach-sweep-221 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3b37wias
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140351-3b37wias/logs
wandb: Agent Starting Run: zuvrq35h with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140411-zuvrq35h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-222
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zuvrq35h
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 477757.9375
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.8809
wandb:  size_std_loss -20.3386
wandb:     wrong_pred 0
wandb: 
wandb:  View run honest-sweep-222 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zuvrq35h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140411-zuvrq35h/logs
wandb: Agent Starting Run: p9ca8ssu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140432-p9ca8ssu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-223
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/p9ca8ssu
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7865297272832.0
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88091
wandb:  size_std_loss -20.33859
wandb:     wrong_pred 0
wandb: 
wandb:  View run lively-sweep-223 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/p9ca8ssu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140432-p9ca8ssu/logs
wandb: Agent Starting Run: r91j03y7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140453-r91j03y7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run honest-sweep-224
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r91j03y7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7865297272832.0
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88091
wandb:  size_std_loss -20.33859
wandb:     wrong_pred 0
wandb: 
wandb:  View run honest-sweep-224 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r91j03y7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140453-r91j03y7/logs
wandb: Agent Starting Run: mr15y4x7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140514-mr15y4x7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run drawn-sweep-225
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mr15y4x7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 6
wandb:           loss 0.15971
wandb:  mask_ent_loss 6.9247
wandb:       num_high 55
wandb:      pred_loss 1.33844
wandb:          score 1.9947
wandb:      size_loss 0.02741
wandb:  size_std_loss -10.21415
wandb:     wrong_pred 0
wandb: 
wandb:  View run drawn-sweep-225 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mr15y4x7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140514-mr15y4x7/logs
wandb: Agent Starting Run: sluxz853 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140534-sluxz853
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-226
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sluxz853
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.02314
wandb:  mask_ent_loss 6.92143
wandb:       num_high 43
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.0272
wandb:  size_std_loss -12.12416
wandb:     wrong_pred 0
wandb: 
wandb:  View run smart-sweep-226 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sluxz853
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140534-sluxz853/logs
wandb: Agent Starting Run: knzqriaz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140555-knzqriaz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-227
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/knzqriaz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.59233
wandb:       num_high 1131
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04068
wandb:  size_std_loss -127.16077
wandb:     wrong_pred 0
wandb: 
wandb:  View run wobbly-sweep-227 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/knzqriaz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140555-knzqriaz/logs
wandb: Agent Starting Run: 7bj59x5l with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140616-7bj59x5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-228
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7bj59x5l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.5922
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04069
wandb:  size_std_loss -127.01217
wandb:     wrong_pred 0
wandb: 
wandb:  View run classic-sweep-228 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7bj59x5l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140616-7bj59x5l/logs
wandb: Agent Starting Run: q4fo8gyy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140637-q4fo8gyy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-229
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/q4fo8gyy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.6443
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.38159
wandb:  size_std_loss -126.8956
wandb:     wrong_pred 0
wandb: 
wandb:  View run smooth-sweep-229 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/q4fo8gyy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140637-q4fo8gyy/logs
wandb: Agent Starting Run: 91sg75cc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140657-91sg75cc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-230
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/91sg75cc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.6443
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.38159
wandb:  size_std_loss -126.8956
wandb:     wrong_pred 0
wandb: 
wandb:  View run twilight-sweep-230 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/91sg75cc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140657-91sg75cc/logs
wandb: Agent Starting Run: nxo0eboa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140718-nxo0eboa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-231
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nxo0eboa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.1257688035667585e+24
wandb:  mask_ent_loss 5.8202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37833
wandb:  size_std_loss -8.98214
wandb:     wrong_pred 0
wandb: 
wandb:  View run wandering-sweep-231 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nxo0eboa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140718-nxo0eboa/logs
wandb: Agent Starting Run: pn2uz99a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140738-pn2uz99a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-232
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pn2uz99a
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.1257688035667585e+24
wandb:  mask_ent_loss 5.8202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37833
wandb:  size_std_loss -8.98214
wandb:     wrong_pred 0
wandb: 
wandb:  View run rural-sweep-232 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pn2uz99a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140738-pn2uz99a/logs
wandb: Agent Starting Run: uwankvpb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140800-uwankvpb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-233
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uwankvpb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.18478
wandb:  mask_ent_loss 6.3244
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03804
wandb:  size_std_loss -9.89736
wandb:     wrong_pred 0
wandb: 
wandb:  View run playful-sweep-233 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uwankvpb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140800-uwankvpb/logs
wandb: Agent Starting Run: 6hbbx781 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140821-6hbbx781
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-234
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6hbbx781
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.07385
wandb:  mask_ent_loss 6.32136
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03807
wandb:  size_std_loss -10.81139
wandb:     wrong_pred 0
wandb: 
wandb:  View run youthful-sweep-234 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6hbbx781
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140821-6hbbx781/logs
wandb: Agent Starting Run: yibsomkv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140841-yibsomkv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-235
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yibsomkv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.00681
wandb:  mask_ent_loss 5.81025
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04138
wandb:  size_std_loss -22.92654
wandb:     wrong_pred 0
wandb: 
wandb:  View run rural-sweep-235 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yibsomkv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140841-yibsomkv/logs
wandb: Agent Starting Run: 03e0yt25 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140902-03e0yt25
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-236
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/03e0yt25
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.00663
wandb:  mask_ent_loss 5.81024
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04138
wandb:  size_std_loss -22.92658
wandb:     wrong_pred 0
wandb: 
wandb:  View run woven-sweep-236 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/03e0yt25
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140902-03e0yt25/logs
wandb: Agent Starting Run: 41jnztz7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140923-41jnztz7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-237
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/41jnztz7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 212364034048.0
wandb:  mask_ent_loss 5.8171
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.341
wandb:  size_std_loss -22.92284
wandb:     wrong_pred 0
wandb: 
wandb:  View run woven-sweep-237 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/41jnztz7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140923-41jnztz7/logs
wandb: Agent Starting Run: bkfgb87a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_140944-bkfgb87a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-238
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bkfgb87a
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 212364034048.0
wandb:  mask_ent_loss 5.8171
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.341
wandb:  size_std_loss -22.92284
wandb:     wrong_pred 0
wandb: 
wandb:  View run laced-sweep-238 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bkfgb87a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_140944-bkfgb87a/logs
wandb: Agent Starting Run: oumkz3k4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141005-oumkz3k4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-239
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/oumkz3k4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.311366395608745e+24
wandb:  mask_ent_loss 5.82021
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37838
wandb:  size_std_loss -8.9382
wandb:     wrong_pred 0
wandb: 
wandb:  View run comic-sweep-239 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/oumkz3k4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141005-oumkz3k4/logs
wandb: Agent Starting Run: hvqfoy3x with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141025-hvqfoy3x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-240
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hvqfoy3x
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.311366395608745e+24
wandb:  mask_ent_loss 5.82021
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37838
wandb:  size_std_loss -8.9382
wandb:     wrong_pred 0
wandb: 
wandb:  View run celestial-sweep-240 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hvqfoy3x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141025-hvqfoy3x/logs
wandb: Agent Starting Run: wp5pe5bq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141046-wp5pe5bq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-241
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wp5pe5bq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7.13535
wandb:  mask_ent_loss 0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run devout-sweep-241 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wp5pe5bq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141046-wp5pe5bq/logs
wandb: Agent Starting Run: zz1zcc2t with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141107-zz1zcc2t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dutiful-sweep-242
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zz1zcc2t
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7.13535
wandb:  mask_ent_loss 0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run dutiful-sweep-242 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zz1zcc2t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141107-zz1zcc2t/logs
wandb: Agent Starting Run: c9dlf6a0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141128-c9dlf6a0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-243
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/c9dlf6a0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110769984.0
wandb:  mask_ent_loss 0.00365
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run desert-sweep-243 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/c9dlf6a0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141128-c9dlf6a0/logs
wandb: Agent Starting Run: of7mqlxn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141153-of7mqlxn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-244
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/of7mqlxn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110836768.0
wandb:  mask_ent_loss 0.00438
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00032
wandb:     wrong_pred 0
wandb: 
wandb:  View run pleasant-sweep-244 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/of7mqlxn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141153-of7mqlxn/logs
wandb: Agent Starting Run: 2y9q15np with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141214-2y9q15np
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-245
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2y9q15np
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run expert-sweep-245 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2y9q15np
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141214-2y9q15np/logs
wandb: Agent Starting Run: w82hy0hw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141235-w82hy0hw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-246
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w82hy0hw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run fine-sweep-246 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w82hy0hw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141235-w82hy0hw/logs
wandb: Agent Starting Run: jsjqy24o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141256-jsjqy24o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-247
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jsjqy24o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run fancy-sweep-247 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jsjqy24o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141256-jsjqy24o/logs
wandb: Agent Starting Run: dzb5zlhp with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141319-dzb5zlhp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-248
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dzb5zlhp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run winter-sweep-248 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dzb5zlhp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141319-dzb5zlhp/logs
wandb: Agent Starting Run: fa3ujce5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141339-fa3ujce5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-249
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fa3ujce5
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74858
wandb:  mask_ent_loss 0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run gentle-sweep-249 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fa3ujce5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141339-fa3ujce5/logs
wandb: Agent Starting Run: jyw1ewi7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141400-jyw1ewi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-250
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jyw1ewi7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74858
wandb:  mask_ent_loss 0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run misty-sweep-250 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jyw1ewi7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141400-jyw1ewi7/logs
wandb: Agent Starting Run: 3elz8d1b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141421-3elz8d1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-251
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3elz8d1b
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110873768.0
wandb:  mask_ent_loss 0.00459
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run rose-sweep-251 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3elz8d1b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141421-3elz8d1b/logs
wandb: Agent Starting Run: 73cli7se with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141442-73cli7se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run laced-sweep-252
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/73cli7se
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110873768.0
wandb:  mask_ent_loss 0.00459
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run laced-sweep-252 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/73cli7se
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141442-73cli7se/logs
wandb: Agent Starting Run: h5c79w5l with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141502-h5c79w5l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dark-sweep-253
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h5c79w5l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run dark-sweep-253 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h5c79w5l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141502-h5c79w5l/logs
wandb: Agent Starting Run: d31sbvbq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141523-d31sbvbq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-254
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d31sbvbq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run charmed-sweep-254 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d31sbvbq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141523-d31sbvbq/logs
wandb: Agent Starting Run: g77k6ca3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141544-g77k6ca3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-255
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g77k6ca3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run comfy-sweep-255 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g77k6ca3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141544-g77k6ca3/logs
wandb: Agent Starting Run: i6t33dc6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141605-i6t33dc6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-256
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i6t33dc6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:  mask_ent_loss nan
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss nan
wandb:  size_std_loss nan
wandb:     wrong_pred 1
wandb: 
wandb:  View run bumbling-sweep-256 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i6t33dc6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141605-i6t33dc6/logs
wandb: Agent Starting Run: khxnz2ap with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141626-khxnz2ap
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-257
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/khxnz2ap
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.82238
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02589
wandb:  size_std_loss -64.71487
wandb:     wrong_pred 1
wandb: 
wandb:  View run autumn-sweep-257 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/khxnz2ap
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141626-khxnz2ap/logs
wandb: Agent Starting Run: 01gfd2k9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141646-01gfd2k9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-258
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/01gfd2k9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.70107
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.0238
wandb:  size_std_loss -77.13292
wandb:     wrong_pred 1
wandb: 
wandb:  View run bright-sweep-258 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/01gfd2k9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141646-01gfd2k9/logs
wandb: Agent Starting Run: xaiu8n9c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141707-xaiu8n9c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-259
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xaiu8n9c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67806
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.94359
wandb:     wrong_pred 1
wandb: 
wandb:  View run earthy-sweep-259 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xaiu8n9c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141707-xaiu8n9c/logs
wandb: Agent Starting Run: fmz86gqk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141728-fmz86gqk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-260
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fmz86gqk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67806
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.94359
wandb:     wrong_pred 1
wandb: 
wandb:  View run toasty-sweep-260 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fmz86gqk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141728-fmz86gqk/logs
wandb: Agent Starting Run: l5tpwkv1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141748-l5tpwkv1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-261
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l5tpwkv1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run visionary-sweep-261 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l5tpwkv1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141748-l5tpwkv1/logs
wandb: Agent Starting Run: n3m11q5b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141809-n3m11q5b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-262
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/n3m11q5b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run ancient-sweep-262 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/n3m11q5b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141809-n3m11q5b/logs
wandb: Agent Starting Run: 2uc3fpeu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141830-2uc3fpeu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-263
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2uc3fpeu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run absurd-sweep-263 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2uc3fpeu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141830-2uc3fpeu/logs
wandb: Agent Starting Run: dolxzr94 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141850-dolxzr94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dry-sweep-264
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dolxzr94
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run dry-sweep-264 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dolxzr94
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141850-dolxzr94/logs
wandb: Agent Starting Run: 4g4ath1r with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141912-4g4ath1r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-265
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4g4ath1r
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00254
wandb:  mask_ent_loss 6.92406
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.02907
wandb:  size_std_loss -14.77352
wandb:     wrong_pred 0
wandb: 
wandb:  View run misty-sweep-265 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4g4ath1r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141912-4g4ath1r/logs
wandb: Agent Starting Run: vo0bzeio with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141933-vo0bzeio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-266
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vo0bzeio
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00289
wandb:  mask_ent_loss 6.92382
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.64462
wandb:     wrong_pred 0
wandb: 
wandb:  View run decent-sweep-266 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vo0bzeio
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141933-vo0bzeio/logs
wandb: Agent Starting Run: qa6fkwnu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_141952-qa6fkwnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-267
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qa6fkwnu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 48420.96875
wandb:  mask_ent_loss 6.92379
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.62811
wandb:     wrong_pred 0
wandb: 
wandb:  View run icy-sweep-267 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qa6fkwnu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_141952-qa6fkwnu/logs
wandb: Agent Starting Run: d472mvp7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142014-d472mvp7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-268
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d472mvp7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 48420.96875
wandb:  mask_ent_loss 6.92379
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.62811
wandb:     wrong_pred 0
wandb: 
wandb:  View run gallant-sweep-268 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d472mvp7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142014-d472mvp7/logs
wandb: Agent Starting Run: hhe2rkcf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142035-hhe2rkcf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-269
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hhe2rkcf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25072318464.0
wandb:  mask_ent_loss 6.92328
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.17832
wandb:  size_std_loss -14.00288
wandb:     wrong_pred 0
wandb: 
wandb:  View run noble-sweep-269 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hhe2rkcf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142035-hhe2rkcf/logs
wandb: Agent Starting Run: wup9fw6c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142056-wup9fw6c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-270
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wup9fw6c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25072318464.0
wandb:  mask_ent_loss 6.92328
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.17832
wandb:  size_std_loss -14.00288
wandb:     wrong_pred 0
wandb: 
wandb:  View run scarlet-sweep-270 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wup9fw6c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142056-wup9fw6c/logs
wandb: Agent Starting Run: 33yi56se with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142117-33yi56se
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run leafy-sweep-271
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/33yi56se
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run leafy-sweep-271 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/33yi56se
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142117-33yi56se/logs
wandb: Agent Starting Run: znxjpsev with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142138-znxjpsev
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-272
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/znxjpsev
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run fragrant-sweep-272 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/znxjpsev
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142138-znxjpsev/logs
wandb: Agent Starting Run: 08wi2680 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142159-08wi2680
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-273
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/08wi2680
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.91398
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02765
wandb:  size_std_loss -29.30841
wandb:     wrong_pred 1
wandb: 
wandb:  View run rose-sweep-273 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/08wi2680
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142159-08wi2680/logs
wandb: Agent Starting Run: 2wuhug8p with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142219-2wuhug8p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-274
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2wuhug8p
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.91948
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02782
wandb:  size_std_loss -24.71729
wandb:     wrong_pred 1
wandb: 
wandb:  View run giddy-sweep-274 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2wuhug8p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142219-2wuhug8p/logs
wandb: Agent Starting Run: 7lzgxzok with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142241-7lzgxzok
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-275
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7lzgxzok
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.90339
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02683
wandb:  size_std_loss -28.89403
wandb:     wrong_pred 1
wandb: 
wandb:  View run logical-sweep-275 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7lzgxzok
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142241-7lzgxzok/logs
wandb: Agent Starting Run: m4j127qh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142302-m4j127qh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sage-sweep-276
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m4j127qh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.89541
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02659
wandb:  size_std_loss -32.0231
wandb:     wrong_pred 1
wandb: 
wandb:  View run sage-sweep-276 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m4j127qh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142302-m4j127qh/logs
wandb: Agent Starting Run: 758adeyk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142322-758adeyk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-277
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/758adeyk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00585
wandb:  mask_ent_loss 6.89103
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 26.91335
wandb:  size_std_loss -40.31203
wandb:     wrong_pred 1
wandb: 
wandb:  View run swept-sweep-277 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/758adeyk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142322-758adeyk/logs
wandb: Agent Starting Run: bo33i6y4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142343-bo33i6y4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-278
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bo33i6y4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00012
wandb:  mask_ent_loss 6.89235
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 27.49122
wandb:  size_std_loss -44.79212
wandb:     wrong_pred 1
wandb: 
wandb:  View run swift-sweep-278 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bo33i6y4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142343-bo33i6y4/logs
wandb: Agent Starting Run: 6r9ppwe0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142403-6r9ppwe0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-279
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6r9ppwe0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00321
wandb:  mask_ent_loss 6.83036
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 30.64126
wandb:  size_std_loss -62.10868
wandb:     wrong_pred 1
wandb: 
wandb:  View run clean-sweep-279 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6r9ppwe0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142403-6r9ppwe0/logs
wandb: Agent Starting Run: 4v5laktj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142424-4v5laktj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-280
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4v5laktj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 5.45119
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 42.00103
wandb:  size_std_loss -115.84666
wandb:     wrong_pred 1
wandb: 
wandb:  View run zesty-sweep-280 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4v5laktj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142424-4v5laktj/logs
wandb: Agent Starting Run: 6zycfb1k with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142446-6zycfb1k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-281
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6zycfb1k
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run smooth-sweep-281 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6zycfb1k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142446-6zycfb1k/logs
wandb: Agent Starting Run: q91yygyg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142506-q91yygyg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-282
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/q91yygyg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run clean-sweep-282 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/q91yygyg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142506-q91yygyg/logs
wandb: Agent Starting Run: 68bywywx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142527-68bywywx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-283
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/68bywywx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run vague-sweep-283 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/68bywywx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142527-68bywywx/logs
wandb: Agent Starting Run: 5mcq3f10 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142548-5mcq3f10
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-284
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5mcq3f10
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run mild-sweep-284 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5mcq3f10
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142548-5mcq3f10/logs
wandb: Agent Starting Run: 73olcguw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142609-73olcguw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run elated-sweep-285
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/73olcguw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.04414
wandb:  mask_ent_loss 6.47913
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.34468
wandb:  size_std_loss -48.85015
wandb:     wrong_pred 1
wandb: 
wandb:  View run elated-sweep-285 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/73olcguw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142609-73olcguw/logs
wandb: Agent Starting Run: tt553uoe with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142629-tt553uoe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-286
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tt553uoe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0115
wandb:  mask_ent_loss 6.47882
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.32539
wandb:  size_std_loss -50.17529
wandb:     wrong_pred 1
wandb: 
wandb:  View run pleasant-sweep-286 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tt553uoe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142629-tt553uoe/logs
wandb: Agent Starting Run: qh7t5y74 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142650-qh7t5y74
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-287
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qh7t5y74
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 10.02365
wandb:  mask_ent_loss 6.17539
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 38.66394
wandb:  size_std_loss -61.42886
wandb:     wrong_pred 1
wandb: 
wandb:  View run true-sweep-287 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qh7t5y74
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142650-qh7t5y74/logs
wandb: Agent Starting Run: dokp34wn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142711-dokp34wn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-288
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dokp34wn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.02441
wandb:  mask_ent_loss 5.93708
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 40.15429
wandb:  size_std_loss -68.69845
wandb:     wrong_pred 1
wandb: 
wandb:  View run curious-sweep-288 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dokp34wn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142711-dokp34wn/logs
wandb: Agent Starting Run: 1qxgjelm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142732-1qxgjelm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-289
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1qxgjelm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.00411
wandb:  mask_ent_loss 6.92809
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.0284
wandb:  size_std_loss -13.88703
wandb:     wrong_pred 1
wandb: 
wandb:  View run gallant-sweep-289 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1qxgjelm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142732-1qxgjelm/logs
wandb: Agent Starting Run: 4p816gmk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142753-4p816gmk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-290
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4p816gmk
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 3e-05
wandb:  mask_ent_loss 6.92526
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02846
wandb:  size_std_loss -18.76861
wandb:     wrong_pred 1
wandb: 
wandb:  View run solar-sweep-290 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4p816gmk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142753-4p816gmk/logs
wandb: Agent Starting Run: t0zg53hz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142815-t0zg53hz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peach-sweep-291
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0zg53hz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.82597
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.0258
wandb:  size_std_loss -61.95299
wandb:     wrong_pred 1
wandb: 
wandb:  View run peach-sweep-291 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0zg53hz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142815-t0zg53hz/logs
wandb: Agent Starting Run: 1zvmnx34 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142837-1zvmnx34
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-292
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1zvmnx34
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88286
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02808
wandb:  size_std_loss -52.66178
wandb:     wrong_pred 1
wandb: 
wandb:  View run fluent-sweep-292 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1zvmnx34
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142837-1zvmnx34/logs
wandb: Agent Starting Run: dwc0g8px with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142858-dwc0g8px
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run chocolate-sweep-293
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dwc0g8px
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.68851
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 24.2302
wandb:  size_std_loss -89.15737
wandb:     wrong_pred 1
wandb: 
wandb:  View run chocolate-sweep-293 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dwc0g8px
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142858-dwc0g8px/logs
wandb: Agent Starting Run: fzvbcwb4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142918-fzvbcwb4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-294
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fzvbcwb4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.64448
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.67216
wandb:  size_std_loss -93.31355
wandb:     wrong_pred 1
wandb: 
wandb:  View run wandering-sweep-294 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fzvbcwb4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142918-fzvbcwb4/logs
wandb: Agent Starting Run: grt61i7w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142939-grt61i7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-295
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/grt61i7w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.63564
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.56225
wandb:  size_std_loss -94.01679
wandb:     wrong_pred 1
wandb: 
wandb:  View run summer-sweep-295 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/grt61i7w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142939-grt61i7w/logs
wandb: Agent Starting Run: 72ovoxvv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_142959-72ovoxvv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run effortless-sweep-296
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/72ovoxvv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.6459
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.65746
wandb:  size_std_loss -92.63474
wandb:     wrong_pred 1
wandb: 
wandb:  View run effortless-sweep-296 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/72ovoxvv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_142959-72ovoxvv/logs
wandb: Agent Starting Run: aqdo43t1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143020-aqdo43t1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-297
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/aqdo43t1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run glorious-sweep-297 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/aqdo43t1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143020-aqdo43t1/logs
wandb: Agent Starting Run: 7zfxln3o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143041-7zfxln3o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-298
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7zfxln3o
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run mild-sweep-298 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7zfxln3o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143041-7zfxln3o/logs
wandb: Agent Starting Run: g72c7c0j with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143102-g72c7c0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-299
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g72c7c0j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run deft-sweep-299 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g72c7c0j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143102-g72c7c0j/logs
wandb: Agent Starting Run: 05yzziwf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143122-05yzziwf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-300
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/05yzziwf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run whole-sweep-300 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/05yzziwf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143122-05yzziwf/logs
wandb: Agent Starting Run: tjr7z2o1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143144-tjr7z2o1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-301
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tjr7z2o1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00015
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.68794
wandb:     wrong_pred 0
wandb: 
wandb:  View run colorful-sweep-301 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tjr7z2o1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143144-tjr7z2o1/logs
wandb: Agent Starting Run: 02g33mqc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143205-02g33mqc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run valiant-sweep-302
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/02g33mqc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00015
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12137
wandb:  size_std_loss -46.68842
wandb:     wrong_pred 0
wandb: 
wandb:  View run valiant-sweep-302 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/02g33mqc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143205-02g33mqc/logs
wandb: Agent Starting Run: rlhgcwnm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143225-rlhgcwnm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-303
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rlhgcwnm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88401
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.86856
wandb:  size_std_loss -50.94912
wandb:     wrong_pred 1
wandb: 
wandb:  View run fresh-sweep-303 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rlhgcwnm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143225-rlhgcwnm/logs
wandb: Agent Starting Run: xldr6yh2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143252-xldr6yh2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misunderstood-sweep-304
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xldr6yh2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2239.97949
wandb:  mask_ent_loss 6.88997
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.04052
wandb:  size_std_loss -46.67917
wandb:     wrong_pred 0
wandb: 
wandb:  View run misunderstood-sweep-304 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xldr6yh2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143252-xldr6yh2/logs
wandb: Agent Starting Run: 42mht74w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143312-42mht74w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-305
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/42mht74w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 2
wandb:           loss 0.0
wandb:  mask_ent_loss 6.8438
wandb:       num_high 44
wandb:      pred_loss 1.36578
wandb:          score 1.99823
wandb:      size_loss 0.02477
wandb:  size_std_loss -23.71974
wandb:     wrong_pred 1
wandb: 
wandb:  View run peachy-sweep-305 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/42mht74w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143312-42mht74w/logs
wandb: Agent Starting Run: vwxbef54 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143333-vwxbef54
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-306
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vwxbef54
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 2
wandb:           loss 0.0
wandb:  mask_ent_loss 6.8659
wandb:       num_high 44
wandb:      pred_loss 1.36578
wandb:          score 1.99823
wandb:      size_loss 0.02556
wandb:  size_std_loss -32.77677
wandb:     wrong_pred 1
wandb: 
wandb:  View run northern-sweep-306 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vwxbef54
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143333-vwxbef54/logs
wandb: Agent Starting Run: 1vo4pd2h with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143355-1vo4pd2h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-307
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1vo4pd2h
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.90525
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.0276
wandb:  size_std_loss -36.48838
wandb:     wrong_pred 1
wandb: 
wandb:  View run morning-sweep-307 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1vo4pd2h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143355-1vo4pd2h/logs
wandb: Agent Starting Run: 1k7ricc7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143417-1k7ricc7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-308
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1k7ricc7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.8889
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02715
wandb:  size_std_loss -44.18983
wandb:     wrong_pred 1
wandb: 
wandb:  View run royal-sweep-308 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1k7ricc7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143417-1k7ricc7/logs
wandb: Agent Starting Run: ayscd5pb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143437-ayscd5pb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-309
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ayscd5pb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.00385
wandb:  mask_ent_loss 6.87241
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 26.07481
wandb:  size_std_loss -39.87395
wandb:     wrong_pred 1
wandb: 
wandb:  View run dandy-sweep-309 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ayscd5pb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143437-ayscd5pb/logs
wandb: Agent Starting Run: u281dhfm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143459-u281dhfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-310
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u281dhfm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.02749
wandb:  mask_ent_loss 6.83671
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.94093
wandb:  size_std_loss -36.73718
wandb:     wrong_pred 1
wandb: 
wandb:  View run resilient-sweep-310 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u281dhfm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143459-u281dhfm/logs
wandb: Agent Starting Run: 3p5yfyh7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143520-3p5yfyh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dulcet-sweep-311
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3p5yfyh7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.8325
wandb:       num_high 0
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 25.47776
wandb:  size_std_loss -52.18875
wandb:     wrong_pred 1
wandb: 
wandb:  View run dulcet-sweep-311 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3p5yfyh7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143520-3p5yfyh7/logs
wandb: Agent Starting Run: s1koe38n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143540-s1koe38n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-312
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s1koe38n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 80
wandb:           loss 6.5746
wandb:  mask_ent_loss 6.46438
wandb:       num_high 1046
wandb:      pred_loss 1.12945
wandb:          score 1.92933
wandb:      size_loss 36.28569
wandb:  size_std_loss -59.76133
wandb:     wrong_pred 1
wandb: 
wandb:  View run wandering-sweep-312 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s1koe38n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143540-s1koe38n/logs
wandb: Agent Starting Run: euymw4dd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143601-euymw4dd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-313
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/euymw4dd
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run decent-sweep-313 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/euymw4dd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143601-euymw4dd/logs
wandb: Agent Starting Run: 9kiiwss9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143622-9kiiwss9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-314
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9kiiwss9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run divine-sweep-314 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9kiiwss9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143622-9kiiwss9/logs
wandb: Agent Starting Run: h59og1kw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143643-h59og1kw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-315
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h59og1kw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run unique-sweep-315 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h59og1kw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143643-h59og1kw/logs
wandb: Agent Starting Run: e67sg8j0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143704-e67sg8j0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-316
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/e67sg8j0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run hardy-sweep-316 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/e67sg8j0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143704-e67sg8j0/logs
wandb: Agent Starting Run: jugsu2l7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143724-jugsu2l7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run copper-sweep-317
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jugsu2l7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78491
wandb:     wrong_pred 0
wandb: 
wandb:  View run copper-sweep-317 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jugsu2l7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143724-jugsu2l7/logs
wandb: Agent Starting Run: vib6dwpj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143745-vib6dwpj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-318
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vib6dwpj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78484
wandb:     wrong_pred 0
wandb: 
wandb:  View run pretty-sweep-318 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vib6dwpj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143745-vib6dwpj/logs
wandb: Agent Starting Run: 76z4i3ge with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143806-76z4i3ge
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sleek-sweep-319
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/76z4i3ge
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 5.26525
wandb:  mask_ent_loss 5.50963
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.59383
wandb:  size_std_loss -64.90524
wandb:     wrong_pred 0
wandb: 
wandb:  View run sleek-sweep-319 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/76z4i3ge
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143806-76z4i3ge/logs
wandb: Agent Starting Run: 222752wh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143826-222752wh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run proud-sweep-320
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/222752wh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.51527
wandb:  mask_ent_loss 5.02908
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 44.74141
wandb:  size_std_loss -68.89646
wandb:     wrong_pred 0
wandb: 
wandb:  View run proud-sweep-320 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/222752wh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143826-222752wh/logs
wandb: Agent Starting Run: 1t9yw0td with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143847-1t9yw0td
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-321
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1t9yw0td
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.056
wandb:  mask_ent_loss 6.92905
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.0281
wandb:  size_std_loss -11.24241
wandb:     wrong_pred 1
wandb: 
wandb:  View run lucky-sweep-321 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1t9yw0td
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143847-1t9yw0td/logs
wandb: Agent Starting Run: ui30if8x with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143908-ui30if8x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-322
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ui30if8x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.02615
wandb:  mask_ent_loss 6.92897
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02824
wandb:  size_std_loss -12.00381
wandb:     wrong_pred 1
wandb: 
wandb:  View run lunar-sweep-322 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ui30if8x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143908-ui30if8x/logs
wandb: Agent Starting Run: o4tl1tlb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143929-o4tl1tlb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-323
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o4tl1tlb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.76312
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02449
wandb:  size_std_loss -66.18631
wandb:     wrong_pred 1
wandb: 
wandb:  View run electric-sweep-323 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o4tl1tlb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143929-o4tl1tlb/logs
wandb: Agent Starting Run: kgunh8lw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_143950-kgunh8lw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run morning-sweep-324
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kgunh8lw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.76307
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 0.02449
wandb:  size_std_loss -66.18984
wandb:     wrong_pred 1
wandb: 
wandb:  View run morning-sweep-324 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kgunh8lw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_143950-kgunh8lw/logs
wandb: Agent Starting Run: ld9t9bmj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144010-ld9t9bmj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-325
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ld9t9bmj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.76308
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48527
wandb:  size_std_loss -66.18834
wandb:     wrong_pred 1
wandb: 
wandb:  View run fallen-sweep-325 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ld9t9bmj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144010-ld9t9bmj/logs
wandb: Agent Starting Run: wu6sufyh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144031-wu6sufyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sunny-sweep-326
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wu6sufyh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.76308
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48527
wandb:  size_std_loss -66.18834
wandb:     wrong_pred 1
wandb: 
wandb:  View run sunny-sweep-326 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wu6sufyh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144031-wu6sufyh/logs
wandb: Agent Starting Run: 9yhadgav with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144052-9yhadgav
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-327
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9yhadgav
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.76308
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48527
wandb:  size_std_loss -66.18834
wandb:     wrong_pred 1
wandb: 
wandb:  View run gallant-sweep-327 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9yhadgav
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144052-9yhadgav/logs
wandb: Agent Starting Run: v3em9ib9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144113-v3em9ib9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-328
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v3em9ib9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 0
wandb:           loss 0.0
wandb:  mask_ent_loss 6.76308
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 2.0
wandb:      size_loss 24.48527
wandb:  size_std_loss -66.18834
wandb:     wrong_pred 1
wandb: 
wandb:  View run twilight-sweep-328 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v3em9ib9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144113-v3em9ib9/logs
wandb: Agent Starting Run: kxf63opi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144133-kxf63opi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-329
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kxf63opi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.08054
wandb:  mask_ent_loss 6.92888
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02855
wandb:  size_std_loss -11.3227
wandb:     wrong_pred 0
wandb: 
wandb:  View run happy-sweep-329 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kxf63opi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144133-kxf63opi/logs
wandb: Agent Starting Run: rzsrz6b7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144154-rzsrz6b7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-330
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rzsrz6b7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02047
wandb:  mask_ent_loss 6.92836
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02853
wandb:  size_std_loss -12.69183
wandb:     wrong_pred 0
wandb: 
wandb:  View run apricot-sweep-330 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rzsrz6b7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144154-rzsrz6b7/logs
wandb: Agent Starting Run: 8oos74rf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144215-8oos74rf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-331
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8oos74rf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 96.91658
wandb:  mask_ent_loss 6.88422
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03082
wandb:  size_std_loss -20.8041
wandb:     wrong_pred 0
wandb: 
wandb:  View run giddy-sweep-331 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8oos74rf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144215-8oos74rf/logs
wandb: Agent Starting Run: 3axw5uh7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144236-3axw5uh7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-332
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3axw5uh7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 96.94469
wandb:  mask_ent_loss 6.88422
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03082
wandb:  size_std_loss -20.8038
wandb:     wrong_pred 0
wandb: 
wandb:  View run noble-sweep-332 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3axw5uh7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144236-3axw5uh7/logs
wandb: Agent Starting Run: 0z2ic84w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144256-0z2ic84w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-333
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0z2ic84w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 230115792.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run restful-sweep-333 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0z2ic84w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144256-0z2ic84w/logs
wandb: Agent Starting Run: fi4zrut0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144318-fi4zrut0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-334
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fi4zrut0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 230115792.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run pleasant-sweep-334 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fi4zrut0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144318-fi4zrut0/logs
wandb: Agent Starting Run: o11fl445 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144338-o11fl445
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-335
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o11fl445
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3788326779748352.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run pious-sweep-335 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o11fl445
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144338-o11fl445/logs
wandb: Agent Starting Run: gyifcab1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144359-gyifcab1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run icy-sweep-336
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gyifcab1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3788326779748352.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run icy-sweep-336 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gyifcab1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144359-gyifcab1/logs
wandb: Agent Starting Run: ln7gl5by with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144420-ln7gl5by
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-337
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ln7gl5by
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92613
wandb:       num_high 42
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.02748
wandb:  size_std_loss -8.25222
wandb:     wrong_pred 0
wandb: 
wandb:  View run jolly-sweep-337 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ln7gl5by
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144420-ln7gl5by/logs
wandb: Agent Starting Run: 58s9pcbf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144441-58s9pcbf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run visionary-sweep-338
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/58s9pcbf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92613
wandb:       num_high 42
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.02748
wandb:  size_std_loss -8.25216
wandb:     wrong_pred 0
wandb: 
wandb:  View run visionary-sweep-338 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/58s9pcbf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144441-58s9pcbf/logs
wandb: Agent Starting Run: 2gmtc7wc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144502-2gmtc7wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-339
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2gmtc7wc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 40
wandb:           loss 0.0
wandb:  mask_ent_loss -6.82366
wandb:       num_high 494
wandb:      pred_loss 0.56427
wandb:          score 1.96466
wandb:      size_loss 0.02922
wandb:  size_std_loss -76.63004
wandb:     wrong_pred 0
wandb: 
wandb:  View run restful-sweep-339 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2gmtc7wc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144502-2gmtc7wc/logs
wandb: Agent Starting Run: 8qxb9z5s with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144522-8qxb9z5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-340
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8qxb9z5s
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.0
wandb:  mask_ent_loss -6.10227
wandb:       num_high 1049
wandb:      pred_loss 3e-05
wandb:          score 1.92845
wandb:      size_loss 0.03713
wandb:  size_std_loss -130.46294
wandb:     wrong_pred 0
wandb: 
wandb:  View run feasible-sweep-340 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8qxb9z5s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144522-8qxb9z5s/logs
wandb: Agent Starting Run: ki9napey with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144543-ki9napey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-341
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ki9napey
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79915
wandb:     wrong_pred 0
wandb: 
wandb:  View run earthy-sweep-341 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ki9napey
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144543-ki9napey/logs
wandb: Agent Starting Run: 6oshnhfa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144604-6oshnhfa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wild-sweep-342
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6oshnhfa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79915
wandb:     wrong_pred 0
wandb: 
wandb:  View run wild-sweep-342 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6oshnhfa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144604-6oshnhfa/logs
wandb: Agent Starting Run: a327vmln with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144624-a327vmln
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-343
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a327vmln
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79916
wandb:     wrong_pred 0
wandb: 
wandb:  View run major-sweep-343 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a327vmln
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144624-a327vmln/logs
wandb: Agent Starting Run: 6k1608xp with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144646-6k1608xp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-344
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6k1608xp
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.66486
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.25958
wandb:  size_std_loss -126.79916
wandb:     wrong_pred 0
wandb: 
wandb:  View run azure-sweep-344 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6k1608xp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144646-6k1608xp/logs
wandb: Agent Starting Run: yt6irk6b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144706-yt6irk6b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-345
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yt6irk6b
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.32437
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.92308
wandb:     wrong_pred 0
wandb: 
wandb:  View run glamorous-sweep-345 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yt6irk6b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144706-yt6irk6b/logs
wandb: Agent Starting Run: anb4wa4c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144727-anb4wa4c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-346
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/anb4wa4c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.32437
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.92306
wandb:     wrong_pred 0
wandb: 
wandb:  View run prime-sweep-346 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/anb4wa4c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144727-anb4wa4c/logs
wandb: Agent Starting Run: t0i0cot7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144751-t0i0cot7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-347
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0i0cot7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2e-05
wandb:  mask_ent_loss -6.09535
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03963
wandb:  size_std_loss -23.24191
wandb:     wrong_pred 0
wandb: 
wandb:  View run swept-sweep-347 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0i0cot7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144751-t0i0cot7/logs
wandb: Agent Starting Run: bde76led with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144812-bde76led
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run firm-sweep-348
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bde76led
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2e-05
wandb:  mask_ent_loss -5.88087
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04097
wandb:  size_std_loss -23.69866
wandb:     wrong_pred 0
wandb: 
wandb:  View run firm-sweep-348 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bde76led
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144812-bde76led/logs
wandb: Agent Starting Run: sr8yuu78 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144833-sr8yuu78
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run twilight-sweep-349
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sr8yuu78
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1864978.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run twilight-sweep-349 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sr8yuu78
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144833-sr8yuu78/logs
wandb: Agent Starting Run: 4w1y4qn4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144854-4w1y4qn4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-350
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4w1y4qn4
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1864978.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run clean-sweep-350 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4w1y4qn4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144854-4w1y4qn4/logs
wandb: Agent Starting Run: toywrzyr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144915-toywrzyr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run classic-sweep-351
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/toywrzyr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 30702657601536.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run classic-sweep-351 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/toywrzyr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144915-toywrzyr/logs
wandb: Agent Starting Run: nw3vwww7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144936-nw3vwww7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-352
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nw3vwww7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 30702657601536.0
wandb:  mask_ent_loss -5.81995
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.32487
wandb:  size_std_loss -22.91246
wandb:     wrong_pred 0
wandb: 
wandb:  View run rose-sweep-352 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nw3vwww7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144936-nw3vwww7/logs
wandb: Agent Starting Run: yhwm69zf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_144957-yhwm69zf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-353
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yhwm69zf
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.29903
wandb:  mask_ent_loss -0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run balmy-sweep-353 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yhwm69zf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_144957-yhwm69zf/logs
wandb: Agent Starting Run: cznj1vdu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145022-cznj1vdu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-354
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cznj1vdu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.29903
wandb:  mask_ent_loss -0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run happy-sweep-354 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cznj1vdu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145022-cznj1vdu/logs
wandb: Agent Starting Run: sh0oynjg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145044-sh0oynjg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-355
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sh0oynjg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 109519992.0
wandb:  mask_ent_loss -0.00757
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00032
wandb:     wrong_pred 0
wandb: 
wandb:  View run avid-sweep-355 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sh0oynjg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145044-sh0oynjg/logs
wandb: Agent Starting Run: ag2tdgzu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145105-ag2tdgzu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lilac-sweep-356
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ag2tdgzu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110017656.0
wandb:  mask_ent_loss -0.00329
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run lilac-sweep-356 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ag2tdgzu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145105-ag2tdgzu/logs
wandb: Agent Starting Run: 90h8ez3w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145125-90h8ez3w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-357
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/90h8ez3w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run swept-sweep-357 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/90h8ez3w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145125-90h8ez3w/logs
wandb: Agent Starting Run: cms09bvi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145146-cms09bvi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deep-sweep-358
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cms09bvi
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run deep-sweep-358 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cms09bvi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145146-cms09bvi/logs
wandb: Agent Starting Run: d9w6adqi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145207-d9w6adqi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run absurd-sweep-359
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d9w6adqi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.945376415348209e+32
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run absurd-sweep-359 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d9w6adqi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145207-d9w6adqi/logs
wandb: Agent Starting Run: giszll01 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145227-giszll01
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-360
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/giszll01
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.945376415348209e+32
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run winter-sweep-360 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/giszll01
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145227-giszll01/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 5ftelkuw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145254-5ftelkuw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-361
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5ftelkuw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.66143
wandb:  mask_ent_loss -0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run curious-sweep-361 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5ftelkuw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145254-5ftelkuw/logs
wandb: Agent Starting Run: 0w6fvejw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145314-0w6fvejw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-362
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0w6fvejw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.66143
wandb:  mask_ent_loss -0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run volcanic-sweep-362 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0w6fvejw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145314-0w6fvejw/logs
wandb: Agent Starting Run: l6qrgl0h with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145335-l6qrgl0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-363
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l6qrgl0h
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 109850536.0
wandb:  mask_ent_loss -0.00488
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.0
wandb:     wrong_pred 0
wandb: 
wandb:  View run vital-sweep-363 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l6qrgl0h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145335-l6qrgl0h/logs
wandb: Agent Starting Run: ua65ow4g with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145356-ua65ow4g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-364
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ua65ow4g
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 109826656.0
wandb:  mask_ent_loss -0.0049
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run vivid-sweep-364 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ua65ow4g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145356-ua65ow4g/logs
wandb: Agent Starting Run: jfsl88un with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145416-jfsl88un
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zesty-sweep-365
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jfsl88un
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run zesty-sweep-365 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jfsl88un
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145416-jfsl88un/logs
wandb: Agent Starting Run: 5lw5hfjs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145437-5lw5hfjs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-366
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5lw5hfjs
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.3965643271524984e+25
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run stellar-sweep-366 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5lw5hfjs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145437-5lw5hfjs/logs
wandb: Agent Starting Run: is74dqky with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145458-is74dqky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-367
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/is74dqky
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.945376415348209e+32
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run noble-sweep-367 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/is74dqky
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145458-is74dqky/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: poth174a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145524-poth174a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-368
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/poth174a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.945376415348209e+32
wandb:  mask_ent_loss -0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run flowing-sweep-368 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/poth174a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145524-poth174a/logs
wandb: Agent Starting Run: 0kzqnf77 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145544-0kzqnf77
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-369
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0kzqnf77
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00087
wandb:  mask_ent_loss -6.92915
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0289
wandb:  size_std_loss -1.99514
wandb:     wrong_pred 0
wandb: 
wandb:  View run misty-sweep-369 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0kzqnf77
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145544-0kzqnf77/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: pmmzab86 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145611-pmmzab86
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-370
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pmmzab86
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00087
wandb:  mask_ent_loss -6.92915
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0289
wandb:  size_std_loss -1.99515
wandb:     wrong_pred 0
wandb: 
wandb:  View run splendid-sweep-370 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pmmzab86
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145611-pmmzab86/logs
wandb: Agent Starting Run: d7w0y15v with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145631-d7w0y15v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-371
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d7w0y15v
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.69025
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02366
wandb:  size_std_loss -77.99466
wandb:     wrong_pred 1
wandb: 
wandb:  View run silver-sweep-371 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d7w0y15v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145631-d7w0y15v/logs
wandb: Agent Starting Run: cz2tyxyc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145652-cz2tyxyc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run royal-sweep-372
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cz2tyxyc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67944
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02351
wandb:  size_std_loss -78.83733
wandb:     wrong_pred 1
wandb: 
wandb:  View run royal-sweep-372 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cz2tyxyc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145652-cz2tyxyc/logs
wandb: Agent Starting Run: ffgd5i8q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145713-ffgd5i8q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-373
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ffgd5i8q
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run jumping-sweep-373 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ffgd5i8q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145713-ffgd5i8q/logs
wandb: Agent Starting Run: kunqbpy0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145734-kunqbpy0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ruby-sweep-374
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kunqbpy0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run ruby-sweep-374 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kunqbpy0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145734-kunqbpy0/logs
wandb: Agent Starting Run: i73ry630 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145755-i73ry630
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-375
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i73ry630
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run wandering-sweep-375 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i73ry630
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145755-i73ry630/logs
wandb: Agent Starting Run: miqdaiaj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145815-miqdaiaj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-376
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/miqdaiaj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss -6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run rose-sweep-376 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/miqdaiaj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145815-miqdaiaj/logs
wandb: Agent Starting Run: num8rzfl with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145836-num8rzfl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-377
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/num8rzfl
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.00231
wandb:  mask_ent_loss -6.93136
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02817
wandb:  size_std_loss -0.56428
wandb:     wrong_pred 1
wandb: 
wandb:  View run zany-sweep-377 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/num8rzfl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145836-num8rzfl/logs
wandb: Agent Starting Run: u2ynh1u4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145857-u2ynh1u4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run volcanic-sweep-378
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u2ynh1u4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.00142
wandb:  mask_ent_loss -6.93135
wandb:       num_high 42
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02817
wandb:  size_std_loss -1.05131
wandb:     wrong_pred 1
wandb: 
wandb:  View run volcanic-sweep-378 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u2ynh1u4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145857-u2ynh1u4/logs
wandb: Agent Starting Run: rbhy3gjd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145918-rbhy3gjd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-379
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rbhy3gjd
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.04767
wandb:  mask_ent_loss -6.92379
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.61166
wandb:     wrong_pred 0
wandb: 
wandb:  View run summer-sweep-379 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rbhy3gjd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145918-rbhy3gjd/logs
wandb: Agent Starting Run: fe2fzh95 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_145938-fe2fzh95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-380
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fe2fzh95
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.04805
wandb:  mask_ent_loss -6.92378
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.60385
wandb:     wrong_pred 0
wandb: 
wandb:  View run iconic-sweep-380 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fe2fzh95
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_145938-fe2fzh95/logs
wandb: Agent Starting Run: 3t8rqrle with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150001-3t8rqrle
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dazzling-sweep-381
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3t8rqrle
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25144.10156
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run dazzling-sweep-381 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3t8rqrle
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150001-3t8rqrle/logs
wandb: Agent Starting Run: w6zifruv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150021-w6zifruv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-382
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w6zifruv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25144.10156
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run glad-sweep-382 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w6zifruv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150021-w6zifruv/logs
wandb: Agent Starting Run: jzegt9g0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150041-jzegt9g0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vocal-sweep-383
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jzegt9g0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 413942513664.0
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run vocal-sweep-383 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jzegt9g0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150041-jzegt9g0/logs
wandb: Agent Starting Run: x5rhvdx4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150102-x5rhvdx4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-384
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x5rhvdx4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 413942513664.0
wandb:  mask_ent_loss -6.92325
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18251
wandb:  size_std_loss -13.97318
wandb:     wrong_pred 0
wandb: 
wandb:  View run efficient-sweep-384 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x5rhvdx4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150102-x5rhvdx4/logs
wandb: Agent Starting Run: ogyd7tp0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150123-ogyd7tp0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-385
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ogyd7tp0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.0
wandb:  mask_ent_loss -6.84958
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02481
wandb:  size_std_loss -17.80387
wandb:     wrong_pred 1
wandb: 
wandb:  View run cool-sweep-385 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ogyd7tp0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150123-ogyd7tp0/logs
wandb: Agent Starting Run: f87x5wlc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150144-f87x5wlc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-386
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/f87x5wlc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00186
wandb:  mask_ent_loss -6.93127
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02843
wandb:  size_std_loss -2.29287
wandb:     wrong_pred 1
wandb: 
wandb:  View run eager-sweep-386 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/f87x5wlc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150144-f87x5wlc/logs
wandb: Agent Starting Run: dcds6nc2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150205-dcds6nc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-387
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dcds6nc2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 5.73433
wandb:  mask_ent_loss -6.92965
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02836
wandb:  size_std_loss -10.24672
wandb:     wrong_pred 1
wandb: 
wandb:  View run polar-sweep-387 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dcds6nc2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150205-dcds6nc2/logs
wandb: Agent Starting Run: 1yp526fa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150226-1yp526fa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vital-sweep-388
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1yp526fa
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.87712
wandb:  mask_ent_loss -6.92871
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0285
wandb:  size_std_loss -12.12538
wandb:     wrong_pred 1
wandb: 
wandb:  View run vital-sweep-388 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1yp526fa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150226-1yp526fa/logs
wandb: Agent Starting Run: fb14xsas with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150246-fb14xsas
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-389
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fb14xsas
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00852
wandb:  mask_ent_loss -6.91663
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.9918
wandb:  size_std_loss -28.74624
wandb:     wrong_pred 1
wandb: 
wandb:  View run autumn-sweep-389 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fb14xsas
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150246-fb14xsas/logs
wandb: Agent Starting Run: wjwx88k8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150307-wjwx88k8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-390
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wjwx88k8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00484
wandb:  mask_ent_loss -6.91595
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.95732
wandb:  size_std_loss -29.27821
wandb:     wrong_pred 1
wandb: 
wandb:  View run celestial-sweep-390 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wjwx88k8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150307-wjwx88k8/logs
wandb: Agent Starting Run: 2lway61w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150328-2lway61w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-391
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2lway61w
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 1.48064
wandb:  mask_ent_loss -6.90394
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.11946
wandb:  size_std_loss -39.71752
wandb:     wrong_pred 1
wandb: 
wandb:  View run smart-sweep-391 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2lway61w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150328-2lway61w/logs
wandb: Agent Starting Run: 9wvjchfh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150349-9wvjchfh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-392
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9wvjchfh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.05678
wandb:  mask_ent_loss -6.89898
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.99548
wandb:  size_std_loss -42.85953
wandb:     wrong_pred 1
wandb: 
wandb:  View run major-sweep-392 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9wvjchfh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150349-9wvjchfh/logs
wandb: Agent Starting Run: s4kaz2bn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150413-s4kaz2bn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-393
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s4kaz2bn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run dashing-sweep-393 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s4kaz2bn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150413-s4kaz2bn/logs
wandb: Agent Starting Run: hj4p9uxi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150435-hj4p9uxi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-394
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hj4p9uxi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run worthy-sweep-394 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hj4p9uxi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150435-hj4p9uxi/logs
wandb: Agent Starting Run: 6vya9k7f with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150455-6vya9k7f
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-395
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6vya9k7f
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run spring-sweep-395 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6vya9k7f
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150455-6vya9k7f/logs
wandb: Agent Starting Run: gtl955wa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150516-gtl955wa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-396
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gtl955wa
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: / 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: - 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: / 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: - 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: / 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: - 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run azure-sweep-396 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gtl955wa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150516-gtl955wa/logs
wandb: Agent Starting Run: 8zzhww3v with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150546-8zzhww3v
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fragrant-sweep-397
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8zzhww3v
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 1e-05
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.40144
wandb:  size_std_loss -45.01017
wandb:     wrong_pred 1
wandb: 
wandb:  View run fragrant-sweep-397 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8zzhww3v
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150546-8zzhww3v/logs
wandb: Agent Starting Run: u5xu6a0s with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150607-u5xu6a0s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-398
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u5xu6a0s
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 1e-05
wandb:  mask_ent_loss -6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.40143
wandb:  size_std_loss -45.01087
wandb:     wrong_pred 1
wandb: 
wandb:  View run glamorous-sweep-398 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u5xu6a0s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150607-u5xu6a0s/logs
wandb: Agent Starting Run: eypuiovn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150627-eypuiovn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dandy-sweep-399
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eypuiovn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.13602
wandb:  mask_ent_loss -6.47867
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.3173
wandb:  size_std_loss -50.72807
wandb:     wrong_pred 1
wandb: 
wandb:  View run dandy-sweep-399 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eypuiovn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150627-eypuiovn/logs
wandb: Agent Starting Run: dvncuj7w with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150648-dvncuj7w
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-400
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dvncuj7w
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.01625
wandb:  mask_ent_loss -6.47802
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.28658
wandb:  size_std_loss -52.82242
wandb:     wrong_pred 1
wandb: 
wandb:  View run fiery-sweep-400 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dvncuj7w
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150648-dvncuj7w/logs
wandb: Agent Starting Run: n3rcsfrm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150710-n3rcsfrm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-401
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/n3rcsfrm
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00175
wandb:  mask_ent_loss -6.93016
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02784
wandb:  size_std_loss -0.81205
wandb:     wrong_pred 1
wandb: 
wandb:  View run comic-sweep-401 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/n3rcsfrm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150710-n3rcsfrm/logs
wandb: Agent Starting Run: ruzd9g2k with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150731-ruzd9g2k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-402
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ruzd9g2k
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00175
wandb:  mask_ent_loss -6.93016
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02784
wandb:  size_std_loss -0.81309
wandb:     wrong_pred 1
wandb: 
wandb:  View run neat-sweep-402 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ruzd9g2k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150731-ruzd9g2k/logs
wandb: Agent Starting Run: 16dxj8oo with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150751-16dxj8oo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-403
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/16dxj8oo
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00016
wandb:  mask_ent_loss -6.92908
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.0277
wandb:  size_std_loss -3.20668
wandb:     wrong_pred 1
wandb: 
wandb:  View run pretty-sweep-403 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/16dxj8oo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150751-16dxj8oo/logs
wandb: Agent Starting Run: 1sqtc6mn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150811-1sqtc6mn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run azure-sweep-404
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1sqtc6mn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss -6.76691
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.0242
wandb:  size_std_loss -58.63078
wandb:     wrong_pred 1
wandb: 
wandb:  View run azure-sweep-404 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/1sqtc6mn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150811-1sqtc6mn/logs
wandb: Agent Starting Run: 4uuop7la with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150832-4uuop7la
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-405
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4uuop7la
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.18602
wandb:  mask_ent_loss -6.92102
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.39061
wandb:  size_std_loss -24.58704
wandb:     wrong_pred 1
wandb: 
wandb:  View run clear-sweep-405 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4uuop7la
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150832-4uuop7la/logs
wandb: Agent Starting Run: xgar0k95 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150853-xgar0k95
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-406
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xgar0k95
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.25268
wandb:  mask_ent_loss -6.91063
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.51961
wandb:  size_std_loss -25.83091
wandb:     wrong_pred 0
wandb: 
wandb:  View run desert-sweep-406 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xgar0k95
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150853-xgar0k95/logs
wandb: Agent Starting Run: e72r21u8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150914-e72r21u8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-407
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/e72r21u8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss -6.64232
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.64638
wandb:  size_std_loss -93.5095
wandb:     wrong_pred 1
wandb: 
wandb:  View run eager-sweep-407 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/e72r21u8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150914-e72r21u8/logs
wandb: Agent Starting Run: i1dqkf45 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150934-i1dqkf45
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-408
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i1dqkf45
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss -6.63963
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.61423
wandb:  size_std_loss -93.74755
wandb:     wrong_pred 1
wandb: 
wandb:  View run floral-sweep-408 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i1dqkf45
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150934-i1dqkf45/logs
wandb: Agent Starting Run: dlgh0etr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_150956-dlgh0etr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-409
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dlgh0etr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run logical-sweep-409 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dlgh0etr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_150956-dlgh0etr/logs
wandb: Agent Starting Run: 9ldyjlle with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151017-9ldyjlle
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-410
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ldyjlle
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run eager-sweep-410 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ldyjlle
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151017-9ldyjlle/logs
wandb: Agent Starting Run: isg5iwvc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151037-isg5iwvc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-411
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/isg5iwvc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run autumn-sweep-411 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/isg5iwvc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151037-isg5iwvc/logs
wandb: Agent Starting Run: 7dp7grme with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151058-7dp7grme
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-412
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7dp7grme
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run rose-sweep-412 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7dp7grme
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151058-7dp7grme/logs
wandb: Agent Starting Run: d6d3wenz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151119-d6d3wenz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-413
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d6d3wenz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run iconic-sweep-413 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d6d3wenz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151119-d6d3wenz/logs
wandb: Agent Starting Run: 45n3e3bm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151140-45n3e3bm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-414
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/45n3e3bm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run confused-sweep-414 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/45n3e3bm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151140-45n3e3bm/logs
wandb: Agent Starting Run: j0iaisyb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151201-j0iaisyb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-415
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j0iaisyb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00249
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12131
wandb:  size_std_loss -46.68871
wandb:     wrong_pred 0
wandb: 
wandb:  View run confused-sweep-415 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j0iaisyb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151201-j0iaisyb/logs
wandb: Agent Starting Run: u49ds7ug with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151222-u49ds7ug
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-416
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u49ds7ug
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00248
wandb:  mask_ent_loss -6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12033
wandb:  size_std_loss -46.69538
wandb:     wrong_pred 0
wandb: 
wandb:  View run curious-sweep-416 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u49ds7ug
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151222-u49ds7ug/logs
wandb: Agent Starting Run: dxdalhzv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151242-dxdalhzv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-417
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dxdalhzv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.00011
wandb:  mask_ent_loss -6.93097
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02849
wandb:  size_std_loss -3.98754
wandb:     wrong_pred 0
wandb: 
wandb:  View run misty-sweep-417 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dxdalhzv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151242-dxdalhzv/logs
wandb: Agent Starting Run: sxjne8dk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151303-sxjne8dk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-418
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sxjne8dk
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.00011
wandb:  mask_ent_loss -6.93097
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02849
wandb:  size_std_loss -3.98759
wandb:     wrong_pred 0
wandb: 
wandb:  View run denim-sweep-418 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sxjne8dk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151303-sxjne8dk/logs
wandb: Agent Starting Run: izssgasn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151324-izssgasn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-419
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/izssgasn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 10.84981
wandb:  mask_ent_loss -6.92943
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02863
wandb:  size_std_loss -8.85111
wandb:     wrong_pred 0
wandb: 
wandb:  View run clear-sweep-419 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/izssgasn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151324-izssgasn/logs
wandb: Agent Starting Run: fvyiu5n5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151344-fvyiu5n5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-420
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fvyiu5n5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 2.49605
wandb:  mask_ent_loss -6.92905
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02853
wandb:  size_std_loss -11.07924
wandb:     wrong_pred 1
wandb: 
wandb:  View run swift-sweep-420 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fvyiu5n5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151344-fvyiu5n5/logs
wandb: Agent Starting Run: bput77xw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151405-bput77xw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run still-sweep-421
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bput77xw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.02702
wandb:  mask_ent_loss -6.91801
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.12749
wandb:  size_std_loss -27.72674
wandb:     wrong_pred 1
wandb: 
wandb:  View run still-sweep-421 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bput77xw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151405-bput77xw/logs
wandb: Agent Starting Run: gl5v8qc2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151427-gl5v8qc2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-422
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gl5v8qc2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 3e-05
wandb:  mask_ent_loss -6.91065
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.04238
wandb:  size_std_loss -34.32755
wandb:     wrong_pred 1
wandb: 
wandb:  View run fast-sweep-422 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gl5v8qc2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151427-gl5v8qc2/logs
wandb: Agent Starting Run: gtpwn7qw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151449-gtpwn7qw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-423
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gtpwn7qw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.05315
wandb:  mask_ent_loss -6.89909
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.19333
wandb:  size_std_loss -43.12326
wandb:     wrong_pred 1
wandb: 
wandb:  View run lively-sweep-423 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gtpwn7qw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151449-gtpwn7qw/logs
wandb: Agent Starting Run: av2ah0sm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151509-av2ah0sm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-424
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/av2ah0sm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00692
wandb:  mask_ent_loss -6.89589
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.12628
wandb:  size_std_loss -45.0977
wandb:     wrong_pred 1
wandb: 
wandb:  View run lively-sweep-424 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/av2ah0sm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151509-av2ah0sm/logs
wandb: Agent Starting Run: 3bl9pir5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151530-3bl9pir5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run frosty-sweep-425
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3bl9pir5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run frosty-sweep-425 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3bl9pir5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151530-3bl9pir5/logs
wandb: Agent Starting Run: foosjabe with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151551-foosjabe
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-426
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/foosjabe
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run lucky-sweep-426 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/foosjabe
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151551-foosjabe/logs
wandb: Agent Starting Run: dq3svhj9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151611-dq3svhj9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run serene-sweep-427
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dq3svhj9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run serene-sweep-427 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dq3svhj9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151611-dq3svhj9/logs
wandb: Agent Starting Run: u7go87aa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151633-u7go87aa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eternal-sweep-428
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u7go87aa
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run eternal-sweep-428 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u7go87aa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151633-u7go87aa/logs
wandb: Agent Starting Run: i5arrchk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151653-i5arrchk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-429
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i5arrchk
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run glowing-sweep-429 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i5arrchk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151653-i5arrchk/logs
wandb: Agent Starting Run: 3s5kr1is with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151714-3s5kr1is
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-430
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3s5kr1is
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run resilient-sweep-430 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3s5kr1is
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151714-3s5kr1is/logs
wandb: Agent Starting Run: tk71ipzr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151735-tk71ipzr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run decent-sweep-431
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tk71ipzr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49449
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6055
wandb:  size_std_loss -69.77669
wandb:     wrong_pred 0
wandb: 
wandb:  View run decent-sweep-431 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tk71ipzr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151735-tk71ipzr/logs
wandb: Agent Starting Run: 4rg0e8g9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151755-4rg0e8g9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run solar-sweep-432
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4rg0e8g9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -5.49449
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.60638
wandb:  size_std_loss -69.71101
wandb:     wrong_pred 0
wandb: 
wandb:  View run solar-sweep-432 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4rg0e8g9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151755-4rg0e8g9/logs
wandb: Agent Starting Run: ivdkshdy with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151816-ivdkshdy
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-433
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ivdkshdy
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92377
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0292
wandb:  size_std_loss -12.49308
wandb:     wrong_pred 0
wandb: 
wandb:  View run jolly-sweep-433 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ivdkshdy
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151816-ivdkshdy/logs
wandb: Agent Starting Run: 9f5tboql with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151838-9f5tboql
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-434
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9f5tboql
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92377
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0292
wandb:  size_std_loss -12.49308
wandb:     wrong_pred 0
wandb: 
wandb:  View run celestial-sweep-434 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9f5tboql
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151838-9f5tboql/logs
wandb: Agent Starting Run: 01m6xrf7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151859-01m6xrf7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweet-sweep-435
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/01m6xrf7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.91449
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02934
wandb:  size_std_loss -24.29931
wandb:     wrong_pred 0
wandb: 
wandb:  View run sweet-sweep-435 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/01m6xrf7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151859-01m6xrf7/logs
wandb: Agent Starting Run: 6ccwyn5m with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151919-6ccwyn5m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run electric-sweep-436
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6ccwyn5m
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.90746
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02951
wandb:  size_std_loss -29.17492
wandb:     wrong_pred 0
wandb: 
wandb:  View run electric-sweep-436 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6ccwyn5m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151919-6ccwyn5m/logs
wandb: Agent Starting Run: 14aiay5q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_151941-14aiay5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-437
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/14aiay5q
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7e-05
wandb:  mask_ent_loss -6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08693
wandb:  size_std_loss -33.60406
wandb:     wrong_pred 0
wandb: 
wandb:  View run rich-sweep-437 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/14aiay5q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_151941-14aiay5q/logs
wandb: Agent Starting Run: jpyicw0h with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152002-jpyicw0h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-438
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jpyicw0h
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7e-05
wandb:  mask_ent_loss -6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60405
wandb:     wrong_pred 0
wandb: 
wandb:  View run stellar-sweep-438 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jpyicw0h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152002-jpyicw0h/logs
wandb: Agent Starting Run: fxquijd6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152023-fxquijd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-439
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fxquijd6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1139.10071
wandb:  mask_ent_loss -6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60405
wandb:     wrong_pred 0
wandb: 
wandb:  View run expert-sweep-439 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fxquijd6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152023-fxquijd6/logs
wandb: Agent Starting Run: feaxjaog with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152044-feaxjaog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run mild-sweep-440
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/feaxjaog
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1139.10071
wandb:  mask_ent_loss -6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60405
wandb:     wrong_pred 0
wandb: 
wandb:  View run mild-sweep-440 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/feaxjaog
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152044-feaxjaog/logs
wandb: Agent Starting Run: 99u7b756 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152105-99u7b756
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-441
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/99u7b756
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92894
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.09085
wandb:     wrong_pred 0
wandb: 
wandb:  View run feasible-sweep-441 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/99u7b756
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152105-99u7b756/logs
wandb: Agent Starting Run: 9n5jm4yu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152125-9n5jm4yu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run hardy-sweep-442
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9n5jm4yu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92894
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.09086
wandb:     wrong_pred 0
wandb: 
wandb:  View run hardy-sweep-442 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9n5jm4yu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152125-9n5jm4yu/logs
wandb: Agent Starting Run: ne0br816 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152152-ne0br816
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-443
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ne0br816
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.19199
wandb:  mask_ent_loss -6.928
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02857
wandb:  size_std_loss -13.2138
wandb:     wrong_pred 0
wandb: 
wandb:  View run noble-sweep-443 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ne0br816
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152152-ne0br816/logs
wandb: Agent Starting Run: m8zovrbb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152212-m8zovrbb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-444
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m8zovrbb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1e-05
wandb:  mask_ent_loss -6.91938
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02894
wandb:  size_std_loss -23.44587
wandb:     wrong_pred 0
wandb: 
wandb:  View run confused-sweep-444 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m8zovrbb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152212-m8zovrbb/logs
wandb: Agent Starting Run: bgrhcgd6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152233-bgrhcgd6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-445
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bgrhcgd6
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 251.34628
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88343
wandb:  size_std_loss -20.32042
wandb:     wrong_pred 0
wandb: 
wandb:  View run legendary-sweep-445 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bgrhcgd6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152233-bgrhcgd6/logs
wandb: Agent Starting Run: 9cq61d28 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152254-9cq61d28
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smart-sweep-446
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9cq61d28
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 251.36115
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88344
wandb:  size_std_loss -20.32037
wandb:     wrong_pred 0
wandb: 
wandb:  View run smart-sweep-446 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9cq61d28
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152254-9cq61d28/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: mgqytueg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152326-mgqytueg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-447
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mgqytueg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4138086656.0
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88344
wandb:  size_std_loss -20.32037
wandb:     wrong_pred 0
wandb: 
wandb:  View run stoic-sweep-447 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mgqytueg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152326-mgqytueg/logs
wandb: Agent Starting Run: qzzqixaa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152346-qzzqixaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-448
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qzzqixaa
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4138086656.0
wandb:  mask_ent_loss -6.88249
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88344
wandb:  size_std_loss -20.32037
wandb:     wrong_pred 0
wandb: 
wandb:  View run happy-sweep-448 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qzzqixaa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152346-qzzqixaa/logs
wandb: Agent Starting Run: y9yar96q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152407-y9yar96q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-449
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/y9yar96q
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.00218
wandb:  mask_ent_loss 0.69261
wandb:       num_high 42
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.02748
wandb:  size_std_loss -8.25501
wandb:     wrong_pred 0
wandb: 
wandb:  View run silver-sweep-449 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/y9yar96q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152407-y9yar96q/logs
wandb: Agent Starting Run: skn66t5a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152428-skn66t5a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-450
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/skn66t5a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.00213
wandb:  mask_ent_loss 0.69261
wandb:       num_high 42
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.02748
wandb:  size_std_loss -8.27862
wandb:     wrong_pred 0
wandb: 
wandb:  View run crisp-sweep-450 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/skn66t5a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152428-skn66t5a/logs
wandb: Agent Starting Run: heqsehmw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152448-heqsehmw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run autumn-sweep-451
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/heqsehmw
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56224
wandb:       num_high 1128
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0405
wandb:  size_std_loss -127.47887
wandb:     wrong_pred 0
wandb: 
wandb:  View run autumn-sweep-451 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/heqsehmw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152448-heqsehmw/logs
wandb: Agent Starting Run: bqfz7a7y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152509-bqfz7a7y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-452
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bqfz7a7y
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56074
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0406
wandb:  size_std_loss -127.07828
wandb:     wrong_pred 0
wandb: 
wandb:  View run unique-sweep-452 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bqfz7a7y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152509-bqfz7a7y/logs
wandb: Agent Starting Run: rbidba2n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152530-rbidba2n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-453
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rbidba2n
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56555
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.31503
wandb:  size_std_loss -126.84858
wandb:     wrong_pred 0
wandb: 
wandb:  View run lunar-sweep-453 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rbidba2n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152530-rbidba2n/logs
wandb: Agent Starting Run: l3zqn85n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152601-l3zqn85n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-454
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l3zqn85n
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.56555
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.31503
wandb:  size_std_loss -126.84858
wandb:     wrong_pred 0
wandb: 
wandb:  View run rare-sweep-454 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l3zqn85n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152601-l3zqn85n/logs
wandb: Agent Starting Run: slawu2eh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152622-slawu2eh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-455
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/slawu2eh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 168172736.0
wandb:  mask_ent_loss 0.57826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.38657
wandb:  size_std_loss -41.48724
wandb:     wrong_pred 0
wandb: 
wandb:  View run earnest-sweep-455 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/slawu2eh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152622-slawu2eh/logs
wandb: Agent Starting Run: t6cl6s2c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152643-t6cl6s2c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-456
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t6cl6s2c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 168172736.0
wandb:  mask_ent_loss 0.57826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.38657
wandb:  size_std_loss -41.48724
wandb:     wrong_pred 0
wandb: 
wandb:  View run rural-sweep-456 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t6cl6s2c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152643-t6cl6s2c/logs
wandb: Agent Starting Run: 9j0m7v90 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152704-9j0m7v90
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-457
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9j0m7v90
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00061
wandb:  mask_ent_loss 0.63244
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.9222
wandb:     wrong_pred 0
wandb: 
wandb:  View run resilient-sweep-457 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9j0m7v90
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152704-9j0m7v90/logs
wandb: Agent Starting Run: 6tsukjyz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152725-6tsukjyz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-458
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6tsukjyz
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00061
wandb:  mask_ent_loss 0.63244
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03805
wandb:  size_std_loss -9.91512
wandb:     wrong_pred 0
wandb: 
wandb:  View run rose-sweep-458 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6tsukjyz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152725-6tsukjyz/logs
wandb: Agent Starting Run: rrxobtns with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152745-rrxobtns
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-459
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rrxobtns
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02147
wandb:  mask_ent_loss 0.58132
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04136
wandb:  size_std_loss -22.92682
wandb:     wrong_pred 0
wandb: 
wandb:  View run glad-sweep-459 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rrxobtns
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152745-rrxobtns/logs
wandb: Agent Starting Run: hf2i5nnq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152806-hf2i5nnq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-460
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hf2i5nnq
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02138
wandb:  mask_ent_loss 0.58121
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04137
wandb:  size_std_loss -22.93077
wandb:     wrong_pred 0
wandb: 
wandb:  View run neat-sweep-460 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hf2i5nnq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152806-hf2i5nnq/logs
wandb: Agent Starting Run: d11l4sr7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152828-d11l4sr7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-461
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d11l4sr7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1129259136.0
wandb:  mask_ent_loss 0.58187
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.33206
wandb:  size_std_loss -22.9154
wandb:     wrong_pred 0
wandb: 
wandb:  View run comfy-sweep-461 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d11l4sr7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152828-d11l4sr7/logs
wandb: Agent Starting Run: 2r07aohc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152848-2r07aohc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-462
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2r07aohc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1129259136.0
wandb:  mask_ent_loss 0.58187
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.33206
wandb:  size_std_loss -22.9154
wandb:     wrong_pred 0
wandb: 
wandb:  View run glamorous-sweep-462 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2r07aohc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152848-2r07aohc/logs
wandb: Agent Starting Run: a3flf1p3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152909-a3flf1p3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-463
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a3flf1p3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.1852920054681287e+22
wandb:  mask_ent_loss 0.58202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37823
wandb:  size_std_loss -8.98454
wandb:     wrong_pred 0
wandb: 
wandb:  View run glad-sweep-463 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/a3flf1p3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152909-a3flf1p3/logs
wandb: Agent Starting Run: 4qgo9l5s with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152929-4qgo9l5s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ethereal-sweep-464
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4qgo9l5s
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.1852920054681287e+22
wandb:  mask_ent_loss 0.58202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37823
wandb:  size_std_loss -8.98454
wandb:     wrong_pred 0
wandb: 
wandb:  View run ethereal-sweep-464 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4qgo9l5s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152929-4qgo9l5s/logs
wandb: Agent Starting Run: zr4urvdh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_152950-zr4urvdh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-465
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zr4urvdh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74608
wandb:  mask_ent_loss 0.00623
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run splendid-sweep-465 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zr4urvdh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_152950-zr4urvdh/logs
wandb: Agent Starting Run: kng7omvj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153011-kng7omvj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-466
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kng7omvj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74608
wandb:  mask_ent_loss 0.00623
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run stoic-sweep-466 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kng7omvj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153011-kng7omvj/logs
wandb: Agent Starting Run: xaw3cwi7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153032-xaw3cwi7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run exalted-sweep-467
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xaw3cwi7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110393704.0
wandb:  mask_ent_loss 0.00025
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run exalted-sweep-467 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xaw3cwi7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153032-xaw3cwi7/logs
wandb: Agent Starting Run: bxfrz2c8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153053-bxfrz2c8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gallant-sweep-468
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bxfrz2c8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110385280.0
wandb:  mask_ent_loss 0.00017
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run gallant-sweep-468 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bxfrz2c8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153053-bxfrz2c8/logs
wandb: Agent Starting Run: kfcs2gnv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153113-kfcs2gnv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-469
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kfcs2gnv
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run misty-sweep-469 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kfcs2gnv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153113-kfcs2gnv/logs
wandb: Agent Starting Run: ndm3a837 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153140-ndm3a837
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-470
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ndm3a837
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run lucky-sweep-470 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ndm3a837
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153140-ndm3a837/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 8exr5n1b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153210-8exr5n1b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-471
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8exr5n1b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9671390143825836e+32
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run floral-sweep-471 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8exr5n1b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153210-8exr5n1b/logs
wandb: Agent Starting Run: 2qhkx6fm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153231-2qhkx6fm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run good-sweep-472
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2qhkx6fm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9671390143825836e+32
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run good-sweep-472 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2qhkx6fm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153231-2qhkx6fm/logs
wandb: Agent Starting Run: 4qrj3f0y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153252-4qrj3f0y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run genial-sweep-473
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4qrj3f0y
loaded data aifb (0.1346s).
Number of entities: 8285
Number of classes: 4
Types of relations: 45
explain all False
Create sweep with ID: rg3hyigg
Sweep URL: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.757922115710244e-07 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0006305979331955314 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 5, 'phone': 1, 'publication': 3}
Important relations {'publication': 1}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0245, 0.0314, 0.9133, 0.0308], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2959, 0.2773, 0.2070, 0.2199], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4933, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5003, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 1 
 overall mean tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.1290, grad_fn=<StdBackward0>) 
 Sparsity 0.9991166077738516 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5168e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9991, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.7582015011139447e-07 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0006391423521563411 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 5, 'phone': 1, 'publication': 3}
Important relations {'publication': 1}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0245, 0.0314, 0.9133, 0.0308], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2959, 0.2773, 0.2070, 0.2199], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4933, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5008, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 1 
 overall mean tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.1290, grad_fn=<StdBackward0>) 
 Sparsity 0.9991166077738516 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5168e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9991, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3281510791585983e-36 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.14398665041697e-43 ; pred:  tensor([0.0037, 0.0066, 0.9846, 0.0051], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 32, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 31}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 23, 'phone': 1, 'publication': 16}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0154, 0.0202, 0.9437, 0.0207], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1284, 0.1524, 0.5688, 0.1504], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6557, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5891, grad_fn=<MeanBackward0>) tensor(0.0714, grad_fn=<StdBackward0>) 40 
 overall mean tensor(0.0405, grad_fn=<MeanBackward0>) tensor(0.1420, grad_fn=<StdBackward0>) 
 Sparsity 0.9646643109540636 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(1.5134e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9647, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7669857957301072e-37 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0 ; pred:  tensor([3.2407e-06, 6.3263e-06, 9.9998e-01, 8.8802e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 40, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 40}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 40, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 38}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0022, 0.0031, 0.9914, 0.0033], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([4.4905e-06, 9.4045e-06, 9.9997e-01, 1.2568e-05],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8171, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6755, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 81 
 overall mean tensor(0.0508, grad_fn=<MeanBackward0>) tensor(0.1795, grad_fn=<StdBackward0>) 
 Sparsity 0.9284452296819788 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9284, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2269134944506976e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3642008161894923e-36 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2269134944506976e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3642008161894923e-36 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.312369994750573e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.8921124264652726e-29 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.312369994750573e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.8921124264652726e-29 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.427226038686058e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8.46492582695646e-07 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.427230131412216e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8.464998586532602e-07 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.006625834386795759 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0002417528157820925 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([9.1542e-04, 1.3721e-03, 9.9628e-01, 1.4339e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7382, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7031, grad_fn=<MeanBackward0>) tensor(0.0226, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0540, grad_fn=<MeanBackward0>) tensor(0.1875, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0026332533452659845 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00010238254617433995 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([6.0646e-04, 9.2216e-04, 9.9749e-01, 9.7962e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7536, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7244, grad_fn=<MeanBackward0>) tensor(0.0227, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0557, grad_fn=<MeanBackward0>) tensor(0.1931, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  124032840.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  5703617.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  124032840.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  5703617.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2041911204380672.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  93897187393536.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2041911204380672.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  93897187393536.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.623260021209717 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.509610176086426 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.623260021209717 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.509610176086426 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109837552.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109577032.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8792e-06, 3.6996e-06, 9.9999e-01, 5.4445e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109888264.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109993320.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8772e-06, 3.6960e-06, 9.9999e-01, 5.4395e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.6682891845703125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.665272235870361 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.6682891845703125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.665272235870361 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8779e-06, 3.6973e-06, 9.9999e-01, 5.4413e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8779e-06, 3.6973e-06, 9.9999e-01, 5.4413e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(1.1990e-07, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0012933711986988783 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0018475897377356887 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0211, 0.0272, 0.9249, 0.0268], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4952, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0381, grad_fn=<MeanBackward0>) tensor(0.1320, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0022358098067343235 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.002268374664708972 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0214, 0.0276, 0.9238, 0.0273], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4957, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1319, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5864639707425387e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.4196797693597273e-34 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0208, 0.0243, 0.9307, 0.0242], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3976, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6737, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0317, grad_fn=<MeanBackward0>) tensor(0.1113, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.436756862081701e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  9.90907184637759e-35 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0213, 0.0248, 0.9292, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3949, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1107, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.194866778890095e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.257902512500613e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.194866778890095e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.257902512500613e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.2392133215112632e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3573619177571333e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.2392133215112632e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3573619177571333e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.002340516773983836 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0022269010078161955 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 2}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0218, 0.0281, 0.9225, 0.0277], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4933, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5022, grad_fn=<MeanBackward0>) tensor(0.0008, grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1316, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0012176277814432979 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0015515622217208147 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 7}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0216, 0.0279, 0.9230, 0.0275], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4932, grad_fn=<UnbindBackward0>) with num edges 7 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1315, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.1536290645599365 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.14504382014274597 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9530, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5104, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.15822172164917 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.1457432061433792 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9531, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5105, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1769729.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  77620.7578125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1769729.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  77620.7578125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  29134522679296.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  1277869031424.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  29134522679296.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  1277869031424.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.001856682007201016 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  7.716492028686517e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0204, 0.0264, 0.9271, 0.0261], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4976, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5027, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0383, grad_fn=<MeanBackward0>) tensor(0.1327, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0018552110996097326 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  8.452598343478002e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0204, 0.0263, 0.9273, 0.0260], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4976, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5039, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0383, grad_fn=<MeanBackward0>) tensor(0.1327, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.734333038330078 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.02237315572296e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0304, 0.0403, 0.8902, 0.0391], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4977, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0377, grad_fn=<MeanBackward0>) tensor(0.1309, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.8771152496337891 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2909215797024531e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0385, 0.0528, 0.8589, 0.0498], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4962, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1298, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.04576222971081734 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0007129525765776634 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0432, 0.0597, 0.8415, 0.0557], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4875, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0367, grad_fn=<MeanBackward0>) tensor(0.1274, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.009544887579977512 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0004904843517579138 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0414, 0.0573, 0.8478, 0.0535], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4926, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0370, grad_fn=<MeanBackward0>) tensor(0.1287, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.9559664130210876 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  9.864741201681682e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0436, 0.0621, 0.8371, 0.0571], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4983, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1299, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.05678058788180351 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0005195647827349603 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0389, 0.0562, 0.8532, 0.0517], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5167, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5167, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1345, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.636680412810355e-27 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.943127545634469e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.636701983225732e-27 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.943127545634469e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.9516330399479886e-20 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.491452058242594e-17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.9516521038761686e-20 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.491452058242594e-17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.769772466937326e-10 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.628244619832913e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.76978301405606e-10 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.628244619832913e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0022976803593337536 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.06493755429983139 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0073, 0.0109, 0.9711, 0.0108], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0491, grad_fn=<MeanBackward0>) tensor(0.1709, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0015529218362644315 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.007304241415113211 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0077, 0.0115, 0.9694, 0.0114], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0491, grad_fn=<MeanBackward0>) tensor(0.1707, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.7449102819664404e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.6603262087986366e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0208, 0.0270, 0.9256, 0.0266], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5019, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5019, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0385, grad_fn=<MeanBackward0>) tensor(0.1334, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.74478186131455e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.898180736539025e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0207, 0.0270, 0.9257, 0.0266], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5020, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0385, grad_fn=<MeanBackward0>) tensor(0.1334, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.294407391280401e-06 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  9.583458332462769e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0224, 0.0306, 0.9170, 0.0300], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5355, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5355, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0404, grad_fn=<MeanBackward0>) tensor(0.1404, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  8.630761383354724e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  7.720411224383661e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0231, 0.0275, 0.9224, 0.0271], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4120, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6203, grad_fn=<MeanBackward0>) tensor(0.0071, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0331, grad_fn=<MeanBackward0>) tensor(0.1161, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.00012327500735409558 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.15358416736125946 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0135, 0.0172, 0.9521, 0.0171], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4950, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5851, grad_fn=<MeanBackward0>) tensor(0.0071, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0387, grad_fn=<MeanBackward0>) tensor(0.1343, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.281740683178327e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.901016011274237e-09 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0100, 0.0130, 0.9641, 0.0129], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5147, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5233, grad_fn=<MeanBackward0>) tensor(0.0273, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0402, grad_fn=<MeanBackward0>) tensor(0.1396, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5022957992280385e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  4.659990625868739e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0182, 0.0210, 0.9397, 0.0211], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3928, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7202, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1157, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.471954648923471e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  4.2165401404221634e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0183, 0.0211, 0.9394, 0.0212], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3922, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7204, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1156, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.583846888544744e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.7847512675950828e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.584020222239739e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.7847512675950828e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4212446969148001e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.344673171267893e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4212771969826117e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.344673171267893e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.0427273702968627e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.979713116810101e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.042797250515011e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.979713116810101e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.702155391302209e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.1206167965143246e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.70228562261785e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.1206167965143246e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0480, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0397, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5724600133608496e-22 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.908349199832628e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 7}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0326, 0.0396, 0.8888, 0.0390], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4312, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5079, grad_fn=<MeanBackward0>) tensor(0.0040, grad_fn=<StdBackward0>) 7 
 overall mean tensor(0.0336, grad_fn=<MeanBackward0>) tensor(0.1168, grad_fn=<StdBackward0>) 
 Sparsity 0.9938162544169611 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9938, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5723519709712705e-22 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.8969897531160314e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 7}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0326, 0.0396, 0.8887, 0.0391], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4312, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5079, grad_fn=<MeanBackward0>) tensor(0.0040, grad_fn=<StdBackward0>) 7 
 overall mean tensor(0.0336, grad_fn=<MeanBackward0>) tensor(0.1168, grad_fn=<StdBackward0>) 
 Sparsity 0.9938162544169611 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9938, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.2598191052540084e-15 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.0351537255723926e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 2}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 2}
Important relations {'publication': 2}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0195, 0.0240, 0.9327, 0.0238], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4548, grad_fn=<UnbindBackward0>) with num edges 2 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5737, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 2 
 overall mean tensor(0.0346, grad_fn=<MeanBackward0>) tensor(0.1204, grad_fn=<StdBackward0>) 
 Sparsity 0.9982332155477032 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9982, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.259724237563916e-15 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  9.655141269826473e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0378, 0.0491, 0.8658, 0.0474], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4686, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0353, grad_fn=<MeanBackward0>) tensor(0.1226, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.128053205931792e-07 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00036200418253429234 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0509, 0.0675, 0.8183, 0.0633], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4529, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0340, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1279113816017343e-07 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.397577893338166e-05 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0485, 0.0659, 0.8243, 0.0613], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4680, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0350, grad_fn=<MeanBackward0>) tensor(0.1218, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2045440673828125 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0773907039028927e-09 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0583, 0.0791, 0.7900, 0.0726], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4473, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0335, grad_fn=<MeanBackward0>) tensor(0.1166, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.3165602684020996 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.006923448760062456 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0560, 0.0773, 0.7960, 0.0707], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4596, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0344, grad_fn=<MeanBackward0>) tensor(0.1197, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.486163166713538e-31 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.203076835227782e-32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.486163166713538e-31 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.2030935860222812e-32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4466256707026432e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.626858762716039e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4466256707026432e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.6268866193667544e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.711781754011211e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5757570758206246e-13 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.711781754011211e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.575769002044522e-13 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.4728818465955555e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.610152250781539e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7522, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.541656016954221e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.7413600491854595e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0024, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7522, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.3065438148914836e-07 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00017460710660088807 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0186, 0.0241, 0.9335, 0.0238], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5020, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1338, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.234851983004774e-07 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00017649489745963365 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0186, 0.0240, 0.9336, 0.0238], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5020, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1338, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0004305969341658056 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.872463898684341e-11 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0256, 0.0396, 0.8984, 0.0365], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5866, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5866, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0451, grad_fn=<MeanBackward0>) tensor(0.1563, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  8.247816595296532e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.02121865004301071 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0174, 0.0221, 0.9386, 0.0219], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4840, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.1290, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1654275323811784e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1027418432177546e-19 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1654027990191185e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1021964210013524e-19 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.02384663532565e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.93551587692226e-19 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.02384663532565e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.93551587692226e-19 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5727187491497716e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.38640937513901e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0185, 0.9489, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5727187491497716e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.386448099718109e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0185, 0.9489, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.07046941667795181 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.09739174693822861 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0136, 0.0175, 0.9516, 0.0174], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0005678583402186632 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.2444608475780115e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0097, 0.0126, 0.9653, 0.0124], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5071, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5071, grad_fn=<MeanBackward0>) tensor(1.1990e-07, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0390, grad_fn=<MeanBackward0>) tensor(0.1351, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3851.25390625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  519.9574584960938 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3851.26123046875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  519.9802856445312 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  63402213376.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8560384512.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  63402213376.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8560384512.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0007634551730006933 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
epoch:  20 ; loss:  0.14103655517101288 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0245, 0.0313, 0.9133, 0.0309], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4910, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.1291, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-2.0644e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0007745568873360753 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
epoch:  20 ; loss:  0.007347554434090853 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0244, 0.0312, 0.9136, 0.0309], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4930, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.1291, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-2.0644e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.524418063242482e-34 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.942726775082116e-44 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.1611e-04, 1.1903e-03, 9.9665e-01, 1.3467e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8360, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7128, grad_fn=<MeanBackward0>) tensor(0.1180, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0548, grad_fn=<MeanBackward0>) tensor(0.1927, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.513107076264915e-34 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.764414778704378e-44 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0230e-04, 1.1703e-03, 9.9670e-01, 1.3254e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7141, grad_fn=<MeanBackward0>) tensor(0.1185, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0549, grad_fn=<MeanBackward0>) tensor(0.1931, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7888845708681272e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2377525724036668e-33 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7066, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.1911, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7888845708681272e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2377525724036668e-33 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7066, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.1911, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5744570662912.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2634952704.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 4, 'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([4.5222e-04, 7.0114e-04, 9.9810e-01, 7.4811e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2347, 0.2544, 0.2687, 0.2422], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7444, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7280, grad_fn=<MeanBackward0>) tensor(0.0366, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0559, grad_fn=<MeanBackward0>) tensor(0.1943, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5744570662912.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2634952704.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 4, 'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([4.5222e-04, 7.0114e-04, 9.9810e-01, 7.4811e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2347, 0.2544, 0.2687, 0.2422], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7444, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7280, grad_fn=<MeanBackward0>) tensor(0.0366, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0559, grad_fn=<MeanBackward0>) tensor(0.1943, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.001061261398717761 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0007625935832038522 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0010617361404001713 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0007647938327863812 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4011023044586182 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.06522268056869507 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.4100e-04, 8.2573e-04, 9.9775e-01, 8.8237e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7308, grad_fn=<MeanBackward0>) tensor(0.0216, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1948, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4004477262496948 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.06509441882371902 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.4011e-04, 8.2441e-04, 9.9775e-01, 8.8104e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7309, grad_fn=<MeanBackward0>) tensor(0.0216, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1948, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  74997309440.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3452347648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3691e-04, 8.1961e-04, 9.9777e-01, 8.7623e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7297, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1945, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  74997309440.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3452347648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3691e-04, 8.1961e-04, 9.9777e-01, 8.7623e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7297, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1945, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2501e-04, 8.0530e-04, 9.9782e-01, 8.5332e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7314, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2501e-04, 8.0530e-04, 9.9782e-01, 8.5332e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7314, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.708218574523926 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.713527202606201 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.724119186401367 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.708218574523926 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.713527202606201 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.724119186401367 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110435400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110421080.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110403816.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8769e-06, 3.6954e-06, 9.9999e-01, 5.4387e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110435400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110420872.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110401288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8766e-06, 3.6948e-06, 9.9999e-01, 5.4379e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9671390143825836e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9671390143825836e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.708218574523926 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.708535194396973 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.7093119621276855 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.708218574523926 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.708535194396973 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.7093119621276855 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110435400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110410976.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110417920.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8779e-06, 3.6972e-06, 9.9999e-01, 5.4411e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110435400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110410976.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110439824.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8779e-06, 3.6972e-06, 9.9999e-01, 5.4412e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9671390143825836e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9671390143825836e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7782906293869019 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.00034524122020229697 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.005154718644917011 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0192, 0.0247, 0.9316, 0.0245], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4979, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0382, grad_fn=<MeanBackward0>) tensor(0.1324, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7782906293869019 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  8.172632492628451e-13 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  6.232835136898984e-09 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0215, 0.0280, 0.9230, 0.0276], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5022, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5046, grad_fn=<MeanBackward0>) tensor(0.0097, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0384, grad_fn=<MeanBackward0>) tensor(0.1335, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  29275476.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.354846476628573e-25 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5359500544482652e-31 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  29275476.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.354746389901223e-25 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5356571212560403e-31 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25175720460288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1513440849737706e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0393984521717178e-21 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25175720460288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1513440849737706e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0393984521717178e-21 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.144610664198376e+20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.0074897339394816e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.61224401674687e-21 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6095, grad_fn=<MeanBackward0>) tensor(0.0888, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0318, grad_fn=<MeanBackward0>) tensor(0.1120, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.144610664198376e+20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.0074897339394816e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.61224401674687e-21 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6095, grad_fn=<MeanBackward0>) tensor(0.0888, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0318, grad_fn=<MeanBackward0>) tensor(0.1120, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7782906293869019 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0011340462369844317 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0005664350464940071 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0200, 0.0256, 0.9291, 0.0254], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4934, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5216, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1318, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7782906293869019 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0001862908247858286 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  2.719144731599954e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0154, 0.0197, 0.9454, 0.0195], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4966, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5562, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0384, grad_fn=<MeanBackward0>) tensor(0.1332, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  29275476.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6348.7783203125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  292.3927001953125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9531, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5104, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  29275476.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6348.7783203125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  292.3927001953125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9531, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5104, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25175720460288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3540627456.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  154844080.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9534, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0117, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25175720460288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3540627456.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  154844080.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9534, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0117, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.144610664198376e+20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.76757199536128e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2374783517851648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0169, 0.9534, 0.0168], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5117, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5142, grad_fn=<MeanBackward0>) tensor(0.0118, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1371, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.144610664198376e+20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.76757199536128e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2374783517851648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0169, 0.9534, 0.0168], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5117, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5142, grad_fn=<MeanBackward0>) tensor(0.0118, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1371, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7496778338216162e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.0673110485076904 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  2.2892309061717242e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0262, 0.0345, 0.9055, 0.0338], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4990, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1314, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7496778338216162e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.4942992031574249 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5634328747182735e-06 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0297, 0.0395, 0.8924, 0.0384], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4989, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0378, grad_fn=<MeanBackward0>) tensor(0.1311, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.8804418298469614e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.5918005108833313 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.579754644776836e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0435, 0.0607, 0.8394, 0.0564], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4904, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0368, grad_fn=<MeanBackward0>) tensor(0.1280, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.8804418298469614e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.03689473494887352 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  4.2990009338841895e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0428, 0.0589, 0.8433, 0.0550], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4868, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0366, grad_fn=<MeanBackward0>) tensor(0.1273, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6756991289289545e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7151745851151645e-05 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.002085919724777341 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0461, 0.0624, 0.8331, 0.0584], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4722, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0356, grad_fn=<MeanBackward0>) tensor(0.1237, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6756991289289545e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.019775938242673874 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.013620765879750252 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0459, 0.0653, 0.8290, 0.0598], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4930, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0369, grad_fn=<MeanBackward0>) tensor(0.1285, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.44049227237701416 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.6729053854942322 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.0224708098103292e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0516, 0.0801, 0.7988, 0.0695], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5216, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5216, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0385, grad_fn=<MeanBackward0>) tensor(0.1348, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.44049227237701416 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.09577106684446335 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.215993870573584e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0345, 0.0473, 0.8733, 0.0449], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5055, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5055, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1322, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7496778338216162e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.223376614035344e-24 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  4.3117282183402405e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7496778338216162e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.223396729988427e-24 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  4.3117282183402405e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.8804418298469614e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.5885597858835516e-17 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  7.098268235130809e-14 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.8804418298469614e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.588577322112538e-17 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  7.098268235130809e-14 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6756991289289545e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5666790293144004e-07 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  7.240642298711464e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0093, 0.9752, 0.0093], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6756991289289545e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5665519842732465e-07 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  7.183336128946394e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0064, 0.0095, 0.9747, 0.0094], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.44049227237701416 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.12245521694421768 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.2504913806915283 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0086, 0.0129, 0.9657, 0.0128], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6551, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6551, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0489, grad_fn=<MeanBackward0>) tensor(0.1704, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.44049227237701416 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.10963883250951767 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.11383208632469177 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0088, 0.0133, 0.9648, 0.0131], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6543, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6543, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0489, grad_fn=<MeanBackward0>) tensor(0.1702, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3184691225189558e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.07593008130788803 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.010526270605623722 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 37}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 3}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0239, 0.0306, 0.9153, 0.0302], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4864, grad_fn=<UnbindBackward0>) with num edges 3 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6338, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0378, grad_fn=<MeanBackward0>) tensor(0.1312, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3184691225189558e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.07046274840831757 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0004960648948326707 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0145, 0.0186, 0.9484, 0.0185], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5008, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5086, grad_fn=<MeanBackward0>) tensor(0.0268, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0391, grad_fn=<MeanBackward0>) tensor(0.1357, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.463095744042689e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.718853342273622e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.4232502287825355e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0132, 0.0169, 0.9532, 0.0168], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4966, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5879, grad_fn=<MeanBackward0>) tensor(0.0083, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0388, grad_fn=<MeanBackward0>) tensor(0.1348, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.463095744042689e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.6031856265252936e-15 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.7653678384225836e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0104, 0.0132, 0.9634, 0.0131], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4872, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6473, grad_fn=<MeanBackward0>) tensor(0.0052, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1344, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.541648307432311e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.776313871663774e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.271524138065601e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0102, 0.0128, 0.9642, 0.0128], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4751, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0046, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1324, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.541648307432311e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.948006614493352e-09 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.01006366778165102 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0114, 0.0144, 0.9599, 0.0143], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4786, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6435, grad_fn=<MeanBackward0>) tensor(0.0051, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1322, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.476778409909457e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.6262313776893396e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  6.677200966083293e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0183, 0.0211, 0.9393, 0.0213], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3921, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7204, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1156, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.476778409909457e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.600967434191354e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  6.641307178598155e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0183, 0.0211, 0.9393, 0.0213], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3921, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7204, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1156, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3184691225189558e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4448347396910838e-25 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.448323062532366e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3184691225189558e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4448622265632501e-25 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.448323062532366e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.463095744042689e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7076600400631155e-25 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  6.462252610084454e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.463095744042689e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7077118090600206e-25 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  6.462252610084454e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.541648307432311e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.796789372299049e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.1553442924583379e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.541648307432311e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.796922187065179e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.1553442924583379e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.476778409909457e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.0863571327235366e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1650066461820217e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0083, 0.0106, 0.9704, 0.0106], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4991, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6678, grad_fn=<MeanBackward0>) tensor(0.0041, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1378, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.476778409909457e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.0864897306492316e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1633472790938413e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0083, 0.0106, 0.9704, 0.0106], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4976, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6701, grad_fn=<MeanBackward0>) tensor(0.0041, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1375, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.696021946418619e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.687795285008611e-19 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.651878432719968e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 7}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0341, 0.0416, 0.8835, 0.0409], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4312, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5086, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0336, grad_fn=<MeanBackward0>) tensor(0.1166, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.696021946418619e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.6876404471376987e-19 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  1.0603522468954907e-06 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 2}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 7}
Important relations {'publication': 2}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0291, 0.0353, 0.9007, 0.0349], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4316, grad_fn=<UnbindBackward0>) with num edges 7 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5259, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 2 
 overall mean tensor(0.0335, grad_fn=<MeanBackward0>) tensor(0.1161, grad_fn=<StdBackward0>) 
 Sparsity 0.9982332155477032 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9982, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.730919670006528e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2396032471210257e-12 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00226187682710588 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0412, 0.0555, 0.8508, 0.0525], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4808, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0360, grad_fn=<MeanBackward0>) tensor(0.1254, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.730919670006528e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2394675050090305e-12 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  4.626958616427146e-05 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0444, 0.0606, 0.8383, 0.0567], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4786, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0358, grad_fn=<MeanBackward0>) tensor(0.1245, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1186879806123216e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0005917708040215075 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  9.185291673929896e-06 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0355, 0.0496, 0.8683, 0.0467], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5117, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5117, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0382, grad_fn=<MeanBackward0>) tensor(0.1330, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1186879806123216e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0005916759837418795 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  2.874699248422985e-06 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0390, 0.0547, 0.8553, 0.0510], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5040, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5040, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0376, grad_fn=<MeanBackward0>) tensor(0.1310, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.3487932085990906 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.797023773193359 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.8475356234357605e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0642, 0.0881, 0.7679, 0.0798], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4430, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0333, grad_fn=<MeanBackward0>) tensor(0.1157, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.3487932085990906 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.09873241931200027 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  4.86048312708931e-09 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0652, 0.0891, 0.7649, 0.0808], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4394, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0331, grad_fn=<MeanBackward0>) tensor(0.1151, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.696021946418619e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1221021655991353e-29 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  7.654382116735326e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.696021946418619e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1221021655991353e-29 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  7.65444079741332e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.730919670006528e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.786092507234418e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2601178271933955e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  7.730919670006528e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.786092507234418e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.260127419742003e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1186879806123216e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.521543943234121e-10 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  5.474818862150066e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1186879806123216e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.521543943234121e-10 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  5.4748608424581846e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.3487932085990906 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0171042550355196 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.002695591188967228 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0023, 0.0038, 0.9901, 0.0038], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7711, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7525, grad_fn=<MeanBackward0>) tensor(0.0620, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.3487932085990906 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.02955237403512001 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.019436078146100044 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0021, 0.0035, 0.9909, 0.0035], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7709, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7532, grad_fn=<MeanBackward0>) tensor(0.0590, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0579, grad_fn=<MeanBackward0>) tensor(0.2014, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.838774814037606e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.07988356053829193 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00011486308358144015 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0165, 0.0212, 0.9411, 0.0211], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4994, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0384, grad_fn=<MeanBackward0>) tensor(0.1331, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.838774814037606e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.009991724975407124 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00011307744716759771 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0177, 0.0227, 0.9370, 0.0226], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4965, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0382, grad_fn=<MeanBackward0>) tensor(0.1323, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  961.2207641601562 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.9372887762273404e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  1.4282517741276902e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0115, 0.0137, 0.9610, 0.0139], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4281, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0329, grad_fn=<MeanBackward0>) tensor(0.1141, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  961.2207641601562 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.9064392661234054e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  7.895050902688104e-27 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0122, 0.0145, 0.9586, 0.0147], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4214, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0324, grad_fn=<MeanBackward0>) tensor(0.1123, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4229864448.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1080354395983676e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  3.7025451250820773e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4229864448.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1080354395983676e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  3.7025451250820773e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.963498337488077e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.736696534475172e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  5.170367989983462e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.963498337488077e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.736696534475172e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  5.170367989983462e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.838774814037606e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.070164843345992e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.863008457003161e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0185, 0.9489, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  5.838774814037606e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.069976396043785e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.859926361357793e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0185, 0.9489, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  961.2207641601562 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.665273427963257 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.3734261691570282 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0064, 0.0085, 0.9766, 0.0085], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5400, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5400, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0415, grad_fn=<MeanBackward0>) tensor(0.1439, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  961.2207641601562 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7236740589141846 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.4010421931743622 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0064, 0.0085, 0.9768, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5407, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5407, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1441, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4229864448.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7309940.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  988227.3125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4229864448.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7309940.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  988227.3125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.963498337488077e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  120341686910976.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  16268903055360.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.963498337488077e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  120341686910976.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  16268903055360.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.29233261942863464 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.16811974346637726 ; pred:  tensor([3.3438e-06, 6.4023e-06, 9.9998e-01, 9.0847e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 41, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
epoch:  20 ; loss:  0.12081465125083923 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 3, 'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0243, 0.0310, 0.9139, 0.0308], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4978, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5022, grad_fn=<MeanBackward0>) tensor(0.0020, grad_fn=<StdBackward0>) 6 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1292, grad_fn=<StdBackward0>) 
 Sparsity 0.9946996466431095 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(6.0782e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9947, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.29233261942863464 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.020693030208349228 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.03474646806716919 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 5, 'publication': 4}
Important relations {'author': 1, 'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0245, 0.0314, 0.9130, 0.0311], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4906, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5241, grad_fn=<MeanBackward0>) tensor(0.0253, grad_fn=<StdBackward0>) 4 
 overall mean tensor(0.0370, grad_fn=<MeanBackward0>) tensor(0.1284, grad_fn=<StdBackward0>) 
 Sparsity 0.9964664310954063 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(6.0782e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9965, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4812587.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  8.633929011909723e-32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.43195995125091e-42 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0067e-04, 1.1680e-03, 9.9671e-01, 1.3229e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7142, grad_fn=<MeanBackward0>) tensor(0.1185, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0549, grad_fn=<MeanBackward0>) tensor(0.1931, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4812587.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.450953421712877e-32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  7.985999948187132e-42 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0058e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7142, grad_fn=<MeanBackward0>) tensor(0.1185, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0549, grad_fn=<MeanBackward0>) tensor(0.1931, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6200389709306266e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.1323799028573795e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0673670703702646e-31 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7066, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.1911, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6200389709306266e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.1323799028573795e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0673670703702646e-31 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7066, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.1911, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.313291198060686e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1257688035667585e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.1257688035667585e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2591e-04, 8.0646e-04, 9.9781e-01, 8.5454e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7315, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.313291198060686e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1257688035667585e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.1257688035667585e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2591e-04, 8.0646e-04, 9.9781e-01, 8.5454e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7315, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.29233261942863464 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.23784498870372772 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.2024444192647934 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6852, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0094, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.29233261942863464 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.1106228455901146 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.1022619977593422 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9942, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6828, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6727, grad_fn=<MeanBackward0>) tensor(0.0086, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4812587.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  262.8688659667969 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  12.206299781799316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.4038e-04, 8.2483e-04, 9.9775e-01, 8.8144e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7308, grad_fn=<MeanBackward0>) tensor(0.0216, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1948, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4812587.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  262.8670959472656 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  12.206031799316406 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.4038e-04, 8.2482e-04, 9.9775e-01, 8.8143e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7308, grad_fn=<MeanBackward0>) tensor(0.0216, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1948, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6200389709306266e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  14111206277120.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  649330294784.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3736e-04, 8.2028e-04, 9.9777e-01, 8.7690e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7297, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1945, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.6200389709306266e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  14111206277120.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  649330294784.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3736e-04, 8.2028e-04, 9.9777e-01, 8.7690e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7297, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1945, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.313291198060686e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.311366395608745e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.311366395608745e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2591e-04, 8.0646e-04, 9.9781e-01, 8.5454e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7315, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.313291198060686e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.311366395608745e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.311366395608745e+24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2591e-04, 8.0646e-04, 9.9781e-01, 8.5454e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7315, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.7384490966796875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.788296222686768 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.904874324798584 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.7384490966796875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.788296222686768 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.904874324798584 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110933208.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110835288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110823664.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8774e-06, 3.6963e-06, 9.9999e-01, 5.4399e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110933208.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110846072.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110864464.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8777e-06, 3.6969e-06, 9.9999e-01, 5.4408e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9850063577120944e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9850063577120944e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.7384490966796875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.741644382476807 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.745560169219971 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.7384490966796875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.741644382476807 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.745560169219971 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110933208.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110895552.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110885400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8778e-06, 3.6971e-06, 9.9999e-01, 5.4410e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110933208.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110895552.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110885400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8778e-06, 3.6971e-06, 9.9999e-01, 5.4410e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.4206368670000876e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9850063577120944e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.9850063577120944e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  nan ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 0 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 0 
 VS label 1-m explain binary 2  
 pred prob explain tensor([nan, nan, nan, nan], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(nan, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  889.9449462890625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.4021235813902785e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.7947175585979e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0143, 0.0174, 0.9510, 0.0173], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4407, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6708, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0347, grad_fn=<MeanBackward0>) tensor(0.1212, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  889.9449462890625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.219927951536154e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  7.6579199597652e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0203, 0.0238, 0.9323, 0.0236], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4004, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6735, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0319, grad_fn=<MeanBackward0>) tensor(0.1120, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14650909696.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.0065314523907854e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  6.49398780899342e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14650909696.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.0065314523907854e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  6.49398780899342e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.259916308250624e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.912987097848713e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  8.624604343650854e-19 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.259916308250624e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.912987097848713e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  8.624604343650854e-19 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0123, 0.0163, 0.9552, 0.0162], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5354, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5345, grad_fn=<MeanBackward0>) tensor(0.0062, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0411, grad_fn=<MeanBackward0>) tensor(0.1424, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0123, 0.0163, 0.9552, 0.0162], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5354, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5345, grad_fn=<MeanBackward0>) tensor(0.0062, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0411, grad_fn=<MeanBackward0>) tensor(0.1424, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  889.9449462890625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.18918518722057343 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.008166063576936722 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0132, 0.0171, 0.9528, 0.0170], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5098, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5128, grad_fn=<MeanBackward0>) tensor(0.0124, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0393, grad_fn=<MeanBackward0>) tensor(0.1364, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  889.9449462890625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.19389048218727112 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.008848696015775204 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9530, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5103, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5134, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14650909696.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3201768.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  147165.34375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9531, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5104, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14650909696.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3201768.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  147165.34375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9531, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5104, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.259916308250624e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1778492375040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  77591830528.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9534, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0117, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.259916308250624e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1778492375040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  77591830528.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9534, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0117, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0123, 0.0163, 0.9552, 0.0162], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5354, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5345, grad_fn=<MeanBackward0>) tensor(0.0062, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0411, grad_fn=<MeanBackward0>) tensor(0.1424, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0741621718550524e+23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0123, 0.0163, 0.9552, 0.0162], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5354, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5345, grad_fn=<MeanBackward0>) tensor(0.0062, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0411, grad_fn=<MeanBackward0>) tensor(0.1424, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.029069208092867e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  10.329898834228516 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.4135262012569e-06 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0362, 0.0491, 0.8680, 0.0467], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4963, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0374, grad_fn=<MeanBackward0>) tensor(0.1300, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.029069208092867e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.6709491014480591 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  9.489326657785568e-06 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0327, 0.0437, 0.8815, 0.0421], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4981, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0377, grad_fn=<MeanBackward0>) tensor(0.1308, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.632935015447134e-16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0061524189077317715 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00045183123438619077 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0422, 0.0571, 0.8469, 0.0538], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4817, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0363, grad_fn=<MeanBackward0>) tensor(0.1262, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.632935015447134e-16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.000887786562088877 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.117162084009806e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0459, 0.0631, 0.8323, 0.0587], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4784, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0360, grad_fn=<MeanBackward0>) tensor(0.1251, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.16145780441002e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0001786666689440608 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  8.234012603759766 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0487, 0.0691, 0.8191, 0.0631], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4863, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0364, grad_fn=<MeanBackward0>) tensor(0.1267, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.16145780441002e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0001530089502921328 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.02749914675951004 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0469, 0.0678, 0.8238, 0.0615], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4977, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0372, grad_fn=<MeanBackward0>) tensor(0.1295, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  101.43431854248047 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.763415770303041e-12 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.008280010893940926 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0343, 0.0529, 0.8652, 0.0477], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5580, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5580, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0413, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  101.43431854248047 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.254368768167686e-19 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.3476508429786776e-22 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0150, 0.9632, 0.0138], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7730, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7730, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0565, grad_fn=<MeanBackward0>) tensor(0.1987, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.029069208092867e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.397774888191578e-21 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.321144026445833e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.029069208092867e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.397780239823959e-21 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.321144026445833e-18 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.632935015447134e-16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.2278979238554075e-14 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  2.17495951804203e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.632935015447134e-16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.2279025825366174e-14 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  2.17495951804203e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.16145780441002e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.859631685074419e-05 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0170486718416214 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0069, 0.0103, 0.9726, 0.0102], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0491, grad_fn=<MeanBackward0>) tensor(0.1709, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.16145780441002e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.78983487887308e-05 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.007697303779423237 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0071, 0.0107, 0.9715, 0.0106], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0491, grad_fn=<MeanBackward0>) tensor(0.1709, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  101.43431854248047 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.7965156435966492 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  1.9485688209533691 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0049, 0.0076, 0.9799, 0.0076], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6995, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6995, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0522, grad_fn=<MeanBackward0>) tensor(0.1819, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  101.43431854248047 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.20162051916122437 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.034506626427173615 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0039, 0.0061, 0.9839, 0.0061], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7278, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7278, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0542, grad_fn=<MeanBackward0>) tensor(0.1890, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.5714997804926196e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.5248774886131287 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.07802478224039078 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0159, 0.0204, 0.9435, 0.0202], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4982, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5592, grad_fn=<MeanBackward0>) tensor(0.0202, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0387, grad_fn=<MeanBackward0>) tensor(0.1343, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.5714997804926196e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0037755495868623257 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.014498510397970676 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0145, 0.0186, 0.9484, 0.0185], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4978, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5716, grad_fn=<MeanBackward0>) tensor(0.0133, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0388, grad_fn=<MeanBackward0>) tensor(0.1346, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.58711263607307e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.09189262334797e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.973899082660147e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0153, 0.0186, 0.9477, 0.0184], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4393, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6582, grad_fn=<MeanBackward0>) tensor(0.0055, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0353, grad_fn=<MeanBackward0>) tensor(0.1237, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.58711263607307e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.699429087040067e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  6.589102705821441e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0098, 0.0123, 0.9656, 0.0123], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4821, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6682, grad_fn=<MeanBackward0>) tensor(0.0047, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0384, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1507464698089507e-09 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.3661239674223058e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.0385552610182736e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0165, 0.0193, 0.9449, 0.0194], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4043, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7166, grad_fn=<MeanBackward0>) tensor(0.0038, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0333, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1507464698089507e-09 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.118618636584804e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.0502358455557906e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0181, 0.0209, 0.9399, 0.0211], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3933, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7200, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1158, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.035407088696956635 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.6352702178479284e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  2.0876954576628028e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0184, 0.0213, 0.9388, 0.0214], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3912, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7203, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0324, grad_fn=<MeanBackward0>) tensor(0.1154, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.035407088696956635 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.920503678644938e-12 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.4016927059239293e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0183, 0.0212, 0.9393, 0.0213], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3932, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7176, grad_fn=<MeanBackward0>) tensor(0.0038, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1157, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.5714997804926196e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.972583769067479e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.683372161710652e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.5714997804926196e-22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.972716297699556e-23 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.683372161710652e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.58711263607307e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.306681446529333e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.1546859105182516e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.58711263607307e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.3067063114250656e-22 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.1546859105182516e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1507464698089507e-09 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7974550453890856e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.640058020617289e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.1507464698089507e-09 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7975188832130016e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.640058020617289e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.035407088696956635 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.278699699573508e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.012749422102388e-07 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0082, 0.0104, 0.9710, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4964, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6761, grad_fn=<MeanBackward0>) tensor(0.0041, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1375, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.035407088696956635 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.544071313146048e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  7.830161763422439e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0083, 0.0106, 0.9705, 0.0106], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5006, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5158, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0396, grad_fn=<MeanBackward0>) tensor(0.1381, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.87188986834489e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.410230712537401e-16 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  4.087200068170205e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 2}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 2}
Important relations {'publication': 2}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0266, 0.0323, 0.9093, 0.0319], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4350, grad_fn=<UnbindBackward0>) with num edges 2 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5404, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 2 
 overall mean tensor(0.0334, grad_fn=<MeanBackward0>) tensor(0.1159, grad_fn=<StdBackward0>) 
 Sparsity 0.9982332155477032 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9982, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.87188986834489e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4101715525799912e-16 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2013675586786121e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 2}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {'publication': 2}
Important relations {'publication': 2}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0199, 0.0244, 0.9316, 0.0242], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4499, grad_fn=<UnbindBackward0>) with num edges 2 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5779, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 2 
 overall mean tensor(0.0343, grad_fn=<MeanBackward0>) tensor(0.1193, grad_fn=<StdBackward0>) 
 Sparsity 0.9982332155477032 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9982, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.374175218175439e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.2388399195373268e-09 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0013762350426986814 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0352, 0.0476, 0.8717, 0.0455], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4971, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1297, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.374175218175439e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.2387879610997743e-09 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  5.370302005758276e-06 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0427, 0.0593, 0.8428, 0.0552], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4912, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0366, grad_fn=<MeanBackward0>) tensor(0.1276, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7468654505137238e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.22511732578277588 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0024349503219127655 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0499, 0.0688, 0.8177, 0.0635], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0352, grad_fn=<MeanBackward0>) tensor(0.1227, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7468654505137238e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.215859055519104 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00100980035495013 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0585, 0.0799, 0.7884, 0.0731], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4503, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0337, grad_fn=<MeanBackward0>) tensor(0.1173, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  28.758146286010742 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.1230614185333252 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.4304409623146057 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0776, 0.1170, 0.7065, 0.0989], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4640, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0345, grad_fn=<MeanBackward0>) tensor(0.1203, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  28.758146286010742 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.605540616503228e-13 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 40}
--------------------------------------------------------------
epoch:  20 ; loss:  1.284407158408385e-08 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0111, 0.0172, 0.9551, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6568, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6559, grad_fn=<MeanBackward0>) tensor(0.0083, grad_fn=<StdBackward0>) 80 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1713, grad_fn=<StdBackward0>) 
 Sparsity 0.9293286219081272 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9293, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.87188986834489e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.111286504143321e-27 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  9.1793653750085e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.87188986834489e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.111286504143321e-27 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  9.17943567145147e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.374175218175439e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.768286455002094e-20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5111712527530112e-20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.374175218175439e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.768286455002094e-20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5111827234216618e-20 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7468654505137238e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.501837018253354e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.565617827192227e-09 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7468654505137238e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.502008259052673e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.566018395659512e-09 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  28.758146286010742 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.4263086318969727 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.067430019378662 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0022, 0.0036, 0.9906, 0.0036], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7696, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7522, grad_fn=<MeanBackward0>) tensor(0.0582, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2011, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  28.758146286010742 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.14452162384986877 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.13957589864730835 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0013, 0.0021, 0.9944, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8087, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7899, grad_fn=<MeanBackward0>) tensor(0.0621, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0607, grad_fn=<MeanBackward0>) tensor(0.2112, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.027670852839946747 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.3729000985622406 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.006729091517627239 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0159, 0.0204, 0.9435, 0.0202], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4944, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1318, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.027670852839946747 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.01285532396286726 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00950639694929123 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0152, 0.0194, 0.9462, 0.0193], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4967, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0382, grad_fn=<MeanBackward0>) tensor(0.1324, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  455537.34375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.151397677176489e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  3.321155686939299e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  455537.34375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.151292987130212e-20 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  3.31702797225273e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2004599963648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.975715946400669e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  1.675613180108712e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2004599963648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.975715946400669e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  1.675613180108712e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3001122427092074e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7589610596123748e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3399492521565535e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3001122427092074e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.7589610596123748e-08 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3399492521565535e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0123, 0.0146, 0.9583, 0.0148], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4206, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(nan, grad_fn=<MeanBackward0>) tensor(nan, grad_fn=<StdBackward0>) 0 
 overall mean tensor(0.0323, grad_fn=<MeanBackward0>) tensor(0.1121, grad_fn=<StdBackward0>) 
 Sparsity 1.0 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(2., grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.027670852839946747 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.025102298706769943 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.03363886475563049 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0184, 0.9491, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5024, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5024, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.027670852839946747 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.024207791313529015 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.022123966366052628 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0139, 0.0179, 0.9505, 0.0177], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5018, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5018, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1337, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  455537.34375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1314.5875244140625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  194.8961181640625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0064, 0.0085, 0.9768, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5407, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5407, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1441, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  455537.34375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1314.6351318359375 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  194.9295654296875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0064, 0.0085, 0.9768, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5407, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5407, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1441, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2004599963648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3516949248.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  475933728.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2004599963648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3516949248.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  475933728.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_1_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3001122427092074e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.789836246830285e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  7835153682399232.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.3001122427092074e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.789836246830285e+16 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  7835153682399232.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_10_type_10_killtype_True_break_no' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5419, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5419, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0416, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.757922115710244e-07 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 1, 'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0239, 0.0306, 0.9152, 0.0303], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4967, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5015, grad_fn=<MeanBackward0>) tensor(0.0014, grad_fn=<StdBackward0>) 4 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1295, grad_fn=<StdBackward0>) 
 Sparsity 0.9964664310954063 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(6.0782e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9965, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.7582015011139447e-07 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 1, 'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0239, 0.0306, 0.9152, 0.0303], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4967, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5015, grad_fn=<MeanBackward0>) tensor(0.0014, grad_fn=<StdBackward0>) 4 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1295, grad_fn=<StdBackward0>) 
 Sparsity 0.9964664310954063 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(6.0782e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9965, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3281510791585983e-36 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.14398665041697e-43 ; pred:  tensor([0.0037, 0.0066, 0.9846, 0.0051], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 32, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 31}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 23, 'phone': 1, 'publication': 16}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0154, 0.0202, 0.9437, 0.0207], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1284, 0.1524, 0.5688, 0.1504], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6557, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5891, grad_fn=<MeanBackward0>) tensor(0.0714, grad_fn=<StdBackward0>) 40 
 overall mean tensor(0.0405, grad_fn=<MeanBackward0>) tensor(0.1420, grad_fn=<StdBackward0>) 
 Sparsity 0.9646643109540636 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(1.5134e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9647, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7669857957301072e-37 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0 ; pred:  tensor([3.2407e-06, 6.3263e-06, 9.9998e-01, 8.8802e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 40, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 40}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 40, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 38}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0022, 0.0031, 0.9914, 0.0033], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([4.4905e-06, 9.4045e-06, 9.9997e-01, 1.2568e-05],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8171, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6755, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 81 
 overall mean tensor(0.0508, grad_fn=<MeanBackward0>) tensor(0.1795, grad_fn=<StdBackward0>) 
 Sparsity 0.9284452296819788 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9284, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2269134944506976e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3642008161894923e-36 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2269134944506976e-26 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3642008161894923e-36 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.312369994750573e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.8921124264652726e-29 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.312369994750573e-19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.8921124264652726e-29 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7040, grad_fn=<MeanBackward0>) tensor(0.1178, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0541, grad_fn=<MeanBackward0>) tensor(0.1904, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.427226038686058e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8.46492582695646e-07 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.5733961592777632e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.427230131412216e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8.464998586532602e-07 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.006625834386795759 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0002417528157820925 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([9.1542e-04, 1.3721e-03, 9.9628e-01, 1.4339e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7382, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7031, grad_fn=<MeanBackward0>) tensor(0.0226, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0540, grad_fn=<MeanBackward0>) tensor(0.1875, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  42.36508560180664 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0026332533452659845 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.00010238254617433995 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([6.0646e-04, 9.2216e-04, 9.9749e-01, 9.7962e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7536, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7244, grad_fn=<MeanBackward0>) tensor(0.0227, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0557, grad_fn=<MeanBackward0>) tensor(0.1931, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  124032840.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  5703617.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2306417885184.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  124032840.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  5703617.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2041911204380672.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  93897187393536.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.7969861652500185e+19 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2041911204380672.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  93897187393536.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3668e-04, 8.1926e-04, 9.9777e-01, 8.7588e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7293, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1944, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.623260021209717 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.509610176086426 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.623260021209717 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.509610176086426 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109837552.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109577032.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8792e-06, 3.6996e-06, 9.9999e-01, 5.4445e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109888264.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109993320.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8772e-06, 3.6960e-06, 9.9999e-01, 5.4395e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.6682891845703125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.665272235870361 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.671455383300781 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.6682891845703125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.665272235870361 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8787e-06, 3.6987e-06, 9.9999e-01, 5.4432e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9999, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9999, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8779e-06, 3.6973e-06, 9.9999e-01, 5.4413e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  109830216.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  109835040.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8779e-06, 3.6973e-06, 9.9999e-01, 5.4413e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(1.1990e-07, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3965643271524984e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.945376415348209e+32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8780e-06, 3.6974e-06, 9.9999e-01, 5.4415e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0173, 0.0225, 0.9379, 0.0223], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5105, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5107, grad_fn=<MeanBackward0>) tensor(0.0008, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0392, grad_fn=<MeanBackward0>) tensor(0.1358, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0173, 0.0225, 0.9379, 0.0223], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5105, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5107, grad_fn=<MeanBackward0>) tensor(0.0008, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0392, grad_fn=<MeanBackward0>) tensor(0.1358, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5864639707425387e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.4196797693597273e-34 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0208, 0.0243, 0.9307, 0.0242], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3976, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6737, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0317, grad_fn=<MeanBackward0>) tensor(0.1113, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.436756862081701e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  9.90907184637759e-35 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0213, 0.0248, 0.9292, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3949, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1107, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.194866778890095e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.257902512500613e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.194866778890095e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  1.257902512500613e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.2392133215112632e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3573619177571333e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.2392133215112632e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
epoch:  20 ; loss:  2.3573619177571333e-24 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 5}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0214, 0.0249, 0.9290, 0.0247], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3945, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6738, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0315, grad_fn=<MeanBackward0>) tensor(0.1106, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.002340516773983836 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0205, 0.0265, 0.9269, 0.0261], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4976, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5001, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0383, grad_fn=<MeanBackward0>) tensor(0.1326, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0008928615134209394 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0012176277814432979 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'publication': 5}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0205, 0.0264, 0.9270, 0.0261], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4976, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5006, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 5 
 overall mean tensor(0.0382, grad_fn=<MeanBackward0>) tensor(0.1325, grad_fn=<StdBackward0>) 
 Sparsity 0.9955830388692579 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9956, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.1536290645599365 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.14504382014274597 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9530, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5104, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  14698.923828125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.15822172164917 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  0.1457432061433792 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0131, 0.0170, 0.9531, 0.0169], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5105, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5135, grad_fn=<MeanBackward0>) tensor(0.0122, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0394, grad_fn=<MeanBackward0>) tensor(0.1366, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1769729.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  77620.7578125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  12640453632.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1769729.5 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  77620.7578125 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  29134522679296.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  1277869031424.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.0809635381169357e+17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  29134522679296.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
epoch:  20 ; loss:  1277869031424.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_overall_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0130, 0.0168, 0.9535, 0.0167], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5120, grad_fn=<UnbindBackward0>) with num edges 5 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5149, grad_fn=<MeanBackward0>) tensor(0.0116, grad_fn=<StdBackward0>) 84 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1370, grad_fn=<StdBackward0>) 
 Sparsity 0.9257950530035336 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9258, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.001856682007201016 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0331, 0.0404, 0.8867, 0.0398], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4335, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5021, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0338, grad_fn=<MeanBackward0>) tensor(0.1172, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0018552110996097326 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0201, 0.0261, 0.9281, 0.0258], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5030, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5030, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1338, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.734333038330078 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0232, 0.0304, 0.9166, 0.0299], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5039, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5039, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0385, grad_fn=<MeanBackward0>) tensor(0.1334, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.8771152496337891 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0232, 0.0305, 0.9163, 0.0300], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5067, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5067, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1340, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.04576222971081734 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0336, 0.0456, 0.8772, 0.0436], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5022, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5022, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1317, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.009544887579977512 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0342, 0.0464, 0.8752, 0.0443], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5018, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5018, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1315, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.9559664130210876 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0388, 0.0548, 0.8554, 0.0510], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5074, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5074, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1324, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.05678058788180351 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0416, 0.0596, 0.8440, 0.0548], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5061, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5061, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1318, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.636680412810355e-27 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.943127545634469e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.268666029877958e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.636701983225732e-27 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  3.943127545634469e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.9516330399479886e-20 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.491452058242594e-17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.734836384053777e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.9516521038761686e-20 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.491452058242594e-17 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.769772466937326e-10 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.628244619832913e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.4693498074389595e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.76978301405606e-10 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  6.628244619832913e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 39}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0062, 0.0093, 0.9752, 0.0092], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0492, grad_fn=<MeanBackward0>) tensor(0.1712, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0022976803593337536 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.06493755429983139 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0073, 0.0109, 0.9711, 0.0108], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0491, grad_fn=<MeanBackward0>) tensor(0.1709, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0005711485864594579 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0015529218362644315 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
epoch:  20 ; loss:  0.007304241415113211 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0077, 0.0115, 0.9694, 0.0114], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6552, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6552, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0491, grad_fn=<MeanBackward0>) tensor(0.1707, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.7449102819664404e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0220, 0.0282, 0.9219, 0.0279], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4917, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5011, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0378, grad_fn=<MeanBackward0>) tensor(0.1312, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.74478186131455e-05 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0220, 0.0282, 0.9219, 0.0279], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4917, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5011, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0378, grad_fn=<MeanBackward0>) tensor(0.1312, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  9.294407391280401e-06 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0218, 0.0279, 0.9226, 0.0276], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4886, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5073, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 3 
 overall mean tensor(0.0377, grad_fn=<MeanBackward0>) tensor(0.1306, grad_fn=<StdBackward0>) 
 Sparsity 0.9973498233215548 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-1.5730e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9973, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  8.630761383354724e-11 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  7.720411224383661e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0231, 0.0275, 0.9224, 0.0271], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4120, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6203, grad_fn=<MeanBackward0>) tensor(0.0071, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0331, grad_fn=<MeanBackward0>) tensor(0.1161, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.00012327500735409558 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  0.15358416736125946 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0135, 0.0172, 0.9521, 0.0171], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4950, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5851, grad_fn=<MeanBackward0>) tensor(0.0071, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0387, grad_fn=<MeanBackward0>) tensor(0.1343, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.281740683178327e-10 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.901016011274237e-09 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0100, 0.0130, 0.9641, 0.0129], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5147, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5233, grad_fn=<MeanBackward0>) tensor(0.0273, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0402, grad_fn=<MeanBackward0>) tensor(0.1396, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5022957992280385e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  4.659990625868739e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0182, 0.0210, 0.9397, 0.0211], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3928, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7202, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1157, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.471954648923471e-17 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  4.2165401404221634e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'publication': 8}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 0 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 1  
 pred prob explain tensor([0.0183, 0.0211, 0.9394, 0.0212], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.3922, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7204, grad_fn=<MeanBackward0>) tensor(0.0037, grad_fn=<StdBackward0>) 8 
 overall mean tensor(0.0325, grad_fn=<MeanBackward0>) tensor(0.1156, grad_fn=<StdBackward0>) 
 Sparsity 0.9929328621908127 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(-3.7253e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9929, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.583846888544744e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.7847512675950828e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1.7825177377496278e-28 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  7.584020222239739e-29 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.7847512675950828e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4212446969148001e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.344673171267893e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.9345052140789107e-21 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4212771969826117e-28 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  3.344673171267893e-26 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.0427273702968627e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.979713116810101e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.439544673584794e-15 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.042797250515011e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  5.979713116810101e-14 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.702155391302209e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.1206167965143246e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0479, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0398, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  4.016148480445736e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.70228562261785e-16 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
epoch:  20 ; loss:  1.1206167965143246e-13 ; pred:  tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) ; Counter {'publication': 8}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 8}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0081, 0.0104, 0.9711, 0.0104], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5020, grad_fn=<UnbindBackward0>) with num edges 8 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5172, grad_fn=<MeanBackward0>) tensor(0.0480, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0397, grad_fn=<MeanBackward0>) tensor(0.1385, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5724600133608496e-22 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 2}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 36}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0180, 0.0232, 0.9357, 0.0231], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5035, grad_fn=<UnbindBackward0>) with num edges 2 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5038, grad_fn=<MeanBackward0>) tensor(0.0017, grad_fn=<StdBackward0>) 81 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9284452296819788 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9284, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5723519709712705e-22 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'publication': 2}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 36}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0180, 0.0232, 0.9357, 0.0231], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5035, grad_fn=<UnbindBackward0>) with num edges 2 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5038, grad_fn=<MeanBackward0>) tensor(0.0017, grad_fn=<StdBackward0>) 81 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9284452296819788 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9284, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.2598191052540084e-15 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'publication': 2}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 36}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0172, 0.0223, 0.9385, 0.0221], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5070, grad_fn=<UnbindBackward0>) with num edges 2 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5073, grad_fn=<MeanBackward0>) tensor(0.0017, grad_fn=<StdBackward0>) 81 
 overall mean tensor(0.0388, grad_fn=<MeanBackward0>) tensor(0.1344, grad_fn=<StdBackward0>) 
 Sparsity 0.9284452296819788 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9284, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.259724237563916e-15 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0192, 0.0250, 0.9310, 0.0248], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5063, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5063, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1340, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.128053205931792e-07 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0270, 0.0357, 0.9024, 0.0349], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5040, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5040, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1321, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.1279113816017343e-07 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  3.397577893338166e-05 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0308, 0.0414, 0.8879, 0.0399], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5043, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5043, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0379, grad_fn=<MeanBackward0>) tensor(0.1317, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3.2045440673828125 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0358, 0.0499, 0.8674, 0.0470], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5095, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5095, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0381, grad_fn=<MeanBackward0>) tensor(0.1327, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.3165602684020996 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 35}
--------------------------------------------------------------
epoch:  20 ; loss:  0.006923448760062456 ; pred:  tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 34}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 1 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0379, 0.0534, 0.8588, 0.0499], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.1000, 0.4033, 0.3232, 0.1735], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5089, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5089, grad_fn=<MeanBackward0>) tensor(5.9986e-08, grad_fn=<StdBackward0>) 79 
 overall mean tensor(0.0380, grad_fn=<MeanBackward0>) tensor(0.1324, grad_fn=<StdBackward0>) 
 Sparsity 0.9302120141342756 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9302, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.486163166713538e-31 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.203076835227782e-32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.136584738664762e-30 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.486163166713538e-31 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.2030935860222812e-32 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4466256707026432e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.626858762716039e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.5173950923047936e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4466256707026432e-24 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.6268866193667544e-25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.711781754011211e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.5757570758206246e-13 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  9.639518350201826e-11 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.711781754011211e-12 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.575769002044522e-13 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7521, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.4728818465955555e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.610152250781539e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0025, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7522, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.00158692488912493 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.541656016954221e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.7413600491854595e-06 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_domain_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0024, 0.0040, 0.9895, 0.0040], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7712, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7522, grad_fn=<MeanBackward0>) tensor(0.0633, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0578, grad_fn=<MeanBackward0>) tensor(0.2012, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0119, 0.0154, 0.9574, 0.0153], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5136, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5136, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1369, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0119, 0.0154, 0.9574, 0.0153], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5136, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5136, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1369, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0086, 0.0112, 0.9691, 0.0111], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5139, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5139, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0395, grad_fn=<MeanBackward0>) tensor(0.1369, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0073, 0.0095, 0.9737, 0.0095], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5160, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5160, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0397, grad_fn=<MeanBackward0>) tensor(0.1375, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0074, 0.0095, 0.9737, 0.0095], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5078, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5078, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0390, grad_fn=<MeanBackward0>) tensor(0.1353, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0074, 0.0095, 0.9737, 0.0095], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5078, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5078, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0390, grad_fn=<MeanBackward0>) tensor(0.1353, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0074, 0.0095, 0.9737, 0.0095], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5078, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5078, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0390, grad_fn=<MeanBackward0>) tensor(0.1353, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0074, 0.0095, 0.9737, 0.0095], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5078, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5078, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0390, grad_fn=<MeanBackward0>) tensor(0.1353, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5727187491497716e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.38640937513901e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0185, 0.9489, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  3.13344017399686e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.5727187491497716e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3.386448099718109e-08 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0143, 0.0185, 0.9489, 0.0183], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.07046941667795181 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.09739174693822861 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0136, 0.0175, 0.9516, 0.0174], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5025, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5025, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0386, grad_fn=<MeanBackward0>) tensor(0.1339, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.5158488154411316 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0005678583402186632 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.2444608475780115e-05 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0097, 0.0126, 0.9653, 0.0124], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5071, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5071, grad_fn=<MeanBackward0>) tensor(1.1990e-07, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0390, grad_fn=<MeanBackward0>) tensor(0.1351, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3851.25390625 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  519.9574584960938 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2269995.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  3851.26123046875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  519.9802856445312 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  63402213376.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8560384512.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  37370246201344.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  63402213376.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  8560384512.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_range_frequency_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_-10_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0063, 0.0084, 0.9769, 0.0084], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.5420, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5420, grad_fn=<MeanBackward0>) tensor(0., grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0417, grad_fn=<MeanBackward0>) tensor(0.1444, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0007634551730006933 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 1, 'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0239, 0.0306, 0.9152, 0.0303], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4967, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5015, grad_fn=<MeanBackward0>) tensor(0.0014, grad_fn=<StdBackward0>) 4 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1295, grad_fn=<StdBackward0>) 
 Sparsity 0.9964664310954063 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(6.0782e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9965, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0007745568873360753 ; pred:  tensor([2.5776e-06, 4.9563e-06, 9.9999e-01, 7.1925e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 41}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 1, 'publication': 3}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 2  
 pred prob explain tensor([0.0239, 0.0306, 0.9152, 0.0303], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.4967, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.5016, grad_fn=<MeanBackward0>) tensor(0.0014, grad_fn=<StdBackward0>) 4 
 overall mean tensor(0.0373, grad_fn=<MeanBackward0>) tensor(0.1295, grad_fn=<StdBackward0>) 
 Sparsity 0.9964664310954063 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(6.0782e-09, grad_fn=<MeanBackward0>) 
 score tensor(1.9965, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  4.524418063242482e-34 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.942726775082116e-44 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.1611e-04, 1.1903e-03, 9.9665e-01, 1.3467e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8360, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7128, grad_fn=<MeanBackward0>) tensor(0.1180, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0548, grad_fn=<MeanBackward0>) tensor(0.1927, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5.513107076264915e-34 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  4.764414778704378e-44 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0230e-04, 1.1703e-03, 9.9670e-01, 1.3254e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7141, grad_fn=<MeanBackward0>) tensor(0.1185, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0549, grad_fn=<MeanBackward0>) tensor(0.1931, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7888845708681272e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2377525724036668e-33 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7066, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.1911, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.7888845708681272e-23 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  1.2377525724036668e-33 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([8.0057e-04, 1.1679e-03, 9.9671e-01, 1.3228e-03],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.8363, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7066, grad_fn=<MeanBackward0>) tensor(0.1181, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0543, grad_fn=<MeanBackward0>) tensor(0.1911, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5744570662912.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2634952704.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 4, 'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([4.5222e-04, 7.0114e-04, 9.9810e-01, 7.4811e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2347, 0.2544, 0.2687, 0.2422], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7444, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7280, grad_fn=<MeanBackward0>) tensor(0.0366, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0559, grad_fn=<MeanBackward0>) tensor(0.1943, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  5744570662912.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2634952704.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 4, 'publication': 5}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([4.5222e-04, 7.0114e-04, 9.9810e-01, 7.4811e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2347, 0.2544, 0.2687, 0.2422], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7444, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7280, grad_fn=<MeanBackward0>) tensor(0.0366, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0559, grad_fn=<MeanBackward0>) tensor(0.1943, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.001061261398717761 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0007625935832038522 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  0.0015522452304139733 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  0.0010617361404001713 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.0007647938327863812 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([0.0015, 0.0022, 0.9941, 0.0022], grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.6853, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.6726, grad_fn=<MeanBackward0>) tensor(0.0095, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0517, grad_fn=<MeanBackward0>) tensor(0.1793, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4011023044586182 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.06522268056869507 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.4100e-04, 8.2573e-04, 9.9775e-01, 8.8237e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7308, grad_fn=<MeanBackward0>) tensor(0.0216, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1948, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  25554.169921875 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  1.4004477262496948 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  0.06509441882371902 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.4011e-04, 8.2441e-04, 9.9775e-01, 8.8104e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7309, grad_fn=<MeanBackward0>) tensor(0.0216, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1948, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  74997309440.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3452347648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3691e-04, 8.1961e-04, 9.9777e-01, 8.7623e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7297, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1945, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  1391204197466112.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  74997309440.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  3452347648.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.3691e-04, 8.1961e-04, 9.9777e-01, 8.7623e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7555, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7297, grad_fn=<MeanBackward0>) tensor(0.0215, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0561, grad_fn=<MeanBackward0>) tensor(0.1945, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2501e-04, 8.0530e-04, 9.9782e-01, 8.5332e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7314, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.2902974840199365e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  2.1852920054681287e+22 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_normal_hops_2_lr_0.01_adaptive_False_size_0.05_sizestd_adaptive_ent_1_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {'author': 6, 'publication': 3}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 2 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([5.2501e-04, 8.0530e-04, 9.9782e-01, 8.5332e-04],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2582, 0.2450, 0.2623, 0.2345], grad_fn=<SoftmaxBackward0>) threshold tensor(0.7428, grad_fn=<UnbindBackward0>) with num edges 9 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.7314, grad_fn=<MeanBackward0>) tensor(0.0085, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0562, grad_fn=<MeanBackward0>) tensor(0.1949, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.708218574523926 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.713527202606201 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.724119186401367 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  6.708218574523926 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  6.713527202606201 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  6.724119186401367 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_1_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.9102e-06, 3.7581e-06, 9.9999e-01, 5.5243e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(0.9992, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(0.9992, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0768, grad_fn=<MeanBackward0>) tensor(0.2663, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110435400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110421080.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110403816.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8769e-06, 3.6954e-06, 9.9999e-01, 5.4387e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  110435400.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  110420872.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  20 ; loss:  110401288.0 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
Finished Training
Directory 'chk/aifb_chk/exp/init_const_hops_2_lr_0.1_adaptive_False_size_5e-05_sizestd_adaptive_ent_1_type_10_killtype_True_break_num_high' already exists.
Important relations thresholded to 10 {}
Important relations {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
node_idx 5757 
 node original label [2] 
 VS label full 2 
 VS label explain 2 
 VS label explain binary 2 
 VS label threshold 0 
 VS label sub 2 
 VS label 1-m explain binary 0  
 pred prob explain tensor([1.8766e-06, 3.6948e-06, 9.9999e-01, 5.4379e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob explain binary tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 pred prob threshold tensor([0.2832, 0.2352, 0.2552, 0.2264], grad_fn=<SoftmaxBackward0>) threshold tensor(1.0000, grad_fn=<UnbindBackward0>) with num edges 0 
 pred prob full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>) 
 pred prob sub tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) 
 final masks and lenght tensor(1.0000, grad_fn=<MeanBackward0>) tensor(5.9950e-08, grad_fn=<StdBackward0>) 87 
 overall mean tensor(0.0769, grad_fn=<MeanBackward0>) tensor(0.2665, grad_fn=<StdBackward0>) 
 Sparsity 0.9231448763250883 
 fidelity_minus tensor(1., grad_fn=<MeanBackward0>) 
 fidelity_plus tensor(2.6077e-08, grad_fn=<MeanBackward0>) 
 score tensor(1.9231, grad_fn=<AddBackward0>)
Explanation for 5757 with original label tensor([2])
num_neighbors: 1069 num_edges: 1132
start training
epoch:  0 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------
epoch:  10 ; loss:  2.4097745017522837e+25 ; pred:  tensor([1.8760e-06, 3.6936e-06, 9.9999e-01, 5.4363e-06],
       grad_fn=<SoftmaxBackward0>) ; Counter {'author': 42, 'fax': 1, 'name': 1, 'phone': 1, 'publication': 42}
--------------------------------------------------------------wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.70922
wandb:  mask_ent_loss 0.00065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run genial-sweep-473 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4qrj3f0y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153252-4qrj3f0y/logs
wandb: Agent Starting Run: 242bu2wc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153312-242bu2wc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run balmy-sweep-474
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/242bu2wc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.70922
wandb:  mask_ent_loss 0.00065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run balmy-sweep-474 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/242bu2wc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153312-242bu2wc/logs
wandb: Agent Starting Run: 61giqxnr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153333-61giqxnr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vivid-sweep-475
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/61giqxnr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110410976.0
wandb:  mask_ent_loss 0.00047
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00026
wandb:     wrong_pred 0
wandb: 
wandb:  View run vivid-sweep-475 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/61giqxnr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153333-61giqxnr/logs
wandb: Agent Starting Run: mmphs5sr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153355-mmphs5sr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run youthful-sweep-476
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mmphs5sr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110404864.0
wandb:  mask_ent_loss 0.00048
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00032
wandb:     wrong_pred 0
wandb: 
wandb:  View run youthful-sweep-476 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mmphs5sr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153355-mmphs5sr/logs
wandb: Agent Starting Run: gngpa4t8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153415-gngpa4t8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rose-sweep-477
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gngpa4t8
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run rose-sweep-477 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gngpa4t8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153415-gngpa4t8/logs
wandb: Agent Starting Run: ntqjd75o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153436-ntqjd75o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-478
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ntqjd75o
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4097745017522837e+25
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run deft-sweep-478 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ntqjd75o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153436-ntqjd75o/logs
wandb: Agent Starting Run: lsu38tbn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153457-lsu38tbn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-479
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/lsu38tbn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9671390143825836e+32
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run magic-sweep-479 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/lsu38tbn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153457-lsu38tbn/logs
wandb: Agent Starting Run: ut5so0vz with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153517-ut5so0vz
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run gentle-sweep-480
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ut5so0vz
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9671390143825836e+32
wandb:  mask_ent_loss 0.0005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run gentle-sweep-480 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ut5so0vz
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153517-ut5so0vz/logs
wandb: Agent Starting Run: hsthsiu6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153538-hsthsiu6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fancy-sweep-481
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hsthsiu6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00391
wandb:  mask_ent_loss 0.693
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02826
wandb:  size_std_loss -9.17096
wandb:     wrong_pred 1
wandb: 
wandb:  View run fancy-sweep-481 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hsthsiu6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153538-hsthsiu6/logs
wandb: Agent Starting Run: eb1ye17c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153559-eb1ye17c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run breezy-sweep-482
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eb1ye17c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00035
wandb:  mask_ent_loss 0.6929
wandb:       num_high 1087
wandb:      pred_loss 1.12945
wandb:          score 1.9258
wandb:      size_loss 0.02845
wandb:  size_std_loss -11.62895
wandb:     wrong_pred 1
wandb: 
wandb:  View run breezy-sweep-482 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eb1ye17c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153559-eb1ye17c/logs
wandb: Agent Starting Run: vyfc7oz3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153620-vyfc7oz3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pious-sweep-483
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vyfc7oz3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: / 0.018 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: - 0.018 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.018 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.018 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: / 0.018 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: - 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.024 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.94307
wandb:     wrong_pred 1
wandb: 
wandb:  View run pious-sweep-483 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vyfc7oz3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153620-vyfc7oz3/logs
wandb: Agent Starting Run: mjzoc5tk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153649-mjzoc5tk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glorious-sweep-484
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mjzoc5tk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.9435
wandb:     wrong_pred 1
wandb: 
wandb:  View run glorious-sweep-484 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mjzoc5tk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153649-mjzoc5tk/logs
wandb: Agent Starting Run: t0fc7p7h with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153710-t0fc7p7h
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-485
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0fc7p7h
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run restful-sweep-485 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0fc7p7h
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153710-t0fc7p7h/logs
wandb: Agent Starting Run: tvyyk67m with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153731-tvyyk67m
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rare-sweep-486
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tvyyk67m
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66781
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.943
wandb:     wrong_pred 1
wandb: 
wandb:  View run rare-sweep-486 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tvyyk67m
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153731-tvyyk67m/logs
wandb: Agent Starting Run: ejautno5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153751-ejautno5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run graceful-sweep-487
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ejautno5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66791
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.51577
wandb:  size_std_loss -79.03844
wandb:     wrong_pred 1
wandb: 
wandb:  View run graceful-sweep-487 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ejautno5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153751-ejautno5/logs
wandb: Agent Starting Run: 3zgdvzf9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153812-3zgdvzf9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fiery-sweep-488
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3zgdvzf9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66791
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.51577
wandb:  size_std_loss -79.03844
wandb:     wrong_pred 1
wandb: 
wandb:  View run fiery-sweep-488 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3zgdvzf9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153812-3zgdvzf9/logs
wandb: Agent Starting Run: s7h101fn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153833-s7h101fn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-sweep-489
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s7h101fn
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.01272
wandb:  mask_ent_loss 0.69302
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02802
wandb:  size_std_loss -6.52119
wandb:     wrong_pred 1
wandb: 
wandb:  View run lunar-sweep-489 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s7h101fn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153833-s7h101fn/logs
wandb: Agent Starting Run: 7ch9opgb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153854-7ch9opgb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-490
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7ch9opgb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69268
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02835
wandb:  size_std_loss -16.46758
wandb:     wrong_pred 1
wandb: 
wandb:  View run pleasant-sweep-490 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7ch9opgb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153854-7ch9opgb/logs
wandb: Agent Starting Run: xzd2iax3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153914-xzd2iax3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run logical-sweep-491
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xzd2iax3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 96.30389
wandb:  mask_ent_loss 0.69238
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.61688
wandb:     wrong_pred 0
wandb: 
wandb:  View run logical-sweep-491 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xzd2iax3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153914-xzd2iax3/logs
wandb: Agent Starting Run: 8dyyuse0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153935-8dyyuse0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-492
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8dyyuse0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 96.30389
wandb:  mask_ent_loss 0.69238
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.61688
wandb:     wrong_pred 0
wandb: 
wandb:  View run glad-sweep-492 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8dyyuse0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153935-8dyyuse0/logs
wandb: Agent Starting Run: 59he6r0e with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_153957-59he6r0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-493
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/59he6r0e
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 50090956.0
wandb:  mask_ent_loss 0.69233
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18021
wandb:  size_std_loss -13.98948
wandb:     wrong_pred 0
wandb: 
wandb:  View run comic-sweep-493 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/59he6r0e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_153957-59he6r0e/logs
wandb: Agent Starting Run: put6988o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154016-put6988o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run toasty-sweep-494
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/put6988o
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 50090956.0
wandb:  mask_ent_loss 0.69233
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.18021
wandb:  size_std_loss -13.98948
wandb:     wrong_pred 0
wandb: 
wandb:  View run toasty-sweep-494 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/put6988o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154016-put6988o/logs
wandb: Agent Starting Run: 4n89cvtq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154038-4n89cvtq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-495
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4n89cvtq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 751856640851968.0
wandb:  mask_ent_loss 0.69234
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.16689
wandb:  size_std_loss -14.06857
wandb:     wrong_pred 0
wandb: 
wandb:  View run comfy-sweep-495 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4n89cvtq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154038-4n89cvtq/logs
wandb: Agent Starting Run: zlc2xst0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154059-zlc2xst0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-496
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zlc2xst0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 751856640851968.0
wandb:  mask_ent_loss 0.69234
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.16689
wandb:  size_std_loss -14.06857
wandb:     wrong_pred 0
wandb: 
wandb:  View run deft-sweep-496 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zlc2xst0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154059-zlc2xst0/logs
wandb: Agent Starting Run: tmc382l0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154120-tmc382l0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-497
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tmc382l0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 3.06731
wandb:  mask_ent_loss 0.69313
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02843
wandb:  size_std_loss -2.50671
wandb:     wrong_pred 1
wandb: 
wandb:  View run sweepy-sweep-497 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/tmc382l0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154120-tmc382l0/logs
wandb: Agent Starting Run: jjyh8slx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154142-jjyh8slx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-498
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jjyh8slx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.4943
wandb:  mask_ent_loss 0.69311
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0284
wandb:  size_std_loss -4.33208
wandb:     wrong_pred 1
wandb: 
wandb:  View run neat-sweep-498 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jjyh8slx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154142-jjyh8slx/logs
wandb: Agent Starting Run: 0110jbui with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154202-0110jbui
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run expert-sweep-499
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0110jbui
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00134
wandb:  mask_ent_loss 0.69191
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02802
wandb:  size_std_loss -26.22825
wandb:     wrong_pred 1
wandb: 
wandb:  View run expert-sweep-499 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0110jbui
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154202-0110jbui/logs
wandb: Agent Starting Run: gz65nxq7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154222-gz65nxq7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-500
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gz65nxq7
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00019
wandb:  mask_ent_loss 0.69176
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02815
wandb:  size_std_loss -28.18093
wandb:     wrong_pred 1
wandb: 
wandb:  View run helpful-sweep-500 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gz65nxq7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154222-gz65nxq7/logs
wandb: Agent Starting Run: wyzel2kg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154245-wyzel2kg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-sweep-501
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wyzel2kg
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.02228
wandb:  mask_ent_loss 0.6909
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.91326
wandb:  size_std_loss -35.31399
wandb:     wrong_pred 1
wandb: 
wandb:  View run fast-sweep-501 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wyzel2kg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154245-wyzel2kg/logs
wandb: Agent Starting Run: wgpf5kaa with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154306-wgpf5kaa
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-502
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wgpf5kaa
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.04528
wandb:  mask_ent_loss 0.69104
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.26834
wandb:  size_std_loss -34.96032
wandb:     wrong_pred 1
wandb: 
wandb:  View run colorful-sweep-502 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wgpf5kaa
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154306-wgpf5kaa/logs
wandb: Agent Starting Run: o4go3gg0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154327-o4go3gg0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run helpful-sweep-503
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o4go3gg0
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.67291
wandb:  mask_ent_loss 0.68906
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.92256
wandb:  size_std_loss -47.90224
wandb:     wrong_pred 1
wandb: 
wandb:  View run helpful-sweep-503 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/o4go3gg0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154327-o4go3gg0/logs
wandb: Agent Starting Run: jqe1nm1l with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154347-jqe1nm1l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-504
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jqe1nm1l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.09577
wandb:  mask_ent_loss 0.68875
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.03058
wandb:  size_std_loss -49.95959
wandb:     wrong_pred 1
wandb: 
wandb:  View run spring-sweep-504 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jqe1nm1l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154347-jqe1nm1l/logs
wandb: Agent Starting Run: 5bltb7rg with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154408-5bltb7rg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run tough-sweep-505
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5bltb7rg
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run tough-sweep-505 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5bltb7rg
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154408-5bltb7rg/logs
wandb: Agent Starting Run: i4nt2a2d with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154429-i4nt2a2d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-506
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i4nt2a2d
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run confused-sweep-506 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/i4nt2a2d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154429-i4nt2a2d/logs
wandb: Agent Starting Run: kx2a8d5r with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154450-kx2a8d5r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-507
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kx2a8d5r
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run legendary-sweep-507 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kx2a8d5r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154450-kx2a8d5r/logs
wandb: Agent Starting Run: 4xmwp486 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154511-4xmwp486
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-508
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4xmwp486
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run summer-sweep-508 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4xmwp486
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154511-4xmwp486/logs
wandb: Agent Starting Run: 4aiefnj3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154532-4aiefnj3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run divine-sweep-509
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4aiefnj3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00576
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.39994
wandb:  size_std_loss -45.11077
wandb:     wrong_pred 1
wandb: 
wandb:  View run divine-sweep-509 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4aiefnj3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154532-4aiefnj3/logs
wandb: Agent Starting Run: 84w3fsyh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154552-84w3fsyh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-510
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/84w3fsyh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00289
wandb:  mask_ent_loss 0.64796
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.38976
wandb:  size_std_loss -45.79141
wandb:     wrong_pred 1
wandb: 
wandb:  View run magic-sweep-510 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/84w3fsyh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154552-84w3fsyh/logs
wandb: Agent Starting Run: z9ghjn4d with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154612-z9ghjn4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-511
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z9ghjn4d
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.27697
wandb:  mask_ent_loss 0.64768
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.21912
wandb:  size_std_loss -57.04512
wandb:     wrong_pred 1
wandb: 
wandb:  View run silver-sweep-511 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z9ghjn4d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154612-z9ghjn4d/logs
wandb: Agent Starting Run: m0tkrteu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154633-m0tkrteu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-512
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m0tkrteu
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.14402
wandb:  mask_ent_loss 0.64813
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.16342
wandb:  size_std_loss -57.64378
wandb:     wrong_pred 1
wandb: 
wandb:  View run woven-sweep-512 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m0tkrteu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154633-m0tkrteu/logs
wandb: Agent Starting Run: od73qwvs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154654-od73qwvs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-513
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/od73qwvs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 3
wandb:           loss 0.00223
wandb:  mask_ent_loss 0.69268
wandb:       num_high 3
wandb:      pred_loss 1.36578
wandb:          score 1.99735
wandb:      size_loss 0.02755
wandb:  size_std_loss -8.19193
wandb:     wrong_pred 1
wandb: 
wandb:  View run stilted-sweep-513 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/od73qwvs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154654-od73qwvs/logs
wandb: Agent Starting Run: qn68c42d with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154715-qn68c42d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-514
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qn68c42d
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69256
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0286
wandb:  size_std_loss -17.53472
wandb:     wrong_pred 0
wandb: 
wandb:  View run spring-sweep-514 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qn68c42d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154715-qn68c42d/logs
wandb: Agent Starting Run: 555oxyv4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154736-555oxyv4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-515
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/555oxyv4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69208
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02848
wandb:  size_std_loss -24.70963
wandb:     wrong_pred 1
wandb: 
wandb:  View run easy-sweep-515 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/555oxyv4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154736-555oxyv4/logs
wandb: Agent Starting Run: qbh3vb79 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154757-qbh3vb79
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run winter-sweep-516
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qbh3vb79
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68962
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02826
wandb:  size_std_loss -45.09116
wandb:     wrong_pred 1
wandb: 
wandb:  View run winter-sweep-516 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qbh3vb79
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154757-qbh3vb79/logs
wandb: Agent Starting Run: 2u9jxbh0 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154818-2u9jxbh0
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cerulean-sweep-517
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2u9jxbh0
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68749
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 27.73402
wandb:  size_std_loss -55.96975
wandb:     wrong_pred 1
wandb: 
wandb:  View run cerulean-sweep-517 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2u9jxbh0
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154818-2u9jxbh0/logs
wandb: Agent Starting Run: 6s9md2py with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154839-6s9md2py
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run efficient-sweep-518
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6s9md2py
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68924
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 27.7933
wandb:  size_std_loss -46.48561
wandb:     wrong_pred 1
wandb: 
wandb:  View run efficient-sweep-518 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6s9md2py
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154839-6s9md2py/logs
wandb: Agent Starting Run: rol6seq4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154900-rol6seq4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-519
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rol6seq4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66393
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.61011
wandb:  size_std_loss -93.77776
wandb:     wrong_pred 1
wandb: 
wandb:  View run vibrant-sweep-519 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rol6seq4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154900-rol6seq4/logs
wandb: Agent Starting Run: dwo9ua3u with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154922-dwo9ua3u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-520
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dwo9ua3u
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.66392
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.60923
wandb:  size_std_loss -93.7823
wandb:     wrong_pred 1
wandb: 
wandb:  View run worldly-sweep-520 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dwo9ua3u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154922-dwo9ua3u/logs
wandb: Agent Starting Run: d3hdmy30 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_154942-d3hdmy30
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-521
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d3hdmy30
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run avid-sweep-521 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d3hdmy30
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_154942-d3hdmy30/logs
wandb: Agent Starting Run: z6lbdq64 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155003-z6lbdq64
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-522
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z6lbdq64
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run clean-sweep-522 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z6lbdq64
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155003-z6lbdq64/logs
wandb: Agent Starting Run: xj039bzc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155024-xj039bzc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-523
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xj039bzc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run prime-sweep-523 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/xj039bzc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155024-xj039bzc/logs
wandb: Agent Starting Run: sbkoqsb9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155045-sbkoqsb9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-524
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sbkoqsb9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run woven-sweep-524 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sbkoqsb9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155045-sbkoqsb9/logs
wandb: Agent Starting Run: 6lh319yp with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155106-6lh319yp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-525
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6lh319yp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run worthy-sweep-525 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6lh319yp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155106-6lh319yp/logs
wandb: Agent Starting Run: h5nfs62b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155127-h5nfs62b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run amber-sweep-526
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h5nfs62b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68891
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run amber-sweep-526 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/h5nfs62b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155127-h5nfs62b/logs
wandb: Agent Starting Run: bt3iqyun with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155148-bt3iqyun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run feasible-sweep-527
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bt3iqyun
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68887
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.96906
wandb:  size_std_loss -47.80079
wandb:     wrong_pred 1
wandb: 
wandb:  View run feasible-sweep-527 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bt3iqyun
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155148-bt3iqyun/logs
wandb: Agent Starting Run: osbfbitb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155208-osbfbitb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-528
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/osbfbitb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68874
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.90196
wandb:  size_std_loss -48.88729
wandb:     wrong_pred 1
wandb: 
wandb:  View run happy-sweep-528 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/osbfbitb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155208-osbfbitb/logs
wandb: Agent Starting Run: r0ioxa6k with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155229-r0ioxa6k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bright-sweep-529
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r0ioxa6k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.23122
wandb:  mask_ent_loss 0.6931
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02849
wandb:  size_std_loss -3.99957
wandb:     wrong_pred 0
wandb: 
wandb:  View run bright-sweep-529 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r0ioxa6k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155229-r0ioxa6k/logs
wandb: Agent Starting Run: nucxiy4a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155251-nucxiy4a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-530
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nucxiy4a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.20937
wandb:  mask_ent_loss 0.6931
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02849
wandb:  size_std_loss -4.09886
wandb:     wrong_pred 0
wandb: 
wandb:  View run snowy-sweep-530 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nucxiy4a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155251-nucxiy4a/logs
wandb: Agent Starting Run: mq5ugl6u with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155319-mq5ugl6u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rural-sweep-531
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mq5ugl6u
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00037
wandb:  mask_ent_loss 0.69175
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02793
wandb:  size_std_loss -27.51701
wandb:     wrong_pred 1
wandb: 
wandb:  View run rural-sweep-531 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mq5ugl6u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155319-mq5ugl6u/logs
wandb: Agent Starting Run: nauxwv2d with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155341-nauxwv2d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-532
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nauxwv2d
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 5e-05
wandb:  mask_ent_loss 0.69161
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0281
wandb:  size_std_loss -29.5952
wandb:     wrong_pred 1
wandb: 
wandb:  View run fallen-sweep-532 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nauxwv2d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155341-nauxwv2d/logs
wandb: Agent Starting Run: ecf6tz41 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155402-ecf6tz41
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earnest-sweep-533
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ecf6tz41
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68953
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.28325
wandb:  size_std_loss -45.585
wandb:     wrong_pred 1
wandb: 
wandb:  View run earnest-sweep-533 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ecf6tz41
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155402-ecf6tz41/logs
wandb: Agent Starting Run: v82je81g with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155422-v82je81g
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run young-sweep-534
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v82je81g
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 0.68936
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.84265
wandb:  size_std_loss -45.75451
wandb:     wrong_pred 1
wandb: 
wandb:  View run young-sweep-534 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/v82je81g
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155422-v82je81g/logs
wandb: Agent Starting Run: se6jlj0n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155443-se6jlj0n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-535
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/se6jlj0n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.37046
wandb:  mask_ent_loss 0.68893
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.84774
wandb:  size_std_loss -48.42416
wandb:     wrong_pred 1
wandb: 
wandb:  View run stellar-sweep-535 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/se6jlj0n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155443-se6jlj0n/logs
wandb: Agent Starting Run: mcx25bck with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155504-mcx25bck
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wandering-sweep-536
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mcx25bck
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.12151
wandb:  mask_ent_loss 0.68879
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 28.03169
wandb:  size_std_loss -49.72271
wandb:     wrong_pred 1
wandb: 
wandb:  View run wandering-sweep-536 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mcx25bck
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155504-mcx25bck/logs
wandb: Agent Starting Run: nbmb0b7b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155526-nbmb0b7b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-537
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nbmb0b7b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run glamorous-sweep-537 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nbmb0b7b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155526-nbmb0b7b/logs
wandb: Agent Starting Run: peoyy0ci with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155547-peoyy0ci
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run unique-sweep-538
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/peoyy0ci
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run unique-sweep-538 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/peoyy0ci
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155547-peoyy0ci/logs
wandb: Agent Starting Run: ixodvqbs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155607-ixodvqbs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-539
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ixodvqbs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run atomic-sweep-539 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ixodvqbs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155607-ixodvqbs/logs
wandb: Agent Starting Run: nt9jdd62 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155628-nt9jdd62
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-540
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nt9jdd62
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run legendary-sweep-540 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/nt9jdd62
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155628-nt9jdd62/logs
wandb: Agent Starting Run: anc0q7mc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155650-anc0q7mc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-541
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/anc0q7mc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run splendid-sweep-541 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/anc0q7mc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155650-anc0q7mc/logs
wandb: Agent Starting Run: 64gn41o4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155710-64gn41o4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dainty-sweep-542
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/64gn41o4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run dainty-sweep-542 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/64gn41o4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155710-64gn41o4/logs
wandb: Agent Starting Run: yt0364v5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155731-yt0364v5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-543
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yt0364v5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0014
wandb:  mask_ent_loss 0.54945
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.62623
wandb:  size_std_loss -68.20956
wandb:     wrong_pred 0
wandb: 
wandb:  View run giddy-sweep-543 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yt0364v5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155731-yt0364v5/logs
wandb: Agent Starting Run: smxzwung with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155751-smxzwung
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-544
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/smxzwung
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02951
wandb:  mask_ent_loss 0.5496
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.65834
wandb:  size_std_loss -65.19399
wandb:     wrong_pred 0
wandb: 
wandb:  View run cool-sweep-544 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/smxzwung
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155751-smxzwung/logs
wandb: Agent Starting Run: 63alfv5u with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155813-63alfv5u
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-545
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/63alfv5u
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 5e-05
wandb:  mask_ent_loss 0.69238
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0292
wandb:  size_std_loss -12.49308
wandb:     wrong_pred 0
wandb: 
wandb:  View run magic-sweep-545 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/63alfv5u
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155813-63alfv5u/logs
wandb: Agent Starting Run: cikbolhf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155834-cikbolhf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-546
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cikbolhf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 5e-05
wandb:  mask_ent_loss 0.69238
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0292
wandb:  size_std_loss -12.49313
wandb:     wrong_pred 0
wandb: 
wandb:  View run pleasant-sweep-546 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cikbolhf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155834-cikbolhf/logs
wandb: Agent Starting Run: zvi8i8ot with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155854-zvi8i8ot
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worthy-sweep-547
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zvi8i8ot
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02908
wandb:  size_std_loss -33.62595
wandb:     wrong_pred 0
wandb: 
wandb:  View run worthy-sweep-547 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zvi8i8ot
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155854-zvi8i8ot/logs
wandb: Agent Starting Run: 3xnjmpio with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155915-3xnjmpio
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run robust-sweep-548
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3xnjmpio
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 0.69078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02909
wandb:  size_std_loss -33.60698
wandb:     wrong_pred 0
wandb: 
wandb:  View run robust-sweep-548 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3xnjmpio
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155915-3xnjmpio/logs
wandb: Agent Starting Run: ctj3psdj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155936-ctj3psdj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-549
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ctj3psdj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.13806
wandb:  mask_ent_loss 0.69078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60406
wandb:     wrong_pred 0
wandb: 
wandb:  View run golden-sweep-549 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ctj3psdj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155936-ctj3psdj/logs
wandb: Agent Starting Run: dgrhhq63 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_155957-dgrhhq63
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run iconic-sweep-550
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dgrhhq63
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.13806
wandb:  mask_ent_loss 0.69078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60406
wandb:     wrong_pred 0
wandb: 
wandb:  View run iconic-sweep-550 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dgrhhq63
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_155957-dgrhhq63/logs
wandb: Agent Starting Run: rpy24y0c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160018-rpy24y0c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-551
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rpy24y0c
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2272893.5
wandb:  mask_ent_loss 0.69078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60406
wandb:     wrong_pred 0
wandb: 
wandb:  View run clear-sweep-551 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rpy24y0c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160018-rpy24y0c/logs
wandb: Agent Starting Run: 9jj9f531 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160038-9jj9f531
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fine-sweep-552
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9jj9f531
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2272893.5
wandb:  mask_ent_loss 0.69078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08694
wandb:  size_std_loss -33.60406
wandb:     wrong_pred 0
wandb: 
wandb:  View run fine-sweep-552 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9jj9f531
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160038-9jj9f531/logs
wandb: Agent Starting Run: l988t1j4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160100-l988t1j4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-553
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l988t1j4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0002
wandb:  mask_ent_loss 0.69289
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.0913
wandb:     wrong_pred 0
wandb: 
wandb:  View run astral-sweep-553 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l988t1j4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160100-l988t1j4/logs
wandb: Agent Starting Run: 41f4v755 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160121-41f4v755
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run woven-sweep-554
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/41f4v755
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0002
wandb:  mask_ent_loss 0.69289
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02856
wandb:  size_std_loss -11.09482
wandb:     wrong_pred 0
wandb: 
wandb:  View run woven-sweep-554 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/41f4v755
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160121-41f4v755/logs
wandb: Agent Starting Run: 0y9qpx8e with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160141-0y9qpx8e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-555
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0y9qpx8e
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.17451
wandb:  mask_ent_loss 0.68854
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03078
wandb:  size_std_loss -20.92798
wandb:     wrong_pred 0
wandb: 
wandb:  View run treasured-sweep-555 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0y9qpx8e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160141-0y9qpx8e/logs
wandb: Agent Starting Run: eqcnnftc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160202-eqcnnftc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-556
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eqcnnftc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.19808
wandb:  mask_ent_loss 0.68843
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03082
wandb:  size_std_loss -20.80125
wandb:     wrong_pred 0
wandb: 
wandb:  View run astral-sweep-556 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eqcnnftc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160202-eqcnnftc/logs
wandb: Agent Starting Run: agb31ht8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160223-agb31ht8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-557
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/agb31ht8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 477757.9375
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.8809
wandb:  size_std_loss -20.3386
wandb:     wrong_pred 0
wandb: 
wandb:  View run curious-sweep-557 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/agb31ht8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160223-agb31ht8/logs
wandb: Agent Starting Run: yo34ze39 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160244-yo34ze39
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stellar-sweep-558
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yo34ze39
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 477757.9375
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.8809
wandb:  size_std_loss -20.3386
wandb:     wrong_pred 0
wandb: 
wandb:  View run stellar-sweep-558 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yo34ze39
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160244-yo34ze39/logs
wandb: Agent Starting Run: qx6jrxla with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160305-qx6jrxla
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devoted-sweep-559
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qx6jrxla
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7865297272832.0
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88091
wandb:  size_std_loss -20.33859
wandb:     wrong_pred 0
wandb: 
wandb:  View run devoted-sweep-559 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qx6jrxla
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160305-qx6jrxla/logs
wandb: Agent Starting Run: j35gt2kf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 1
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160326-j35gt2kf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glowing-sweep-560
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j35gt2kf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7865297272832.0
wandb:  mask_ent_loss 0.68826
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.88091
wandb:  size_std_loss -20.33859
wandb:     wrong_pred 0
wandb: 
wandb:  View run glowing-sweep-560 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j35gt2kf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160326-j35gt2kf/logs
wandb: Agent Starting Run: twtnpjd2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160346-twtnpjd2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-561
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/twtnpjd2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.14742
wandb:  mask_ent_loss 6.92536
wandb:       num_high 73
wandb:      pred_loss 1.33844
wandb:          score 1.99293
wandb:      size_loss 0.02747
wandb:  size_std_loss -10.32411
wandb:     wrong_pred 0
wandb: 
wandb:  View run polar-sweep-561 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/twtnpjd2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160346-twtnpjd2/logs
wandb: Agent Starting Run: mxm0pwji with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160408-mxm0pwji
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lyric-sweep-562
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mxm0pwji
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 10
wandb:           loss 0.01315
wandb:  mask_ent_loss 6.92669
wandb:       num_high 97
wandb:      pred_loss 1.33844
wandb:          score 1.99117
wandb:      size_loss 0.02774
wandb:  size_std_loss -12.78161
wandb:     wrong_pred 0
wandb: 
wandb:  View run lyric-sweep-562 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mxm0pwji
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160408-mxm0pwji/logs
wandb: Agent Starting Run: capkazd1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160428-capkazd1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run usual-sweep-563
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/capkazd1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.59233
wandb:       num_high 1131
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04068
wandb:  size_std_loss -127.16077
wandb:     wrong_pred 0
wandb: 
wandb:  View run usual-sweep-563 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/capkazd1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160428-capkazd1/logs
wandb: Agent Starting Run: yu9jkkbh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160449-yu9jkkbh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run apricot-sweep-564
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yu9jkkbh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.5922
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04069
wandb:  size_std_loss -127.01217
wandb:     wrong_pred 0
wandb: 
wandb:  View run apricot-sweep-564 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yu9jkkbh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160449-yu9jkkbh/logs
wandb: Agent Starting Run: 6r0rs6ax with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160510-6r0rs6ax
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-565
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6r0rs6ax
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.6443
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.38159
wandb:  size_std_loss -126.8956
wandb:     wrong_pred 0
wandb: 
wandb:  View run jumping-sweep-565 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6r0rs6ax
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160510-6r0rs6ax/logs
wandb: Agent Starting Run: 0s3nzpk9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160531-0s3nzpk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-566
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0s3nzpk9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.6443
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 40.38159
wandb:  size_std_loss -126.8956
wandb:     wrong_pred 0
wandb: 
wandb:  View run kind-sweep-566 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/0s3nzpk9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160531-0s3nzpk9/logs
wandb: Agent Starting Run: gybpnfmo with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160551-gybpnfmo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run silver-sweep-567
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gybpnfmo
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.1257688035667585e+24
wandb:  mask_ent_loss 5.8202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37833
wandb:  size_std_loss -8.98214
wandb:     wrong_pred 0
wandb: 
wandb:  View run silver-sweep-567 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gybpnfmo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160551-gybpnfmo/logs
wandb: Agent Starting Run: uspi4ppk with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160612-uspi4ppk
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run misty-sweep-568
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uspi4ppk
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.1257688035667585e+24
wandb:  mask_ent_loss 5.8202
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37833
wandb:  size_std_loss -8.98214
wandb:     wrong_pred 0
wandb: 
wandb:  View run misty-sweep-568 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/uspi4ppk
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160612-uspi4ppk/logs
wandb: Agent Starting Run: vergd68y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160634-vergd68y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run eager-sweep-569
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vergd68y
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.18478
wandb:  mask_ent_loss 6.3244
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03804
wandb:  size_std_loss -9.89736
wandb:     wrong_pred 0
wandb: 
wandb:  View run eager-sweep-569 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/vergd68y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160634-vergd68y/logs
wandb: Agent Starting Run: zw4ikwzj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160655-zw4ikwzj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run prime-sweep-570
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zw4ikwzj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.07385
wandb:  mask_ent_loss 6.32136
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03807
wandb:  size_std_loss -10.81139
wandb:     wrong_pred 0
wandb: 
wandb:  View run prime-sweep-570 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zw4ikwzj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160655-zw4ikwzj/logs
wandb: Agent Starting Run: ed9g7a3y with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160716-ed9g7a3y
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run sweepy-sweep-571
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ed9g7a3y
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.00681
wandb:  mask_ent_loss 5.81025
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04138
wandb:  size_std_loss -22.92654
wandb:     wrong_pred 0
wandb: 
wandb:  View run sweepy-sweep-571 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ed9g7a3y
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160716-ed9g7a3y/logs
wandb: Agent Starting Run: 9m7r86xc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: | Waiting for wandb.init()...wandb: / Waiting for wandb.init()...wandb: - Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160741-9m7r86xc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-572
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9m7r86xc
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.00663
wandb:  mask_ent_loss 5.81024
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04138
wandb:  size_std_loss -22.92658
wandb:     wrong_pred 0
wandb: 
wandb:  View run golden-sweep-572 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9m7r86xc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160741-9m7r86xc/logs
wandb: Agent Starting Run: t7ioovhu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160810-t7ioovhu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run playful-sweep-573
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t7ioovhu
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 212364034048.0
wandb:  mask_ent_loss 5.8171
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.341
wandb:  size_std_loss -22.92284
wandb:     wrong_pred 0
wandb: 
wandb:  View run playful-sweep-573 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t7ioovhu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160810-t7ioovhu/logs
wandb: Agent Starting Run: 5d5kk2yd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160830-5d5kk2yd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run peachy-sweep-574
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5d5kk2yd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 212364034048.0
wandb:  mask_ent_loss 5.8171
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.341
wandb:  size_std_loss -22.92284
wandb:     wrong_pred 0
wandb: 
wandb:  View run peachy-sweep-574 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5d5kk2yd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160830-5d5kk2yd/logs
wandb: Agent Starting Run: g6b3ptfj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160851-g6b3ptfj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comfy-sweep-575
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g6b3ptfj
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.311366395608745e+24
wandb:  mask_ent_loss 5.82021
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37838
wandb:  size_std_loss -8.9382
wandb:     wrong_pred 0
wandb: 
wandb:  View run comfy-sweep-575 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g6b3ptfj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160851-g6b3ptfj/logs
wandb: Agent Starting Run: w75xt91a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160912-w75xt91a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run atomic-sweep-576
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w75xt91a
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 4.311366395608745e+24
wandb:  mask_ent_loss 5.82021
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 41.37838
wandb:  size_std_loss -8.9382
wandb:     wrong_pred 0
wandb: 
wandb:  View run atomic-sweep-576 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w75xt91a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160912-w75xt91a/logs
wandb: Agent Starting Run: ut34gm4s with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160933-ut34gm4s
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run resilient-sweep-577
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ut34gm4s
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7.13535
wandb:  mask_ent_loss 0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run resilient-sweep-577 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ut34gm4s
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160933-ut34gm4s/logs
wandb: Agent Starting Run: ajydtujr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_160954-ajydtujr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-578
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ajydtujr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 7.13535
wandb:  mask_ent_loss 0.06233
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.05656
wandb:  size_std_loss -0.00013
wandb:     wrong_pred 0
wandb: 
wandb:  View run happy-sweep-578 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ajydtujr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_160954-ajydtujr/logs
wandb: Agent Starting Run: aa85gf6l with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161014-aa85gf6l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-579
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/aa85gf6l
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110769984.0
wandb:  mask_ent_loss 0.00365
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run glad-sweep-579 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/aa85gf6l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161014-aa85gf6l/logs
wandb: Agent Starting Run: wrj4yu2o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161035-wrj4yu2o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-580
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wrj4yu2o
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110836768.0
wandb:  mask_ent_loss 0.00438
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00032
wandb:     wrong_pred 0
wandb: 
wandb:  View run true-sweep-580 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wrj4yu2o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161035-wrj4yu2o/logs
wandb: Agent Starting Run: cx96te1p with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161056-cx96te1p
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run splendid-sweep-581
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cx96te1p
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run splendid-sweep-581 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cx96te1p
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161056-cx96te1p/logs
wandb: Agent Starting Run: z1nl8hr6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161117-z1nl8hr6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run warm-sweep-582
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z1nl8hr6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run warm-sweep-582 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z1nl8hr6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161117-z1nl8hr6/logs
wandb: Agent Starting Run: pagwx95k with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161137-pagwx95k
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-583
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pagwx95k
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9850063577120944e+32
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run astral-sweep-583 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/pagwx95k
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161137-pagwx95k/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: wvkr6n50 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161204-wvkr6n50
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lucky-sweep-584
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wvkr6n50
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9850063577120944e+32
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run lucky-sweep-584 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wvkr6n50
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161204-wvkr6n50/logs
wandb: Agent Starting Run: 5f9ioam3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161224-5f9ioam3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run cool-sweep-585
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5f9ioam3
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74858
wandb:  mask_ent_loss 0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run cool-sweep-585 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5f9ioam3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161224-5f9ioam3/logs
wandb: Agent Starting Run: 7pdd43gb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161245-7pdd43gb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-586
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7pdd43gb
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 6.74858
wandb:  mask_ent_loss 0.0065
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run olive-sweep-586 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7pdd43gb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161245-7pdd43gb/logs
wandb: Agent Starting Run: 8uh120zq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161306-8uh120zq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run brisk-sweep-587
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8uh120zq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110873768.0
wandb:  mask_ent_loss 0.00459
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run brisk-sweep-587 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8uh120zq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161306-8uh120zq/logs
wandb: Agent Starting Run: eo2kbm17 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161327-eo2kbm17
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-588
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eo2kbm17
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 110873768.0
wandb:  mask_ent_loss 0.00459
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0566
wandb:  size_std_loss -0.00019
wandb:     wrong_pred 0
wandb: 
wandb:  View run kind-sweep-588 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/eo2kbm17
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161327-eo2kbm17/logs
wandb: Agent Starting Run: 9ubeb9y2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161348-9ubeb9y2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-589
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ubeb9y2
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run polar-sweep-589 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ubeb9y2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161348-9ubeb9y2/logs
wandb: Agent Starting Run: sintw9wd with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161409-sintw9wd
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run giddy-sweep-590
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sintw9wd
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.4206368670000876e+25
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run giddy-sweep-590 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sintw9wd
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161409-sintw9wd/logs
wandb: Agent Starting Run: z974tunx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161429-z974tunx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clear-sweep-591
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z974tunx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9850063577120944e+32
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run clear-sweep-591 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/z974tunx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161429-z974tunx/logs
wandb: Agent Starting Run: 37e3pmuo with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: const
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161451-37e3pmuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fresh-sweep-592
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/37e3pmuo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3.9850063577120944e+32
wandb:  mask_ent_loss 0.005
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 56.59742
wandb:  size_std_loss -6e-05
wandb:     wrong_pred 0
wandb: 
wandb:  View run fresh-sweep-592 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/37e3pmuo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161451-37e3pmuo/logs
wandb: Agent Starting Run: dkgn4k5n with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161512-dkgn4k5n
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run treasured-sweep-593
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dkgn4k5n
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.82238
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02589
wandb:  size_std_loss -64.71487
wandb:     wrong_pred 1
wandb: 
wandb:  View run treasured-sweep-593 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/dkgn4k5n
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161512-dkgn4k5n/logs
wandb: Agent Starting Run: s945ujlh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161532-s945ujlh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swept-sweep-594
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s945ujlh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.70107
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.0238
wandb:  size_std_loss -77.13292
wandb:     wrong_pred 1
wandb: 
wandb:  View run swept-sweep-594 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s945ujlh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161532-s945ujlh/logs
wandb: Agent Starting Run: 76slqx3a with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161554-76slqx3a
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pleasant-sweep-595
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/76slqx3a
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67806
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.94359
wandb:     wrong_pred 1
wandb: 
wandb:  View run pleasant-sweep-595 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/76slqx3a
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161554-76slqx3a/logs
wandb: Agent Starting Run: sil1deeh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161616-sil1deeh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run curious-sweep-596
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sil1deeh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67806
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 0.02349
wandb:  size_std_loss -78.94359
wandb:     wrong_pred 1
wandb: 
wandb:  View run curious-sweep-596 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/sil1deeh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161616-sil1deeh/logs
wandb: Agent Starting Run: ewbktrnu with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161636-ewbktrnu
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vibrant-sweep-597
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ewbktrnu
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run vibrant-sweep-597 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ewbktrnu
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161636-ewbktrnu/logs
wandb: Agent Starting Run: yuwwvmxv with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161657-yuwwvmxv
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run flowing-sweep-598
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yuwwvmxv
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 5
wandb:           loss 0.0
wandb:  mask_ent_loss 6.67807
wandb:       num_high 84
wandb:      pred_loss 1.36578
wandb:          score 1.99558
wandb:      size_loss 23.49492
wandb:  size_std_loss -78.94301
wandb:     wrong_pred 1
wandb: 
wandb:  View run flowing-sweep-598 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yuwwvmxv
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161657-yuwwvmxv/logs
wandb: Agent Starting Run: 9ynhozcq with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161717-9ynhozcq
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-599
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ynhozcq
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run confused-sweep-599 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/9ynhozcq
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161717-9ynhozcq/logs
wandb: Agent Starting Run: l0ltzgpw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161738-l0ltzgpw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run light-sweep-600
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l0ltzgpw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run light-sweep-600 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/l0ltzgpw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161738-l0ltzgpw/logs
wandb: Agent Starting Run: muitozdi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161759-muitozdi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fluent-sweep-601
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/muitozdi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00254
wandb:  mask_ent_loss 6.92406
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.02907
wandb:  size_std_loss -14.77352
wandb:     wrong_pred 0
wandb: 
wandb:  View run fluent-sweep-601 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/muitozdi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161759-muitozdi/logs
wandb: Agent Starting Run: 2blhcn4b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161820-2blhcn4b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run swift-sweep-602
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2blhcn4b
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 0.00289
wandb:  mask_ent_loss 6.92382
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.64462
wandb:     wrong_pred 0
wandb: 
wandb:  View run swift-sweep-602 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/2blhcn4b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161820-2blhcn4b/logs
wandb: Agent Starting Run: bpfe9rzs with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161841-bpfe9rzs
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-603
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bpfe9rzs
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 48420.96875
wandb:  mask_ent_loss 6.92379
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.62811
wandb:     wrong_pred 0
wandb: 
wandb:  View run magic-sweep-603 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bpfe9rzs
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161841-bpfe9rzs/logs
wandb: Agent Starting Run: gc6o1bho with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161902-gc6o1bho
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fallen-sweep-604
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gc6o1bho
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 48420.96875
wandb:  mask_ent_loss 6.92379
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 0.0291
wandb:  size_std_loss -14.62811
wandb:     wrong_pred 0
wandb: 
wandb:  View run fallen-sweep-604 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gc6o1bho
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161902-gc6o1bho/logs
wandb: Agent Starting Run: yts2ys5x with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161923-yts2ys5x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stilted-sweep-605
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yts2ys5x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25072318464.0
wandb:  mask_ent_loss 6.92328
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.17832
wandb:  size_std_loss -14.00288
wandb:     wrong_pred 0
wandb: 
wandb:  View run stilted-sweep-605 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yts2ys5x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161923-yts2ys5x/logs
wandb: Agent Starting Run: k17c3734 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_161944-k17c3734
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-606
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/k17c3734
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 84
wandb:           loss 25072318464.0
wandb:  mask_ent_loss 6.92328
wandb:       num_high 1129
wandb:      pred_loss 1e-05
wandb:          score 1.9258
wandb:      size_loss 29.17832
wandb:  size_std_loss -14.00288
wandb:     wrong_pred 0
wandb: 
wandb:  View run glad-sweep-606 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/k17c3734
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_161944-k17c3734/logs
wandb: Agent Starting Run: 3p1pylk9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162004-3p1pylk9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run stoic-sweep-607
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3p1pylk9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run stoic-sweep-607 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3p1pylk9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162004-3p1pylk9/logs
wandb: Agent Starting Run: bpwp1wr9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: overall_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162025-bpwp1wr9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run earthy-sweep-608
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bpwp1wr9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2.0741621718550524e+23
wandb:  mask_ent_loss 6.90612
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.31156
wandb:  size_std_loss -1.99157
wandb:     wrong_pred 0
wandb: 
wandb:  View run earthy-sweep-608 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bpwp1wr9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162025-bpwp1wr9/logs
wandb: Agent Starting Run: 56r0jmo6 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162046-56r0jmo6
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run driven-sweep-609
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/56r0jmo6
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 10.3299
wandb:  mask_ent_loss 6.93039
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02843
wandb:  size_std_loss -7.52973
wandb:     wrong_pred 1
wandb: 
wandb:  View run driven-sweep-609 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/56r0jmo6
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162046-56r0jmo6/logs
wandb: Agent Starting Run: 7pv7waq1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162106-7pv7waq1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run avid-sweep-610
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7pv7waq1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.67095
wandb:  mask_ent_loss 6.92964
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02837
wandb:  size_std_loss -10.26302
wandb:     wrong_pred 1
wandb: 
wandb:  View run avid-sweep-610 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7pv7waq1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162106-7pv7waq1/logs
wandb: Agent Starting Run: 85ollsz9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162127-85ollsz9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run ancient-sweep-611
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/85ollsz9
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00084
wandb:  mask_ent_loss 6.91195
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02794
wandb:  size_std_loss -32.92071
wandb:     wrong_pred 1
wandb: 
wandb:  View run ancient-sweep-611 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/85ollsz9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162127-85ollsz9/logs
wandb: Agent Starting Run: g8bb4r0l with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162148-g8bb4r0l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run zany-sweep-612
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g8bb4r0l
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00017
wandb:  mask_ent_loss 6.91068
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02811
wandb:  size_std_loss -34.48748
wandb:     wrong_pred 1
wandb: 
wandb:  View run zany-sweep-612 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/g8bb4r0l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162148-g8bb4r0l/logs
wandb: Agent Starting Run: j1e1sd0j with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162209-j1e1sd0j
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run deft-sweep-613
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j1e1sd0j
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 8.23401
wandb:  mask_ent_loss 6.90832
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.85
wandb:  size_std_loss -35.556
wandb:     wrong_pred 1
wandb: 
wandb:  View run deft-sweep-613 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/j1e1sd0j
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162209-j1e1sd0j/logs
wandb: Agent Starting Run: fiuyup4d with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162231-fiuyup4d
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-614
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fiuyup4d
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00055
wandb:  mask_ent_loss 6.89344
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.6281
wandb:  size_std_loss -44.92445
wandb:     wrong_pred 1
wandb: 
wandb:  View run celestial-sweep-614 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fiuyup4d
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162231-fiuyup4d/logs
wandb: Agent Starting Run: d7exrsp2 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162252-d7exrsp2
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run celestial-sweep-615
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d7exrsp2
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00321
wandb:  mask_ent_loss 6.83036
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 30.64126
wandb:  size_std_loss -62.10868
wandb:     wrong_pred 1
wandb: 
wandb:  View run celestial-sweep-615 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d7exrsp2
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162252-d7exrsp2/logs
wandb: Agent Starting Run: 4qguueey with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162312-4qguueey
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-616
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4qguueey
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 5.45119
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 42.00103
wandb:  size_std_loss -115.84666
wandb:     wrong_pred 1
wandb: 
wandb:  View run whole-sweep-616 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/4qguueey
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162312-4qguueey/logs
wandb: Agent Starting Run: u15zrbcb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162333-u15zrbcb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run generous-sweep-617
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u15zrbcb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run generous-sweep-617 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/u15zrbcb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162333-u15zrbcb/logs
wandb: Agent Starting Run: bv9qomky with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162353-bv9qomky
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glad-sweep-618
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bv9qomky
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run glad-sweep-618 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/bv9qomky
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162353-bv9qomky/logs
wandb: Agent Starting Run: gx4cjf4l with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162415-gx4cjf4l
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run spring-sweep-619
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gx4cjf4l
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run spring-sweep-619 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/gx4cjf4l
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162415-gx4cjf4l/logs
wandb: Agent Starting Run: 7fy3ryi3 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162435-7fy3ryi3
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run desert-sweep-620
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7fy3ryi3
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.47959
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0364
wandb:  size_std_loss -45.0101
wandb:     wrong_pred 1
wandb: 
wandb:  View run desert-sweep-620 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7fy3ryi3
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162435-7fy3ryi3/logs
wandb: Agent Starting Run: cnd2esp5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162456-cnd2esp5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-621
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cnd2esp5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.04414
wandb:  mask_ent_loss 6.47913
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.34468
wandb:  size_std_loss -48.85015
wandb:     wrong_pred 1
wandb: 
wandb:  View run devout-sweep-621 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cnd2esp5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162456-cnd2esp5/logs
wandb: Agent Starting Run: wcwa6fay with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162517-wcwa6fay
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-622
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wcwa6fay
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0115
wandb:  mask_ent_loss 6.47882
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 36.32539
wandb:  size_std_loss -50.17529
wandb:     wrong_pred 1
wandb: 
wandb:  View run vague-sweep-622 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/wcwa6fay
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162517-wcwa6fay/logs
wandb: Agent Starting Run: w5xo8e2r with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162538-w5xo8e2r
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wobbly-sweep-623
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w5xo8e2r
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 10.02365
wandb:  mask_ent_loss 6.17539
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 38.66394
wandb:  size_std_loss -61.42886
wandb:     wrong_pred 1
wandb: 
wandb:  View run wobbly-sweep-623 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w5xo8e2r
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162538-w5xo8e2r/logs
wandb: Agent Starting Run: t0wto73c with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162558-t0wto73c
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run major-sweep-624
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0wto73c
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.02441
wandb:  mask_ent_loss 5.93708
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 40.15429
wandb:  size_std_loss -68.69845
wandb:     wrong_pred 1
wandb: 
wandb:  View run major-sweep-624 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t0wto73c
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162558-t0wto73c/logs
wandb: Agent Starting Run: r8n2cpkr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162619-r8n2cpkr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run denim-sweep-625
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r8n2cpkr
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.00411
wandb:  mask_ent_loss 6.92809
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.0284
wandb:  size_std_loss -13.88703
wandb:     wrong_pred 1
wandb: 
wandb:  View run denim-sweep-625 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/r8n2cpkr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162619-r8n2cpkr/logs
wandb: Agent Starting Run: zm8m3c5q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162640-zm8m3c5q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run true-sweep-626
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zm8m3c5q
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 3e-05
wandb:  mask_ent_loss 6.92526
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02846
wandb:  size_std_loss -18.76861
wandb:     wrong_pred 1
wandb: 
wandb:  View run true-sweep-626 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zm8m3c5q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162640-zm8m3c5q/logs
wandb: Agent Starting Run: w5gu33yx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162701-w5gu33yx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run radiant-sweep-627
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w5gu33yx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.012 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.012 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.82597
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.0258
wandb:  size_std_loss -61.95299
wandb:     wrong_pred 1
wandb: 
wandb:  View run radiant-sweep-627 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/w5gu33yx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162701-w5gu33yx/logs
wandb: Agent Starting Run: k1bkl868 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162723-k1bkl868
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-628
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/k1bkl868
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88286
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 0.02808
wandb:  size_std_loss -52.66178
wandb:     wrong_pred 1
wandb: 
wandb:  View run golden-sweep-628 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/k1bkl868
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162723-k1bkl868/logs
wandb: Agent Starting Run: qvsmpib5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162743-qvsmpib5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run astral-sweep-629
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qvsmpib5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.68851
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 24.2302
wandb:  size_std_loss -89.15737
wandb:     wrong_pred 1
wandb: 
wandb:  View run astral-sweep-629 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qvsmpib5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162743-qvsmpib5/logs
wandb: Agent Starting Run: 7avo1vsp with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162804-7avo1vsp
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run easy-sweep-630
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7avo1vsp
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.64448
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.67216
wandb:  size_std_loss -93.31355
wandb:     wrong_pred 1
wandb: 
wandb:  View run easy-sweep-630 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7avo1vsp
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162804-7avo1vsp/logs
wandb: Agent Starting Run: 44zlkero with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162824-44zlkero
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run snowy-sweep-631
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/44zlkero
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.63564
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.56225
wandb:  size_std_loss -94.01679
wandb:     wrong_pred 1
wandb: 
wandb:  View run snowy-sweep-631 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/44zlkero
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162824-44zlkero/logs
wandb: Agent Starting Run: d9fs9yvx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162845-d9fs9yvx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run clean-sweep-632
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d9fs9yvx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.6459
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 23.65746
wandb:  size_std_loss -92.63474
wandb:     wrong_pred 1
wandb: 
wandb:  View run clean-sweep-632 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d9fs9yvx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162845-d9fs9yvx/logs
wandb: Agent Starting Run: yi8nntt9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162906-yi8nntt9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run comic-sweep-633
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yi8nntt9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run comic-sweep-633 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yi8nntt9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162906-yi8nntt9/logs
wandb: Agent Starting Run: t836xxu4 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162927-t836xxu4
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jumping-sweep-634
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t836xxu4
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run jumping-sweep-634 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/t836xxu4
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162927-t836xxu4/logs
wandb: Agent Starting Run: 6b4fb50z with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_162948-6b4fb50z
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-635
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6b4fb50z
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run restful-sweep-635 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6b4fb50z
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_162948-6b4fb50z/logs
wandb: Agent Starting Run: fdea088q with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163009-fdea088q
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-636
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fdea088q
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02912
wandb:  size_std_loss -46.6879
wandb:     wrong_pred 0
wandb: 
wandb:  View run scarlet-sweep-636 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fdea088q
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163009-fdea088q/logs
wandb: Agent Starting Run: f2u017gl with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163030-f2u017gl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run magic-sweep-637
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/f2u017gl
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00015
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12144
wandb:  size_std_loss -46.68794
wandb:     wrong_pred 0
wandb: 
wandb:  View run magic-sweep-637 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/f2u017gl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163030-f2u017gl/logs
wandb: Agent Starting Run: ywi2ykk7 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163051-ywi2ykk7
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-638
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ywi2ykk7
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00015
wandb:  mask_ent_loss 6.88914
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.12137
wandb:  size_std_loss -46.68842
wandb:     wrong_pred 0
wandb: 
wandb:  View run dashing-sweep-638 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ywi2ykk7
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163051-ywi2ykk7/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: skgh6ta9 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163121-skgh6ta9
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run golden-sweep-639
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/skgh6ta9
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 8
wandb:           loss 0.0
wandb:  mask_ent_loss 6.88401
wandb:       num_high 87
wandb:      pred_loss 1.36578
wandb:          score 1.99293
wandb:      size_loss 28.86856
wandb:  size_std_loss -50.94912
wandb:     wrong_pred 1
wandb: 
wandb:  View run golden-sweep-639 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/skgh6ta9
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163121-skgh6ta9/logs
wandb: Agent Starting Run: mb4eciq8 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: inverse_relative_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163143-mb4eciq8
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-640
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mb4eciq8
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 2239.97949
wandb:  mask_ent_loss 6.88997
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.04052
wandb:  size_std_loss -46.67917
wandb:     wrong_pred 0
wandb: 
wandb:  View run kind-sweep-640 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/mb4eciq8
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163143-mb4eciq8/logs
wandb: Agent Starting Run: yt6udb0x with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163204-yt6udb0x
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run vague-sweep-641
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yt6udb0x
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 3.66074
wandb:  mask_ent_loss 6.93032
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02848
wandb:  size_std_loss -7.47475
wandb:     wrong_pred 0
wandb: 
wandb:  View run vague-sweep-641 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yt6udb0x
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163204-yt6udb0x/logs
wandb: Agent Starting Run: qtn4o2xb with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163224-qtn4o2xb
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run confused-sweep-642
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qtn4o2xb
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.025 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.94455
wandb:  mask_ent_loss 6.92953
wandb:       num_high 1089
wandb:      pred_loss 1e-05
wandb:          score 1.92845
wandb:      size_loss 0.02861
wandb:  size_std_loss -8.8288
wandb:     wrong_pred 0
wandb: 
wandb:  View run confused-sweep-642 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qtn4o2xb
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163224-qtn4o2xb/logs
wandb: Agent Starting Run: evulk49o with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163246-evulk49o
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run bumbling-sweep-643
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/evulk49o
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 3e-05
wandb:  mask_ent_loss 6.9075
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.0279
wandb:  size_std_loss -36.37903
wandb:     wrong_pred 1
wandb: 
wandb:  View run bumbling-sweep-643 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/evulk49o
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163246-evulk49o/logs
wandb: Agent Starting Run: fye96vnh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163307-fye96vnh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run crisp-sweep-644
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fye96vnh
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0
wandb:  mask_ent_loss 6.89742
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 0.02778
wandb:  size_std_loss -43.06397
wandb:     wrong_pred 1
wandb: 
wandb:  View run crisp-sweep-644 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fye96vnh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163307-fye96vnh/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ma062x94 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163336-ma062x94
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run polar-sweep-645
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ma062x94
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.005 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: | 0.005 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.0028
wandb:  mask_ent_loss 6.89752
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.94077
wandb:  size_std_loss -43.62224
wandb:     wrong_pred 1
wandb: 
wandb:  View run polar-sweep-645 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ma062x94
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163336-ma062x94/logs
wandb: Agent Starting Run: def233lc with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163357-def233lc
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run glamorous-sweep-646
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/def233lc
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.00406
wandb:  mask_ent_loss 6.89712
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.72449
wandb:  size_std_loss -43.03402
wandb:     wrong_pred 1
wandb: 
wandb:  View run glamorous-sweep-646 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/def233lc
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163357-def233lc/logs
wandb: Agent Starting Run: fu30mwyw with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163418-fu30mwyw
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run devout-sweep-647
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fu30mwyw
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 79
wandb:           loss 0.3825
wandb:  mask_ent_loss 6.87714
wandb:       num_high 1045
wandb:      pred_loss 1.12945
wandb:          score 1.93021
wandb:      size_loss 27.7072
wandb:  size_std_loss -54.43984
wandb:     wrong_pred 1
wandb: 
wandb:  View run devout-sweep-647 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fu30mwyw
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163418-fu30mwyw/logs
wandb: Agent Starting Run: cja7q3ru with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163439-cja7q3ru
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run noble-sweep-648
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cja7q3ru
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 80
wandb:           loss 6.5746
wandb:  mask_ent_loss 6.46438
wandb:       num_high 1046
wandb:      pred_loss 1.12945
wandb:          score 1.92933
wandb:      size_loss 36.28569
wandb:  size_std_loss -59.76133
wandb:     wrong_pred 1
wandb: 
wandb:  View run noble-sweep-648 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/cja7q3ru
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163439-cja7q3ru/logs
wandb: Agent Starting Run: kir5uss1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163500-kir5uss1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-649
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kir5uss1
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run colorful-sweep-649 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/kir5uss1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163500-kir5uss1/logs
wandb: Agent Starting Run: ca7tz6ne with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163520-ca7tz6ne
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-650
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ca7tz6ne
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run charmed-sweep-650 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ca7tz6ne
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163520-ca7tz6ne/logs
wandb: Agent Starting Run: ebshuyun with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163541-ebshuyun
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run happy-sweep-651
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ebshuyun
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run happy-sweep-651 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ebshuyun
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163541-ebshuyun/logs
wandb: Agent Starting Run: jieynnfm with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163602-jieynnfm
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run whole-sweep-652
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jieynnfm
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.04261
wandb:  size_std_loss -69.78493
wandb:     wrong_pred 0
wandb: 
wandb:  View run whole-sweep-652 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/jieynnfm
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163602-jieynnfm/logs
wandb: Agent Starting Run: yq7nyu01 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163623-yq7nyu01
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run pretty-sweep-653
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yq7nyu01
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78491
wandb:     wrong_pred 0
wandb: 
wandb:  View run pretty-sweep-653 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/yq7nyu01
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163623-yq7nyu01/logs
wandb: Agent Starting Run: 5r6cek7e with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163643-5r6cek7e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run neat-sweep-654
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5r6cek7e
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.0
wandb:  mask_ent_loss 5.49448
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.6054
wandb:  size_std_loss -69.78484
wandb:     wrong_pred 0
wandb: 
wandb:  View run neat-sweep-654 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/5r6cek7e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163643-5r6cek7e/logs
wandb: Agent Starting Run: ldxg0lty with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163704-ldxg0lty
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run legendary-sweep-655
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ldxg0lty
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 5.26525
wandb:  mask_ent_loss 5.50963
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 42.59383
wandb:  size_std_loss -64.90524
wandb:     wrong_pred 0
wandb: 
wandb:  View run legendary-sweep-655 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ldxg0lty
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163704-ldxg0lty/logs
wandb: Agent Starting Run: 90h495au with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: domain_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163725-90h495au
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dashing-sweep-656
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/90h495au
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.51527
wandb:  mask_ent_loss 5.02908
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 44.74141
wandb:  size_std_loss -68.89646
wandb:     wrong_pred 0
wandb: 
wandb:  View run dashing-sweep-656 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/90h495au
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163725-90h495au/logs
wandb: Agent Starting Run: lf4u9hsn with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163746-lf4u9hsn
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run restful-sweep-657
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/lf4u9hsn
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02476
wandb:  mask_ent_loss 6.92377
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.0292
wandb:  size_std_loss -12.49782
wandb:     wrong_pred 0
wandb: 
wandb:  View run restful-sweep-657 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/lf4u9hsn
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163746-lf4u9hsn/logs
wandb: Agent Starting Run: rgel89bj with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: - Waiting for wandb.init()...wandb: \ Waiting for wandb.init()...wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163811-rgel89bj
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run charmed-sweep-658
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rgel89bj
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02233
wandb:  mask_ent_loss 6.92376
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02919
wandb:  size_std_loss -12.60109
wandb:     wrong_pred 0
wandb: 
wandb:  View run charmed-sweep-658 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/rgel89bj
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163811-rgel89bj/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: ymbl4hju with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163841-ymbl4hju
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run olive-sweep-659
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ymbl4hju
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00027
wandb:  mask_ent_loss 6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02909
wandb:  size_std_loss -33.60466
wandb:     wrong_pred 0
wandb: 
wandb:  View run olive-sweep-659 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/ymbl4hju
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163841-ymbl4hju/logs
wandb: Agent Starting Run: 3h56qg1t with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163901-3h56qg1t
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lively-sweep-660
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3h56qg1t
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.00027
wandb:  mask_ent_loss 6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02909
wandb:  size_std_loss -33.60461
wandb:     wrong_pred 0
wandb: 
wandb:  View run lively-sweep-660 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/3h56qg1t
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163901-3h56qg1t/logs
wandb: Agent Starting Run: owvaucog with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163924-owvaucog
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run colorful-sweep-661
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/owvaucog
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 69.19694
wandb:  mask_ent_loss 6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08693
wandb:  size_std_loss -33.60408
wandb:     wrong_pred 0
wandb: 
wandb:  View run colorful-sweep-661 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/owvaucog
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163924-owvaucog/logs
wandb: Agent Starting Run: d8sv5loh with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_163945-d8sv5loh
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run floral-sweep-662
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d8sv5loh
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 69.19694
wandb:  mask_ent_loss 6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08693
wandb:  size_std_loss -33.60408
wandb:     wrong_pred 0
wandb: 
wandb:  View run floral-sweep-662 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/d8sv5loh
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_163945-d8sv5loh/logs
wandb: Agent Starting Run: 8ca1v9u1 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164006-8ca1v9u1
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run rich-sweep-663
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8ca1v9u1
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1139169408.0
wandb:  mask_ent_loss 6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08693
wandb:  size_std_loss -33.60408
wandb:     wrong_pred 0
wandb: 
wandb:  View run rich-sweep-663 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8ca1v9u1
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164006-8ca1v9u1/logs
wandb: Agent Starting Run: 8g8b859b with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164026-8g8b859b
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-sweep-664
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8g8b859b
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 1139169408.0
wandb:  mask_ent_loss 6.9078
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 29.08693
wandb:  size_std_loss -33.60408
wandb:     wrong_pred 0
wandb: 
wandb:  View run worldly-sweep-664 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/8g8b859b
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164026-8g8b859b/logs
wandb: Agent Starting Run: euiucf0e with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164047-euiucf0e
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run summer-sweep-665
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/euiucf0e
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.08054
wandb:  mask_ent_loss 6.92888
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02855
wandb:  size_std_loss -11.3227
wandb:     wrong_pred 0
wandb: 
wandb:  View run summer-sweep-665 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/euiucf0e
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164047-euiucf0e/logs
wandb: Agent Starting Run: hib26mr5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164108-hib26mr5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run scarlet-sweep-666
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hib26mr5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 0.02047
wandb:  mask_ent_loss 6.92836
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.02853
wandb:  size_std_loss -12.69183
wandb:     wrong_pred 0
wandb: 
wandb:  View run scarlet-sweep-666 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/hib26mr5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164108-hib26mr5/logs
wandb: Agent Starting Run: fabiac47 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164129-fabiac47
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run jolly-sweep-667
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fabiac47
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 96.91658
wandb:  mask_ent_loss 6.88422
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03082
wandb:  size_std_loss -20.8041
wandb:     wrong_pred 0
wandb: 
wandb:  View run jolly-sweep-667 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/fabiac47
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164129-fabiac47/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: opf8hfit with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164200-opf8hfit
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-668
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/opf8hfit
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.023 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 96.94469
wandb:  mask_ent_loss 6.88422
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 0.03082
wandb:  size_std_loss -20.8038
wandb:     wrong_pred 0
wandb: 
wandb:  View run wise-sweep-668 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/opf8hfit
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164200-opf8hfit/logs
wandb: Agent Starting Run: 6lkqssaf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164221-6lkqssaf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lemon-sweep-669
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6lkqssaf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: | 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: / 0.004 MB of 0.022 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 230115792.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run lemon-sweep-669 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/6lkqssaf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164221-6lkqssaf/logs
wandb: Sweep Agent: Waiting for job.
wandb: Job received.
wandb: Agent Starting Run: 42jdskff with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164251-42jdskff
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run wise-sweep-670
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/42jdskff
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 230115792.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run wise-sweep-670 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/42jdskff
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164251-42jdskff/logs
wandb: Agent Starting Run: zde4xvpf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164313-zde4xvpf
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run grateful-sweep-671
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zde4xvpf
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.025 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3788326779748352.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run grateful-sweep-671 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/zde4xvpf
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164313-zde4xvpf/logs
wandb: Agent Starting Run: 7n8l2kc5 with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: False
wandb: 	break_on_number_of_high: True
wandb: 	dataset_name: aifb
wandb: 	ent: 10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: range_frequency
wandb: 	kill_type: True
wandb: 	lr: 0.01
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164333-7n8l2kc5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run dauntless-sweep-672
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7n8l2kc5
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 87
wandb:           loss 3788326779748352.0
wandb:  mask_ent_loss 6.88261
wandb:       num_high 1132
wandb:      pred_loss 1e-05
wandb:          score 1.92314
wandb:      size_loss 30.87881
wandb:  size_std_loss -20.35363
wandb:     wrong_pred 0
wandb: 
wandb:  View run dauntless-sweep-672 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/7n8l2kc5
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164333-7n8l2kc5/logs
wandb: Agent Starting Run: s94g07xi with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: True
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164355-s94g07xi
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run northern-sweep-673
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s94g07xi
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92613
wandb:       num_high 42
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.02748
wandb:  size_std_loss -8.25222
wandb:     wrong_pred 0
wandb: 
wandb:  View run northern-sweep-673 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/s94g07xi
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164355-s94g07xi/logs
wandb: Agent Starting Run: m1x05wuo with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: True
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164416-m1x05wuo
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fearless-sweep-674
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m1x05wuo
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.024 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 4
wandb:           loss 0.0
wandb:  mask_ent_loss -6.92613
wandb:       num_high 42
wandb:      pred_loss 1.33844
wandb:          score 1.99647
wandb:      size_loss 0.02748
wandb:  size_std_loss -8.25216
wandb:     wrong_pred 0
wandb: 
wandb:  View run fearless-sweep-674 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/m1x05wuo
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164416-m1x05wuo/logs
wandb: Agent Starting Run: x7x306xx with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: True
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.9
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164436-x7x306xx
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run smooth-sweep-675
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x7x306xx
wandb: Waiting for W&B process to finish... (success).
wandb: - 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: \ 0.004 MB of 0.004 MB uploaded (0.000 MB deduped)wandb: 
wandb: Run summary:
wandb: len mask > 0.5 40
wandb:           loss 0.0
wandb:  mask_ent_loss -6.82366
wandb:       num_high 494
wandb:      pred_loss 0.56427
wandb:          score 1.96466
wandb:      size_loss 0.02922
wandb:  size_std_loss -76.63004
wandb:     wrong_pred 0
wandb: 
wandb:  View run smooth-sweep-675 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/x7x306xx
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164436-x7x306xx/logs
wandb: Agent Starting Run: qtd2e8kr with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: True
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 5e-05
wandb: 	threshold: 0.5
wandb: 	type: 10
wandb: 	weight_decay: 0.1
wandb: wandb version 0.15.4 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.0
wandb: Run data is saved locally in /home/tliberatore/RGCN-Explainer/RGCN_stuff/wandb/run-20230614_164457-qtd2e8kr
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run kind-sweep-676
wandb:  View project at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757
wandb:  View sweep at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/sweeps/rg3hyigg
wandb:  View run at https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qtd2e8kr
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run summary:
wandb: len mask > 0.5 81
wandb:           loss 0.0
wandb:  mask_ent_loss -6.10227
wandb:       num_high 1049
wandb:      pred_loss 3e-05
wandb:          score 1.92845
wandb:      size_loss 0.03713
wandb:  size_std_loss -130.46294
wandb:     wrong_pred 0
wandb: 
wandb:  View run kind-sweep-676 at: https://wandb.ai/t-liberatore/RGCNExplainer_aifb_5757/runs/qtd2e8kr
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)
wandb: Find logs at: ./wandb/run-20230614_164457-qtd2e8kr/logs
wandb: Agent Starting Run: cn8w4orf with config:
wandb: 	adaptive: False
wandb: 	break_if_wrong_pred: True
wandb: 	break_on_number_of_high: False
wandb: 	dataset_name: aifb
wandb: 	ent: -10
wandb: 	epochs: 30
wandb: 	explain_all: False
wandb: 	hops: 2
wandb: 	init_strategy: normal
wandb: 	kill_type: True
wandb: 	lr: 0.1
wandb: 	pred: 1
wandb: 	print: False
wandb: 	prune: True
wandb: 	relation_id: 39
wandb: 	size: 0.05
wandb: 	threshold: 0.5
wandb: 	type: 1
wandb: 	weight_decay: 0.9
slurmstepd: error: *** JOB 11918882 ON r29n2 CANCELLED AT 2023-06-14T16:45:22 DUE TO TIME LIMIT ***
