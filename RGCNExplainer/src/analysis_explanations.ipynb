{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import src.kgbench as kg\n",
    "\n",
    "\n",
    "from kgbench import load, tic, toc, d\n",
    "\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_columns_with_non_zero_values(df):\n",
    "    ''' Keep only columns with non-zero values'''\n",
    "\n",
    "    df = df.fillna(0)\n",
    "    # Get the column names with non-zero values\n",
    "    non_zero_columns = df.columns[df.astype(bool).any(axis=0)]\n",
    "\n",
    "    # Create a new DataFrame with only the columns containing non-zero values\n",
    "    modified_df = df[non_zero_columns]\n",
    "\n",
    "    return modified_df\n",
    "\n",
    "\n",
    "def accuracy_func(df, comparison='prediction_full'):\n",
    "    ''' Compute per class accuracy\n",
    "    Args:\n",
    "        df: dataframe containing the results of the experiments\n",
    "        comparison: full, explain, explain binary, inverse\n",
    "        binary: True if binary explanation is considered, False otherwise\n",
    "        inverse: True if inverse explanation is considered, False otherwise\n",
    "        overall: True if overall accuracy is considered, False otherwise    \n",
    "    '''\n",
    "    mismatch, matc = {}, {}\n",
    "    match_count, mismatch_count = 0, 0\n",
    "\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "\n",
    "        c = np.argmax([float(num) for num in row[comparison][1:-1].split()])\n",
    "\n",
    "        #original = int(row['label'])\n",
    "        original = np.argmax(row['prediction_full'][1:-1].split())\n",
    "\n",
    "        match_count, mismatch_count = (match_count + 1, mismatch_count) if original == c else (match_count, mismatch_count + 1)\n",
    "        match_dict = matc if original == c else mismatch\n",
    "        match_dict.setdefault(original, []).append(index)\n",
    "\n",
    "\n",
    "    #labels = [int(i) for i in set(df['label'])]\n",
    "    labels = [np.argmax([float(num) for num in row['prediction_full'][1:-1].split()]) for index, row in df.iterrows()]\n",
    "\n",
    "    accuracy = {i: len(matc[i]) / (len(matc[i]) + len(mismatch[i])) if i in mismatch.keys() and i in matc.keys() else (1 if i not in mismatch.keys() else 0) for i in labels}\n",
    "    #accuracy = {key: value for key, value in accuracy.items()}\n",
    "    accuracy = dict(sorted(accuracy.items()))\n",
    "\n",
    "\n",
    "    accuracy = list(accuracy.values())\n",
    "\n",
    "    return mismatch, matc, accuracy\n",
    "\n",
    "def fidelity(df, modality ,comparison_minus=None, comparison_inverse=None):\n",
    "    ''' Compute fidelity as defined in the paper\n",
    "    Args:\n",
    "        df: dataframe containing the results of the experiments\n",
    "         modality: minus or plus depending on the type of fidelity to compute\n",
    "    '''\n",
    "\n",
    "    mismatch_f, matc_f, accuracy_f = accuracy_func(df, comparison ='prediction_full')\n",
    "    if modality == 'minus':\n",
    "        mismatch_e, matc_e, accuracy_e = accuracy_func(df, comparison=comparison_minus)\n",
    "        fidelity = {i: accuracy_f[i] - accuracy_e[i] for i in range(len(accuracy_f))}\n",
    "        fidelity = {key: value for key, value in fidelity.items()}\n",
    "        fidelity = dict(sorted(fidelity.items()))\n",
    "    if modality == 'plus':\n",
    "        mismatch_e, matc_e, accuracy_e = accuracy_func(df, comparison=comparison_inverse)\n",
    "        fidelity = {i: accuracy_f[i] - accuracy_e[i] for i in range(len(accuracy_f))}\n",
    "        fidelity = {key: value for key, value in fidelity.items()}\n",
    "        fidelity = dict(sorted(fidelity.items()))\n",
    "\n",
    "    return fidelity\n",
    "\n",
    "\n",
    "def result_table_norel_int(path):\n",
    "    d = pd.read_csv(path+'/Relations_Important_full_threshold.csv', sep=',')\n",
    "    d.set_index('node_idx', inplace=True)\n",
    "    d['label'] = d['label'].apply(lambda x: int(x[1]))\n",
    "\n",
    "    fidelity_plus_threshold = np.round(list(fidelity(d, modality = 'plus', comparison_inverse= 'res_threshold_lekker_inverse').values()),3)\n",
    "    fidelity_minus_threshold = np.round(list(fidelity(d, modality = 'minus', comparison_minus = 'prediction_threshold_lekker').values()),3)\n",
    "    df = pd.DataFrame()\n",
    "    sparsity = np.round(d.groupby('label')['sparsity_threshold'].mean(),3)\n",
    "    df['Sparsity'] = sparsity\n",
    "    df['Fidelity- '] = 1 - fidelity_minus_threshold\n",
    "    df['Fidelity+ '] = fidelity_plus_threshold\n",
    "\n",
    "\n",
    "    fidelity_plus_random = np.round(list(fidelity(d, modality = 'plus', comparison_inverse= 'res_random_inverse').values()),3)\n",
    "    fidelity_minus_random = np.round(list(fidelity(d, modality = 'minus', comparison_minus = 'prediction_random').values()),3)\n",
    "    df['Fidelity- Random'] = 1 - fidelity_minus_random\n",
    "    df['Fidelity+ Random'] = fidelity_plus_random\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    table = df.to_latex(index=True, caption = path.split('/')[-2].replace('_','-'), label = path.split('/')[-2].replace('_','-'),column_format='|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|')\n",
    "    latex_table = table.replace('\\\\midrule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\toprule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\bottomrule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\begin{tabular}', '\\\\begin{adjustbox}{scale=0.5}\\\\begin{tabular}')  # Add scaling parameter\n",
    "    latex_table = latex_table.replace('\\\\end{tabular}', '\\\\end{tabular}\\\\end{adjustbox}')  # Close the adjustbox environment\n",
    "    return latex_table\n",
    "\n",
    "def metrics(path):\n",
    "    d = pd.read_csv(path+'/Relations_Important_full_threshold.csv', sep=',')\n",
    "\n",
    "\n",
    "    fidelity_plus_threshold = np.round(np.round(list(fidelity(d, modality = 'plus', comparison_inverse= 'res_threshold_lekker_inverse').values()),3).mean(),3)\n",
    "    fidelity_minus_threshold = np.round(1-np.round(list(fidelity(d, modality = 'minus', comparison_minus = 'prediction_threshold_lekker').values()),3).mean(),3)\n",
    "    sparsity = np.round(d['sparsity_threshold'].mean(),3)\n",
    "\n",
    "\n",
    "    fidelity_plus_random = np.round(np.round(list(fidelity(d, modality = 'plus', comparison_inverse= 'res_random_inverse').values()),3).mean(),3)\n",
    "    fidelity_minus_random = np.round((1-np.round(list(fidelity(d, modality = 'minus', comparison_minus = 'prediction_random').values()),3)).mean(),3)\n",
    "\n",
    "    score = sparsity + fidelity_plus_threshold + fidelity_minus_threshold \n",
    "    \n",
    "    return score, sparsity, fidelity_minus_threshold, fidelity_plus_threshold, fidelity_minus_random, fidelity_plus_random\n",
    "\n",
    "def table_metrics_overview(name, exp):\n",
    "    init = ['normal','const','overall_frequency','relative_frequency','inverse_relative_frequency','domain_frequency','range_frequency']\n",
    "    #init = ['normal','overall_frequency','relative_frequency','domain_frequency']\n",
    "    df = pd.DataFrame(columns = ['init','Score','Sparsity', 'Fidelity-', 'Fidelity+', 'Fidelity- random', 'Fidelity+ random'])\n",
    "    for i in init:\n",
    "        #m = metrics(f'chk/{name}_chk/exp/init_{i}_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance')\n",
    "        m = metrics(f'chk/{name}_chk/exp/init_{i}_{exp}/Relation_Importance')\n",
    "        df.loc[len(df)] = [i] + list(m)\n",
    "    df.set_index('init', inplace=True)\n",
    "    table = df.to_latex(index=True, caption = name, label = name,column_format='|c|c|c|c|c|c|c|')\n",
    "    latex_table = table.replace('\\\\midrule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\toprule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\bottomrule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\begin{tabular}', '\\\\begin{adjustbox}{scale=0.5}\\\\begin{tabular}')  # Add scaling parameter\n",
    "    latex_table = latex_table.replace('\\\\end{tabular}', '\\\\end{tabular}\\\\end{adjustbox}')  # Close the adjustbox environment\n",
    "    print(latex_table)\n",
    "    return latex_table\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#STAT TESTS\n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "def anova_relations(path,relations):\n",
    "    ''' Perform ANOVA test to check if relations have significantly different frequencies between classes\n",
    "    '''\n",
    "\n",
    "    d = pd.read_csv(path+'/Relations_Important_full_threshold.csv', sep=',')\n",
    "\n",
    "    df = d[relations]\n",
    "\n",
    "    #df['label'] = d['label'].apply(lambda x: int(x[1]))\n",
    "    df.loc[:, 'label'] = d['label'].apply(lambda x: int(x[1])).values\n",
    "\n",
    "    df = df.groupby('label', as_index=False).mean()\n",
    "    #df = keep_columns_with_non_zero_values(df)\n",
    "    data = df.to_dict()\n",
    "\n",
    "    classes = sorted(set(data['label'].values()))\n",
    "    relation_freq_lists = {relation: [data[relation][i] for i in classes] for relation in data if relation != 'label'}\n",
    "\n",
    "    # Perform the ANOVA test\n",
    "    anova_results = {}\n",
    "    for relation, freq_list in relation_freq_lists.items():\n",
    "        anova_result = f_oneway(*[freq_list for _ in classes])\n",
    "        anova_results[relation] = anova_result\n",
    "\n",
    "    # Extract p-values from the ANOVA results\n",
    "    p_values = {relation: result.pvalue for relation, result in anova_results.items()}\n",
    "\n",
    "    # Define the significance level\n",
    "    alpha = 0.9\n",
    "\n",
    "    # Identify relations that have significantly different frequencies between classes\n",
    "    significant_relations = [relation for relation, p_value in p_values.items() if p_value < alpha]\n",
    "\n",
    "    # Print the results\n",
    "    for relation in relation_freq_lists:\n",
    "        if relation in significant_relations:\n",
    "            print(f\"The relation '{relation}' has significantly different frequencies between classes.\")\n",
    "        else:\n",
    "            #print(f\"The relation '{relation}' does not have significantly different frequencies between classes.\")\n",
    "            #print(f'{relation} not significant')\n",
    "            pass\n",
    "\n",
    "\n",
    "def anova_relations_inits(name):\n",
    "    init = ['normal','const','overall_frequency','relative_frequency','inverse_relative_frequency','domain_frequency','range_frequency']\n",
    "\n",
    "    for i in init:\n",
    "        print(i)\n",
    "        m = anova_relations(f'chk/{name}_chk/exp/init_{i}_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data mdgenre (70.49s).\n",
      "rel: 154 ent: 349344 triples: torch.Size([1252247, 3])\n",
      "training torch.Size([4863, 2]) withheld torch.Size([500, 2])\n"
     ]
    }
   ],
   "source": [
    "from src.rgcn_explainer_utils import *\n",
    "name = 'mdgenre'\n",
    "if name in ['aifb', 'mutag', 'bgs', 'am', 'mdgenre']:\n",
    "    data = kg.load(name, torch=True, final=False)\n",
    "if 'IMDb' in name:    \n",
    "    data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "if 'dbo' in name:\n",
    "    data = torch.load(f'data/DBO/finals/{name}.pt')\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)\n",
    "print('rel:', data.num_relations, 'ent:', data.num_entities, 'triples:', data.triples.shape)\n",
    "print('training', data.training.shape, 'withheld', data.withheld.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'chk/mdgenre_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance/Relations_Important_full_threshold.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[170], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmutag\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m      5\u001b[0m     exp \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mhops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m----> 6\u001b[0m table_metrics_overview(name, exp)\n",
      "Cell \u001b[0;32mIn[137], line 125\u001b[0m, in \u001b[0;36mtable_metrics_overview\u001b[0;34m(name, exp)\u001b[0m\n\u001b[1;32m    122\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(columns \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39minit\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mScore\u001b[39m\u001b[39m'\u001b[39m,\u001b[39m'\u001b[39m\u001b[39mSparsity\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFidelity-\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFidelity+\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFidelity- random\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mFidelity+ random\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    123\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m init:\n\u001b[1;32m    124\u001b[0m     \u001b[39m#m = metrics(f'chk/{name}_chk/exp/init_{i}_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance')\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     m \u001b[39m=\u001b[39m metrics(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mchk/\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m_chk/exp/init_\u001b[39;49m\u001b[39m{\u001b[39;49;00mi\u001b[39m}\u001b[39;49;00m\u001b[39m_\u001b[39;49m\u001b[39m{\u001b[39;49;00mexp\u001b[39m}\u001b[39;49;00m\u001b[39m/Relation_Importance\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    126\u001b[0m     df\u001b[39m.\u001b[39mloc[\u001b[39mlen\u001b[39m(df)] \u001b[39m=\u001b[39m [i] \u001b[39m+\u001b[39m \u001b[39mlist\u001b[39m(m)\n\u001b[1;32m    127\u001b[0m df\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39minit\u001b[39m\u001b[39m'\u001b[39m, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "Cell \u001b[0;32mIn[137], line 104\u001b[0m, in \u001b[0;36mmetrics\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmetrics\u001b[39m(path):\n\u001b[0;32m--> 104\u001b[0m     d \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(path\u001b[39m+\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m/Relations_Important_full_threshold.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m,\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    107\u001b[0m     fidelity_plus_threshold \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(np\u001b[39m.\u001b[39mround(\u001b[39mlist\u001b[39m(fidelity(d, modality \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplus\u001b[39m\u001b[39m'\u001b[39m, comparison_inverse\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mres_threshold_lekker_inverse\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mvalues()),\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mmean(),\u001b[39m3\u001b[39m)\n\u001b[1;32m    108\u001b[0m     fidelity_minus_threshold \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(\u001b[39m1\u001b[39m\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mround(\u001b[39mlist\u001b[39m(fidelity(d, modality \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mminus\u001b[39m\u001b[39m'\u001b[39m, comparison_minus \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mprediction_threshold_lekker\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mvalues()),\u001b[39m3\u001b[39m)\u001b[39m.\u001b[39mmean(),\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:678\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    663\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    664\u001b[0m     dialect,\n\u001b[1;32m    665\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    674\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    675\u001b[0m )\n\u001b[1;32m    676\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 678\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:932\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    931\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1216\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1212\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1213\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1214\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1215\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1216\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1217\u001b[0m     f,\n\u001b[1;32m   1218\u001b[0m     mode,\n\u001b[1;32m   1219\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1220\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1221\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1222\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1223\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1224\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1225\u001b[0m )\n\u001b[1;32m   1226\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    787\u001b[0m             handle,\n\u001b[1;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    792\u001b[0m         )\n\u001b[1;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'chk/mdgenre_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance/Relations_Important_full_threshold.csv'"
     ]
    }
   ],
   "source": [
    "#ALl initializations\n",
    "if name=='aifb':\n",
    "    exp = 'hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no'\n",
    "if name == 'mutag':\n",
    "    exp = 'hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no'\n",
    "table_metrics_overview(name, exp)\n",
    "\n",
    "#anova_relations_inits(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{init-range-frequency-hops-2-lr-0.5-adaptive-False-size-0.005-sizestd-adaptive-ent-10-type-1-killtype-True-break-no}\n",
      "\\label{init-range-frequency-hops-2-lr-0.5-adaptive-False-size-0.005-sizestd-adaptive-ent-10-type-1-killtype-True-break-no}\n",
      "\\begin{adjustbox}{scale=0.5}\\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "{} &  Sparsity &  Fidelity-  &  Fidelity+  &  Fidelity- Random &  Fidelity+ Random \\\\\n",
      "label &           &             &             &                   &                   \\\\\n",
      "\\hline\n",
      "0     &     0.378 &           1 &       0.099 &             0.975 &             0.006 \\\\\n",
      "1     &     0.180 &           1 &       0.921 &             0.955 &             0.910 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_89370/4231652731.py:95: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  table = df.to_latex(index=True, caption = path.split('/')[-2].replace('_','-'), label = path.split('/')[-2].replace('_','-'),column_format='|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|')\n"
     ]
    }
   ],
   "source": [
    "init = 'normal'\n",
    "path = f'chk/{name}_chk/exp/init_{init}_{exp}/Relation_Importance'\n",
    "path = 'chk/dbo_gender_chk/exp/init_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_False_break_no/Relation_Importance'\n",
    "path = 'chk/dbo_gender_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "\n",
    "path = 'chk/dbo_gender_chk/exp/init_overall_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "path = 'chk/dbo_gender_chk/exp/init_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_False_break_no/Relation_Importance'\n",
    "path = 'chk/dbo_gender_chk/exp/init_domain_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "#path = 'chk/dbo_gender_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "#path = 'chk/dbo_gender_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.0005_sizestd_adaptive_ent_1_type_1_killtype_False_break_no/Relation_Importance'\n",
    "path = 'chk/dbo_gender_chk/exp/init_range_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "print(result_table_norel_int(path) )\n",
    "#print(anova_relations(path,relations) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{dbo_gender}\n",
      "\\label{dbo_gender}\n",
      "\\begin{adjustbox}{scale=0.5}\\begin{tabular}{|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "{} &  Score &  Sparsity &  Fidelity- &  Fidelity+ &  Fidelity- random &  Fidelity+ random \\\\\n",
      "init                       &        &           &            &            &                   &                   \\\\\n",
      "\\hline\n",
      "normal                     &  1.836 &     0.805 &      1.000 &      0.031 &             0.568 &             0.037 \\\\\n",
      "overall\\_frequency          &  1.792 &     0.287 &      1.000 &      0.505 &             0.954 &             0.447 \\\\\n",
      "relative\\_frequency         &  1.580 &     0.602 &      0.736 &      0.242 &             0.742 &             0.242 \\\\\n",
      "inverse\\_relative\\_frequency &  1.789 &     0.284 &      1.000 &      0.505 &             0.960 &             0.452 \\\\\n",
      "domain\\_frequency           &  1.817 &     0.329 &      0.989 &      0.499 &             0.948 &             0.447 \\\\\n",
      "range\\_frequency            &  1.799 &     0.289 &      1.000 &      0.510 &             0.965 &             0.458 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_89370/1777732654.py:16: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  table = df.to_latex(index=True, caption = name, label = name,column_format='|c|c|c|c|c|c|c|')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "init = ['normal','overall_frequency','relative_frequency','inverse_relative_frequency','domain_frequency','range_frequency']\n",
    "paths = ['chk/dbo_gender_chk/exp/init_normal_hops_2_lr_0.1_adaptive_False_size_0.0005_sizestd_adaptive_ent_1_type_1_killtype_False_break_no/Relation_Importance',\n",
    "        'chk/dbo_gender_chk/exp/init_overall_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance',\n",
    "         'chk/dbo_gender_chk/exp/init_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_False_break_no/Relation_Importance',\n",
    "         'chk/dbo_gender_chk/exp/init_inverse_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance',\n",
    "         'chk/dbo_gender_chk/exp/init_domain_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance',\n",
    "         'chk/dbo_gender_chk/exp/init_range_frequency_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "         \n",
    "             ]\n",
    "df = pd.DataFrame(columns = ['init','Score','Sparsity', 'Fidelity-', 'Fidelity+', 'Fidelity- random', 'Fidelity+ random'])\n",
    "for i,j in zip(init,paths):\n",
    "    #m = metrics(f'chk/{name}_chk/exp/init_{i}_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance')\n",
    "    m = metrics(j)\n",
    "    df.loc[len(df)] = [i] + list(m)\n",
    "df.set_index('init', inplace=True)\n",
    "table = df.to_latex(index=True, caption = name, label = name,column_format='|c|c|c|c|c|c|c|')\n",
    "latex_table = table.replace('\\\\midrule', '\\\\hline')\n",
    "latex_table = latex_table.replace('\\\\toprule', '\\\\hline')\n",
    "latex_table = latex_table.replace('\\\\bottomrule', '\\\\hline')\n",
    "latex_table = latex_table.replace('\\\\begin{tabular}', '\\\\begin{adjustbox}{scale=0.5}\\\\begin{tabular}')  # Add scaling parameter\n",
    "latex_table = latex_table.replace('\\\\end{tabular}', '\\\\end{tabular}\\\\end{adjustbox}')  # Close the adjustbox environment\n",
    "print(latex_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of values (8) does not match length of index (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[171], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mchk/mdgenre_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39m#path = 'chk/dbo_gender_chk/exp/init_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_False_break_no/Relation_Importance'\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mprint\u001b[39m(result_table_norel_int(path) )\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(anova_relations(path,relations) )\n",
      "Cell \u001b[0;32mIn[137], line 83\u001b[0m, in \u001b[0;36mresult_table_norel_int\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     81\u001b[0m sparsity \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(d\u001b[39m.\u001b[39mgroupby(\u001b[39m'\u001b[39m\u001b[39mlabel\u001b[39m\u001b[39m'\u001b[39m)[\u001b[39m'\u001b[39m\u001b[39msparsity_threshold\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mmean(),\u001b[39m3\u001b[39m)\n\u001b[1;32m     82\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mSparsity\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sparsity\n\u001b[0;32m---> 83\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mFidelity- \u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m \u001b[39m-\u001b[39m fidelity_minus_threshold\n\u001b[1;32m     84\u001b[0m df[\u001b[39m'\u001b[39m\u001b[39mFidelity+ \u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m fidelity_plus_threshold\n\u001b[1;32m     87\u001b[0m fidelity_plus_random \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mround(\u001b[39mlist\u001b[39m(fidelity(d, modality \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mplus\u001b[39m\u001b[39m'\u001b[39m, comparison_inverse\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mres_random_inverse\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mvalues()),\u001b[39m3\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/core/frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/core/frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3823\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   3825\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[1;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[1;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   3838\u001b[0m     ):\n\u001b[1;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/core/frame.py:4538\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4535\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[1;32m   4537\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m-> 4538\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[1;32m   4539\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/pandas/core/common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[0;34m(data, index)\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[1;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[0;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    562\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Length of values (8) does not match length of index (3)"
     ]
    }
   ],
   "source": [
    "init = 'overall_frequency'\n",
    "path = 'chk/mdgenre_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "#path = 'chk/dbo_gender_chk/exp/init_relative_frequency_hops_2_lr_0.5_adaptive_False_size_0.0005_sizestd_adaptive_ent_10_type_1_killtype_False_break_no/Relation_Importance'\n",
    "print(result_table_norel_int(path) )\n",
    "print(anova_relations(path,relations) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\caption{init-normal-hops-2-lr-0.5-adaptive-False-size-0.005-sizestd-adaptive-ent-10-type-1-killtype-True-break-no}\n",
      "\\label{init-normal-hops-2-lr-0.5-adaptive-False-size-0.005-sizestd-adaptive-ent-10-type-1-killtype-True-break-no}\n",
      "\\begin{adjustbox}{scale=0.5}\\begin{tabular}{|c|m{3cm}|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}\n",
      "\\hline\n",
      "{} &  Sparsity &  Fidelity- &  Fidelity+ &  Fidelity- Random &  Fidelity+ Random \\\\\n",
      "label &           &            &            &                   &                   \\\\\n",
      "\\hline\n",
      "0     &  0.988429 &   0.909571 &   0.083571 &          0.908429 &          0.083000 \\\\\n",
      "1     &  0.986200 &   0.998800 &   0.031600 &          1.002800 &          0.034000 \\\\\n",
      "2     &  0.988417 &   0.822541 &   0.164735 &          0.822159 &          0.164827 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\\end{adjustbox}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_89370/2549546134.py:16: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  table = df.to_latex(index=True, caption = path.split('/')[-2].replace('_','-'), label = path.split('/')[-2].replace('_','-'),column_format='|c|m{3cm}|c|c|c|c|c|c|c|c|c|c|c|c|c|c|')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def result_table_norel(path):\n",
    "    d = pd.read_csv(path+'/Relations_Important_full_threshold.csv', sep=',')\n",
    "    d.set_index('node_idx', inplace=True)\n",
    "    d['label'] = d['label'].apply(lambda x: int(x[1]))\n",
    "    df = pd.DataFrame()\n",
    "    df['label'] = d['label']\n",
    "    df['Sparsity'] = d['sparsity_threshold'].apply(lambda x: np.round(x,3))\n",
    "    df['Fidelity-'] = d['fidelity_minus_threshold'].apply(lambda x: np.round(x,3))\n",
    "    df['Fidelity+'] = d['fidelity_plus_threshold'].apply(lambda x: np.round(x,3))\n",
    "    df['Fidelity- Random'] = d['fidelity_minus_random'].apply(lambda x: np.round(x,3))\n",
    "    df['Fidelity+ Random'] = d['fidelity_plus_random'].apply(lambda x: np.round(x,3))\n",
    "    df = df.groupby(by='label').mean()\n",
    "\n",
    "\n",
    "\n",
    "    table = df.to_latex(index=True, caption = path.split('/')[-2].replace('_','-'), label = path.split('/')[-2].replace('_','-'),column_format='|c|m{3cm}|c|c|c|c|c|c|c|c|c|c|c|c|c|c|')\n",
    "    latex_table = table.replace('\\\\midrule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\toprule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\bottomrule', '\\\\hline')\n",
    "    latex_table = latex_table.replace('\\\\begin{tabular}', '\\\\begin{adjustbox}{scale=0.5}\\\\begin{tabular}')  # Add scaling parameter\n",
    "    latex_table = latex_table.replace('\\\\end{tabular}', '\\\\end{tabular}\\\\end{adjustbox}')  # Close the adjustbox environment\n",
    "    return latex_table\n",
    "\n",
    "path = 'chk/mdgenre_chk/exp/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/init_normal_hops_2_lr_0.5_adaptive_False_size_0.005_sizestd_adaptive_ent_10_type_1_killtype_True_break_no/Relation_Importance'\n",
    "print(result_table_norel(path) )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.812,  0.   , -0.088,  0.175,  0.333,  0.552,  0.   ,  0.238])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df = pd.read_csv(path+'/Relations_Important_full_threshold.csv', sep=',')\n",
    "d = pd.read_csv(path+'/Relations_Important_full_threshold.csv', sep=',')\n",
    "d.set_index('node_idx', inplace=True)\n",
    "d['label'] = d['label'].apply(lambda x: int(x[1]))\n",
    "\n",
    "fidelity_plus_threshold = np.round(list(fidelity(d, modality = 'plus', comparison_inverse= 'res_threshold_lekker_inverse').values()),3)\n",
    "fidelity_minus_threshold = np.round(list(fidelity(d, modality = 'minus', comparison_minus = 'prediction_threshold_lekker').values()),3)\n",
    "df = pd.DataFrame()\n",
    "sparsity = np.round(d.groupby('label')['sparsity_threshold'].mean(),3)\n",
    "df['Sparsity'] = sparsity\n",
    "fidelity_minus_threshold\n",
    "\n",
    "# df['Fidelity- '] = 1 - fidelity_minus_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data aifb (0.2069s).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[5757,    2],\n",
       "        [5797,    2],\n",
       "        [5678,    0],\n",
       "        [5900,    2],\n",
       "        [5677,    2],\n",
       "        [5731,    1],\n",
       "        [5724,    0],\n",
       "        [5791,    2],\n",
       "        [5699,    0],\n",
       "        [5857,    3],\n",
       "        [5752,    3],\n",
       "        [5688,    0],\n",
       "        [5702,    0],\n",
       "        [5714,    0],\n",
       "        [5905,    1],\n",
       "        [5795,    3],\n",
       "        [5811,    2],\n",
       "        [5708,    0],\n",
       "        [5843,    0],\n",
       "        [5873,    0],\n",
       "        [5697,    0],\n",
       "        [5753,    3],\n",
       "        [5831,    2],\n",
       "        [5839,    2],\n",
       "        [5783,    0],\n",
       "        [5755,    2],\n",
       "        [5808,    1],\n",
       "        [5844,    2],\n",
       "        [5798,    3],\n",
       "        [5701,    0],\n",
       "        [5845,    0],\n",
       "        [5861,    2],\n",
       "        [5778,    0],\n",
       "        [5854,    3],\n",
       "        [5785,    1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.rgcn_explainer_utils import *\n",
    "name = 'aifb'\n",
    "if name in ['aifb', 'mutag', 'bgs', 'am', 'mdgenre', 'amplus', 'dmg777k']:\n",
    "    data = kg.load(name, torch=True, final=False)\n",
    "    data = prunee(data, 2)\n",
    "data.withheld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_idx not in explanation\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5724"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_threshold = torch.load('chk/aifb_chk/exp/init_normal_lr_0.5_size_0.0005_ent_1_type_1_wd_0.9_MFR_1/masked_adj/masked_ver_thresh5724')\n",
    "h_threshold = torch.load('chk/aifb_chk/exp/init_normal_lr_0.5_size_0.0005_ent_1_type_1_wd_0.9_MFR_1/masked_adj/masked_hor_thresh5724')\n",
    "node_idx = 5724\n",
    "row_indices =  torch.nonzero(v_threshold.coalesce().indices()[1] == node_idx, as_tuple=False)[:, 0]\n",
    "if v_threshold.coalesce().values()[row_indices].count_nonzero() != 0:\n",
    "    print('node_idx in explanation')\n",
    "else:\n",
    "    print('node_idx not in explanation')\n",
    "5724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_idx in explanation\n"
     ]
    }
   ],
   "source": [
    "from src.rgcn_explainer_utils import *\n",
    "v = torch.load('chk/aifb_chk/exp/init_normal_lr_0.5_size_0.0005_ent_1_type_1_wd_0.9_MFR_1/masked_adj/masked_ver5724')\n",
    "row_indices =  torch.nonzero(v.coalesce().indices()[1] == node_idx, as_tuple=False)[:, 0]\n",
    "if v.coalesce().values()[row_indices].count_nonzero() != 0:\n",
    "    print('node_idx in explanation')\n",
    "else:\n",
    "    print('node_idx not in explanation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9581])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.coalesce().values()[row_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://www.aifb.uni-karlsruhe.de/Publikationen/viewPublikationOWL/id306instance',\n",
       " 'iri')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = v_threshold.coalesce().indices()[0]%data.num_entities\n",
    "r = torch.divide(v_threshold.coalesce().indices()[0], data.num_entities, rounding_mode = 'floor')\n",
    "o = v_threshold.coalesce().indices()[1]\n",
    "triples = torch.stack([s,r,o],dim=1)\n",
    "triples\n",
    "# if 56 in triples[:,0]:\n",
    "#     print(triples[triples[:,0]==5678])\n",
    "data.i2e[7327]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[   0,    0, 5677],\n",
       "        [   0,    0, 5687],\n",
       "        [3162,    0, 5693],\n",
       "        [   0,    0, 5697],\n",
       "        [   0,    0, 5699],\n",
       "        [3162,    0, 5723],\n",
       "        [   0,    0, 5754],\n",
       "        [   0,    0, 5772],\n",
       "        [   0,    0, 5805],\n",
       "        [   0,    0, 5808],\n",
       "        [   0,    0, 5816],\n",
       "        [   0,    0, 5857],\n",
       "        [   0,    0, 5858],\n",
       "        [   0,    0, 5864],\n",
       "        [6070,    0, 7327]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = h_threshold.coalesce().indices()[1]%data.num_entities\n",
    "r = torch.divide(h_threshold.coalesce().indices()[0], data.num_entities, rounding_mode = 'floor')\n",
    "o = h_threshold.coalesce().indices()[0]\n",
    "triples = torch.stack([s,r,o],dim=1)\n",
    "triples\n",
    "# if 5678 in triples[:,0]:\n",
    "#     print(triples[triples[:,0]==5678])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('http://www.aifb.uni-karlsruhe.de/Publikationen/viewPublikationOWL/id1169instance',\n",
       " 'iri')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.i2e[6981]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6881,    2, 5678],\n",
       "        [6881,    2, 5743],\n",
       "        [6981,    2, 5745],\n",
       "        [7045,    2, 5743],\n",
       "        [7100,    2, 5746],\n",
       "        [7393,    2, 5678],\n",
       "        [7393,    2, 5745],\n",
       "        [7393,    2, 5747],\n",
       "        [7968,    2, 6404],\n",
       "        [8013,    2, 5743],\n",
       "        [8015,    2, 5746],\n",
       "        [5357,   18, 5743],\n",
       "        [5357,   18, 5745],\n",
       "        [5357,   18, 5746],\n",
       "        [5357,   18, 5777],\n",
       "        [5408,   18, 5859],\n",
       "        [5494,   18, 5745],\n",
       "        [5494,   18, 5910],\n",
       "        [5502,   21, 5837],\n",
       "        [5937,   21, 5678],\n",
       "        [5678,   30, 7045],\n",
       "        [5678,   30, 7068],\n",
       "        [5678,   30, 8013],\n",
       "        [5745,   30, 6981],\n",
       "        [5745,   30, 7393],\n",
       "        [5746,   30, 7068],\n",
       "        [6404,   30, 8013],\n",
       "        [5746,   36, 5939],\n",
       "        [5357,    0, 5678],\n",
       "        [5357,    0, 5737],\n",
       "        [5408,    0, 5744],\n",
       "        [5413,    0, 5761],\n",
       "        [5431,    0, 5879],\n",
       "        [5431,    0, 5910],\n",
       "        [5431,    0, 5913],\n",
       "        [5450,    0, 5743],\n",
       "        [5494,    0, 5745],\n",
       "        [5494,    0, 5824],\n",
       "        [5502,    0, 5767],\n",
       "        [5502,    0, 5770],\n",
       "        [5502,    0, 5778],\n",
       "        [5502,    0, 5814],\n",
       "        [5502,    0, 5852],\n",
       "        [5678,    0, 8013],\n",
       "        [5743,    0, 7100],\n",
       "        [5743,    0, 7861],\n",
       "        [5743,    0, 8014],\n",
       "        [5746,    0, 8010],\n",
       "        [5747,    0, 5939],\n",
       "        [6404,    0, 6997],\n",
       "        [6611,    0, 6888],\n",
       "        [6981,    0, 5678],\n",
       "        [7045,    0, 5743],\n",
       "        [8010,    0, 5743],\n",
       "        [8013,    0, 5743],\n",
       "        [8014,    0, 5678]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def match_to_triples(v,h, data, sparse=True):\n",
    "    \"\"\"\n",
    "    v: vertical adjacency matrix\n",
    "    h: horizontal adjacency matrix\n",
    "    data: dataset\n",
    "    sparse: if True, the adjacency matrix is sparse, otherwise it is dense\n",
    "    returns: the triples corresponding to the adjacency matrix (from stack indexes to original indexes)\n",
    "    \"\"\"\n",
    "\n",
    "    n_ent = data.num_entities\n",
    "    if sparse:\n",
    "        pv,_ = torch.div(v.coalesce().indices(), n_ent, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sv,ov = v.coalesce().indices()% n_ent\n",
    "        result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        ph,_ = torch.div(h.coalesce().indices(),  n_ent, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        sh,oh = h.coalesce().indices()% n_ent\n",
    "        result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "\n",
    "                    \n",
    "    else:\n",
    "\n",
    "        # _,ph = torch.div(h, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        # sh,oh = h%data.num_entities\n",
    "        # result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "\n",
    "        # pv, _ = torch.div(v, data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "        # sv,ov = v%data.num_entities\n",
    "        # result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "\n",
    "        # result = torch.cat((result_v, result_h), 0)\n",
    "\n",
    "        if len(h )!= 0:\n",
    "            _,ph = torch.div(h,  n_ent, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sh,oh = h% n_ent\n",
    "            result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "        if len(v)!=0:\n",
    "            pv, _ = torch.div(v,  n_ent, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "            sv,ov = v% n_ent\n",
    "            result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "        if len(h) != 0 and len(v) != 0:\n",
    "            result = torch.cat((result_v, result_h), 0)\n",
    "            #print('all good')\n",
    "        if len(h) == 0:\n",
    "            result = result_v\n",
    "            print('ph is empty')\n",
    "        if len(v) == 0:\n",
    "            result = result_h             \n",
    "    \n",
    "    return result\n",
    "match_to_triples(v_threshold, h_threshold, data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[7327,    2, 5723],\n",
       "        [5686,   10,    0],\n",
       "        [5693,   10,    0],\n",
       "        [5701,   10,    0],\n",
       "        [5714,   10,    0],\n",
       "        [5735,   10,    0],\n",
       "        [5772,   10,    0],\n",
       "        [5786,   10,    0],\n",
       "        [5891,   10,    0],\n",
       "        [5700,   27,    0],\n",
       "        [5723,   27,    0],\n",
       "        [5772,   27,    0],\n",
       "        [5882,   27,    0],\n",
       "        [5891,   27,    0],\n",
       "        [6069,   30, 7327],\n",
       "        [5677,    0,    0],\n",
       "        [5687,    0,    0],\n",
       "        [5693,    0, 3162],\n",
       "        [5697,    0,    0],\n",
       "        [5699,    0,    0],\n",
       "        [5723,    0, 3162],\n",
       "        [5754,    0,    0],\n",
       "        [5772,    0,    0],\n",
       "        [5805,    0,    0],\n",
       "        [5808,    0,    0],\n",
       "        [5816,    0,    0],\n",
       "        [5857,    0,    0],\n",
       "        [5858,    0,    0],\n",
       "        [5864,    0,    0],\n",
       "        [7327,    0, 6070]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = v_threshold\n",
    "h = h_threshold\n",
    "pv,_ = torch.div(v.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "sv,ov = v.coalesce().indices()%data.num_entities\n",
    "result_v = torch.stack([sv,pv,ov], dim=1)\n",
    "ph,_ = torch.div(h.coalesce().indices(), data.num_entities, rounding_mode='floor')#v.coalesce().indices()//data.num_entities\n",
    "sh,oh = h.coalesce().indices()%data.num_entities\n",
    "result_h = torch.stack([sh,ph,oh], dim=1)\n",
    "result = torch.cat((result_v, result_h), 0)\n",
    "result\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
