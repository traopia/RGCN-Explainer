{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/RGCNExplainer/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import src.kgbench as kg\n",
    "from src.rgcn_explainer_utils import *\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "\n",
    "# Check if the current directory is already the parent directory\n",
    "if current_dir != '/Users/macoftraopia/Documents/GitHub/RGCN-Explainer':\n",
    "    # Set the parent directory as the current directory\n",
    "    os.chdir(parent_dir)\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data mdgender (75.42s).\n",
      "rel: 154 ent: 349347 triples: torch.Size([1203789, 3])\n",
      "training torch.Size([45321, 2]) withheld torch.Size([1000, 2])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.rgcn_explainer_utils import *\n",
    "name = 'mdgender'\n",
    "if name in ['aifb', 'mutag', 'bgs', 'am', 'mdgenre', 'amplus', 'mdgender']:\n",
    "    data = kg.load(name, torch=True, final=False)\n",
    "if 'IMDb' in name:    \n",
    "    data = torch.load(f'data/IMDB/finals/{name}.pt')\n",
    "if 'dbo' in name:\n",
    "    data = torch.load(f'data/DBO/finals/{name}.pt')\n",
    "get_relations(data)\n",
    "relations = [data.i2rel[i][0] for i in range(len(data.i2rel))]\n",
    "data.entities = np.append(data.triples[:,0].tolist(),(data.triples[:,2].tolist()))\n",
    "data.triples = torch.Tensor(data.triples).to(int)\n",
    "data.withheld = torch.Tensor(data.withheld).to(int)\n",
    "data.training = torch.Tensor(data.training).to(int)\n",
    "print('rel:', data.num_relations, 'ent:', data.num_entities, 'triples:', data.triples.shape)\n",
    "print('training', data.training.shape, 'withheld', data.withheld.shape)\n",
    "# data.entities = np.append(data.triples[:,0].detach().numpy(),(data.triples[:,2].detach().numpy()))\n",
    "# relations = get_relations(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val = data.withheld[:,0]\n",
    "# most_common_node = {}\n",
    "# for i in val:\n",
    "#     sub_edges, neighborhoods, sub_edges_tensor = find_n_hop_neighbors(data, 2,int(i), adj=True)\n",
    "\n",
    "#     counter = Counter([num for tup in sub_edges for num in tup]).most_common(1)[0][0]\n",
    "#     most_common_node[int(i)] = counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if name=='dbo_gender':\n",
    "    male = data.training[data.training[:,1] == 0][:,0].tolist()\n",
    "    female = data.training[data.training[:,1] == 1][:,0].tolist()\n",
    "    male_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if male[i] in  data.triples[:,0].tolist() ]\n",
    "    female_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if female[i] in  data.triples[:,0].tolist() ]\n",
    "    female_triples = [data.triples[i][1].tolist() for i in data.triples[:,1].tolist() if data.triples[i][0] in female ]\n",
    "    def frequency_relations(data, subset=None, all = True):\n",
    "        if all:\n",
    "            freq = Counter(data.triples[:,1].tolist())\n",
    "            print(freq)\n",
    "        else:\n",
    "            freq = Counter(subset)\n",
    "            print(freq)\n",
    "        sorted_freq = {data.i2r[k]: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True)}\n",
    "        return sorted_freq\n",
    "    #f = frequency_relations(data,male, all = False)\n",
    "    f = frequency_relations(data,female_triples, all = False)\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "\n",
    "def select_matching_triples(triples_tensor, nodes_to_check):\n",
    "    selected_triples = []\n",
    "\n",
    "    # Iterate over the triples and check if any node matches with nodes_to_check\n",
    "    for triple in triples_tensor:\n",
    "        head, relation, tail = triple.tolist()\n",
    "        if head in nodes_to_check or tail in nodes_to_check:\n",
    "            selected_triples.append(triple)\n",
    "\n",
    "    return torch.stack(selected_triples)\n",
    "\n",
    "def compute_average_node_degree(triples_tensor):\n",
    "    # Create a dictionary to store the node degrees\n",
    "    node_degrees = {}\n",
    "\n",
    "    # Count the node degrees using NumPy\n",
    "    unique_nodes, counts = np.unique(triples_tensor[:, [0, 2]], return_counts=True)\n",
    "    node_degrees.update(dict(zip(unique_nodes.tolist(), counts)))\n",
    "\n",
    "    # Compute the average node degree and standard deviation using NumPy\n",
    "    num_nodes = len(node_degrees)\n",
    "    total_degree = sum(node_degrees.values())\n",
    "    average_degree = total_degree / num_nodes\n",
    "\n",
    "    degree_values = list(node_degrees.values())\n",
    "    degree_std = np.std(degree_values)\n",
    "\n",
    "    return average_degree, degree_std\n",
    "\n",
    "\n",
    "def compute_average_degree_at_2_hops(triples_tensor):\n",
    "    # Create an adjacency dictionary to store the neighbors of each node\n",
    "    adjacency_dict = {}\n",
    "\n",
    "    # Iterate over the triples and build the adjacency dictionary\n",
    "    for head, _, tail in triples_tensor:\n",
    "        if head not in adjacency_dict:\n",
    "            adjacency_dict[head] = set()\n",
    "        adjacency_dict[head].add(tail)\n",
    "\n",
    "        if tail not in adjacency_dict:\n",
    "            adjacency_dict[tail] = set()\n",
    "        adjacency_dict[tail].add(head)\n",
    "\n",
    "    # Compute the average degree at 2 hops for each node\n",
    "    average_degrees_2_hops = []\n",
    "    for node, neighbors in adjacency_dict.items():\n",
    "        two_hop_neighbors = set()\n",
    "        for neighbor in neighbors:\n",
    "            two_hop_neighbors.update(adjacency_dict.get(neighbor, set()))\n",
    "        average_degrees_2_hops.append(len(neighbors) + len(two_hop_neighbors))\n",
    "\n",
    "    # Compute the average degree at 2 hops and its standard deviation using NumPy\n",
    "    average_degrees_2_hops = np.array(average_degrees_2_hops)\n",
    "    average_degree_2_hops = np.mean(average_degrees_2_hops)\n",
    "    degree_std_2_hops = np.std(average_degrees_2_hops)\n",
    "\n",
    "    return average_degree_2_hops, degree_std_2_hops\n",
    "\n",
    "\n",
    "def compute_num_edges_to_node(triples_list, node):\n",
    "    # Create an adjacency dictionary to store the neighbors of each node\n",
    "    adjacency_dict = defaultdict(set)\n",
    "\n",
    "    # Iterate over the triples and build the adjacency dictionary\n",
    "    for head, _, tail in triples_list:\n",
    "        adjacency_dict[head].add(tail)\n",
    "        adjacency_dict[tail].add(head)\n",
    "\n",
    "    # Compute the number of edges to the given node at 0 and 2 hops\n",
    "    neighbors_0_hop = adjacency_dict.get(node, set())\n",
    "    neighbors_2_hops = set()\n",
    "\n",
    "    # Compute neighbors at 2 hops away\n",
    "    for neighbor in neighbors_0_hop:\n",
    "        neighbors_2_hops.update(adjacency_dict.get(neighbor, set()))\n",
    "\n",
    "    num_edges_to_node_0_hop = len(neighbors_0_hop)\n",
    "    num_edges_to_node_2_hops = len(neighbors_2_hops) - 1  # Exclude the starting node itself from 2-hop neighbors\n",
    "\n",
    "    return num_edges_to_node_0_hop, num_edges_to_node_2_hops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[198665, 108380, 164115, 241860, 184391, 256831, 233709, 206749]\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "from src.rgcn_explainer_utils import d_classes\n",
    "num_samples_per_class = 4\n",
    "random.seed(42)\n",
    "dict_classes = d_classes(data)\n",
    "sampled_data = []\n",
    "for key in dict_classes:\n",
    "    if key == 7 or key == 8:\n",
    "\n",
    "        sampled_data.extend(random.sample(dict_classes[key], num_samples_per_class))\n",
    "print(sampled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "avg num edges validation 0 hop 16.75 ± 8.089\n",
      "avg num edges validation 2 hop 60618.375 ± 2387.198\n",
      "Average Node Degree: 6.892 ± 138.437\n",
      "Average full Degree at 2 Hops: 2.0 ± 0.0\n"
     ]
    }
   ],
   "source": [
    "val = data.withheld[:, 0]\n",
    "\n",
    "#selected_triples = select_matching_triples(data.triples, sampled_data)\n",
    "sum_0, sum_2 = [], []\n",
    "for i in sampled_data:\n",
    "    num_edges_0_hop, num_edges_2_hops = compute_num_edges_to_node(data.triples.tolist(), int(i))\n",
    "    sum_0.append(num_edges_0_hop)\n",
    "    sum_2.append(num_edges_2_hops)\n",
    "\n",
    "print('avg num edges validation 0 hop', np.round(np.mean(sum_0), 3), '±', np.round(np.std(sum_0), 3))\n",
    "print('avg num edges validation 2 hop', np.round(np.mean(sum_2), 3), '±', np.round(np.std(sum_2), 3))\n",
    "average_degree, std_degree = compute_average_node_degree(data.triples)\n",
    "print(\"Average Node Degree:\", np.round(average_degree,3), \"±\", np.round(std_degree,3))\n",
    "average_degree_2_hops, degree_std_2_hops = compute_average_degree_at_2_hops(data.triples)\n",
    "print(\"Average full Degree at 2 Hops:\", np.round(average_degree_2_hops,3),'±', np.round(degree_std_2_hops,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def object_type(v,h,data, relation_id = None,type=True):\n",
    "    ''' Get the object class of a specific relation'''\n",
    "    if type:\n",
    "        relation_id = [i for i in range(data.num_relations) if 'type' in data.i2r[i]][-1]\n",
    "    output_indices_v, output_values, value_indices = select_relation(v, data.num_entities, relation_id)\n",
    "    output_indices_h, output_values, value_indices = select_relation(h, data.num_entities, relation_id)\n",
    "    objects_types = match_to_triples(output_indices_v, output_indices_h,data, sparse=False)\n",
    "    list = []\n",
    "    for i in objects_types:\n",
    "        list.append(data.i2e[i[2]][0])#.split('#')[1])\n",
    "    result = Counter(list)\n",
    "    return result\n",
    "\n",
    "for node_idx in data.withheld[:,0]:\n",
    "    h, v = torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_ver{node_idx}'), torch.load(f'chk/aifb_chk/hops_2_size_5e-05_lr_0.1_ent_-1_type_1_threshold_0.5_init_const_exp_/masked_adj/masked_hor{node_idx}')\n",
    "    print(f'node {node_idx}:', object_type(v,h,data, 39))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
