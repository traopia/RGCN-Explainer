  0%|                                                                                                                | 0/10 [00:00<?, ?it/s]/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
119
start training
masked_hor: tensor(indices=tensor([[  5357,   5357,   5408,   5408,   5413,   5413,   5431,
                          5431,   5450,   5450,   5494,   5494,   5502,   5502,
                          5502,   5502,   5502,   5502,   5502,   5502,   5502,
                          5502,   5502,   5502,   5502,   5502,   5502,   5502,
                          5502,   5502,   5502,   5502,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5937,   5937,   5937,   5937,   5937,   5939,
                          5939,   5939,   5939,   5939,   5939,   5939,   5939,
                          5939,   5939,   5939,   5939,   5939,   5939,   5939,
                          6881,   6881,   6881,   6887,   6887,   6887,   6888,
                          6888,   6981,   6981,   6997,   6997,   6997,   7045,
                          7045,   7068,   7068,   7100,   7100,   7393,   7393,
                          7393,   7861,   7911,   7911,   7911,   7968,   8010,
                          8010,   8010,   8012,   8012,   8012,   8013,   8013,
                          8013,   8014,   8014,   8014,   8015,   8015,   8015],
                       [ 63934, 154808,  63934, 154808,  63934, 154808,  63932,
                        154808,  63934, 154808,  63932, 154808,  47362,  47364,
                        179663, 263716, 263722, 263723, 263816, 263832, 263880,
                        263903, 263935, 264228, 264696, 264746, 264803, 264845,
                        264847, 264848, 264849, 264850,  82872, 124392, 192770,
                        223730, 237515, 255431, 255437, 255438, 255531, 255547,
                        255595, 255618, 255650, 255943, 256411, 256461, 256518,
                        256560, 256562, 256563, 256564, 256565, 304199, 328345,
                        328346,  38642, 146276, 146339, 179663, 247153,  38642,
                        146202, 146253, 146258, 146295, 179663, 247146, 247152,
                        247262, 248176, 248275, 248277, 248278, 248279, 248280,
                         22248, 113644, 146202,  80243, 113644, 146295,  22248,
                        113642,  22248, 146295,  22248, 113644, 146295,  22248,
                        146295,  22248, 146295,  22248, 146295,  22248, 146202,
                        146295,  22248,  22248, 113644, 146295,  22248,  22248,
                        113644, 146295,  22248, 113644, 146295,  22248, 113644,
                        146295,  22248, 113644, 146295,  22248, 113644, 146295]]),
       values=tensor([0.7773, 0.7672, 0.7534, 0.6742, 0.7480, 0.6985, 0.7300,
                      0.6883, 0.7115, 0.7710, 0.7209, 0.6938, 0.3561, 0.3583,
                      0.7110, 0.0441, 0.0453, 0.0428, 0.0422, 0.0437, 0.0418,
                      0.0446, 0.0442, 0.0454, 0.0448, 0.0449, 0.0439, 0.0449,
                      0.0427, 0.0431, 0.0426, 0.0443, 0.6943, 0.7083, 0.7253,
                      0.7725, 0.7391, 0.0424, 0.0435, 0.0418, 0.0406, 0.0445,
                      0.0417, 0.0421, 0.0410, 0.0460, 0.0411, 0.0423, 0.0416,
                      0.0420, 0.0431, 0.0438, 0.0423, 0.0447, 0.7098, 0.3559,
                      0.3469, 0.7320, 0.3647, 0.3740, 0.7286, 0.7754, 0.6998,
                      0.1912, 0.1916, 0.1881, 0.1959, 0.7442, 0.0822, 0.0807,
                      0.0781, 0.0847, 0.0807, 0.0827, 0.0814, 0.0824, 0.0828,
                      0.7144, 0.6713, 0.7115, 0.7313, 0.7223, 0.6955, 0.7159,
                      0.7445, 0.7442, 0.7591, 0.7324, 0.7496, 0.7186, 0.7035,
                      0.7462, 0.6850, 0.7094, 0.7637, 0.7432, 0.6625, 0.3717,
                      0.3753, 0.7318, 0.7471, 0.7457, 0.7574, 0.7443, 0.7565,
                      0.7127, 0.7561, 0.7225, 0.7440, 0.7408, 0.7160, 0.7414,
                      0.7162, 0.7438, 0.7188, 0.7183, 0.7379, 0.7165, 0.7480]),
       size=(8285, 753935), nnz=119, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
 10%|██████████▍                                                                                             | 1/10 [00:26<03:57, 26.38s/it]
epoch:  0 ; loss:  0.2886563837528229 ; pred:  tensor([0.5654, 0.1537, 0.1557, 0.1251], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5357,   5357,   5408,   5408,   5413,   5413,   5431,
                          5431,   5450,   5450,   5494,   5494,   5502,   5502,
                          5502,   5502,   5502,   5502,   5502,   5502,   5502,
                          5502,   5502,   5502,   5502,   5502,   5502,   5502,
                          5502,   5502,   5502,   5502,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5937,   5937,   5937,   5937,   5937,   5939,
                          5939,   5939,   5939,   5939,   5939,   5939,   5939,
                          5939,   5939,   5939,   5939,   5939,   5939,   5939,
                          6881,   6881,   6881,   6887,   6887,   6887,   6888,
                          6888,   6981,   6981,   6997,   6997,   6997,   7045,
                          7045,   7068,   7068,   7100,   7100,   7393,   7393,
                          7393,   7861,   7911,   7911,   7911,   7968,   8010,
                          8010,   8010,   8012,   8012,   8012,   8013,   8013,
                          8013,   8014,   8014,   8014,   8015,   8015,   8015],
                       [ 63934, 154808,  63934, 154808,  63934, 154808,  63932,
                        154808,  63934, 154808,  63932, 154808,  47362,  47364,
                        179663, 263716, 263722, 263723, 263816, 263832, 263880,
                        263903, 263935, 264228, 264696, 264746, 264803, 264845,
                        264847, 264848, 264849, 264850,  82872, 124392, 192770,
                        223730, 237515, 255431, 255437, 255438, 255531, 255547,
                        255595, 255618, 255650, 255943, 256411, 256461, 256518,
                        256560, 256562, 256563, 256564, 256565, 304199, 328345,
                        328346,  38642, 146276, 146339, 179663, 247153,  38642,
                        146202, 146253, 146258, 146295, 179663, 247146, 247152,
                        247262, 248176, 248275, 248277, 248278, 248279, 248280,
                         22248, 113644, 146202,  80243, 113644, 146295,  22248,
                        113642,  22248, 146295,  22248, 113644, 146295,  22248,
                        146295,  22248, 146295,  22248, 146295,  22248, 146202,
                        146295,  22248,  22248, 113644, 146295,  22248,  22248,
                        113644, 146295,  22248, 113644, 146295,  22248, 113644,
                        146295,  22248, 113644, 146295,  22248, 113644, 146295]]),
       values=tensor([0.7773, 0.7672, 0.7534, 0.6742, 0.7480, 0.6985, 0.7300,
                      0.6883, 0.7115, 0.7710, 0.7209, 0.6938, 0.3561, 0.3583,
                      0.7110, 0.0441, 0.0453, 0.0428, 0.0422, 0.0437, 0.0418,
                      0.0446, 0.0442, 0.0454, 0.0448, 0.0449, 0.0439, 0.0495,
                      0.0427, 0.0431, 0.0426, 0.0443, 0.6943, 0.7083, 0.7253,
                      0.7725, 0.7391, 0.0424, 0.0484, 0.0418, 0.0406, 0.0445,
                      0.0417, 0.0421, 0.0410, 0.0460, 0.0411, 0.0423, 0.0416,
                      0.0420, 0.0431, 0.0438, 0.0423, 0.0447, 0.7098, 0.3559,
                      0.3469, 0.7320, 0.3647, 0.3740, 0.7286, 0.7754, 0.7935,
                      0.2107, 0.2110, 0.2084, 0.2142, 0.8275, 0.0916, 0.0685,
                      0.0885, 0.0934, 0.0905, 0.0919, 0.0910, 0.0917, 0.0920,
                      0.8048, 0.7710, 0.8026, 0.6228, 0.8109, 0.7902, 0.8060,
                      0.8277, 0.8275, 0.8386, 0.8186, 0.8315, 0.8081, 0.7964,
                      0.8290, 0.7819, 0.8010, 0.8420, 0.8267, 0.7640, 0.4134,
                      0.4161, 0.8181, 0.8296, 0.8286, 0.8373, 0.8276, 0.8367,
                      0.8035, 0.8364, 0.8111, 0.8274, 0.8250, 0.8061, 0.8254,
                      0.8062, 0.8272, 0.8082, 0.8079, 0.8227, 0.8064, 0.8303]),
       size=(8285, 753935), nnz=119, layout=torch.sparse_coo,
 10%|██████████▍                                                                                             | 1/10 [00:50<07:31, 50.13s/it]
Traceback (most recent call last):
  File "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r.py", line 667, in <module>
    main2(name = 'aifb', node_idx = 5757, n_hops = 0,threshold = 0.5, train= True)
  File "/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r.py", line 550, in main2
    loss.backward()
  File "/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/_tensor.py", line 396, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph, inputs=inputs)
  File "/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/torch/autograd/__init__.py", line 173, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.