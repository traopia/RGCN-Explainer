  0%|                                                                                                                | 0/10 [00:00<?, ?it/s]/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
24
start training
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.8258, 0.8068, 0.7790, 0.0597, 0.0768, 0.0656, 0.0729,
                      0.0631, 0.0751, 0.0690, 0.0702, 0.0745, 0.0664, 0.7362,
                      0.5820, 0.7186, 0.7131, 0.7080, 0.7742, 0.6944, 0.6962,
                      0.7275, 0.6815, 0.7494]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.8258, 0.8068, 0.7790, 0.5968, 0.7678, 0.6556, 0.7286, 0.6311, 0.7508,
        0.6904, 0.7022, 0.7445, 0.6636, 0.7362, 0.5820, 0.7186, 0.7131, 0.7080,
        0.7742, 0.6944, 0.6962, 0.7275, 0.6815, 0.7494],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(1.2367, grad_fn=<MulBackward0>)
size_loss tensor(-0.3599, grad_fn=<MulBackward0>) tensor(-88.3619, grad_fn=<MulBackward0>)
size_num_loss 10.0
loss_reg tensor(1.7124, grad_fn=<MulBackward0>)
epoch:  0 ; loss:  -75.77268981933594 ; pred:  tensor([0.2633, 0.2760, 0.2903, 0.1704], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7420, 0.7169, 0.6814, 0.0709, 0.0667, 0.0758, 0.0620,
                      0.0738, 0.0646, 0.0786, 0.0795, 0.0639, 0.0765, 0.6286,
                      0.6966, 0.6076, 0.6012, 0.7999, 0.6752, 0.7893, 0.7907,
                      0.6182, 0.7792, 0.6446]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.7420, 0.7169, 0.6814, 0.7093, 0.6673, 0.7583, 0.6195, 0.7382, 0.6463,
        0.7861, 0.7954, 0.6387, 0.7648, 0.6286, 0.6966, 0.6076, 0.6012, 0.7999,
        0.6752, 0.7893, 0.7907, 0.6182, 0.7792, 0.6446],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.4699, grad_fn=<MulBackward0>) tensor(-86.7596, grad_fn=<MulBackward0>)
size_num_loss 10.0
loss_reg tensor(1.6895, grad_fn=<MulBackward0>)
 10%|██████████▍                                                                                             | 1/10 [00:23<03:35, 23.89s/it]
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.6476, 0.6314, 0.6384, 0.0771, 0.0653, 0.0771, 0.0688,
                      0.0777, 0.0676, 0.0747, 0.0741, 0.0684, 0.0765, 0.6867,
                      0.7649, 0.6877, 0.6862, 0.7390, 0.6445, 0.7444, 0.7433,
                      0.6886, 0.7534, 0.6766]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.6476, 0.6314, 0.6384, 0.7707, 0.6532, 0.7709, 0.6883, 0.7769, 0.6761,
        0.7465, 0.7410, 0.6837, 0.7649, 0.6867, 0.7649, 0.6877, 0.6862, 0.7390,
        0.6445, 0.7444, 0.7433, 0.6886, 0.7534, 0.6766],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.2321, grad_fn=<MulBackward0>) tensor(-90.5967, grad_fn=<MulBackward0>)
size_num_loss 10.0

 20%|████████████████████▊                                                                                   | 2/10 [00:46<03:03, 22.99s/it]
epoch:  2 ; loss:  -79.12830352783203 ; pred:  tensor([2.8156e-24, 3.2584e-23, 1.0000e+00, 2.3771e-23],
       grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.6437, 0.6549, 0.6832, 0.0784, 0.0702, 0.0738, 0.0753,
                      0.0765, 0.0731, 0.0680, 0.0664, 0.0741, 0.0724, 0.7472,
                      0.7871, 0.7574, 0.7588, 0.6571, 0.6914, 0.6743, 0.6716,
                      0.7535, 0.6959, 0.7320]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.6437, 0.6549, 0.6832, 0.7838, 0.7024, 0.7384, 0.7526, 0.7654, 0.7310,
        0.6801, 0.6641, 0.7406, 0.7239, 0.7472, 0.7871, 0.7574, 0.7588, 0.6571,
        0.6914, 0.6743, 0.6716, 0.7535, 0.6959, 0.7320],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.1887, grad_fn=<MulBackward0>) tensor(-91.5014, grad_fn=<MulBackward0>)
size_num_loss 10.0

 30%|███████████████████████████████▏                                                                        | 3/10 [01:08<02:39, 22.72s/it]
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.6861, 0.7066, 0.7374, 0.0770, 0.0750, 0.0694, 0.0769,
                      0.0732, 0.0756, 0.0669, 0.0665, 0.0758, 0.0680, 0.7630,
                      0.7810, 0.7776, 0.7819, 0.6625, 0.7434, 0.6679, 0.6675,
                      0.7701, 0.6685, 0.7568]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.6861, 0.7066, 0.7374, 0.7697, 0.7498, 0.6935, 0.7691, 0.7316, 0.7563,
        0.6685, 0.6654, 0.7577, 0.6799, 0.7630, 0.7810, 0.7776, 0.7819, 0.6625,
        0.7434, 0.6679, 0.6675, 0.7701, 0.6685, 0.7568],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.2002, grad_fn=<MulBackward0>) tensor(-91.2519, grad_fn=<MulBackward0>)
size_num_loss 10.0

 40%|█████████████████████████████████████████▌                                                              | 4/10 [01:30<02:13, 22.32s/it]
epoch:  4 ; loss:  -79.7109146118164 ; pred:  tensor([0., 0., 1., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7354, 0.7541, 0.7719, 0.0743, 0.0770, 0.0679, 0.0758,
                      0.0697, 0.0753, 0.0701, 0.0703, 0.0748, 0.0682, 0.7520,
                      0.7601, 0.7694, 0.7760, 0.7027, 0.7722, 0.7023, 0.7030,
                      0.7593, 0.6929, 0.7530]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.7354, 0.7541, 0.7719, 0.7427, 0.7697, 0.6793, 0.7582, 0.6971, 0.7529,
        0.7006, 0.7034, 0.7481, 0.6821, 0.7520, 0.7601, 0.7694, 0.7760, 0.7027,
        0.7722, 0.7023, 0.7030, 0.7593, 0.6929, 0.7530],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.1067, grad_fn=<MulBackward0>) tensor(-93.5748, grad_fn=<MulBackward0>)
size_num_loss 10.0

 50%|████████████████████████████████████████████████████                                                    | 5/10 [01:51<01:50, 22.05s/it]
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7732, 0.7809, 0.7769, 0.0714, 0.0761, 0.0710, 0.0732,
                      0.0697, 0.0733, 0.0748, 0.0752, 0.0727, 0.0721, 0.7279,
                      0.7305, 0.7425, 0.7500, 0.7518, 0.7711, 0.7496, 0.7504,
                      0.7327, 0.7392, 0.7329]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.7732, 0.7809, 0.7769, 0.7136, 0.7610, 0.7095, 0.7320, 0.6966, 0.7330,
        0.7476, 0.7516, 0.7269, 0.7207, 0.7279, 0.7305, 0.7425, 0.7500, 0.7518,
        0.7711, 0.7496, 0.7504, 0.7327, 0.7392, 0.7329],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.0462, grad_fn=<MulBackward0>) tensor(-95.7488, grad_fn=<MulBackward0>)
size_num_loss 10.0

 60%|██████████████████████████████████████████████████████████████▍                                         | 6/10 [02:15<01:30, 22.63s/it]
epoch:  6 ; loss:  -84.0147933959961 ; pred:  tensor([0., 0., 1., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7827, 0.7782, 0.7562, 0.0712, 0.0734, 0.0756, 0.0720,
                      0.0731, 0.0728, 0.0779, 0.0781, 0.0730, 0.0767, 0.7251,
                      0.7113, 0.7164, 0.7182, 0.7822, 0.7468, 0.7796, 0.7799,
                      0.7191, 0.7776, 0.7278]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
tensor([0.7827, 0.7782, 0.7562, 0.7116, 0.7345, 0.7558, 0.7198, 0.7308, 0.7281,
        0.7791, 0.7810, 0.7302, 0.7668, 0.7251, 0.7113, 0.7164, 0.7182, 0.7822,
        0.7468, 0.7796, 0.7799, 0.7191, 0.7776, 0.7278],
       grad_fn=<SigmoidBackward0>)
num_high 24
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-0.0739, grad_fn=<MulBackward0>) tensor(-94.6357, grad_fn=<MulBackward0>)
size_num_loss 10.0

