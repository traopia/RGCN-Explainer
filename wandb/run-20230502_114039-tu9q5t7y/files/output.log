7
start training
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.7649, 0.7444, 0.7550, 0.7546, 0.5986, 0.7110, 0.8985]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(0.3572, grad_fn=<SelectBackward0>)
mask_without_small tensor([0.7649, 0.7444, 0.7550, 0.7546, 0.5986, 0.7110, 0.8985],
       grad_fn=<IndexBackward0>)
num_high 7
pred_loss tensor(1.0295, grad_fn=<MulBackward0>)
size_loss tensor(0.4449, grad_fn=<AddBackward0>)
size_num_loss 1.0
  0%|                                                                                                                                                   | 0/10 [00:00<?, ?it/s]/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
epoch:  0 ; loss:  2.4743752479553223 ; pred:  tensor([0.3572, 0.2205, 0.2761, 0.1462], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.6637, 0.6385, 0.8355, 0.6509, 0.4750, 0.5988, 0.9359]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.6637, 0.6385, 0.8355, 0.6509, 0.5988, 0.9359],
       grad_fn=<IndexBackward0>)
num_high 6
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-176.2616, grad_fn=<AddBackward0>)
size_num_loss 0.8571428571428571
 10%|█████████████▉                                                                                                                             | 1/10 [00:30<04:36, 30.77s/it]
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.5764, 0.5490, 0.8805, 0.5624, 0.3929, 0.5071, 0.9549]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.5764, 0.5490, 0.8805, 0.5624, 0.5071, 0.9549],
       grad_fn=<IndexBackward0>)
num_high 6
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-371.9994, grad_fn=<AddBackward0>)

 20%|███████████████████████████▊                                                                                                               | 2/10 [00:57<03:46, 28.33s/it]
epoch:  2 ; loss:  -371.1422424316406 ; pred:  tensor([1.0000e+00, 5.1046e-28, 1.1208e-27, 8.3401e-28],
       grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.4725, 0.4436, 0.9187, 0.4575, 0.3331, 0.4016, 0.9702]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9187, 0.9702], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-12.2940, grad_fn=<AddBackward0>)

 30%|█████████████████████████████████████████▋                                                                                                 | 3/10 [01:22<03:09, 27.08s/it]
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.3887, 0.3605, 0.9344, 0.3739, 0.2877, 0.3211, 0.9799]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9344, 0.9799], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-9.3547, grad_fn=<AddBackward0>)

 40%|███████████████████████████████████████████████████████▌                                                                                   | 4/10 [01:48<02:38, 26.48s/it]
epoch:  4 ; loss:  -9.069008827209473 ; pred:  tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.3225, 0.2960, 0.9418, 0.3085, 0.2524, 0.2603, 0.9860]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9418, 0.9860], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-8.8253, grad_fn=<AddBackward0>)

 50%|█████████████████████████████████████████████████████████████████████▌                                                                     | 5/10 [02:13<02:09, 25.83s/it]
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.2706, 0.2462, 0.9447, 0.2576, 0.2244, 0.2143, 0.9900]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9447, 0.9900], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-9.3163, grad_fn=<AddBackward0>)

 60%|███████████████████████████████████████████████████████████████████████████████████▍                                                       | 6/10 [02:38<01:42, 25.56s/it]
epoch:  6 ; loss:  -9.03062915802002 ; pred:  tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.2298, 0.2076, 0.9445, 0.2179, 0.2018, 0.1792, 0.9927]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9445, 0.9927], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-10.6239, grad_fn=<AddBackward0>)

 70%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                         | 7/10 [03:04<01:17, 25.70s/it]
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.1976, 0.1774, 0.9417, 0.1868, 0.1833, 0.1522, 0.9945]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9417, 0.9945], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-12.9567, grad_fn=<AddBackward0>)

 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 8/10 [03:29<00:51, 25.51s/it]
epoch:  8 ; loss:  -12.67099666595459 ; pred:  tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.1719, 0.1536, 0.9360, 0.1621, 0.1680, 0.1310, 0.9958]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9360, 0.9958], grad_fn=<IndexBackward0>)
num_high 2
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(-16.9178, grad_fn=<AddBackward0>)

 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 9/10 [03:54<00:25, 25.32s/it]
sel masked ver tensor(indices=tensor([[5724, 5724],
                       [3162, 5230]]),
       values=tensor([0.9360, 0.9958]),
       size=(5725, 5231), nnz=2, layout=torch.sparse_coo,

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [04:19<00:00, 25.95s/it]
Counter({'homepage': 1, 'type': 1})
dict index: {}
/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/networkx/drawing/nx_pylab.py:433: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  node_collection = ax.scatter(
ypred explain tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
ypred full tensor([0.4840, 0.2345, 0.2195, 0.0620], grad_fn=<SoftmaxBackward0>)
original label [0]
num mislabel 1
num correct 34