[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:221: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
node_idx 5757
masked_adj tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0609, 0.1418, 0.6873, 0.1100], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.6873], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.3750], grad_fn=<MulBackward0>)
size_loss tensor(-3.7072e-13, grad_fn=<MulBackward0>)
size_num_loss 0.72
loss: tensor([1.0950], grad_fn=<AddBackward0>)
0
epoch:  0 ; loss:  1.095016360282898 ; pred:  tensor([0.0609, 0.1418, 0.6873, 0.1100], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
        0.6225, 0.8176, 0.8176, 0.6225, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
        0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
                      0.6225, 0.6225, 0.6225, 0.8176, 0.8176, 0.6225, 0.8176,
                      0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
                      0.8176, 0.8176, 0.8176]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0389, 0.0989, 0.7813, 0.0809], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.7813], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
        0.6225, 0.8176, 0.8176, 0.6225, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
        0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.2468], grad_fn=<MulBackward0>)
size_loss tensor(-0.9862, grad_fn=<MulBackward0>)
size_num_loss 0.72
loss: tensor([-0.0194], grad_fn=<AddBackward0>)
1
epoch:  1 ; loss:  -0.019435644149780273 ; pred:  tensor([0.0389, 0.0989, 0.7813, 0.0809], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
        0.5316, 0.8691, 0.8713, 0.5256, 0.8707, 0.8737, 0.8737, 0.8737, 0.8737,
        0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8678],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
                      0.5316, 0.5316, 0.5316, 0.8691, 0.8713, 0.5256, 0.8707,
                      0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8737,
                      0.8737, 0.8737, 0.8678]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0278, 0.0743, 0.8343, 0.0636], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8343], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
        0.5316, 0.8691, 0.8713, 0.5256, 0.8707, 0.8737, 0.8737, 0.8737, 0.8737,
        0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8678],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.1811], grad_fn=<MulBackward0>)
size_loss tensor(-3.0206, grad_fn=<MulBackward0>)
size_num_loss 0.72
loss: tensor([-2.1195], grad_fn=<AddBackward0>)
2
epoch:  2 ; loss:  -2.1195061206817627 ; pred:  tensor([0.0278, 0.0743, 0.8343, 0.0636], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,
        0.4275, 0.9115, 0.9139, 0.4195, 0.9132, 0.9164, 0.9164, 0.9164, 0.9164,
        0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9101],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,
                      0.4275, 0.4275, 0.4275, 0.9115, 0.9139, 0.4195, 0.9132,
                      0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164,
                      0.9164, 0.9164, 0.9101]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0208, 0.0576, 0.8700, 0.0515], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8700], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9115, 0.9139, 0.9132, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164,
        0.9164, 0.9164, 0.9164, 0.9101], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1392], grad_fn=<MulBackward0>)
size_loss tensor(-0.0484, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([1.6221], grad_fn=<AddBackward0>)
3
epoch:  3 ; loss:  1.6221100091934204 ; pred:  tensor([0.0208, 0.0576, 0.8700, 0.0515], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465,
        0.3465, 0.8999, 0.9218, 0.3362, 0.9136, 0.9463, 0.9463, 0.9463, 0.9463,
        0.9463, 0.9463, 0.9463, 0.9463, 0.9463, 0.8939],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465,
                      0.3465, 0.3465, 0.3465, 0.8999, 0.9218, 0.3362, 0.9136,
                      0.9463, 0.9463, 0.9463, 0.9463, 0.9463, 0.9463, 0.9463,
                      0.9463, 0.9463, 0.8939]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0172, 0.0485, 0.8891, 0.0451], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8891], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.8999, 0.9218, 0.9136, 0.9463, 0.9463, 0.9463, 0.9463, 0.9463, 0.9463,
        0.9463, 0.9463, 0.9463, 0.8939], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1175], grad_fn=<MulBackward0>)
size_loss tensor(-3.9276, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([-2.2788], grad_fn=<AddBackward0>)
4
epoch:  4 ; loss:  -2.2787811756134033 ; pred:  tensor([0.0172, 0.0485, 0.8891, 0.0451], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842,
        0.2842, 0.8714, 0.9014, 0.2721, 0.8897, 0.9622, 0.9622, 0.9622, 0.9622,
        0.9622, 0.9622, 0.9622, 0.9622, 0.9622, 0.8633],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842,
                      0.2842, 0.2842, 0.2842, 0.8714, 0.9014, 0.2721, 0.8897,
                      0.9622, 0.9622, 0.9622, 0.9622, 0.9622, 0.9622, 0.9622,
                      0.9622, 0.9622, 0.8633]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0157, 0.0445, 0.8969, 0.0429], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8969], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.8714, 0.9014, 0.8897, 0.9622, 0.9622, 0.9622, 0.9622, 0.9622, 0.9622,
        0.9622, 0.9622, 0.9622, 0.8633], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1089], grad_fn=<MulBackward0>)
size_loss tensor(-15.8011, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([-14.1610], grad_fn=<AddBackward0>)
5
epoch:  5 ; loss:  -14.160993576049805 ; pred:  tensor([0.0157, 0.0445, 0.8969, 0.0429], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
        0.2364, 0.8289, 0.8700, 0.2230, 0.8537, 0.9742, 0.9742, 0.9742, 0.9742,
        0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.8181],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
                      0.2364, 0.2364, 0.2364, 0.8289, 0.8700, 0.2230, 0.8537,
                      0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.9742,
                      0.9742, 0.9742, 0.8181]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0149, 0.0422, 0.9010, 0.0419], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.9010], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.8289, 0.8700, 0.8537, 0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.9742,
        0.9742, 0.9742, 0.9742, 0.8181], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1043], grad_fn=<MulBackward0>)
size_loss tensor(-41.3103, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([-39.6748], grad_fn=<AddBackward0>)
6
epoch:  6 ; loss:  -39.67479705810547 ; pred:  tensor([0.0149, 0.0422, 0.9010, 0.0419], grad_fn=<SoftmaxBackward0>)
Finished Training
masked_ver tensor(indices=tensor([[ 23430,  23444,  23490,  23546,  24301,  24407,  24427,
                         24475,  24503,  24543,  88607, 196312, 229452, 254307,
                        254307, 254307, 254307, 254307, 254307, 254307, 254307,
                        254307, 254307, 328872],
                       [  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,    908,   2227,   1002,   6860,
                          6874,   6920,   6976,   7731,   7837,   7857,   7905,
                          7933,   7973,   5230]]),
       values=tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
                      0.2364, 0.2364, 0.2364, 0.8289, 0.8700, 0.2230, 0.8537,
                      0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.9742,
                      0.9742, 0.9742, 0.8181]),
       size=(753935, 8285), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
sel masked ver tensor(indices=tensor([[5757, 5757, 5757, 5757, 5757, 5757, 5757, 5757, 5757,
                        5757, 5757, 5757, 5757],
                       [ 908, 2227, 6860, 6874, 6920, 6976, 7731, 7837, 7857,
                        7905, 7933, 7973, 5230]]),
       values=tensor([0.8289, 0.8700, 0.8537, 0.9742, 0.9742, 0.9742, 0.9742,
                      0.9742, 0.9742, 0.9742, 0.9742, 0.9742, 0.8181]),
       size=(5758, 7974), nnz=13, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/networkx/drawing/nx_pylab.py:433: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  node_collection = ax.scatter(
Counter({'publication': 10, 'fax': 1, 'name': 1, 'type': 1})
dict index: {}
ypred explain tensor([0.0149, 0.0422, 0.9010, 0.0419], grad_fn=<SoftmaxBackward0>)
ypred full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>)