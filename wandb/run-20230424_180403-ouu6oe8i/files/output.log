[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:221: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:247: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
node_idx 5757
masked_adj tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0609, 0.1418, 0.6873, 0.1100], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.6873], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.3750], grad_fn=<MulBackward0>)
size_loss tensor(-3.7072e-13, grad_fn=<MulBackward0>)
size_num_loss 0.72
loss: tensor([1.0950], grad_fn=<AddBackward0>)
0
epoch:  0 ; loss:  1.095016360282898 ; pred:  tensor([0.0609, 0.1418, 0.6873, 0.1100], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
        0.6225, 0.8176, 0.8176, 0.6225, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
        0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
                      0.6225, 0.6225, 0.6225, 0.8176, 0.8176, 0.6225, 0.8176,
                      0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
                      0.8176, 0.8176, 0.8176]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0389, 0.0989, 0.7813, 0.0809], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.7813], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
        0.6225, 0.8176, 0.8176, 0.6225, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
        0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.2468], grad_fn=<MulBackward0>)
size_loss tensor(-0.9862, grad_fn=<MulBackward0>)
size_num_loss 0.72
loss: tensor([-0.0194], grad_fn=<AddBackward0>)
1
epoch:  1 ; loss:  -0.019435644149780273 ; pred:  tensor([0.0389, 0.0989, 0.7813, 0.0809], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
        0.5316, 0.8691, 0.8713, 0.5256, 0.8707, 0.8737, 0.8737, 0.8737, 0.8737,
        0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8678],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
                      0.5316, 0.5316, 0.5316, 0.8691, 0.8713, 0.5256, 0.8707,
                      0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8737,
                      0.8737, 0.8737, 0.8678]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0278, 0.0743, 0.8343, 0.0636], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8343], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
        0.5316, 0.8691, 0.8713, 0.5256, 0.8707, 0.8737, 0.8737, 0.8737, 0.8737,
        0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8678],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.1811], grad_fn=<MulBackward0>)
size_loss tensor(-3.0206, grad_fn=<MulBackward0>)
size_num_loss 0.72
loss: tensor([-2.1195], grad_fn=<AddBackward0>)
2
epoch:  2 ; loss:  -2.1195061206817627 ; pred:  tensor([0.0278, 0.0743, 0.8343, 0.0636], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,
        0.4275, 0.9115, 0.9139, 0.4195, 0.9132, 0.9164, 0.9164, 0.9164, 0.9164,
        0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9101],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,
                      0.4275, 0.4275, 0.4275, 0.9115, 0.9139, 0.4195, 0.9132,
                      0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164,
                      0.9164, 0.9164, 0.9101]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0208, 0.0576, 0.8700, 0.0515], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8700], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9115, 0.9139, 0.9132, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164,
        0.9164, 0.9164, 0.9164, 0.9101], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1392], grad_fn=<MulBackward0>)
size_loss tensor(-0.0005, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([1.6700], grad_fn=<AddBackward0>)
3
epoch:  3 ; loss:  1.6699786186218262 ; pred:  tensor([0.0208, 0.0576, 0.8700, 0.0515], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465,
        0.3465, 0.9360, 0.9387, 0.3362, 0.9380, 0.9415, 0.9415, 0.9415, 0.9415,
        0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9345],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465,
                      0.3465, 0.3465, 0.3465, 0.9360, 0.9387, 0.3362, 0.9380,
                      0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415,
                      0.9415, 0.9415, 0.9345]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0174, 0.0488, 0.8889, 0.0449], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8889], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9360, 0.9387, 0.9380, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415,
        0.9415, 0.9415, 0.9415, 0.9345], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1178], grad_fn=<MulBackward0>)
size_loss tensor(-0.0006, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([1.6485], grad_fn=<AddBackward0>)
4
epoch:  4 ; loss:  1.6484647989273071 ; pred:  tensor([0.0174, 0.0488, 0.8889, 0.0449], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842,
        0.2842, 0.9513, 0.9541, 0.2721, 0.9535, 0.9571, 0.9571, 0.9571, 0.9571,
        0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9496],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842,
                      0.2842, 0.2842, 0.2842, 0.9513, 0.9541, 0.2721, 0.9535,
                      0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571,
                      0.9571, 0.9571, 0.9496]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0154, 0.0437, 0.8998, 0.0411], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8998], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9513, 0.9541, 0.9535, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571,
        0.9571, 0.9571, 0.9571, 0.9496], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1056], grad_fn=<MulBackward0>)
size_loss tensor(-0.0007, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([1.6361], grad_fn=<AddBackward0>)
5
epoch:  5 ; loss:  1.63613760471344 ; pred:  tensor([0.0154, 0.0437, 0.8998, 0.0411], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
        0.2364, 0.9613, 0.9643, 0.2230, 0.9636, 0.9673, 0.9673, 0.9673, 0.9673,
        0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9596],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
                      0.2364, 0.2364, 0.2364, 0.9613, 0.9643, 0.2230, 0.9636,
                      0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673,
                      0.9673, 0.9673, 0.9596]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0142, 0.0405, 0.9067, 0.0387], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.9067], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9613, 0.9643, 0.9636, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673,
        0.9673, 0.9673, 0.9673, 0.9596], grad_fn=<IndexBackward0>)
pred_loss tensor([0.0980], grad_fn=<MulBackward0>)
size_loss tensor(-0.0007, grad_fn=<MulBackward0>)
size_num_loss 1.53125
loss: tensor([1.6285], grad_fn=<AddBackward0>)
6
epoch:  6 ; loss:  1.6284996271133423 ; pred:  tensor([0.0142, 0.0405, 0.9067, 0.0387], grad_fn=<SoftmaxBackward0>)
Finished Training
masked_ver tensor(indices=tensor([[ 23430,  23444,  23490,  23546,  24301,  24407,  24427,
                         24475,  24503,  24543,  88607, 196312, 229452, 254307,
                        254307, 254307, 254307, 254307, 254307, 254307, 254307,
                        254307, 254307, 328872],
                       [  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,    908,   2227,   1002,   6860,
                          6874,   6920,   6976,   7731,   7837,   7857,   7905,
                          7933,   7973,   5230]]),
       values=tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
                      0.2364, 0.2364, 0.2364, 0.9613, 0.9643, 0.2230, 0.9636,
                      0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673,
                      0.9673, 0.9673, 0.9596]),
       size=(753935, 8285), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
sel masked ver tensor(indices=tensor([[5757, 5757, 5757, 5757, 5757, 5757, 5757, 5757, 5757,
                        5757, 5757, 5757, 5757],
                       [ 908, 2227, 6860, 6874, 6920, 6976, 7731, 7837, 7857,
                        7905, 7933, 7973, 5230]]),
       values=tensor([0.9613, 0.9643, 0.9636, 0.9673, 0.9673, 0.9673, 0.9673,
                      0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9596]),
       size=(5758, 7974), nnz=13, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
Counter({'publication': 10, 'fax': 1, 'name': 1, 'type': 1})
dict index: {}
/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/networkx/drawing/nx_pylab.py:433: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  node_collection = ax.scatter(
ypred explain tensor([0.0142, 0.0405, 0.9067, 0.0387], grad_fn=<SoftmaxBackward0>)
ypred full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>)