  0%|                                                                                                                                                   | 0/10 [00:00<?, ?it/s]/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r.py:126: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
7
start training
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.7649, 0.7444, 0.7550, 0.7546, 0.5986, 0.7110, 0.8985]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(0.3572, grad_fn=<SelectBackward0>)
mask_without_small tensor([0.7649, 0.7444, 0.7550, 0.7546, 0.5986, 0.7110, 0.8985],
       grad_fn=<IndexBackward0>)
num_high 7 original num_nodes 7
pred_loss tensor(1.0295, grad_fn=<MulBackward0>)
size_loss tensor(0.4449, grad_fn=<AddBackward0>)
size_num_loss 1.0
 10%|█████████████▉                                                                                                                             | 1/10 [00:29<04:29, 29.99s/it]
epoch:  0 ; loss:  2.4743752479553223 ; pred:  tensor([0.3572, 0.2205, 0.2761, 0.1462], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.6637, 0.6385, 0.8355, 0.6509, 0.4750, 0.5988, 0.9359]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.6637, 0.6385, 0.8355, 0.6509, 0.5988, 0.9359],
       grad_fn=<IndexBackward0>)
num_high 6 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(1.9832, grad_fn=<AddBackward0>)
size_num_loss 0.8571428571428571
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.5729, 0.5434, 0.8637, 0.5495, 0.3929, 0.4965, 0.9583]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.5729, 0.5434, 0.8637, 0.5495, 0.9583], grad_fn=<IndexBackward0>)
num_high 5 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(1.3519, grad_fn=<AddBackward0>)

 20%|███████████████████████████▊                                                                                                               | 2/10 [00:56<03:42, 27.83s/it]
epoch:  2 ; loss:  2.0661826133728027 ; pred:  tensor([1.0000e+00, 1.0180e-27, 2.1374e-27, 1.6413e-27],
       grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.4668, 0.4360, 0.9010, 0.4396, 0.3331, 0.4172, 0.9733]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,

 30%|█████████████████████████████████████████▋                                                                                                 | 3/10 [01:21<03:06, 26.70s/it]
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9010, 0.9733], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9110, grad_fn=<AddBackward0>)

 40%|███████████████████████████████████████████████████████▌                                                                                   | 4/10 [01:46<02:36, 26.07s/it]
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.3816, 0.3519, 0.9245, 0.3534, 0.2877, 0.3551, 0.9816]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9245, 0.9816], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9368, grad_fn=<AddBackward0>)

 50%|█████████████████████████████████████████████████████████████████████▌                                                                     | 5/10 [02:10<02:06, 25.34s/it]
epoch:  4 ; loss:  -0.0 ; pred:  tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.3147, 0.2871, 0.9402, 0.2870, 0.2524, 0.3060, 0.9866]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9402, 0.9866], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9527, grad_fn=<AddBackward0>)

 60%|███████████████████████████████████████████████████████████████████████████████████▍                                                       | 6/10 [02:37<01:42, 25.64s/it]
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.2625, 0.2374, 0.9513, 0.2363, 0.2244, 0.2670, 0.9898]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9513, 0.9898], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9631, grad_fn=<AddBackward0>)

 70%|█████████████████████████████████████████████████████████████████████████████████████████████████▎                                         | 7/10 [03:01<01:15, 25.28s/it]
epoch:  6 ; loss:  -0.0 ; pred:  tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.2217, 0.1991, 0.9593, 0.1973, 0.2018, 0.2356, 0.9920]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9593, 0.9920], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9703, grad_fn=<AddBackward0>)
size_num_loss 0.2857142857142857
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.1897, 0.1694, 0.9654, 0.1671, 0.1833, 0.2101, 0.9935]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9654, 0.9935], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9755, grad_fn=<AddBackward0>)

 80%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████▏                           | 8/10 [03:25<00:49, 24.83s/it]
epoch:  8 ; loss:  -0.0 ; pred:  tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
masked_hor: tensor(indices=tensor([[  5724,   5724,   5724,   5724,   5724,   5724,   7327],
                       [ 82850, 127437, 195107, 223695, 255877, 328345,  22294]]),
       values=tensor([0.1644, 0.1461, 0.9700, 0.1436, 0.1680, 0.1893, 0.9946]),
       size=(8285, 753935), nnz=7, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
gt_label_node tensor(0, dtype=torch.int32)
gt_label_node <class 'torch.Tensor'>
logit tensor(1., grad_fn=<SelectBackward0>)
mask_without_small tensor([0.9700, 0.9946], grad_fn=<IndexBackward0>)
num_high 2 original num_nodes 7
pred_loss tensor(-0., grad_fn=<MulBackward0>)
size_loss tensor(0.9792, grad_fn=<AddBackward0>)

 90%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████              | 9/10 [03:51<00:25, 25.29s/it]
sel masked ver tensor(indices=tensor([[5724, 5724],
                       [3162, 5230]]),
       values=tensor([0.9700, 0.9946]),
       size=(5725, 5231), nnz=2, layout=torch.sparse_coo,

100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [04:18<00:00, 25.80s/it]
Counter({'homepage': 1, 'type': 1})
dict index: {}
/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/networkx/drawing/nx_pylab.py:433: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  node_collection = ax.scatter(
ypred explain tensor([1., 0., 0., 0.], grad_fn=<SoftmaxBackward0>)
ypred full tensor([0.4840, 0.2345, 0.2195, 0.0620], grad_fn=<SoftmaxBackward0>)
original label [0]
num mislabel 1
num correct 34