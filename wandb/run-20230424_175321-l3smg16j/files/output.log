loaded data aifb (0.158s).
Number of entities: 8285
Number of classes: 4
Types of relations: 45
['abstract', 'address', 'author', 'booktitle', 'carriedOutBy', 'carriesOut', 'chapter', 'dealtWithIn', 'edition', 'editor', 'fax', 'financedBy', 'finances', 'hasProject', 'head', 'homepage', 'howpublished', 'isAbout', 'isWorkedOnBy', 'isbn', 'journal', 'member', 'month', 'name', 'note', 'number', 'pages', 'phone', 'photo', 'projectInfo', 'publication', 'publishes', 'series', 'title', 'type', 'volume', 'worksAtProject', 'year', 'type', 'type', 'range', 'subClassOf', 'allValuesFrom', 'inverseOf', 'onProperty']
node_idx 5757
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:364: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.triples = torch.tensor(data.triples)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:365: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.withheld = torch.tensor(data.withheld)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:366: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  data.training = torch.tensor(data.training)
node label: 2
14
neigh graph idx:  <__main__.Explainer object at 0x7fe358cf41c0> 5757 0
Node predicted label:  tensor(2)
torch.Size([24])
node_idx 5757
masked_adj tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
                      0.7311, 0.7311, 0.7311]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0609, 0.1418, 0.6873, 0.1100], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.6873], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311,
        0.7311, 0.7311, 0.7311, 0.7311, 0.7311, 0.7311],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.3750], grad_fn=<MulBackward0>)
size_loss tensor(-3.7072e-13, grad_fn=<MulBackward0>)
size_num_loss 72.0
loss: tensor([72.3750], grad_fn=<AddBackward0>)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  hor_graph, ver_graph = torch.tensor(sub_hor_graph, dtype=torch.float), torch.tensor(sub_ver_graph, dtype=torch.float)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  adj = torch.tensor(adj)
0
epoch:  0 ; loss:  72.37501525878906 ; pred:  tensor([0.0609, 0.1418, 0.6873, 0.1100], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
        0.6225, 0.8176, 0.8176, 0.6225, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
        0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
                      0.6225, 0.6225, 0.6225, 0.8176, 0.8176, 0.6225, 0.8176,
                      0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
                      0.8176, 0.8176, 0.8176]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0389, 0.0989, 0.7813, 0.0809], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.7813], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225, 0.6225,
        0.6225, 0.8176, 0.8176, 0.6225, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176,
        0.8176, 0.8176, 0.8176, 0.8176, 0.8176, 0.8176],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.2468], grad_fn=<MulBackward0>)
size_loss tensor(-0.9862, grad_fn=<MulBackward0>)
size_num_loss 72.0
loss: tensor([71.2606], grad_fn=<AddBackward0>)
1
epoch:  1 ; loss:  71.26056671142578 ; pred:  tensor([0.0389, 0.0989, 0.7813, 0.0809], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
        0.5316, 0.8691, 0.8713, 0.5256, 0.8707, 0.8737, 0.8737, 0.8737, 0.8737,
        0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8678],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
                      0.5316, 0.5316, 0.5316, 0.8691, 0.8713, 0.5256, 0.8707,
                      0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8737,
                      0.8737, 0.8737, 0.8678]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0278, 0.0743, 0.8343, 0.0636], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8343], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316, 0.5316,
        0.5316, 0.8691, 0.8713, 0.5256, 0.8707, 0.8737, 0.8737, 0.8737, 0.8737,
        0.8737, 0.8737, 0.8737, 0.8737, 0.8737, 0.8678],
       grad_fn=<IndexBackward0>)
pred_loss tensor([0.1811], grad_fn=<MulBackward0>)
size_loss tensor(-3.0206, grad_fn=<MulBackward0>)
size_num_loss 72.0
loss: tensor([69.1605], grad_fn=<AddBackward0>)
2
epoch:  2 ; loss:  69.16049194335938 ; pred:  tensor([0.0278, 0.0743, 0.8343, 0.0636], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,
        0.4275, 0.9115, 0.9139, 0.4195, 0.9132, 0.9164, 0.9164, 0.9164, 0.9164,
        0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9101],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275, 0.4275,
                      0.4275, 0.4275, 0.4275, 0.9115, 0.9139, 0.4195, 0.9132,
                      0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164,
                      0.9164, 0.9164, 0.9101]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0208, 0.0576, 0.8700, 0.0515], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8700], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9115, 0.9139, 0.9132, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164, 0.9164,
        0.9164, 0.9164, 0.9164, 0.9101], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1392], grad_fn=<MulBackward0>)
size_loss tensor(-0.0005, grad_fn=<MulBackward0>)
size_num_loss 153.125
loss: tensor([153.2637], grad_fn=<AddBackward0>)
3
epoch:  3 ; loss:  153.26373291015625 ; pred:  tensor([0.0208, 0.0576, 0.8700, 0.0515], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465,
        0.3465, 0.9360, 0.9387, 0.3362, 0.9380, 0.9415, 0.9415, 0.9415, 0.9415,
        0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9345],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465, 0.3465,
                      0.3465, 0.3465, 0.3465, 0.9360, 0.9387, 0.3362, 0.9380,
                      0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415,
                      0.9415, 0.9415, 0.9345]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0174, 0.0488, 0.8889, 0.0449], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8889], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9360, 0.9387, 0.9380, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415, 0.9415,
        0.9415, 0.9415, 0.9415, 0.9345], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1178], grad_fn=<MulBackward0>)
size_loss tensor(-0.0006, grad_fn=<MulBackward0>)
size_num_loss 153.125
loss: tensor([153.2422], grad_fn=<AddBackward0>)
4
epoch:  4 ; loss:  153.24221801757812 ; pred:  tensor([0.0174, 0.0488, 0.8889, 0.0449], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842,
        0.2842, 0.9513, 0.9541, 0.2721, 0.9535, 0.9571, 0.9571, 0.9571, 0.9571,
        0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9496],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842, 0.2842,
                      0.2842, 0.2842, 0.2842, 0.9513, 0.9541, 0.2721, 0.9535,
                      0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571,
                      0.9571, 0.9571, 0.9496]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0154, 0.0437, 0.8998, 0.0411], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.8998], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9513, 0.9541, 0.9535, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571, 0.9571,
        0.9571, 0.9571, 0.9571, 0.9496], grad_fn=<IndexBackward0>)
pred_loss tensor([0.1056], grad_fn=<MulBackward0>)
size_loss tensor(-0.0007, grad_fn=<MulBackward0>)
size_num_loss 153.125
loss: tensor([153.2299], grad_fn=<AddBackward0>)
5
epoch:  5 ; loss:  153.22988891601562 ; pred:  tensor([0.0154, 0.0437, 0.8998, 0.0411], grad_fn=<SoftmaxBackward0>)
node_idx 5757
masked_adj tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
        0.2364, 0.9613, 0.9643, 0.2230, 0.9636, 0.9673, 0.9673, 0.9673, 0.9673,
        0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9596],
       grad_fn=<MulBackward0>)
masked_hor tensor(indices=tensor([[  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          6860,   6874,   6920,   6976,   7731,   7837,   7857,
                          7905,   7933,   7973],
                       [ 83758, 192782, 224697, 255410, 255424, 255470, 255526,
                        256281, 256387, 256407, 256455, 256483, 256523, 328345,
                         22327,  22327,  22327,  22327,  22327,  22327,  22327,
                         22327,  22327,  22327]]),
       values=tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
                      0.2364, 0.2364, 0.2364, 0.9613, 0.9643, 0.2230, 0.9636,
                      0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673,
                      0.9673, 0.9673, 0.9596]),
       size=(8285, 753935), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
ypred tensor([[ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        ...,
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028],
        [ 0.1214, -0.0644,  0.0171, -0.1028]], grad_fn=<AddBackward0>)
res: tensor([0.0142, 0.0405, 0.9067, 0.0387], grad_fn=<SoftmaxBackward0>)
label tensor([2])
logit tensor([0.9067], grad_fn=<IndexBackward0>)
mask_without_small tensor([0.9613, 0.9643, 0.9636, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673,
        0.9673, 0.9673, 0.9673, 0.9596], grad_fn=<IndexBackward0>)
pred_loss tensor([0.0980], grad_fn=<MulBackward0>)
size_loss tensor(-0.0007, grad_fn=<MulBackward0>)
size_num_loss 153.125
loss: tensor([153.2222], grad_fn=<AddBackward0>)
6
epoch:  6 ; loss:  153.2222442626953 ; pred:  tensor([0.0142, 0.0405, 0.9067, 0.0387], grad_fn=<SoftmaxBackward0>)
Finished Training
masked_ver tensor(indices=tensor([[ 23430,  23444,  23490,  23546,  24301,  24407,  24427,
                         24475,  24503,  24543,  88607, 196312, 229452, 254307,
                        254307, 254307, 254307, 254307, 254307, 254307, 254307,
                        254307, 254307, 328872],
                       [  5757,   5757,   5757,   5757,   5757,   5757,   5757,
                          5757,   5757,   5757,    908,   2227,   1002,   6860,
                          6874,   6920,   6976,   7731,   7837,   7857,   7905,
                          7933,   7973,   5230]]),
       values=tensor([0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364, 0.2364,
                      0.2364, 0.2364, 0.2364, 0.9613, 0.9643, 0.2230, 0.9636,
                      0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9673,
                      0.9673, 0.9673, 0.9596]),
       size=(753935, 8285), nnz=24, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
sel masked ver tensor(indices=tensor([[5757, 5757, 5757, 5757, 5757, 5757, 5757, 5757, 5757,
                        5757, 5757, 5757, 5757],
                       [ 908, 2227, 6860, 6874, 6920, 6976, 7731, 7837, 7857,
                        7905, 7933, 7973, 5230]]),
       values=tensor([0.9613, 0.9643, 0.9636, 0.9673, 0.9673, 0.9673, 0.9673,
                      0.9673, 0.9673, 0.9673, 0.9673, 0.9673, 0.9596]),
       size=(5758, 7974), nnz=13, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/networkx/drawing/nx_pylab.py:433: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  node_collection = ax.scatter(
Counter({'publication': 10, 'fax': 1, 'name': 1, 'type': 1})
dict index: {}
ypred explain tensor([0.0142, 0.0405, 0.9067, 0.0387], grad_fn=<SoftmaxBackward0>)
ypred full tensor([1.2879e-20, 7.0437e-17, 1.0000e+00, 1.2028e-17],
       grad_fn=<SoftmaxBackward0>)