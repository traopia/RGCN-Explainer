
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
masked_adj tensor([0.7773, 0.7672, 0.7534, 0.6742, 0.7480, 0.6985, 0.7300, 0.6883, 0.7115,
        0.7710, 0.7209, 0.6938, 0.7121, 0.7166, 0.7110, 0.7500, 0.7708, 0.7270,
        0.7182, 0.7421, 0.7113, 0.7576, 0.7510, 0.7717, 0.7624, 0.7628, 0.7463,
        0.7637, 0.7251, 0.7321, 0.7246, 0.7524, 0.6943, 0.7083, 0.7253, 0.7725,
        0.7391, 0.7201, 0.7388, 0.7109, 0.6896, 0.7557, 0.7081, 0.7155, 0.6974,
        0.7816, 0.6985, 0.7184, 0.7071, 0.7140, 0.7330, 0.7442, 0.7184, 0.7603,
        0.7098, 0.7119, 0.6938, 0.7320, 0.7294, 0.7479, 0.7286, 0.7754, 0.6998,
        0.7648, 0.7663, 0.7523, 0.7837, 0.7442, 0.7398, 0.7260, 0.7033, 0.7624,
        0.7266, 0.7442, 0.7325, 0.7418, 0.7455, 0.7144, 0.6713, 0.7115, 0.7313,
        0.7223, 0.6955, 0.7159, 0.7445, 0.7442, 0.7591, 0.7324, 0.7496, 0.7186,
        0.7035, 0.7462, 0.6850, 0.7094, 0.7637, 0.7432, 0.6625, 0.7433, 0.7506,
        0.7318, 0.7471, 0.7457, 0.7574, 0.7443, 0.7565, 0.7127, 0.7561, 0.7225,
        0.7440, 0.7408, 0.7160, 0.7414, 0.7162, 0.7438, 0.7188, 0.7183, 0.7379,
        0.7165, 0.7480], grad_fn=<MulBackward0>)
res: tensor([9.9855e-01, 6.6735e-04, 9.8767e-05, 6.8133e-04],
       grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.7773, 0.7672, 0.7534, 0.6742, 0.7480, 0.6985, 0.7300, 0.6883, 0.7115,
        0.7710, 0.7209, 0.6938, 0.7121, 0.7166, 0.7110, 0.7500, 0.7708, 0.7270,
        0.7182, 0.7421, 0.7113, 0.7576, 0.7510, 0.7717, 0.7624, 0.7628, 0.7463,
        0.7637, 0.7251, 0.7321, 0.7246, 0.7524, 0.6943, 0.7083, 0.7253, 0.7725,
        0.7391, 0.7201, 0.7388, 0.7109, 0.6896, 0.7557, 0.7081, 0.7155, 0.6974,
        0.7816, 0.6985, 0.7184, 0.7071, 0.7140, 0.7330, 0.7442, 0.7184, 0.7603,
        0.7098, 0.7119, 0.6938, 0.7320, 0.7294, 0.7479, 0.7286, 0.7754, 0.6998,
        0.7648, 0.7663, 0.7523, 0.7837, 0.7442, 0.7398, 0.7260, 0.7033, 0.7624,
        0.7266, 0.7442, 0.7325, 0.7418, 0.7455, 0.7144, 0.6713, 0.7115, 0.7313,
        0.7223, 0.6955, 0.7159, 0.7445, 0.7442, 0.7591, 0.7324, 0.7496, 0.7186,
        0.7035, 0.7462, 0.6850, 0.7094, 0.7637, 0.7432, 0.6625, 0.7433, 0.7506,
        0.7318, 0.7471, 0.7457, 0.7574, 0.7443, 0.7565, 0.7127, 0.7561, 0.7225,
        0.7440, 0.7408, 0.7160, 0.7414, 0.7162, 0.7438, 0.7188, 0.7183, 0.7379,
        0.7165, 0.7480], grad_fn=<IndexBackward0>)
num_high 119 len(mask) 119
pred_loss tensor([0.0014], grad_fn=<MulBackward0>)
size_loss tensor(8.7027, grad_fn=<AddBackward0>)
size_num_loss 1.0000008403361345
loss: tensor([10.2840], grad_fn=<AddBackward0>)
0
epoch:  0 ; loss:  10.283982276916504 ; pred:  tensor([9.9855e-01, 6.6735e-04, 9.8767e-05, 6.8133e-04],
       grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.6791, 0.6666, 0.6495, 0.5565, 0.6429, 0.5842, 0.6211, 0.5725, 0.5993,
        0.6712, 0.6104, 0.5788, 0.6000, 0.6053, 0.5988, 0.6454, 0.6710, 0.6176,
        0.6072, 0.6358, 0.5991, 0.6547, 0.6465, 0.6721, 0.6606, 0.6611, 0.6409,
        0.6622, 0.6154, 0.6237, 0.6148, 0.6483, 0.5794, 0.5956, 0.6156, 0.6732,
        0.6321, 0.6094, 0.6317, 0.5986, 0.5740, 0.6523, 0.5953, 0.6040, 0.5829,
        0.6846, 0.5842, 0.6075, 0.5942, 0.6022, 0.6248, 0.6383, 0.6075, 0.6580,
        0.5974, 0.5998, 0.5789, 0.6236, 0.6205, 0.6428, 0.6195, 0.6768, 0.5858,
        0.6636, 0.6654, 0.6482, 0.6873, 0.6383, 0.6330, 0.6164, 0.5898, 0.6605,
        0.6172, 0.6383, 0.6242, 0.6354, 0.6398, 0.6027, 0.5533, 0.5993, 0.6228,
        0.6121, 0.5808, 0.6045, 0.6387, 0.6383, 0.6565, 0.6240, 0.6448, 0.6077,
        0.5900, 0.6407, 0.5687, 0.5969, 0.6622, 0.6371, 0.5436, 0.6372, 0.6460,
        0.6233, 0.6418, 0.6401, 0.6544, 0.6384, 0.6533, 0.6008, 0.6528, 0.6123,
        0.6381, 0.6342, 0.6046, 0.6349, 0.6048, 0.6378, 0.6079, 0.6074, 0.6307,
        0.6052, 0.6429], grad_fn=<MulBackward0>)
res: tensor([0.9885, 0.0053, 0.0013, 0.0049], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.6791, 0.6666, 0.6495, 0.5565, 0.6429, 0.5842, 0.6211, 0.5725, 0.5993,
        0.6712, 0.6104, 0.5788, 0.6000, 0.6053, 0.5988, 0.6454, 0.6710, 0.6176,
        0.6072, 0.6358, 0.5991, 0.6547, 0.6465, 0.6721, 0.6606, 0.6611, 0.6409,
        0.6622, 0.6154, 0.6237, 0.6148, 0.6483, 0.5794, 0.5956, 0.6156, 0.6732,
        0.6321, 0.6094, 0.6317, 0.5986, 0.5740, 0.6523, 0.5953, 0.6040, 0.5829,
        0.6846, 0.5842, 0.6075, 0.5942, 0.6022, 0.6248, 0.6383, 0.6075, 0.6580,
        0.5974, 0.5998, 0.5789, 0.6236, 0.6205, 0.6428, 0.6195, 0.6768, 0.5858,
        0.6636, 0.6654, 0.6482, 0.6873, 0.6383, 0.6330, 0.6164, 0.5898, 0.6605,
        0.6172, 0.6383, 0.6242, 0.6354, 0.6398, 0.6027, 0.5533, 0.5993, 0.6228,
        0.6121, 0.5808, 0.6045, 0.6387, 0.6383, 0.6565, 0.6240, 0.6448, 0.6077,
        0.5900, 0.6407, 0.5687, 0.5969, 0.6622, 0.6371, 0.5436, 0.6372, 0.6460,
        0.6233, 0.6418, 0.6401, 0.6544, 0.6384, 0.6533, 0.6008, 0.6528, 0.6123,
        0.6381, 0.6342, 0.6046, 0.6349, 0.6048, 0.6378, 0.6079, 0.6074, 0.6307,
        0.6052, 0.6429], grad_fn=<IndexBackward0>)
num_high 119 len(mask) 119
pred_loss tensor([0.0116], grad_fn=<MulBackward0>)
size_loss tensor(7.4144, grad_fn=<AddBackward0>)
size_num_loss 1.0000008403361345
loss: tensor([9.0863], grad_fn=<AddBackward0>)
1
epoch:  1 ; loss:  9.08627700805664 ; pred:  tensor([0.9885, 0.0053, 0.0013, 0.0049], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.5657, 0.5519, 0.5334, 0.4398, 0.5263, 0.4663, 0.5036, 0.4550, 0.4813,
        0.5570, 0.4926, 0.4611, 0.4821, 0.4873, 0.4808, 0.5290, 0.5567, 0.4999,
        0.4893, 0.5188, 0.4811, 0.5390, 0.5302, 0.5580, 0.5453, 0.5459, 0.5242,
        0.5471, 0.4976, 0.5062, 0.4970, 0.5321, 0.4617, 0.4776, 0.4979, 0.5591,
        0.5150, 0.4916, 0.5148, 0.4806, 0.4564, 0.5364, 0.4773, 0.4860, 0.4651,
        0.5718, 0.4663, 0.4896, 0.4763, 0.4843, 0.5074, 0.5215, 0.4896, 0.5425,
        0.4794, 0.4818, 0.4611, 0.5061, 0.5029, 0.5263, 0.5018, 0.5631, 0.4680,
        0.5486, 0.5506, 0.5320, 0.5748, 0.5215, 0.5159, 0.4988, 0.4720, 0.5454,
        0.4996, 0.5215, 0.5068, 0.5185, 0.5231, 0.4849, 0.4369, 0.4814, 0.5053,
        0.4944, 0.4634, 0.4868, 0.5219, 0.5218, 0.5412, 0.5068, 0.5286, 0.4901,
        0.4724, 0.5241, 0.4520, 0.4792, 0.5474, 0.5205, 0.4285, 0.5206, 0.5300,
        0.5060, 0.5253, 0.5234, 0.5387, 0.5217, 0.5376, 0.4829, 0.5370, 0.4947,
        0.5214, 0.5173, 0.4868, 0.5180, 0.4870, 0.5210, 0.4901, 0.4896, 0.5147,
        0.4874, 0.5265], grad_fn=<MulBackward0>)
res: tensor([0.9274, 0.0321, 0.0122, 0.0283], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.5657, 0.5519, 0.5334, 0.5263, 0.5036, 0.5570, 0.5290, 0.5567, 0.5188,
        0.5390, 0.5302, 0.5580, 0.5453, 0.5459, 0.5242, 0.5471, 0.5062, 0.5321,
        0.5591, 0.5150, 0.5148, 0.5364, 0.5718, 0.5074, 0.5215, 0.5425, 0.5061,
        0.5029, 0.5263, 0.5018, 0.5631, 0.5486, 0.5506, 0.5320, 0.5748, 0.5215,
        0.5159, 0.5454, 0.5215, 0.5068, 0.5185, 0.5231, 0.5053, 0.5219, 0.5218,
        0.5412, 0.5068, 0.5286, 0.5241, 0.5474, 0.5205, 0.5206, 0.5300, 0.5060,
        0.5253, 0.5234, 0.5387, 0.5217, 0.5376, 0.5370, 0.5214, 0.5173, 0.5180,
        0.5210, 0.5147, 0.5265], grad_fn=<IndexBackward0>)
num_high 66 len(mask) 119
pred_loss tensor([0.0753], grad_fn=<MulBackward0>)
size_loss tensor(-0.3221, grad_fn=<MulBackward0>)
size_num_loss 0.5546226890756303
loss: tensor([0.9990], grad_fn=<AddBackward0>)
2
epoch:  2 ; loss:  0.9989820718765259 ; pred:  tensor([0.9274, 0.0321, 0.0122, 0.0283], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.5783, 0.5367, 0.4476, 0.3711, 0.4171, 0.3858, 0.3874, 0.3792, 0.3954,
        0.5542, 0.4031, 0.3827, 0.3959, 0.3994, 0.3950, 0.4272, 0.5535, 0.4083,
        0.4008, 0.3988, 0.3953, 0.4772, 0.4325, 0.5573, 0.5091, 0.5116, 0.4104,
        0.5183, 0.4066, 0.3885, 0.4062, 0.4412, 0.3831, 0.3930, 0.4068, 0.5608,
        0.3940, 0.4024, 0.3940, 0.3949, 0.3800, 0.4633, 0.3928, 0.3986, 0.3851,
        0.5920, 0.3858, 0.4010, 0.3921, 0.3974, 0.3890, 0.4038, 0.4010, 0.4957,
        0.3941, 0.3957, 0.3827, 0.3884, 0.3872, 0.4168, 0.3868, 0.5718, 0.3889,
        0.5239, 0.5321, 0.4415, 0.5980, 0.4040, 0.3951, 0.4083, 0.3913, 0.5121,
        0.4095, 0.4042, 0.3886, 0.3985, 0.4081, 0.4000, 0.3721, 0.3955, 0.3881,
        0.4061, 0.3891, 0.4034, 0.4048, 0.4058, 0.4954, 0.3885, 0.4288, 0.4062,
        0.3950, 0.4113, 0.3869, 0.3970, 0.5241, 0.4033, 0.3754, 0.4029, 0.4365,
        0.3882, 0.4145, 0.4089, 0.4773, 0.4048, 0.4723, 0.3986, 0.4686, 0.4068,
        0.4039, 0.3968, 0.4011, 0.3978, 0.4008, 0.4034, 0.4033, 0.4028, 0.3957,
        0.4018, 0.4188], grad_fn=<MulBackward0>)
res: tensor([0.7897, 0.0880, 0.0464, 0.0758], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.5783, 0.5367, 0.5542, 0.5535, 0.5573, 0.5091, 0.5116, 0.5183, 0.5608,
        0.5920, 0.5718, 0.5239, 0.5321, 0.5980, 0.5121, 0.5241],
       grad_fn=<IndexBackward0>)
num_high 16 len(mask) 119
pred_loss tensor([0.2360], grad_fn=<MulBackward0>)
size_loss tensor(-0.8478, grad_fn=<MulBackward0>)
size_num_loss 0.1344546218487395
loss: tensor([0.1985], grad_fn=<AddBackward0>)
3
epoch:  3 ; loss:  0.198472261428833 ; pred:  tensor([0.7897, 0.0880, 0.0464, 0.0758], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.6472, 0.4696, 0.3892, 0.3508, 0.3483, 0.3509, 0.3129, 0.3503, 0.3527,
        0.6034, 0.3550, 0.3505, 0.3529, 0.3538, 0.3526, 0.3617, 0.6005, 0.3568,
        0.3542, 0.3248, 0.3527, 0.4309, 0.3686, 0.6144, 0.4332, 0.4357, 0.3396,
        0.4426, 0.3562, 0.3135, 0.3560, 0.3804, 0.3505, 0.3522, 0.3562, 0.6227,
        0.3190, 0.3547, 0.3273, 0.3526, 0.3503, 0.4110, 0.3521, 0.3536, 0.3508,
        0.6617, 0.3509, 0.3543, 0.3520, 0.3532, 0.3139, 0.3311, 0.3543, 0.4580,
        0.3524, 0.3528, 0.3505, 0.3135, 0.3128, 0.3479, 0.3126, 0.6396, 0.3575,
        0.4487, 0.4597, 0.3824, 0.6677, 0.3332, 0.3227, 0.3586, 0.3582, 0.4363,
        0.3618, 0.3345, 0.3154, 0.3270, 0.3394, 0.3612, 0.3582, 0.3530, 0.3130,
        0.3619, 0.3662, 0.3680, 0.3331, 0.3433, 0.4679, 0.3198, 0.3727, 0.3720,
        0.3687, 0.3449, 0.3776, 0.3616, 0.4492, 0.3417, 0.3778, 0.3379, 0.3862,
        0.3161, 0.3493, 0.3411, 0.4341, 0.3366, 0.4294, 0.3612, 0.4229, 0.3635,
        0.3348, 0.3253, 0.3611, 0.3265, 0.3595, 0.3348, 0.3612, 0.3607, 0.3613,
        0.3625, 0.3553], grad_fn=<MulBackward0>)
res: tensor([0.6880, 0.1274, 0.0756, 0.1089], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.6472, 0.6034, 0.6005, 0.6144, 0.6227, 0.6617, 0.6396, 0.6677],
       grad_fn=<IndexBackward0>)
num_high 8 len(mask) 119
pred_loss tensor([0.3739], grad_fn=<MulBackward0>)
size_loss tensor(-0.6644, grad_fn=<MulBackward0>)
size_num_loss 0.06722773109243697
loss: tensor([0.4285], grad_fn=<AddBackward0>)
4
epoch:  4 ; loss:  0.4284866154193878 ; pred:  tensor([0.6880, 0.1274, 0.0756, 0.1089], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.7253, 0.4158, 0.3611, 0.3634, 0.3195, 0.3509, 0.2746, 0.3557, 0.3459,
        0.5450, 0.3430, 0.3530, 0.3457, 0.3443, 0.3460, 0.3332, 0.5405, 0.3415,
        0.3438, 0.2930, 0.3459, 0.4040, 0.3403, 0.5680, 0.3726, 0.3751, 0.3101,
        0.3826, 0.3420, 0.2761, 0.3421, 0.3522, 0.3528, 0.3470, 0.3419, 0.6034,
        0.2854, 0.3432, 0.3058, 0.3461, 0.3550, 0.3833, 0.3471, 0.3446, 0.3514,
        0.7392, 0.3509, 0.3437, 0.3474, 0.3451, 0.2769, 0.3006, 0.3437, 0.4329,
        0.3465, 0.3457, 0.3530, 0.2760, 0.2743, 0.3190, 0.2738, 0.7131, 0.3622,
        0.3884, 0.4021, 0.3570, 0.7444, 0.3051, 0.2931, 0.3450, 0.3618, 0.3767,
        0.3515, 0.3082, 0.2810, 0.2990, 0.3137, 0.3596, 0.3776, 0.3465, 0.2748,
        0.3549, 0.3797, 0.3698, 0.3036, 0.3254, 0.4600, 0.2921, 0.3576, 0.3759,
        0.3793, 0.3203, 0.4034, 0.3622, 0.3924, 0.3253, 0.4128, 0.3174, 0.3754,
        0.2827, 0.3266, 0.3165, 0.4129, 0.3121, 0.4113, 0.3608, 0.4025, 0.3574,
        0.3090, 0.2969, 0.3587, 0.2989, 0.3554, 0.3098, 0.3559, 0.3553, 0.3770,
        0.3607, 0.3334], grad_fn=<MulBackward0>)
res: tensor([0.6670, 0.1365, 0.0805, 0.1160], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.7253, 0.5450, 0.5405, 0.5680, 0.6034, 0.7392, 0.7131, 0.7444],
       grad_fn=<IndexBackward0>)
num_high 8 len(mask) 119
pred_loss tensor([0.4050], grad_fn=<MulBackward0>)
size_loss tensor(-8.3387, grad_fn=<MulBackward0>)
size_num_loss 0.06722773109243697
loss: tensor([-7.2263], grad_fn=<AddBackward0>)
5
epoch:  5 ; loss:  -7.226280689239502 ; pred:  tensor([0.6670, 0.1365, 0.0805, 0.1160], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.7885, 0.3763, 0.3585, 0.3968, 0.3201, 0.3745, 0.2628, 0.3835, 0.3639,
        0.4684, 0.3568, 0.3785, 0.3634, 0.3600, 0.3642, 0.3334, 0.4631, 0.3525,
        0.3588, 0.2912, 0.3640, 0.3956, 0.3399, 0.4954, 0.3258, 0.3283, 0.3106,
        0.3370, 0.3538, 0.2659, 0.3542, 0.3507, 0.3780, 0.3664, 0.3537, 0.5373,
        0.2811, 0.3574, 0.3140, 0.3643, 0.3823, 0.3778, 0.3666, 0.3608, 0.3754,
        0.8045, 0.3745, 0.3586, 0.3673, 0.3619, 0.2674, 0.3002, 0.3586, 0.4212,
        0.3652, 0.3635, 0.3785, 0.2657, 0.2621, 0.3197, 0.2610, 0.7748, 0.3906,
        0.3425, 0.3595, 0.3585, 0.8099, 0.3070, 0.2933, 0.3576, 0.3897, 0.3317,
        0.3675, 0.3121, 0.2744, 0.3010, 0.3181, 0.3833, 0.4177, 0.3649, 0.2635,
        0.3738, 0.4163, 0.3962, 0.3041, 0.3371, 0.4682, 0.2923, 0.3714, 0.4042,
        0.4135, 0.3248, 0.4500, 0.3865, 0.3520, 0.3384, 0.4667, 0.3264, 0.3925,
        0.2766, 0.3339, 0.3221, 0.4115, 0.3177, 0.4137, 0.3848, 0.4034, 0.3768,
        0.3131, 0.2981, 0.3820, 0.3014, 0.3770, 0.3146, 0.3757, 0.3751, 0.4207,
        0.3841, 0.3410], grad_fn=<MulBackward0>)
res: tensor([0.7037, 0.1240, 0.0674, 0.1049], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.7885, 0.5373, 0.8045, 0.7748, 0.8099], grad_fn=<IndexBackward0>)
num_high 5 len(mask) 119
pred_loss tensor([0.3514], grad_fn=<MulBackward0>)
size_loss tensor(-13.4185, grad_fn=<MulBackward0>)
size_num_loss 0.04201764705882353
loss: tensor([-12.3835], grad_fn=<AddBackward0>)
6
epoch:  6 ; loss:  -12.383525848388672 ; pred:  tensor([0.7037, 0.1240, 0.0674, 0.1049], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.8468, 0.3507, 0.3751, 0.4424, 0.3416, 0.4134, 0.2701, 0.4254, 0.3986,
        0.4027, 0.3882, 0.4188, 0.3979, 0.3929, 0.3991, 0.3540, 0.3970, 0.3818,
        0.3912, 0.3102, 0.3988, 0.4030, 0.3598, 0.4321, 0.2905, 0.2932, 0.3320,
        0.3037, 0.3838, 0.2752, 0.3843, 0.3688, 0.4182, 0.4021, 0.3835, 0.4673,
        0.2974, 0.3891, 0.3423, 0.3992, 0.4238, 0.3898, 0.4024, 0.3941, 0.4146,
        0.8614, 0.4134, 0.3909, 0.4034, 0.3958, 0.2776, 0.3207, 0.3909, 0.4218,
        0.4004, 0.3981, 0.4188, 0.2749, 0.2690, 0.3412, 0.2671, 0.8339, 0.4340,
        0.3093, 0.3306, 0.3793, 0.8661, 0.3299, 0.3140, 0.3883, 0.4328, 0.2987,
        0.4013, 0.3366, 0.2873, 0.3236, 0.3432, 0.4234, 0.4692, 0.3999, 0.2716,
        0.4098, 0.4669, 0.4384, 0.3256, 0.3686, 0.4877, 0.3120, 0.4048, 0.4474,
        0.4622, 0.3494, 0.5069, 0.4263, 0.3253, 0.3713, 0.5289, 0.3556, 0.4282,
        0.2898, 0.3619, 0.3484, 0.4258, 0.3438, 0.4310, 0.4241, 0.4200, 0.4131,
        0.3377, 0.3198, 0.4222, 0.3248, 0.4156, 0.3398, 0.4122, 0.4115, 0.4814,
        0.4237, 0.3686], grad_fn=<MulBackward0>)
res: tensor([0.7750, 0.0971, 0.0460, 0.0819], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.8468, 0.8614, 0.8339, 0.8661, 0.5069, 0.5289],
       grad_fn=<IndexBackward0>)
num_high 6 len(mask) 119
pred_loss tensor([0.2548], grad_fn=<MulBackward0>)
size_loss tensor(-29.9461, grad_fn=<MulBackward0>)
size_num_loss 0.05042100840336134
loss: tensor([-28.9918], grad_fn=<AddBackward0>)
7
epoch:  7 ; loss:  -28.991840362548828 ; pred:  tensor([0.7750, 0.0971, 0.0460, 0.0819], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.8941, 0.3374, 0.4055, 0.4922, 0.3780, 0.4605, 0.2921, 0.4739, 0.4434,
        0.3478, 0.4309, 0.4666, 0.4425, 0.4367, 0.4440, 0.3892, 0.3418, 0.4231,
        0.4345, 0.3447, 0.4436, 0.4222, 0.3940, 0.3782, 0.2649, 0.2678, 0.3685,
        0.2806, 0.4255, 0.2995, 0.4261, 0.4010, 0.4659, 0.4476, 0.4252, 0.4066,
        0.3291, 0.4320, 0.3847, 0.4442, 0.4722, 0.4148, 0.4479, 0.4381, 0.4619,
        0.9060, 0.4605, 0.4342, 0.4491, 0.4401, 0.3029, 0.3565, 0.4342, 0.4326,
        0.4455, 0.4428, 0.4666, 0.2990, 0.2905, 0.3776, 0.2878, 0.8831, 0.4846,
        0.2870, 0.3136, 0.4135, 0.9097, 0.3680, 0.3498, 0.4310, 0.4832, 0.2754,
        0.4460, 0.3761, 0.3151, 0.3613, 0.3830, 0.4725, 0.5228, 0.4449, 0.2945,
        0.4560, 0.5223, 0.4886, 0.3624, 0.4136, 0.5132, 0.3462, 0.4504, 0.4971,
        0.5165, 0.3883, 0.4455, 0.4742, 0.3095, 0.4176, 0.4674, 0.3988, 0.4751,
        0.3177, 0.4039, 0.3894, 0.4509, 0.3845, 0.4576, 0.4713, 0.4469, 0.4592,
        0.3769, 0.3565, 0.4717, 0.3632, 0.4638, 0.3796, 0.4584, 0.4575, 0.5493,
        0.4720, 0.4098], grad_fn=<MulBackward0>)
res: tensor([0.8392, 0.0717, 0.0293, 0.0598], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.8941, 0.9060, 0.8831, 0.9097, 0.5228, 0.5223, 0.5132, 0.5165, 0.5493],
       grad_fn=<IndexBackward0>)
num_high 9 len(mask) 119
pred_loss tensor([0.1754], grad_fn=<MulBackward0>)
size_loss tensor(-38.8800, grad_fn=<MulBackward0>)
size_num_loss 0.07563109243697479
loss: tensor([-37.9722], grad_fn=<AddBackward0>)
8
epoch:  8 ; loss:  -37.97218704223633 ; pred:  tensor([0.8392, 0.0717, 0.0293, 0.0598], grad_fn=<SoftmaxBackward0>)
masked_adj tensor([0.9296, 0.3349, 0.4444, 0.5377, 0.4241, 0.5085, 0.3261, 0.5212, 0.4914,
        0.3026, 0.4785, 0.5144, 0.4905, 0.4845, 0.4920, 0.4337, 0.2966, 0.4701,
        0.4823, 0.3903, 0.4916, 0.4495, 0.4373, 0.3332, 0.2470, 0.2504, 0.4152,
        0.2659, 0.4727, 0.3357, 0.4734, 0.4419, 0.5137, 0.4957, 0.4724, 0.3551,
        0.3725, 0.4797, 0.4360, 0.4922, 0.5196, 0.4481, 0.4960, 0.4860, 0.5099,
        0.9383, 0.5085, 0.4819, 0.4972, 0.4880, 0.3401, 0.4031, 0.4819, 0.4508,
        0.4936, 0.4908, 0.5144, 0.3350, 0.3238, 0.4238, 0.3202, 0.9212, 0.5341,
        0.2736, 0.3068, 0.4555, 0.9410, 0.4163, 0.3966, 0.4792, 0.5326, 0.2601,
        0.4948, 0.4253, 0.3546, 0.4095, 0.4322, 0.5227, 0.4625, 0.4930, 0.3295,
        0.5052, 0.4621, 0.5387, 0.4100, 0.4661, 0.4527, 0.3911, 0.5007, 0.5452,
        0.4563, 0.4363, 0.3925, 0.5226, 0.3025, 0.4713, 0.4137, 0.4506, 0.5256,
        0.3570, 0.4539, 0.4391, 0.4814, 0.4345, 0.4884, 0.5187, 0.4790, 0.5079,
        0.4259, 0.4038, 0.5221, 0.4118, 0.5137, 0.4288, 0.5069, 0.5060, 0.4908,
        0.5213, 0.4586], grad_fn=<MulBackward0>)
res: tensor([0.8595, 0.0625, 0.0251, 0.0529], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.9296, 0.5377, 0.5085, 0.5212, 0.5144, 0.5137, 0.5196, 0.5099, 0.9383,
        0.5085, 0.5144, 0.9212, 0.5341, 0.9410, 0.5326, 0.5227, 0.5052, 0.5387,
        0.5007, 0.5452, 0.5226, 0.5256, 0.5187, 0.5079, 0.5221, 0.5137, 0.5069,
        0.5060, 0.5213], grad_fn=<IndexBackward0>)
num_high 29 len(mask) 119
pred_loss tensor([0.1514], grad_fn=<MulBackward0>)
size_loss tensor(-21.1996, grad_fn=<MulBackward0>)
size_num_loss 0.2436983193277311
loss: tensor([-20.1436], grad_fn=<AddBackward0>)
9
epoch:  9 ; loss:  -20.143646240234375 ; pred:  tensor([0.8595, 0.0625, 0.0251, 0.0529], grad_fn=<SoftmaxBackward0>)
Finished Training
sel masked ver tensor(indices=tensor([[6881, 6997, 7068, 7393, 8010, 7911, 5937, 5939, 6881,
                        6887, 8012, 5408, 5413, 5502, 5678, 5939, 5939, 5678,
                        5678, 5678, 5678, 5678, 5502, 5502, 5502, 5502, 5502,
                        5502, 5678],
                       [5678, 5678, 5678, 5678, 5678, 5939, 5494, 5450, 5357,
                        5450, 5450, 5678, 5678, 5678,   35, 8010, 8015, 6887,
                        7068, 7100, 7968, 8015, 7068, 7393, 7968, 8012, 8014,
                        8015, 5230]]),
       values=tensor([0.9296, 0.5377, 0.5085, 0.5212, 0.5144, 0.5137, 0.5196,
                      0.5099, 0.9383, 0.5085, 0.5144, 0.9212, 0.5341, 0.9410,
                      0.5326, 0.5227, 0.5052, 0.5387, 0.5007, 0.5452, 0.5226,
                      0.5256, 0.5187, 0.5079, 0.5221, 0.5137, 0.5069, 0.5060,
                      0.5213]),
       size=(8013, 8016), nnz=29, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>)
/usr/local/Caskroom/miniconda/base/lib/python3.9/site-packages/networkx/drawing/nx_pylab.py:433: UserWarning: No data for colormapping provided via 'c'. Parameters 'cmap' will be ignored
  node_collection = ax.scatter(
Counter({'publishes': 6, 'publication': 5, 'isAbout': 5, 'author': 5, 'isWorkedOnBy': 2, 'projectInfo': 2, 'member': 1, 'phone': 1, 'type': 1, 'hasProject': 1})
dict index: {}
node_idx 5678
 node original label [0]
 node predicted label explain 0
 node prediction probability explain tensor([0.8595, 0.0625, 0.0251, 0.0529], grad_fn=<SoftmaxBackward0>)
 node predicted label full 0 most important relations  {'isWorkedOnBy': 2, 'member': 1, 'publishes': 6, 'phone': 1, 'type': 1, 'publication': 5, 'isAbout': 5, 'projectInfo': 2, 'author': 5, 'hasProject': 1, 'label': 0, 'node_idx': '5678'}
 final masks and lenght tensor(indices=tensor([[ 23451,  23458,  23551,  23567,  23615,  23638,  23670,
                         23963,  24431,  24481,  24538,  24580,  24582,  24583,
                         24584,  24585,  39077,  39079,  46927,  46927,  63352,
                         63403,  63408,  63426,  63445,  63489,  81452,  88528,
                        114586, 114592, 114593, 114702, 115616, 115715, 115717,
                        115718, 115719, 115720, 129953, 146782, 146782, 146784,
                        146784, 146784, 146784, 147726, 147732, 147826, 147842,
                        147890, 147913, 147945, 148238, 148238, 148756, 148855,
                        148857, 148858, 148859, 148860, 154487, 154538, 154543,
                        154561, 154580, 154624, 179487, 179922, 179924, 196233,
                        229373, 237658, 246202, 246204, 246204, 246204, 246204,
                        246204, 246204, 246204, 246204, 246204, 254228, 254228,
                        254228, 254228, 254228, 254228, 254228, 254228, 254228,
                        254228, 254228, 254228, 254228, 254228, 254228, 254228,
                        254228, 262337, 262337, 262337, 262337, 262337, 262337,
                        262337, 262337, 262337, 262337, 262337, 262337, 262337,
                        262337, 262337, 262337, 262337, 303938, 328793, 328793],
                       [  5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   5678,
                          5678,   5678,   5502,   5502,   5937,   5939,   5939,
                          5939,   5939,   5937,   5939,   5937,   5678,     22,
                          5939,   5939,   5937,   5939,   5939,   5939,   5939,
                          5939,   5939,   5939,    117,   5431,   5494,   5357,
                          5408,   5413,   5450,   5357,   5450,   5450,   5450,
                          5450,   5450,   5450,   5357,   5450,   5450,   5450,
                          5450,   5450,   5450,   5450,   5678,   5678,   5678,
                          5678,   5678,   5678,   5678,   5678,   5678,   2215,
                            35,   5535,   6888,   6881,   6887,   6997,   7911,
                          8010,   8012,   8013,   8014,   8015,   6881,   6887,
                          6888,   6981,   6997,   7045,   7068,   7100,   7393,
                          7861,   7911,   7968,   8010,   8012,   8013,   8014,
                          8015,   6881,   6887,   6888,   6981,   6997,   7045,
                          7068,   7100,   7393,   7861,   7911,   7968,   8010,
                          8012,   8013,   8014,   8015,   5939,   5230,   5231]]),
       values=tensor([0.9296, 0.3349, 0.4444, 0.5377, 0.4241, 0.5085, 0.3261,
                      0.5212, 0.4914, 0.3026, 0.4785, 0.5144, 0.4905, 0.4845,
                      0.4920, 0.4337, 0.2966, 0.4701, 0.4823, 0.3903, 0.4916,
                      0.4495, 0.4373, 0.3332, 0.2470, 0.2504, 0.4152, 0.2659,
                      0.4727, 0.3357, 0.4734, 0.4419, 0.5137, 0.4957, 0.4724,
                      0.3551, 0.3725, 0.4797, 0.4360, 0.4922, 0.5196, 0.4481,
                      0.4960, 0.4860, 0.5099, 0.9383, 0.5085, 0.4819, 0.4972,
                      0.4880, 0.3401, 0.4031, 0.4819, 0.4508, 0.4936, 0.4908,
                      0.5144, 0.3350, 0.3238, 0.4238, 0.3202, 0.9212, 0.5341,
                      0.2736, 0.3068, 0.4555, 0.9410, 0.4163, 0.3966, 0.4792,
                      0.5326, 0.2601, 0.4948, 0.4253, 0.3546, 0.4095, 0.4322,
                      0.5227, 0.4625, 0.4930, 0.3295, 0.5052, 0.4621, 0.5387,
                      0.4100, 0.4661, 0.4527, 0.3911, 0.5007, 0.5452, 0.4563,
                      0.4363, 0.3925, 0.5226, 0.3025, 0.4713, 0.4137, 0.4506,
                      0.5256, 0.3570, 0.4539, 0.4391, 0.4814, 0.4345, 0.4884,
                      0.5187, 0.4790, 0.5079, 0.4259, 0.4038, 0.5221, 0.4118,
                      0.5137, 0.4288, 0.5069, 0.5060, 0.4908, 0.5213, 0.4586]),
       size=(753935, 8285), nnz=119, layout=torch.sparse_coo,
       grad_fn=<SparseCooTensorWithDimsAndTensorsBackward0>) 29
 ---------------------------------------------------------------
/Users/macoftraopia/Documents/GitHub/RGCN-Explainer/RGCN_stuff/r_exp.py:102: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  hor_graph, ver_graph = torch.tensor(sub_hor_graph, dtype=torch.float), torch.tensor(sub_ver_graph, dtype=torch.float)
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.login() after wandb.init() has no effect.
node label: 0
5
masked_adj tensor([1.5299, 0.7444, 0.7550, 1.5091, 0.5986, 0.7110, 0.8985],
       grad_fn=<MulBackward0>)
res: tensor([0.3776, 0.2412, 0.2576, 0.1236], grad_fn=<SoftmaxBackward0>)
mask_without_small tensor([0.7649, 0.7444, 0.7550, 0.7546, 0.5986, 0.7110, 0.8985],
       grad_fn=<IndexBackward0>)
num_high 7 len(mask) 7
pred_loss tensor([0.9740], grad_fn=<MulBackward0>)
size_loss tensor(0.4449, grad_fn=<AddBackward0>)
size_num_loss 1.0000142857142857
