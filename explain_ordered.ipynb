{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNDERSTANDING GNN EXPLAINER\n",
    "\n",
    "In this tutorial we are going to explore how GNN Explainer works by breaking it down in pieces that will hopefully make it more intuitevely understandable.\n",
    "\n",
    "The goal of this is to get a full understanding of the method such that the user can expand it to its use.\n",
    "\n",
    "We will work on the Cora dataset to show all the steps involved, and the model that we will explain is a small GCN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we import the necessary libraries\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "#for the model \n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "#Explain Module\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "#to import the data\n",
    "from torch_geometric.datasets import Planetoid\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.utils import to_networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 1\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "dataset under study\n",
      "Number of nodes: 2708\n",
      "Number of edges: 10556\n"
     ]
    }
   ],
   "source": [
    "#Here we import the Cora dataset. We use the Cora dataset because it is a small dataset and it is easy to understand.\n",
    "#We import the dataset from the Pytorch Geometric library as it is already preprocessed - and the goal is then to further expand the GNN implementation to other datasets starting from the PYG implementation.\n",
    "\n",
    "#import the dataset and print some information about it\n",
    "dataset = Planetoid(root='data/Planetoid', name='Cora', transform=NormalizeFeatures())\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "data = dataset[0]\n",
    "print('dataset under study')\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for convention to how things are named we rename the data\n",
    "label = data.y\n",
    "feat = data.x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to visualize the graph, we need to convert the data into a networkx graph. We can then use the networkx library to visualize the graph. Each node color represents a different class in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "G = to_networkx(data, to_undirected=True)\n",
    "nx.draw(G, with_labels=False, node_color=data.y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another cool thing about importing our graph into a networkx object is that we can easily extract its adjacency matrix - which we will need to dig into the GNN Explainer method.\n",
    "\n",
    "We can easily see from the Adjacency matrix that the graph is directed as adj is not symmetric, but indeed as it should be is a square matrix.\n",
    "\n",
    "Just a reminder: what is an Adjacency matrix of a graph?\n",
    "\n",
    "It is a matrix where each row correspond to a node, and the row/column combination represent the connectivity between two nodes. \n",
    "In particular for node 1, we can see that it has a connection towards node 2, because it is a non zero element of the node 1 row.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connectivity for node 1: \n",
      " we can see that it is connected to node 2 [0 0 1 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "adj = nx.adjacency_matrix(G).todense()\n",
    "print('Connectivity for node 1: \\n we can see that it is connected to node 2',adj[1][0:10])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to start exploring the GNN Explainer implementation.\n",
    "\n",
    "The explain module (explain.py) is made of two classes:\n",
    "- ExplainModule - which is a nn.Module\n",
    "- Explainer - which uses ExplainModule to perform the explanation\n",
    "\n",
    "# Class Explainer:\n",
    "explain: Given a node index it returns the masked adjacency matrix for that node:\n",
    "1. Extract the neighborhood of the given node\n",
    "2. Get the original label of the node\n",
    "3. Get the predicted label of the node (argmax from the softmax layer of the network)\n",
    "4. Call the ExplainModule to do the dirty jobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Extract the neighborhood of the given node\n",
    "- We are interested in getting a neighborhood not just in terms of actual neighbors but also in terms of potentian neighbors - namely node which are not directly connected but they would be connected if we consider a different number of hops.\n",
    "\n",
    "- For instance in a simple graph a-b-c: a is connected to c if we consider 2 hops.\n",
    "\n",
    "- We want to have a function that gets that for all our graph - so we rely on the adjacency matrix and we modify it according to the number of hops that we want to take into consideration.\n",
    "\n",
    "- We add self loops as well in terms of connections\n",
    "\n",
    "#from graph_utils import neighborhoods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 2 hops Connectivity for node 1: \n",
      " we can see that it is connected to node 2 [0 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "#line 147 in utils/graph_utils.py\n",
    "def neighborhoods(adj, n_hops):\n",
    "    \"\"\"Returns the n_hops degree adjacency matrix adj.\"\"\"\n",
    "\n",
    "    adj = torch.tensor(adj, dtype=torch.float)\n",
    "    hop_adj = power_adj = adj\n",
    "    for i in range(n_hops - 1):\n",
    "        power_adj = power_adj @ adj\n",
    "        prev_hop_adj = hop_adj\n",
    "        hop_adj = hop_adj + power_adj\n",
    "        #print(type(hop_adj))\n",
    "        hop_adj = (hop_adj > 0).float()\n",
    "        #print(hop_adj)\n",
    "    return hop_adj.cpu().numpy().astype(int)\n",
    "n_hops = 2\n",
    "adj_hop = neighborhoods(adj, n_hops)\n",
    "print(' 2 hops Connectivity for node 1: \\n we can see that it is connected to node 2',adj_hop[1,:])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract neighborhood\n",
    "We are simplifying the function as we are working with 1 graph only (indeed we are working on node mode)\n",
    "\n",
    "Extract neighborhood which returns the new index node, the adjacency matrix of the neighboor, the features of the neighboor, the label and the actual neighbors.\n",
    "\n",
    "\n",
    "- So the neighbors are indeed the neighbros as defined to be the neighbors according to the number of hops used\n",
    "- the sub adj: is the adjacency matrix of the neighbors (adjacency where select only row and cols of the neighbor ) -- thus its size depends on how many neighbors the node has\n",
    "- new index usually just zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " array([[0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
       "        [1, 0, 1, 0, 0, 0, 1, 1, 1],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 0, 0, 0, 0, 0]]),\n",
       " tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " tensor([4, 4, 3, 4, 4, 4, 4, 3, 3]),\n",
       " array([   1,    2,  332,  470,  652,  654, 1454, 1666, 1986]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#line 506 in explain.py\n",
    "\n",
    "def extract_neighborhood(node_idx,adj,feat,label,n_hops):\n",
    "    \"\"\"Returns the neighborhood of a given ndoe.\"\"\"\n",
    "    neighbors_adj_row = neighborhoods(adj,n_hops)[node_idx, :] #take row of the node in the new adj matrix\n",
    "    # index of the query node in the new adj\n",
    "    node_idx_new = sum(neighbors_adj_row[:node_idx]) #sum of all the nodes before the query node (since they are 1 or 0) - it becomes count of nodes before the query node\n",
    "    neighbors = np.nonzero(neighbors_adj_row)[0] #return the indices of the nodes that are connected to the query node (and thus are non zero)\n",
    "    sub_adj = adj[neighbors][:, neighbors]\n",
    "    sub_feat = feat[neighbors]\n",
    "    sub_label = label[neighbors]\n",
    "    return node_idx_new, sub_adj, sub_feat, sub_label, neighbors\n",
    "\n",
    "node_idx_new, sub_adj, sub_feat, sub_label, neighbors = extract_neighborhood(1,adj,feat,label,n_hops)\n",
    "node_idx_new, sub_adj, sub_feat, sub_label, neighbors"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can visualize the neighbors for a given node and for a given number of hops!\n",
    "\n",
    "Due to the message passing idea of GNN, this is the structure which is going to be the most influential for the node classification task (namely: number of hops more and less corresponds to the number of layers in our model - IS IT CORRECT???)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApQAAAHzCAYAAACe1o1DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABr0klEQVR4nO3dd3hUZeL28e9MeiEhgQAhQArSewdBpCkoHVQQlbVgARRZseC6qyvqWvBFEFAsoKAoFlQUlSZF6Z3QCb2E9AJpTKa8f/Bj1ixFIJOcyeT+XNdea2bOnLlHCbnzPOc8j8nhcDgQEREREblOZqMDiIiIiEjZpkIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixaJCKSIiIiLFokIpIiIiIsWiQikiIiIixeJtdAARKVvsdjs2mw2TyYSXlxcmk8noSCIiYjAVShG5IofDQVpaGomJiWRmZpKbm4vD4QDAbDYTGhpKWFgYNWvWpEKFCganFRERI5gcF34yiIj8icPhIDExkX379pGfn4/JZOJyf11ceC48PJxGjRoRGhpaymlFRMRIKpQicpFz584RHx9PcnLyNb3uQrGsU6cOderUwWzWZdoiIuWBCqWIFJGfn8/atWspKCi47Ijk1ahWrRotW7ZUqRQRKQf0N72IOBUWFrJu3bpil0mApKQkduzYUezziIiI+1OhFBGn3bt3k5eX57ISeOrUKU6fPu2Sc4mIiPvSXd4iwtatW/nHP/7BmjVrsFgsVKtWjZ49e9KvXz8Ann/+eXbt2nXR61q2bMnLL7982fN+9dVX9O3bl4YNG7J79+4Syy8iIsZSoRQp55YsWULfvn2pU6cOQ4YMISAggNOnT5Oenl7kuMqVKzN8+PAij4WHh1/2vGlpaXzzzTf4+/tTWFhYItlFRMQ9qFCKlGNnzpxh+PDh9OzZkxEjRlzxBprAwEC6du161eeeNWsW9erVw263k5OTg8Ph0CLoIiIeStdQipRjX3zxBcnJyTz++OOYzWYKCgqw2+2XPd5ms5Gfn/+X5921axdr1qzh4YcfBs7vrnP27FmX5RYREfeiEUqRcmzZsmWEhIRw6NAhXnvtNU6dOoW/vz9du3ZlxIgR+Pr6Oo9NTEzkjjvuwGq1UrFiRXr27MnQoUPx9i7614jNZuODDz7g1ltvJSYmxvl4dnY2ISEhpfXRRESkFKlQipRjCQkJWK1WnnrqKXr06MHw4cPZuXMnCxcuJDc3l2eeeQaAyMhImjZtSnR0NAUFBaxdu5avvvqKU6dO8dxzzxU556JFi0hNTeXVV18t8rhGKEVEPJcKpUg5lpOTQ15eHn369OHRRx8F4MYbb8RqtbJo0SLuueceqlevzpgxY4q8rlu3bkybNo3FixfTv39/6tevD5y/JnPu3LkMGTLkou0XbTZb6XwoEREpdbqGUqQcCwgIAKB79+5FHr/55psB2Ldv32VfO2DAAAB27NjhfOzzzz8nODiYPn36XHS8dswREfFc+htepByrXr16kf+/4MLoYk5OzmVfW7lyZeC/U9mJiYksXryYvn37kpGRQXJyMsnJyRQWFmKz2cjIyCAjI6MkPoaIiBhMU94i5VirVq1YunQp+fn5BAUFOXfIuVD8rnQTTXJyMvDf8pmeno7dbufDDz/kww8/vOj4zp078+STTzJ58mQXfwoRETGaCqVIOXbXXXfxxhtv8NNPP3H//fc7H1+yZAleXl40adKEvLw8fHx88PHxcT7vcDj46quvAGjRogUAtWrV4h//+MdF7/H555+Tn5/PjBkzqFOnTsl+IBERMYQKpUg51qJFCx588EFmzZpFWloaDRo0YOfOnaxZs4Y777yTSpUqsXPnTiZOnEjnzp2JjIzEYrGwbt069u7dS8+ePbnhhhuA8yOVHTp0uOg9fvzxR3x8fBg0aFBpfzwRESklKpQi5dyMGTOoVasWH330EWvWrCEiIoIRI0bQv39/ACIiImjYsCHr1q0jKysLk8lEzZo1GTVqFL169bqq9/jzepYiIuJ5TI4LF02JSLlmt9v5448/nNskukpcXBwNGzZ02flERMT96C5vEQHOL+tz4XpIVzCZTAQFBVGvXj2XnVNERNyTCqWIOIWEhNC6dWtMJlOxzmMymfD19aV9+/Z4eXm5KJ2IiLgrTXmLyEVSU1PZunUrVqv1uqa/Q0JCaNOmjXPhdBER8WwqlCJySRaLhZ07d3L69GlMJtNVFUuTyUS9evWIi4vTzjgiIuWICqWIXNHZs2c5duwYp06dorCw8JLHJCcn07lzZ6Kjo3VHt4hIOaRCKSJXxeFwUFBQQHZ2NlarFZPJhJ+fH3/88QeDBg1i3LhxvP3220bHFBERA2gdShG5KiaTiYCAgIuui7Tb7QBMmjSJfv360blzZyPiiYiIgXSRk4gUy+7du4HzI5i9e/cmPj7e4EQiIlLaVChFpFi2bdvm/Oe8vDy6d+/OkSNHDEwkIiKlTYVSRIpl06ZNzn+22+1kZmbSrVs30tLSDEwlIiKlSYVSRK5bZmYmp06dKvKY3W7n6NGj7Nixw6BUIiJS2lQoReS67d271/nPF9adnDFjBidPnqR79+5GxRIRkVKmQiki161p06ZMmTKF1atX89ZbbwEQHBxMVFSUwclERKQ0aR1KEXGJnJwcKlSowC233MKSJUuMjiMiIqVIhVJEXKZ69erk5uaSnZ1tdBQRESlFmvIWEZfp2rUrZ86c4dixY0ZHERGRUqRCKSIuM2rUKACmTZtmcBIRESlNmvIWEZfy8/MjNjaWffv2GR1FRERKiUYoRcSlGjduzMGDB517fIuIiOdToRQRl7rjjjuw2WwsWLDA6CgiIlJKNOUtIi6VlZVFWFgYvXv3ZuHChUbHERGRUqBCKSIuV6VKFaxWKxkZGUZHERGRUqApbxFxuc6dO5OZmUlSUpLRUUREpBSoUIqIyz322GMATJ8+3eAkIiJSGjTlLSIlwsfHh3r16rFr1y6jo4iISAnTCKWIlIgGDRqwf/9+LR8kIlIOqFCKSIkYOHAgVquVpUuXGh1FRERKmKa8RaREpKSkULVqVQYOHMh3331ndBwRESlBKpQiUmIqVaqE2WwmNTXV6CgiIlKCNOUtIiWmY8eOpKWlaT1KEREPp0IpIiVmxIgRALz//vsGJxERkZKkKW8RKTF2ux1fX1+aNGnCtm3bjI4jIiIlRCOUIlJizGYzderUYc+ePUZHERGREqRCKSIlql+/flgsFn7//Xejo4iISAlRoRSREjV69GhA11GKiHgyXUMpIiWuYsWKBAQEcPr0aaOjiIhICdAIpYiUuPbt25OUlEROTo7RUUREpASoUIpIiXvggQcA+OCDDwxOIiIiJUFT3iJS4ux2Oz4+PrRq1YqNGzcaHUdERFxMhVJESkWdOnU4efIk+fn5RkcREREX05S3iJSK22+/nYKCAjZt2mR0FBERcTEVShEpFWPGjAFg+vTpBicRERFX05S3iJSaChUqEBoaysmTJ42OIiIiLqQRShEpNW3atOHUqVMUFBQYHUVERFxIhVJESs19990HwKxZswxOIiL/K99aSFJeNom5WWQU5KIJTLkWmvIWkVJjtVrx9fXlxhtvZPXq1UbHESnXHA4Hh86ksTr5EAlZyaSdyy3yvJ+XN9HB4bSuHE27KjH4e/sYlFTKAhVKESlVMTExpKSkkJeXZ3QUkXLrYHYKnx/cxOm8bMwmE/a/qAK+Zi9uqdGA22s2wtvsVUoppSzRlLeIlKpevXqRn5/Prl27jI4iUu7Y7Ha+PryFifHLSMo7A/CXZRLAYrfx8/FdvLL1V07lZpVwSimLVChFpFQ98cQTAEybNs3gJCLli9Vu4709v7P81H4AHFz7BGVK/lne3LGEI2fTXB1PyjhNeYtIqQsKCiIiIoKjR48aHUWk3Ji5bw2bUo9dR40syoQJPy9v/tmiFxEBFVySTco+jVCKSKlr0aIFx48fx2KxGB1FpFzYnHqMjS4ok3B+ZNNis/LJgXVXNV0u5YMKpYiUunvuuQeHw8HcuXONjiLiEXJycnjppZfo1asX4eHhmEwmPv30UwDyrRbmHtzoPHbX/CV8fe8zfNz9b3w+6HHWTfucwvyL14bNS8vk94kf8+VdY5nZ436+HPp31k37nILss9j5vzvEkw4CYLfbef/992nevDkBAQFUqlSJbt26sWPHjlL5/GI8FUoRKXUPPPAAAHPmzDE4iYhnSEtLY8KECezdu5dmzZoVeW5d8hHyrIUAbHj/S9ZOmU1YXA1uHHMfsTe3Ydf8JSz95+QirynMK+CHUf/m6O+bqdOrEx3H/o1a7Zuz+7sl/PzU6zjsdgAWndiD3eHgwQcfZMyYMbRq1YqpU6fy4osvUqtWLVJSUkrl84vxvI0OICLlj7+/P1FRUWzevNnoKCIeITIyktOnT1OtWjU2b95MmzZtgPNrTa5IPACcH3GM//pX6vTsRNcXRjpfG1ojkrVTZnNszVaiO7YE4NiaLeQkpdHrzaep1aGF81i/kCC2fvo96QePU7luDOnncpn8yUfMnj2b7777joEDB5bipxZ3ohFKETHELbfcQk5ODgkJCUZHESnz/Pz8qFat2kWPZ1rySCk4C0Dy7oM4bDZqd+tQ5Jgbup//+tBv65yPWfLyAQgICy1ybGCligB4+/kC4GUyMWPqVNq2bcvAgQOx2+3k5hZdIF3KBxVKETHE6NGjAZg6darBSUQ817GzGc5/thWen/b29iu64423//lymHrgiPOxyGb1MZlNrH13Dsm7E8hJSef4uu1sm7OAmJtaUzG6OgD5Obkc3LGbNm3a8I9//IPQ0FCCg4OJi4vj66+/LumPJ25EU94iYojWrVvj7+/PL7/8wrvvvmt0HBGPlJx/BjMm7DioWDMSgKSdB6jespHzmNPx59elzEvNdD4WFlODm54ewfr35rJg5L+dj9ftdROdn33Y+fWZUyk4HA7mzZuHt7c3b731FqGhoUyZMoWhQ4cSEhJCr169SvhTijtQoRQRwzRt2pTNmzdjtVrx9tZfRyKuZrHbMJkAB1SuF0uVhrXZ8cVCgiLCqd6iIZnHTrF60ieYvb2w/s8yXkERYVRpUJua7ZtToVplTu/Yx675S/APrUD70fcAOO8OT09PZ/369bRr1w6Afv36ERsby6uvvqpCWU5oyltEDDNkyBDsdjvffPON0VFEPJK3yavI2pO3vDKW8BtqseqND/lyyFgWP///iOvajkp1YvAJ8Hcel7RzP4vGv02bh++iyZ29iLmpNR0ev5eWw/sT//WvZB49ef78/3ctZWxsrLNMAgQHB9O3b182btyI1Wotlc8qxlKhFBHDPPLIIwDO9fJExLWqBAQXWXw8KCKc/tNfYsjc/0ffqf/inm+n0n7kMHJT0gmt8d+bevb+uJyAsFAi6scVOV90x1bgcJC86/zNdIGVwwCoWrXqxe9dpQqFhYW6Saec0ByTiBgmODiYatWqsWHDBqOjiHik6OBKl3w8tGY1QmueL5CZR0+Sl55F3ds6O5/Pz8h2rjX5Z3ar7fz/287/f0hEOBUjKnHq1KmLjk1MTMTf358KFbQ9Y3mgEUoRMVTXrl3Jzs7m+PHjRkcR8TiV/YOo6Bt42ecddjsb3v8Sb38/Gvbv7nw8tGYk+RnZJG7bU+T4g7+tPX/eOjEA2BwObh80gBMnTrB06VLncWlpaSxYsIBu3bphNqtqlAcmh0MbcYqIcVavXs1NN93EM888w1tvvWV0HJEya9q0aWRlZZGYmMj777/PoEGDaNGiBQnZKZi7NcU3OJC1U+ZgtRRSuU40dquVg8vWkrL3MF3+8Sh1e97kPFfW8US+e/ifmDDRaPCtBFetzOkdezm0bB1RrRvTe9LzAIT6BvD36Pa0atmKnJwcnnrqKUJDQ5kxYwYnTpxg3bp1F+3cI55JhVJEDOfn50dcXBx79+41OopImRUTE8OxY8cu+dzwb97Fv2ol9v+6il3fLCL7VDImk4kqDWrT4r7+RZYRuiDreCKbPv6GlD2HyM/IIrByGHFd2tH6wcF4+/sBMDi2BbfWaMDhw4d5+umn+e233ygsLKRDhw688cYbzh17xPOpUIqI4Vq2bEl8fDwWi0XTYyIl4PfTB5l7cKPLzmfGRGRgKC+06IWXvmcFXUMpIm5g8ODB2Gw2fvrpJ6OjiHikm6rVpmHFSEyYin0uE2A2mXiwfgeVSXHSnwQRMdyFbRg//vhjg5OIeCaTycSjDTsRUyG8WKXyfJk0M7rRzdQICnNdQCnzNOUtIm6hSpUqWK1WMjIy/vpgEbku52xW5iSsZ3Pqcf5vA52rZsJEiK8fj9TvxA2hVUoqopRRGqEUEbdw0003kZmZSVJSktFRRDyWn5c3D9fvxKMNbqKCz/mdcf5qvNL0f2OanarF8XKrviqTckkqlCLiFh577DEA3nvvPYOTiHi+lpVr8kbbATza4CZyDp7EYSm86BgTUDUghN61GvF62wHcW6cdAd4+pR9WygRNeYuIW7Db7fj5+VG/fn127txpdByRcmHVqlV06dKFgQMH8sHc2WSey8PmcBDg7UP1wFB8vbShnlwd/UkREbdgNpupX78++/btw263a/kgkRJ2/PhxevfuDYDNZiMioAIRAdomUa6P/sYWEbcxcOBArFYrv/32m9FRRDxaRkYGPXr0IDc3F4DU1FSDE0lZpylvEXEbSUlJREZGMmjQIObPn290HBGPVFBQQLdu3di4cSM2mw2AgIAAzp49i5eXl8HppKxSoRQRtxIeHo63tzcpKSlGRxHxOA6Hg8GDB/PDDz/wvz/+9+zZQ4MGDQxKJmWdprxFxK107NiR1NRUrUcpUgLy8vJYsWIFDocDk6nogkGbN282KJV4AhVKEXErI0aMAOD99983OImI5wkKCuLUqVMsWrSIkJCQIqVyz549BiaTsk5T3iLiVux2O76+vjRt2pStW7caHUfEI9ntdnx8fGjRogU///wzq1atom3btsTExBgdTcooLRskIm7FbDZTp04ddu/ebXQUEY/1008/YbfbGTRoEFWrVuWuu+4yOpKUcZryFhG307dvXywWC6tXrzY6iohH+vTTTwF49NFHjQ0iHkNT3iLido4fP050dDR33303X3zxhdFxRDxOlSpVsFqtuvlNXEYjlCLidmrVqkVoaCgrVqwwOoqIxzl79iypqam0a9fO6CjiQVQoRcQttWvXjqSkJHJycoyOIuJRZs6cCcC9995rcBLxJCqUIuKW7r//fgA+/PBDY4OIeJhvvvkGk8nEkCFDjI4iHkTXUIqIW7qwrEnr1q3ZsGGD0XFEPEZwcDDh4eEcP37c6CjiQTRCKSJuyWw2ExsbS3x8vNFRRDzGoUOHyM3NpVu3bkZHEQ+jQikibuv222+noKBAW8KJuMh7770HaLkgcT1NeYuI20pISKBu3brcf//9fPLJJ0bHESnzGjRowKFDh7BYLEZHEQ+jQikibq1ChQqEhoZy8uRJo6OIlHk+Pj40aNBAl5KIy2nKW0TcWuvWrTl16hQFBQVGRxEp05YvX47VaqVv375GRxEPpEIpIm5t+PDhAJryFimmjz76CICRI0canEQ8kaa8RcStWSwW/P39ufHGG7W3t0gxREVFcfbsWc6cOWN0FPFAGqEUEbfm6+tLrVq12LZtm9FRRMqsc+fOkZiYSKtWrYyOIh5KhVJE3F6vXr3Iy8tj165dRkcRKZM+//xzAO6++26Dk4inUqEUEbf3+OOPAzBt2jSDk4iUTV988QXw32uSRVxN11CKSJkQFBREREQER48eNTqKSJkTGhpKYGAgp0+fNjqKeCiNUIpImdCiRQuOHz+uBZlFrlFiYiJnzpzh5ptvNjqKeDAVShEpE4YNG4bD4WDu3LlGRxEpU2bMmAHAQw89ZHAS8WSa8haRMqGgoICAgAC6du3K8uXLjY4jUmY0b96cXbt2YbFYMJs1jiQlQ4VSRMqMGjVqkJ2dzdmzZ42OIlJm+Pn5ERsby759+4yOIh5Mv6qISJnRo0cPcnJySEhIMDqKSJmwadMmLBYLt912m9FRxMOpUIpImTF69GhAyweJXK33338fgFGjRhmcRDydprxFpEwJCAggKiqKgwcPGh1FxO3FxMSQmppKbm6u0VHEw2mEUkTKlCZNmnDkyBGsVqvRUUTcmtVq5fjx4zRr1szoKFIOqFCKSJkydOhQ7HY78+fPNzqKiFubP38+DoeDO+64w+goUg5oyltEypScnBwqVKjArbfeyuLFi42OI+K2evfuzS+//EJ2djYhISFGxxEPp0IpImVOZGQk+fn5ZGVlGR1FxG1VqlQJs9lMamqq0VGkHNCUt4iUOV27diU7O5vjx48bHUXELWVmZpKRkcGNN95odBQpJ1QoRaTMeeyxxwAtHyRyOR9++CEAw4cPNziJlBea8haRMsnPz4+4uDj27t1rdBQRt9O2bVu2bNlCYWGhtluUUqE/ZSJSJjVq1IiEhATsdrvRUUTczq5du4iOjlaZlFKjP2kiUiYNHjwYm83GTz/9ZHQUEbeye/du8vPzueWWW4yOIuWICqWIlEkjR44E4OOPPzY4iYh7mTFjBvDf7xGR0qBrKEWkzKpSpQo2m4309HSjo4i4jTp16nDixAkKCgqMjiLliEYoRaTMuummm8jIyCApKcnoKCJuwW63c+TIERo1amR0FClnVChFpMx65JFHAHjvvfcMTiLiHn799VdsNhv9+/c3OoqUM5ryFpEyy2634+fnR4MGDYiPjzc6jojh7rjjDubPn09ycjJVqlQxOo6UIyqUIlKmNWnShH379nHu3DktkSLlXtWqVbFYLGRmZhodRcoZ/e0rImXagAEDsFqt/Pbbb0ZHETFUXl4eKSkptG3b1ugoUg6pUIpImTZ69GgAPvjgA4OTiBhr1qxZAAwbNszgJFIeacpbRMq88PBwvL29SUlJMTqKiGE6d+7M6tWrKSgowNfX1+g4Us5ohFJEyryOHTuSmppKRkaG0VFEDLNt2zaioqJUJsUQKpQiUuaNGDEC0LS3lF9Hjx4lJyeHrl27Gh1FyikVShEp8/r27YuXlxfffPON0VFEDPH+++8D/12bVaS06RpKEfEI9evX58iRI5w7d87oKCKlrlGjRiQkJGCxWIyOIuWURihFxCP069cPi8XC6tWrjY4iUuoOHDhA3bp1jY4h5ZgKpYh4hMcffxzQNoxS/vz+++9YrVb69OljdBQpxzTlLSIeIzQ0lMDAQE6fPm10FJFSc++99zJ37lyOHj1KdHS00XGknNIIpYh4jPbt25OUlEROTo7RUURKzcqVKwkODlaZFEOpUIqIx7j//vsBeOihh7jzzjtp1KiR9jQWj2axWEhMTKRly5ZGR5FyztvoACIixZWcnMw777zDjz/+CMDXX3+NyWTC4XCgq3rEk33xxRc4HA6GDBlidBQp53QNpYiUeR9++CGPPvroRY9Xr16dU6dOGZBIpHTccsstLFu2jNzcXAIDA42OI+WYprxFpMx76KGHGDBgAGbzf/9KM5lMtG7d2sBUIiVv06ZNVK1aVWVSDKdCKSJlnpeXF19++SUdO3YsUip1XZl4sqSkJLKzs7npppuMjiKiQikinsHf35+FCxfSsGFDABwOBy1atDA4lUjJubB3/YMPPmhwEhFdQykiHiYpKYmYmBjOnTvHwYMHqV27ttGRREpEy5YtiY+Px2KxFBmZFzGC7vIWEY9SrVo1PvzwQyZPnsyRI0fIzMzk3LlzOBwO/Pz8CA0NpWLFilSuXFk/hKVM27NnD3FxcfpzLG5BhVJEPEZhYSFHjhyhWrVqTJgwgfz8fAoKCoock5KSgsPhwMfHh+joaOLi4vD19TUoscj12bp1K+fOnaNXr15GRxEBVChFxEOkpKSwfft2LBaL8zGTyXTRcReu8iksLOTgwYMcO3aMpk2bEhkZWWpZRYprxowZAIwcOdLgJCLn6RpKESnTHA4HCQkJHDhwoFjniYuLo0GDBpcsoSLuJjY2luTkZPLy8oyOIgLoLm8RKeMOHjxY7DIJcPjwYfbt2+eCRCIly263c/z4cZo0aWJ0FBEnFUoRKbPS0tLYv3+/y8536NAhkpKSXHY+kZLw3XffYbfbGTx4sNFRRJx0DaWIlElWq5Xt27df8Zj8/Hy+++47Dhw4wIEDB8jJyeHJJ5+kR48el31NfHw84eHhulFH3Nbs2bMBeOSRRwxOIvJfGqEUkTLp+PHjF93B/b/OnDnDvHnzOHHiBLGxsVd1XovFwpEjR1wRUaRErFu3jkqVKlGxYkWjo4g4qVCKSJnjcDiuqvSFh4czZ84cZs2axQMPPHDV5z927Bh2u704EUVKRFZWFunp6bRv397oKCJFqFCKSJmTlZVFfn7+Xx7n4+NDWFjYNZ/fYrGQnp5+PdFEStTHH38MwPDhww1OIlKUCqWIlDlZWVklen6TyUR2dnaJvofI9Zg/fz4mk4lBgwYZHUWkCBVKESlzzpw5U6LrRTocjhIvrSLXIz4+nlq1auHtrXtqxb2oUIpImWOxWCjpPRkKCwtL9Pwi12r//v3k5eVdcZUCEaOoUIpImaPdbKQ8eu+99wB47LHHDE4icjEVShFxS8eOHWPHjh2XHCn09fUt8VLp5+dXoucXuVaLFi3C19eX1q1bGx1F5CK6CENE3NLdd9/NunXr8PHxoVGjRrRt25aWLVtSu3Zt8vLyMJlMJVoqQ0NDS+zcItfKbrdz6NAhbbcobkuFUkTcUqtWrdiwYQOFhYVs376dHTt2OK+bjI2N5d133y3R99ei0eJOlixZgs1mo3///kZHEbkkFUoRcTsJCQkcPXq0yOLiF8pkYGAgkyZNIjg4mJycnL8818KFC8nNzXWuK7lx40bnP/fp04egoKAixzscDrKzs3nwwQfp0KEDcP6u8uzsbM6cOYPFYuH1118nLi7OJZ9V5GrMmjUL0PWT4r5MjpK+VVJE5C8UFBQwa9YsvvzyS7Zt20Zubu5Fx5jNZpo3b86iRYuIiIjg2LFj7Ny58y/P/dBDD5GSknLJ5z7++GOqVq160eNr167l9ddfd37t7e2NyWTCarXicDhYv3497dq1u4ZPKFI8kZGR5OfnazkrcVsqlCJiiDVr1vD++++zYsUKEhMTgfN3b9eoUYMePXowatQonn76aVatWoXJZKJHjx589913BAcHA2Cz2fjjjz+uapTyWgQEBHDzzTczbty4i6bVTSYTTZo0Yfv27brTXEpNfn4+gYGBdO/enWXLlhkdR+SSdJe3iJSKtLQ0JkyYQIsWLfDz86NTp07MnTuXs2fP0rVrV2bOnElBQQHHjx9n1qxZtG7dmttvvx2AYcOG8fPPPzvLJICXlxfNmzd3ec7mzZvj7e3N5MmTGTFiRJHi6HA42Lt3Lw888AAZGRkuf2+RS5k9ezZw/vtAxF1phFJESoTdbueHH37gk08+Ye3atc4C5uXlxQ033EDfvn15/PHHiY6Ovuw5cnNzWbJkCf3798dsvvTvv8ePHyc+Pt4lmRs2bFjk2sjCwkJ69OjBmjVrsNlsBAYGEhwcTEpKCiaTifbt2zNlyhTatGnjkvcXuZQuXbrw+++/U1BQgK+vr9FxRC5JhVJEXObgwYNMmzaNX375hUOHDjlvqqlcuTKdOnXioYce4vbbb79sObxeF0qlyWS65h10Lrzmf8vkBRkZGbRu3ZojR47w0ksv8e9//5vffvuNp59+mu3btwNQs2ZNXnjhBR5++GGXfzaRkJAQKlSowKlTp4yOInJZKpQict0KCgqYPXs2X3zxBVu2bHHeTOPn50fjxo0ZPHgwjz32GGFhYSWeJTs7m23btl3zNZWBgYG0aNHiihkPHDjAiy++yNSpU4mIiHA+furUKcaOHcuCBQsoLCwkMDCQ++67j7feeouQkJDr/iwiFxw/fpzo6GiGDRvG3LlzjY4jclkqlCJyTTZs2MB7773Hb7/9RmJiIg6HA5PJRFRUlPNmGqOmgO12OydPnuTIkSOcPXsWoMio5Z//OSgoiNjYWGrWrImXl1ex3tdqtfLqq68ybdo00tPTMZvNdO7cmalTp9K4cePifSgp155//nneeOMNVqxYQZcuXYyOI3JZKpQickUZGRm8//77zJ8/n927d2OxWAAIDg6mdevW3HPPPQwfPtytru1yOBzk5OSQlZVFdna2M7OPjw+hoaFUrFiRChUqlMid2j/99BPjx49nz549AMTFxfHyyy9z7733uvy9xPM1adKEffv2XXILUhF3okIpIkXY7XYWLlzIzJkzWbNmjXMRcC8vL2rXrk3v3r15/PHHtbD3Xzhy5AhPPPEEixYtwmazUaFCBR566CFef/11/P39jY4nZYSvry833HCD8xcUEXelq8dFhCNHjvDUU09Rr149fH196d+/Pz/++CMA/fr1Y8GCBVgsFvbv38+kSZNUJq9CbGysc5eeZ599FrPZzOTJkwkODqZXr14kJCQYHVHc3Jo1aygsLKR3795GRxH5SxqhFCmHLBYLs2fPZu7cuWzZssV5I4uvry+NGjVi8ODBjBw5kvDwcIOTepavvvqKf/3rX84yWa9ePV5//XUGDhxocDJxR3/729+YM2cOhw8fJjY21ug4IlekQilSTmzatIn33nuPZcuWcerUKefNKVFRUXTv3p2RI0fSvn17g1OWD3v37uWJJ55gxYoV2O12wsLCGDlyJC+99JJbXYsqxqpVqxYZGRku3w1KpCSoUIp4qKysLOfNNLt27eLcuXPA+bubW7Vq5byZRtfzGSc3N5fx48fz6aefkpOTg7e3N7179+bdd9+lVq1aRscTA1mtVnx9fbnxxhtZvXq10XFE/pKuoRTxEBduphk4cCARERGEhYXxj3/8g23btlGrVi2efPJJEhISyMnJYdWqVTzyyCMqkwYLCgpi6tSpnD17lpkzZ1KjRg0WLFhAdHQ0TZs2ZfHixUZHFIPMmzcPh8PBkCFDjI4iclU0QilShh07doypU6eycOFCDh48iM1mAyA8PJwbb7yRBx988IrbFor72bZtG08++SSrV6/G4XAQERHBk08+yXPPPYe3t7fR8aSU9OrVi8WLF3P27Nkie9iLuCsVSpEyxGKx8NlnnzF37lw2b97sXLzb19eXhg0bMnDgQEaNGkXlypUNTirFlZWVxdNPP80XX3xBfn4+vr6+DBw4kMmTJ1OtWjWj40kJCwsLw9fXl+TkZKOjiFwVFUoRN7d161amTZvGsmXLOHnypPNmmurVq9OtWzcee+wxOnbsaHBKKSl2u53333+f119/3bmXc6tWrXjnnXe46aabDE4nJSEtLY2IiAgGDhzId999Z3Qc+R/5+fmkp6eTnZ1Nbm4uNpsNLy8vgoODCQ0NpXLlyvj5+Rkds9SpUIq4maysLD788EO++eYbdu7cWeRmmhYtWjBs2DAeeOABXf9YDq1du5a///3vbNq0CYfDQWRkJM8++yxjxozRZQ0e5LXXXuOf//wnCxYsoF+/fkbHkf+Tnp7O4cOHnaPGf97K9X+/joyMJC4ujrCwMEOyGkGFUsRgdrudRYsW8fHHH7N69WpSU1MBMJvNxMXFcdtttzF69Gjq1atncFJxFykpKTz11FN8++23nDt3Dn9/f4YMGcKkSZO0dqgHaN26Ndu2baOwsFC/KLiBwsJCdu/ezcmTJy8qkZdz4bjY2Fjq16+Pl5dXKSQ1lgqliAGOHz/OtGnT+Omnn0hISHDeTBMWFkaHDh144IEHGDRokH6YyBXZ7XbefvttJk2aRHJyMiaTiQ4dOjB58mTatGljdDy5TgEBAURFRXHw4EGjo5R7ubm5rFu3joKCgus+R1BQEO3btycgIMCFydyPCqWUSYWFhRQUFOBwOPDy8iIwMBCTyWR0rMuyWq3MnTuXzz77jE2bNnHmzBkAfHx8aNCggfNmmipVqhicVMqq3377jaeffprt27cDULNmTf75z38yYsQI/WJShsTHx9OsWTNGjRrF9OnTjY5TruXl5bF69WoKCwuvalTyckwmEwEBAXTs2NGjr61UoZQyweFwkJWVxfHjx0lLSyM/P7/I82azmZCQEKpVq0atWrXcYreR7du3M23aNJYuXcqJEyeKXFvTtWtXRo4cSadOnQxOKZ7m5MmTjB07lh9//JHCwkKCgoK47777mDhxopafKQNGjhzJjBkz2LlzJ40bNzY6TrnlcDhYvXo1Z86cKVaZvMBkMlG5cmXatm3r1oMfxaFCKW4vKyuL+Ph4zpw5c1XXr5hMJqKjo6lfv36prtt35swZPvjgA+fNNBemSAIDA2nRogVDhw7lwQcfJDAwsNQySflltVp55ZVXmD59Ounp6ZjNZm6++WbeffddFRU3Vrt2bRITEy/6pVlcKycnh4kTJ7JhwwY2btxIZmYmn3zyCffffz8Ahw4dYu/evUVeY7VaGTNmDCdOnHBelnRBcnIyI0aMuOR7PfPMM3Tu3BmAZs2aUbNmTedzhYWFNGvWjL179zJx4kSefvppF3/S0qNVcsVtORwODhw4QEJCQpHHruZ1R48eJSkpiZYtW5bYTQp2u52lS5fy0Ucf8ccff5CSkgKcHy2NiYlx3kzToEGDEnl/kSvx9vbm5Zdf5uWXX+bHH3/k+eefZ8WKFTRp0oS4uDgmTJjAPffcY3RM+RO73c7Ro0dp2bKl0VE8XlpaGhMmTKBWrVo0a9aMlStXOp+zWq3s37//otcsXLjQedPk5XTu3JnWrVsXeax+/frOf967dy9RUVHOy1CmTp3K8ePHi/FJ3IcurBG35HA42LZtW5Eyea0KCgpYt26ds+i5wsmTJ3n++edp2LAhfn5+9OrVi/nz52OxWLjtttv46quvKCws5NChQ0ybNk1lUtxCv3792L17N4cOHaJ3794cO3aMe++9l9DQUJ566qli3XAgrvPjjz9it9uLjHxJyYiMjOT06dMcO3aMiRMnFnnu5MmT2O32Io9lZWUxb948Bg8efMXz1q5dm65duxb535+vjbdYLCQlJQHnV2uYMGECzz33nIs+lbFUKMUt7d69m8TExGKfx+FwsHnzZrKysi75/JkzZ+jTpw/PPvvsJZ+3Wq3MmTOHW265hdDQUGrWrMkbb7zBwYMHadCgAf/61784ffo0mZmZ/PLLL9x11126AULcVlxcHAsXLiQnJ4dnnnkGk8nEO++8Q3BwMLfddpvuKjbYp59+CsCjjz5qbJBywM/P77I7Tp08efKix2bPnk1UVBRdunT5y3MXFBRQWFh42ecvnH/8+PHUq1ePe++99+pCuzn95BO3k5qaytGjR112PrvdzrZt25xL81yQlJREx44d+fnnn/noo4+cv5HGx8fzyCOPEBMTg6+vL3/7299YtmwZgYGBDB06lBUrVmCxWIiPj2fChAnaBk/KHH9/f9566y2ysrL48ssviY2NZdGiRdSpU4cGDRrw/fffGx2xXFq7di3h4eFaS9RAdrud7OzsIo8dOHCA5cuX8/DDD//lDTXz5s3jzjvvZPDgwfz9739n69atFx2TmZnJxo0bmT17NpMnT/aYm3R0DaW4lU2bNjFmzBh27dqFxWKhWrVq9OzZ07lbxPPPP8+uXbsuel3Lli15+eWXnV9f+AsgPj6elJQUKlSoQOvWrZkyZQp169YlISGB7t27O0dBs7KyaNq0KYcOHXJO/wUEBNC+fXvuvvtuHnroId1MIx5p6NChDB06lD179jBmzBhWrFjBoEGDCAsLY9SoUbz44otusWqCpztz5gypqancdtttRkcp13Jycopcq+9wOPjggw/o1KkT9evXv+ze6iaTiRYtWtChQwcqVapEUlISP/zwAy+//DL//Oc/i6wLa7FYGD16NEOGDKFDhw4uHUAxkgqluI0lS5bQt29fYmNjGTJkCAEBAZw+fZr09PQix1WuXJnhw4cXeex/f6OfP38+e/fupWPHjsTExJCVlcXPP/9My5Yt+fjjj3n44YfJzc0t8hfH7t27iY2NpVevXowePZpGjRqV3IcVcTMNGzZk2bJl5OTk8Pzzz/PJJ5/w2muv8eabb9KnTx+mTJlCrVq1jI7psWbNmgXgMdOfZZXFYiny9W+//cbRo0cZP378FV9XpUoVJkyYUOSxrl27MmrUKGbOnFmkUP7222/s3r3b4/ZpV6EUt3DmzBmGDx9O+/btGTdu3BWvQwwMDKRr165XPN+AAQN4+umn8fHxcT520003MWrUKO6+++5LvqZdu3asX7/++j6AiIcIDg5m6tSpTJ06lZkzZ/LKK6/www8/8MMPP9CkSRMmTpxIz549jY7pcb755htMJhN33XWX0VHKtT9PP+fl5TF79mwGDRpERETENZ+rQoUK9OjRg2+//Za0tDQqV67sPOeYMWOKLB/kCXQNpbiFL774guTkZIYOHYrZbKagoOCiu+z+zGazXXGdtgYNGhQpkwDVqlUjIiICLy8vKlWq5PyLw2QyYTKZiuxgIyLw0EMPcfToUbZs2UKnTp3YtWsXvXr1okqVKvznP/+54veoXJsdO3ZQs2bNUl07Vy7258s7vvvuO6xWKzfddBPJyckkJyeTlpYGnJ8aT05OvuLNN3B+Rg3g7NmzRc45ZMgQjh49ytGjR5036WRmZnL06NGLRknLCv3JFbewbNkyKlSoQHp6Oq+99hqnTp3C39+frl27MmLEiCLf5ImJidxxxx1YrVYqVqxIz549GTp06F/+RWwymbBarXTv3p3FixdTUFDAzp072bp1K9u2beP06dO6VkzkElq2bMkff/xBVlYW48aN44svvuCFF17g5ZdfZtCgQUyZMkXbhhbDwYMHyc3N5c477zQ6Srmwbt06+vbtS0xMDK1atSI0NBQ4PyLp7+/vPC41NZWcnBxGjx590Tm++eYbvvnmG6ZMmUJcXNxl3+vCEkEX3uPCOS+11uh//vMf/vOf/7Bt2zaaN29enI9oCO2UI26hWbNmJCQkYLfbueWWW2jSpAk7d+5k4cKFdO7cmWeeeQaAd999l4iICKKjoykoKGDt2rVs2LCBTp06/eVaXitWrGDSpEnMnDmTBx98sDQ+lohHstvtTJ8+nTfeeIPExERMJhMtW7Zk8uTJ2k70OowbN45Jkyaxfv162rVrZ3Qcj3dhv3Q4vwGA1Wot8vzEiROpV68ehw4dumgh8+zsbKZPn0737t1p164dTZs2JSgoiOzsbGdpvCA9PZ3HH3+cypUrM3XqVOD8Lw+FhYXUqVPHeVxKSgqPPvoo999/P/3796dr164XnassUKEUt1C7dm0OHz7MbbfdxqhRo5yPT58+nUWLFvHBBx9QvXr1S7522rRpLF68mIkTJxbZkeDPTpw4wdNPP02tWrXYuXOnppVEXGT16tWMGzeOTZs24XA4iIyM5Nlnn2XMmDFak/UqNWjQgMOHD3Pu3Dmjo5QLNpuNSpUqXbQ8EJy/Rn/IkCH07NmToKCgi56/sMXi/269OHnyZJKSkmjWrBnh4eEkJyezaNEi8vPzmTBhAk2aNHEe26pVKyIjI51fHz16lNjY2DK/9aK+26VUbdq0iUmTJrFhw4Yi154EBAQAOPc7veDmm28GYN++fZc954ABA4Dz1yBdSmZmJhMmTCAwMJDx48fj5eVVnI8gIn/SqVMnNmzYQFJSEsOGDSM9PZ2///3vBAUF8cADD1x2UwE5z263c/Dgwcv+MiyukZaWxr///W8aNWqEn5/fJcsknJ/2/uSTT655L/UWLVoA8PPPP/P++++zePFiGjduzMSJE4uUSV9fX6pWrXr9H8SNaZhGStWnn37Ke++9B5xfXLl9+/Z07drVee1ixYoVixx/Ydg/Jyfnsuf834ue/yw3N5d///vf5Obm8sYbb1CzZk2PWURWxJ1UqVKFuXPn8tlnnzFx4kQmTZrEp59+yuzZs+nQoQNTpky5aI9jOX8pjtVqpW/fvkZH8Thr1qxh6tSpLF++3Dl17e3tTaNGjWjatCmff/6589ixY8fy//7f/3OOqh8+fJg9e/ZcdM6qVavy008/XfT4zTff7BwAuZKGDRteNHIfExODJ0wWa4RSStWf1+IqKChg5cqVvPTSS2zbtg3gojUnMzIyAAgJCbnsOS8sNPu/15xYLBZeeeUVTp06xYsvvkh0dDRhYWEu+Rwicmlms5nnnnuO5ORkli5dStOmTVm7di1t2rQhOjqajz76yCN+eLrKxx9/DMDIkSMNTlL2FRQUMHXqVNq1a4e/vz+dOnXiq6++orCwkD59+vDzzz9z7tw5duzYwQcffOAcyHj11VeZNGlSkaIXGxtLxYoVXTYAYTKZiIiIICoqyiXnc0cqlFLi7HY7v//+OyNHjuTVV1+95DEXlvhZuXJlkceXLFmCl5cXTZo0IS8v76IlGhwOB1999RXw3ykHOH+NzFtvvcW+ffsYP3489evXx+FwOEczRaTk9ejRg+3bt3PixAkGDhzI6dOneeSRR6hQoQKjRo264sxDebFq1SpCQkI8umiUpP379zNy5Eiio6MJDAxkzJgxbNq0iRo1avDUU09x7NgxMjMz+emnn7j99tudpTEwMJD//Oc/fPLJJ7zwwgsXFUeTyUSrVq3w9fUtdqk0mUwEBATQokULj54h00054nIFBQV88803fP/992zatInExETnenW+vr5YrVbn1yaTiTZt2rBgwQJeeOEFZs2aRadOnWjcuDE7d+5kzZo13HnnnQwfPpydO3cyceJEOnfuTGRkJBaLhXXr1rF371569uzJ448/7szw0Ucf8eOPP9K2bVvnXadms5kmTZpgNpu1G4WIAaxWKxMmTGD69OlkZGRgNpu5+eabeffdd2ncuLHR8UpdQUEBAQEBdO3aleXLlxsdp0yw2+188803fPzxx6xfv975S0lgYCCtW7fm/vvv57777nPZjZd5eXmsW7fumq+p/LPg4GDat29fZEkiT6RCKcV28uRJPvvsM3799Vd27dpFZmam87mQkBAaNmzILbfcwn333UedOnUYOHAgP/zwAwD33XcfH330EX5+fhQWFvLqq6/ywQcfkJ6eTkREBL1796Z///7A+fW8Pv30UxISEsjKysJkMlGzZk1uvfVWevXqVeQ3v8vt+X2B/tiLGOvHH39k/Pjx7N27Fzi/0sMrr7xy2Z2sPNFHH33EI488wgcffMAjjzxidBy3lZKSwpQpU/juu+84cOCAc0AiMjKSnj178uSTT5bouo1Wq5U9e/Zw/PhxTCbTVf38uHBcXFwc9erVKxc3g6pQyjVbv349c+fOZdWqVSQkJFBQUACc/waqWrUqLVu2pF+/ftx9992XvPZx2rRpjBkzhrfeeotx48ZdNAWQlJTE5s2bXZo5ICCALl26lItvapGy5NChQ4wZM4bFixdjs9kICQlhxIgRvPbaax4/otOtWzdWrFhBfn6+x3/Wa7Vy5UqmTZvGypUrndfW+/j40LhxY4YOHcpjjz12xWvrS0JGRgaHDx92Llb+v+Xywtcmk4nq1asTFxdXJteTvF4qlHJFFouF77//nvnz57NhwwZOnTqFzWYDzn9zx8TE0LFjR+666y569ux5VevO2Ww2Tpw4QUxMzGWP2b59u3M7quIymUx06NCB8PBwl5xPRFyvoKCAf/3rX3z44YecOXMGLy8vbr31VqZOnUrt2rWNjlciQkNDCQoKIjEx0egohsvLy2PGjBl88cUX7Ny507n9YHh4OJ07d2bUqFHccsstBqc8r6CggIyMDLKzs8nNzcVms+Hl5UVwcDChoaFUqlSpXO66pkIpRSQnJ/PZZ5/xyy+/EB8fX+Su6+DgYOrXr0+PHj249957adSoUYnlsNvtbN68mZSUlGKfq2XLlpddFF1E3M+XX37Jiy++yMGDBwGoX78+b7zxhvPyF0+QmJhIVFQUQ4YMYd68eUbHMcSuXbuYPHkyixcvdg4gmM1mateuzYABAxg7dqz+7i5DVCjLua1bt/L555+zYsUKDhw4QF5eHvDfJQ6aN29O3759GTZsWKmP8Nntdnbv3s2xY8eu6/U+Pj60aNFCewyLlFG7d+/mySefZMWKFdjtdsLCwhg9ejQvvfRSmd/t6l//+hevvvoqS5cupUePHkbHKRVWq5V58+Yxa9YsNm7cSG5uLgBBQUG0bduWBx98kKFDh5b5/7bllQplOWK1Wvnxxx/59ttvWb9+PSdOnHDuYert7U2tWrXo0KEDd955J71793abb+q0tDTi4+PJy8u76guio6KiaNSoUbmcdhDxNDk5OYwfP55PP/2U3NxcvL296dOnD1OnTqVGjRpGx7tqy5Yt46233qJz587Mnj2bw4cPU1hY6NFbVCYmJjJ58mR++OEHDh065LyhJioqil69ejF27NhyeYe/J1Kh9GBpaWnMnTuXn3/+me3bt5OWluYsY0FBQdStW5du3bpx7733lugdcq7gcDhIS0vj2LFjpKenX7QeJZz/TJGRkURHRzu3chQRzzJz5kxeeeUV58xF06ZNefvtt93m+roree+99xg9ejRmsxm73Y7ZbGbAgAH07duXv/3tbx6zRuHSpUuZPn06f/zxh3NzCl9fX5o0acKwYcN47LHHCAwMNDiluFq5LJQOh4OCggKysrKcF9SazWaCgoKoWLEiAQEBZfIbe9euXcyZM4fly5ezb98+53QCQKVKlWjevDm333479957b5meBr7w3y8/Px+Hw+G8GNpdRlRFpORt2bKFsWPHsmbNGhwOBxEREfz973/nueeec9sRv40bN9KuXbuLHjeZTJw4caLMLm6ek5PDe++9x7x589i1a5fzF/5KlSrRpUsXRo8eTdeuXQ1OKSWtXBXKwsJCTp48yZEjR4pcK3jBhX8V/v7+xMTEUKtWLbedMrXb7fzyyy988803rF27lmPHjjm/ib28vKhRowbt27dn8ODB9O/f320/h4hIcWRlZfHUU0/x5ZdfUlBQgK+vL4MGDWLKlClu94tzQUEBwcHBzpUyLpg6dWqRjRnKgu3btzN58mSWLFnC6dOngfM31NStW5eBAwcyZswYqlWrZnBKKU3lolA6HA5Onz5NfHy885rBq+Hl5UWjRo2oWbOm4SOWWVlZfPnll/z4449s27aNlJQUZwEOCAjghhtuoGvXrtx7771F9ssWESkP7HY706dP54033iAxMdG5dd7kyZPp2LGj0fGcmjRpUmTThWeffZY333zTwERXx2q18tlnn/HJJ5+wZcsW56DMhV1gRowYwZ133um2o8NS8jy+UNpsNnbs2FGsdb4iIiJo1apVqU6p7t+/nzlz5rBs2TL27t3L2bNnnc+Fh4fTpEkTevXqxfDhw7WsgojIn6xevZqnnnqKzZs343A4qF69Os8++yxPPPGE4YVnxIgRzJw5E4Bhw4bx2WefGZ7pco4fP87kyZP58ccfOXz4sHPR7ho1anD77bczduxY6tevb3RMcRMeXSjtdjubNm0iNTW12OcKCwujffv2JbLTit1u57fffmPevHmsXr2ao0ePOhd1NZvNREVF0aZNGwYNGsTgwYO1o4KIyFVISUlh7NixzJ8/H4vFgr+/P3fffTeTJk2iYsWKhmR6+OGH+fjjj7nhhhvYvXu3W12OZLfb+fXXX5kxYwarV68mKysLAD8/P5o1a8a9997Lww8/rJ9BckkeXSh3797NkSNHXHa+qKgoWrRoccnncnNzmTdvHvfdd99f/gWRk5PDV199xQ8//MCWLVtISkoqcv1mXFwcN998M8OGDePGG290299eRUTKArvdzltvvcU777xDSkoKJpOJG2+8kXfffZeWLVu6/P0cDgdnz54lKyuLM2fOUFhYiMlkws/Pj4ULFzJx4kS2b9/uFrNLWVlZTJ8+na+//po9e/Y4LwuLiIigW7duPP7443Tq1MnglFIWeGyhTE9PZ926dXz11Vd8/vnn1KpVi+nTpwPnd4MZMWLEZV9766238sQTTzi/LiwsZO7cuaxYsYK8vDyaNm3Kq6++6lym4sSJE9x+++3s2rWLefPmMWTIkCLnO3LkCHPmzGHJkiXs3r2b7Oxs53MVK1akUaNG9OzZk+HDhxMdHe3Kfw0iIvInS5cu5ZlnnmHHjh0AREdH889//vOKPxOultVq5cSJE5e98RP+e/NnpUqViImJoVq1aqV+jf7mzZuZPHkyv/32m3Nfai8vL+rVq8cdd9zBE088QeXKlUs1k5R9HlkoHQ4Hq1at4ujRozz22GOYTCaqVKniLJQFBQWsW7fuotdt3bqVlStX8txzzxX5jWzixImsWbOGfv36UatWLTZu3MimTZtYsWIFXl5e9O3b1zk1MHLkSO644w6+/PJLfv/9dw4fPsy5c+eA89PX1apVo3Xr1gwYMIAhQ4ZoLS4REQOcPHmSMWPG8NNPP2G1WgkKCuJvf/sbb775JsHBwc7jjhw5wssvv8zEiROJiIi47PnS0tLYvn07BQUFV/X+FzZpCA8Pp3nz5iX6s8BisfDpp58yZ84ctmzZ4swYEhJChw4dePjhhxk4cKBmw6RYPLJQXhidfOutt8jOzsZut3PmzBlnobycf/7znyQkJPDZZ585p60PHDjAuHHjeOCBBxg0aBAAjRs3pkePHphMJo4ePYrNZrvk7i2+vr7ExcXRqVMnhg4dSteuXfUNKyLiRqxWKxMmTGD69OlkZGRgNpvp0qUL7777Lo0aNeKRRx7ho48+on379qxcuRI/P78ir3c4HBw4cICEhITren+TyYTJZKJ169YuXeboyJEjvPPOOyxcuJCjR486b6iJjo6mT58+jB07ltq1a7vs/UQ8st0cP36c3bt3s2bNGh5++OGrek1GRgY7d+6kQ4cORa6BXLNmDWazmV69ejkfuzBtffDgQaxW60Vl8tlnn+XAgQOcO3eOvXv38tFHH9G9e3eVSRERN+Pt7c2ECRNIT09nwYIF1KtXj+XLl9O4cWPi4uL45JNPgPOLko8YMeKiv+/3799/3WUSzhfSCzeQpqSkXPa4gwcPMn78+MuOgNrtdhYsWMDtt99OaGgocXFxTJ06ldOnT9O+fXvee+89CgoKOHLkCFOnTlWZFJfzyIaTkpLCjBkzuPXWW4mJibmq1/z+++/Y7Xa6dOlS5PHDhw8TFRVVZDoiNzeX9PR059f/WxRvueUW6tSpc935RUSk9PXr1489e/Zw8OBBbr/9do4ePeq8ScVut/P5558XWTMyMTGRgwcPuuS9HQ4HW7ZsIT8//6LnduzYQfv27XnzzTdZtGiR8/GMjAxefvllmjRpgq+vLwMGDODXX38lICCAYcOGsX79evLz81m7di0jR450qzvKxfN43F51hYWF/PDDD6SmpvLqq69e9etWrVpFeHg4TZs2LfJ4RkYGYWFhRR4LDAxk48aNtGnThieeeIIKFSqwYsUKNm3ahNVqZf/+/fTo0cMln0dEREpX7dq1WbBgATVq1CA5ObnIc88//zwhISE89NBD7Ny587LnOHDgAMuXLyc+Pp6UlBQqVKhAvXr1uO+++y67xaLdbmfHjh20a9fOeaPOmjVr6NWrF/n5+Xh5eTFr1iy++uorli9f7hzR9Pb2pmHDhtx11108/vjjhi2JJOWbxxXKU6dOMXfuXIYMGUJoaOhVv+bgwYP079//otFGi8WCj4/PRa+58M0eFxfH2LFjgfM3++zcuZOGDRsW70OIiIihFi5cSHJyMiaTCS8vLxwOh3PLxNGjR2OxWLjhhhsu+/r58+ezd+9eOnbsSExMDFlZWSxcuJCxY8fy9ttvX3JFD4fDQVpaGqmpqVSpUoVFixYxYMAALBaLc6r9p59+AiA0NJTbb7+dRx99lD59+uiSKjGcxxXKV155heDgYPr06XPVr1m5ciXARdPdcP7Gmgt7ZP/ZhetYAgICnI/5+/tr20MREQ9Qo0YNevfuTXBwMCEhIYSGhhISEkJubi7x8fHUqFHjiq8fMGAATz/9dJEBiZtuuonHH3+cb7/9lnHjxl3ydSaTiQMHDvDkk08yb968Sx6zcOFCevfuff0fTqQEeFShTEhI4NNPP2XEiBFkZGQ4Hy8sLMRms5GcnExgYCAVKlQo8rpVq1YRFRV1yd82w8PDi1wvecGFx9xhYVoREXGt1q1bs3Dhwks+l5iYyNatW6/4+gYNGlz0WPXq1alVqxYnTpy47OscDgeZmZn88ssvzscujJJeuJ5z27ZtKpTidjyqUJ46dQq73c6HH37Ihx9+eNHzI0aMoF+/fkXu/N6/fz+nT5/mnnvuueQ5Y2NjiY+PJy8vr8iNOfHx8QA0b97ctR9CRETcWmZmpnMdyWvhcDjIysqiVq1aVzzOZDKxfv16qlatys6dO4mPjyc+Pp7Nmzezd+/eSw5yiBjNowpl48aN+f7779m3bx9nz551Pv7555+Tn5/Pww8/TGRkZJHXrFq1CoCbb775kufs2LEj33//PYsWLXKuQ+nr68vs2bNp164dNWvWLKFPIyIi7igrK+uayyScv7wqPT39sgMYF5hMJry9vQkPD+fmm28u8vPJbrfreklxSx5VKCtXrsyAAQM4evQou3btcj7+448/AtChQ4cix9tsNv744w/q1at3UdG8oF69enTs2JE5c+aQnZ1NZGQka9eu5ejRo8ycObPkPoyIiLilC7ufXYsTJ04wY8YM6tevT7du3a77PVQmxV155J/MqKioq/qm27FjB1lZWZcdnbzgqaeeol+/fqxYsYIPP/wQs9nMwoUL6dy5s6sii4hIGXGto5OZmZlMmDCBwMBAxo8fj5eXVwklEzGOR269CMXfveByatWqddFalSIiUn788ccfZGdnX9Wxubm5/OMf/yA1NZU33njjL6+fhPNT3jfccAP16tUrblSRUuORI5QAN9xwA0FBQc71Il3B399fa0yKiJRzFStWvKqfLRaLhVdeeYVTp07x4osvXlWZhPMjoCEhIcWNKVKqPLZQenl50apVK5ddb2IymWjZsiXe3h512amIiFyjihUr/uW0t81m46233mLfvn2MHz+e+vXrX/N7iJQlHt2OQkJCaN++PevXr8dut1/XXXkmkwmTyUSbNm0IDw8vgZQiIlKWVK1a9S+XDZo1axYbNmygbdu2nD17lhUrVhR5vmvXrpd9bcWKFYtsmiFSFnh0oQQICwujc+fObN++nczMzGt+fXBwMC1atND0g4iIAOeXjouKiuLUqVOXLZWHDx8GYOPGjWzcuPGi569UKGNjY10TVKQUeexNOf/L4XBw7NgxDh06RH5+/mV/u7zwuJ+fH3FxccTGxmqZBhERKSI3N5dVq1Zht9tddk6TyURwcDA33XSTfu5ImVNuCuUFDoeDtLQ0UlNTycrKIicnB7vd7vxGrlixIpUrV6ZKlSouvaFHREQ8y+HDh9mzZ49Lz9m5c2fNiEmZVO4KpYiIiCs4HA62bt3K6dOnXXK+Jk2aEB0d7ZJziZQ2jamLiIhcB5PJRIsWLS6709rVuDCm07hxY5VJKdNUKEVERK6T2WymZcuWNG7cGLPZfM2XSuXm5vLSSy9x4MCBEkooUjo05S0iIuICeXl5HDp0iBMnTjivzb/w/xf8+cbP2NhY/P39qVmzJgCjRo3ipZdeokqVKkZ9BJHrpkIpIiLiQlarlZSUFDZu3Mju3bvp0KEDPj4++Pv7ExoaSlhYGJUrV3YWzZCQEM6ePYvJZMLf35/nnnuOcePGERwcbPAnEbl6KpQiIiIloFGjRuzZs4e8vLwrLlR+6623snTpUufXZrOZsLAwZs6cSf/+/Usjqkix6RpKERERF9uwYYNzSaFff/31isfWr18fHx8f59d2u5309HSWLFlSohlFXEmFUkRExIXOnTvH8OHDnV/PmTPnisfXrVsXq9Xq/NpkMjFp0iSmTp1aYhlFXE2FUkRExIVefvllEhISnF///PPPV9z6t06dOjgcDkwmE4GBgTgcDkJCQrRbjpQp+tMqIiLiIlu2bOHNN98ssrWvzWbj22+/vexrmjdvTqVKlRg3bhwnT54kKCiIkSNHkpKSUhqRRVxCN+WIiIi4yC233MKyZcswm81F9vnu2LEjq1evvqpzLF68mF69etGgQQOXb+0oUlI0QikiIuIiL7zwAs899xwdO3YEIDg4GJPJxL59+676HD179uTuu+9m7969vPjiiyUVVcSlNEIpIiLiYhMmTOCll15i7dq1tGrVCqvVSmBg4FW/3m63ExkZSWpqKjt37qRRo0YlmFak+DRCKSIi4mL79+8HoEWLFvj6+l5TmYTza1FeWJuyR48eRabPRdyRCqWIiIiLHTlyBC8vL/z9/a/7HE2bNmX8+PEkJSXxwAMPuDCdiOtpyltERMTFYmJiyMzMJDs7u9jnqlevHgcOHGDZsmV0797dBelEXE+FUkRExMVCQ0OpVKkShw8fLva5EhMTiY6Oxt/fn9TU1GKNeoqUFE15i4iIuFhubi6RkZEuOVf16tWZPn06OTk59O7d2yXnFHE1FUoREREXysvLw2azERsb67JzPvLII3Tq1Inly5cze/Zsl51XxFVUKEVERFxo69atADRo0MCl5128eDGBgYE8/PDD2kVH3I4KpYiIiAtdKJTNmzd36XkDAwP59ttvKSwspFu3bi49t0hxqVCKiIi40IXtEtu2bevyc992220MGTKE3bt38/LLL7v8/CLXS3d5i4iIuFCPHj1Yvnx5iS1GbrfbqVatGunp6ezatcvlU+si10MjlCIiIi508uRJAgICSuz8ZrOZJUuW4HA46N69u3bREbegQikiIuJCaWlpVKxYsUTfo3nz5jzzzDOcPn2ahx56qETfS+RqaMpbRETEhfz8/GjUqJHz5pySVLduXRISElixYgVdunQp8fcTuRyNUIqIiLiI3W7HYrEQHR1dKu+3cuVKvL296devHwUFBaXyniKXokIpIiLiIvv37wfOjxyWhurVq/Puu+9y9uxZ+vbtWyrvKXIpKpQiIiIusmnTJgCaNGlSau85cuRIbrzxRpYtW8acOXNK7X1F/kyFUkRExEV27twJQJs2bUr1fRcvXkxAQAAPP/wwaWlppfreIqBCKSIi4jIHDhwAoE6dOqX6vsHBwXz99ddYLBbtoiOGUKEUERFxkePHj+Pr64vZXPo/Xvv06cMdd9zBzp07efXVV0v9/aV807JBIiIiLlK9enUsFoth0852u50qVaqQmZnJnj17qFevniE5pPzRCKWIiIiLZGVlERERYdj7/3kXnW7dumkXHSk1KpQiIiIuUlBQQI0aNQzN0LJlS8aNG0diYiKPPPKIoVmk/FChFBERcYGUlBQcDgc33HCD0VGYOHEitWvXZubMmfz+++9Gx5FyQIVSRETEBTZs2ABAo0aNDE5y3oVddPr06YPFYjE6jng4FUoREREX2LFjB3B+ytkd1KhRg3feeUe76EipUKEUERFxgb179wLuUygBHn/8cdq3b8+SJUuYO3eu0XHEg2nZIBERERfo2LEjGzZswGq1Gh2liJycHKpUqYLNZuP06dOEh4cbHUk8kEYoRUREXCAxMZGgoCCjY1wkODiYefPmYbFY6Nq1q9FxxEOpUIqIiLhARkaG247+9evXj0GDBhEfH8/rr79udBzxQJryFhERcQFvb2/atWvHmjVrjI5ySVarlapVq5KVlcW+fftKfb9x8WwaoRQRESmmgoICbDYbsbGxRke5LG9vbxYvXozD4aBr167aRUdcSoVSRESkmLZs2QJA/fr1DU5yZa1bt2bs2LGcOnWKxx57zOg44kFUKEVERIpp69atADRv3tzYIFdh0qRJxMXF8dFHH7F69Wqj44iHUKEUEREppt27dwPQtm1bg5NcnRUrVuDl5UXv3r21i464hAqliIhIMR06dAiTyUSVKlWMjnJVatWqxTvvvMOZM2fo37+/0XHEA6hQioiIFNPJkyfx9/c3OsY1eeKJJ2jbti2LFi3iyy+/NDqOlHFaNkhERKSYKleujK+vL4mJiUZHuSZnzpyhatWqOBwOEhMT3XYdTXF/GqEUEREpprNnz1K1alWjY1yzkJAQ5s2bx7lz5+jevbvRcaQMU6EUEREpBrvdjsViITo62ugo16V///4MGDCA7du388YbbxgdR8ooFUoREZFiOHDgAAB169Y1OMn1++abbwgLC+OFF17g0KFDRseRMkiFUkREpBg2b94MQJMmTQxOcv20i44UlwqliIhIMcTHxwPnd6Epy9q0acMTTzzBiRMnGD16tNFxpIzRXd4iIiLFMGDAABYsWIDNZsNsLvvjNLGxsRw9epTVq1fTsWNHo+NIGVH2/+SLiIgY6Pjx4/j6+npEmQRYuXKldtGRa+YZf/pFREQMkpSURIUKFYyO4TLR0dG8/fbbZGdnM3DgQKPjSBmhQikiIlIMWVlZREREGB3DpcaOHUvr1q355Zdf+Prrr42OI2WArqEUEREpBrPZTPfu3Vm6dKnRUVzqz7voJCUlUbFiRaMjiRvTCKWIiMh1SklJweFwULt2baOjuFxISAiff/65dtGRq6JCKSIicp02btwIQKNGjQxOUjIGDx5Mv3792Lp1KxMnTjQ6jrgxFUoREZHrtGPHDgBatmxpcJKSM3/+fMLCwhg/fjxHjhwxOo64KRVKERGR67R3717Aswult7c3v/76Kw6Hgy5duhgdR9yUCqWIiMh1OnLkCF5eXgQEBBgdpUS1a9eO0aNHc/z4ce2iI5eku7xFRESuU2xsLBkZGWRnZxsdpVTExMRw7Ngx1q5dS4cOHYyOI25EhVJEROQ6hYaGEh4eXm6uLTxy5Ah16tShQoUKpKam4u3tbXQkcROa8hYREblOubm5REZGGh2j1MTGxvLmm2+SlZWlXXSkCBVKERGR61BQUIDNZiM2NtboKKVq3LhxtGrVioULF/Ltt98aHUfchAqliIjIddi2bRsA9evXNzhJ6Vu2bBn+/v7cd999ZGVlGR1H3IAKpYiIyHXYsmULAM2aNTM4SemrWLEin332GQUFBfTo0cPoOOIGVChFRESuw+7duwFo3769wUmMcccdd9C7d2+2bNnCpEmTjI4jBtNd3iIiItfh1ltvZdmyZdjtdqOjGMZqtRIREcHZs2c5dOgQ0dHRRkcSg2iEUkRE5DqcOHECf39/o2MYytvbm19++QWbzcbNN99sdBwxkAqliIjIdUhNTaVixYpGxzBchw4dGDlyJMeOHWPMmDFGxxGDaMpbRETkOvj5+dGwYUPn3d7lmd1uJyYmhpMnT7Ju3TratWtndCQpZRqhFBERuUZ2ux2LxUKtWrWMjuIWzGYzq1atwmQycdttt2G1Wo2OJKVMhVJEROQaJSQkAFC3bl2Dk7iP2NhY3njjDTIzM7njjjuMjiOlTIVSRETkGm3evBmAJk2aGJzEvTzzzDO0aNGCBQsW8P333xsdR0qRCqWIiMg1io+PB6B169YGJ3E/y5cvx8/Pj2HDhnHmzBmj40gpUaEUERG5RgcOHADK57aLf6VixYrMmTNHu+iUMyqUIiIi1+jYsWP4+vpiNuvH6KXcdddd3HbbbWzatIkpU6YYHUdKgZYNEhERuUZRUVGcO3eOtLQ0o6O4LYvFQpUqVcjJyeHw4cO6I97D6VcrERGRa5SVlUXlypWNjuHWfH19+fnnn7HZbHTp0sXoOFLCVChFRESuUX5+PjVq1DA6htvr2LEjjz76KEeOHOHvf/+70XGkBKlQioiIXIO0tDQcDgc33HCD0VHKhPfee48aNWowZcoU53JL4nlUKEVERK7Bxo0bAWjQoIHBScoGs9nMypUrMZlM9OzZU7voeCgVShERkWtwYe/uVq1aGZyk7KhduzavvfYaGRkZ3HXXXUbHkRKgQikiInIN9u3bB0DLli0NTlK2jB8/nmbNmvH999+zYMECo+OIi2nZIBERkWvQqVMn1q9fr6nb65CRkUH16tUxm82kpKQQHBxsdCRxEY1QioiIXIPExEQCAwONjlEmhYeH88knn5Cfn69ddDyMCqWIiMg1SE9PJzw83OgYZdbdd99Nz5492bBhA1OnTjU6jriIprxFRESugbe3N23btmXt2rVGRymzLBYLERER5ObmahcdD6ERShERkatUUFCAzWYjJibG6Chl2p930enatavRccQFVChFRESu0vbt2wGoX7++sUE8QKdOnRgxYgSHDx9m3LhxRseRYlKhFBERuUpbt24FoHnz5sYG8RAffPABUVFRvPPOO85/t1I2qVCKiIhcpV27dgHQtm1bg5N4BrPZzIoVKzCZTNx6661aiqkMU6EUERG5SgcPHsRkMlGtWjWjo3iMOnXqMGHCBNLT0xk6dKjRceQ66S5vERGRq9SwYUOOHj1KXl6e0VE8TtOmTdm5cycLFiygX79+RseRa6RCKSIicpUiIiLw9vbm9OnTRkfxOGlpaURFReHl5aVddMogTXmLiIhcpTNnzlC1alWjY3ikypUrM2vWLPLz87n11lsByMnJYfbs2RQWFhqcTv6KCqWIiMhVsNvtWCwWoqOjjY7ise655x5uueUW1q1bxzPPPEOTJk24//77+fXXX42OJn/B2+gAIiIiZcGhQ4eA8zeRSMn5/vvvCQ8P5+2338ZsNmM2mzlw4IDRseQvaIRSRETkKmzcuBGAJk2aGJzEcx0+fJjOnTtjsViA86PCKpRlgwqliIjIVdi5cycArVu3NjiJ55oxY8ZFC5xbrVb27t1rUCK5WpryFhERuQoXRskaNGhgcBLPNWHCBKpWrcqECRM4e/YsFxaiubCg/J85HA6yLPlknsvD7rDj5+VDtcAQfMxepR1b0LJBIiIiV6VVq1bs3LnTOR0rJSczM5PXX3+dd955x7l7TnZ2NsEVKrAn8zR/JB0kITuFXGvR/xZmTFQLDKFV5VrcFHkDob4BRsQvl1QoRURErkJUVBQFBQWkp6cbHaXcOHHiBP369WP79u28MO1t7G1uIP1cLmZM2Ll8fTEBJkx0qlabQbEtCPD2Kb3Q5ZQKpYiIyFUICgqiRo0a7N+/3+go5Uqh3cbjn06GOpGY4Ao18mImTIT4+vNI/Y7cEFqlhBIK6KYcERGRq5Kfn0+NGjWMjlGuFNptTN+9ClOdSODayuT54x2cseQzaedv7MpIdH1AcVKhFBER+Qvp6ek4HA5q165tdJRyw+Fw8Mn+dezLSrrmIlnkPIDd4eC9Pb9zPCfDVfHkf6hQioiI/IULa1A2bNjQ4CSeIycnh5deeolevXoRHh6OyWTi008/dT6/OfUYW9KO4wAcdjt7fljG/AefZ2aP+5nd51EWPvka6QePXXTeM6eS+W3CNOb0G8nMHvcz7+6n2PDR1zgcDmbtW4vVbgPOr3H5/vvv07x5cwICAqhUqRLdunVjx44dpfRvwLNo2SAREZG/sH37dgBatmxpbBAPkpaWxoQJE6hVqxbNmjVj5cqVzufyrYXMPbjJ+fWqNz4kYela6vbsRKNBt1KYf470hKPkZ54pes6Eoyx88jWCKofRdMjt+IcGk5OcTk5KOnYcnM4/w9JT+7itZiMefPBB5s6dy/Dhw3n88cfJzc1l27ZtpKSklNa/Ao+iQikiIvIXLiysrUXNXScyMpLTp09TrVo1Nm/eTJs2bZzPrU85Qr6tEIBDy9dzYNEf3PLqWGI7t7nc6XDY7ax49X0q1oqkz5R/4u3ne8njlp3aR/aancyePZvvvvuOgQMHuvaDlVOa8hYREfkLhw8fxsvLi8DAQKOjeAw/Pz+qVat2yedWJP73TvqdX/9CRIPaxHZug8NupzC/4JKvOblpJ5lHTtLy/kF4+/liLTiH3Wa/6LicwnO89vZbtG3bloEDB2K328nNzXXNhyrHVChFRET+wunTp1UmS0m2JZ/k/LMAWHLzSNl7mIj6cWz88Cs+ve1hPun5EF8OGcuh5euLvO7U5vO76Xj5+PDdw/9k1q0PMuvWB1j276kUnMlxHmfLy2f31u20adOGf/zjH4SGhhIcHExcXBxff/116X1QD6MpbxERkb+Qnp5OeHi40THKhT/fiX3mVAo4HBxavg6zlxftRt6Nb1AAO79dzG8vT8M3KICa7ZoBkH0yCYBl/36Xmm2b0fyefmQcOs62z38kNyWdftNfwmQykXkyGYfDwbx58/D29uatt94iNDSUKVOmMHToUEJCQujVq5chn70sU6EUERH5Czk5OdrDu5Qk5591LmB+YXr7XHYOA2a8TJWGNwAQ3bEVXw4Zy9Y5PzgLZWH+OQCq1I+j279GARDXpS3efr5s/PArTm3ZTY3WjZ3nTE9PZ/369bRr1w6Afv36ERsby6uvvqpCeR005S0iInIFFosFm81GTEyM0VHKBavdhslkAnDeWFMhMsJZJgF8Av2p1bElqXsPYbfa/u/Y89sr1u5+Y5Hz3XDL+a+Tdx0ocs7Y2FhnmQQIDg6mb9++bNy40bl/uFw9FUoREZEr2LZtGwD169c3OEn54G324sKu0IGVwwAICA+96LiAiiHYrTasBeeueKx/xRAAzp3NLXJc1apVLzpnlSpVKCws1E0610GFUkRE5Aq2bNkCQPPmzY0NUk5UCwhx7owTVDmMgPCK5KZmXnRcXnomXr4++AT6A1C5biwAuakZ/3NcFnC+gF44Z3DlME6dOnXRORMTE/H396dChQou+jTlhwqliIjIFezevRugyDqJUnJqBRe9+al2t/bkpqRzctNO52MFWWc5unoL1Vs2wmQ+X2ViOrXCy9eHA7/+jsP+3+WC9i1cAUBU68YAeJlMdOrdkxMnTrB06VLncWlpaSxYsIBu3bphNqseXSvdlCMiInIFBw8exGQyUb16daOjeJxp06aRlZVFYmIiAD/99BMnT54k4dR+ovvdjG9wIM3v7cfhFetZ+q/JNLnrdnyDA9m74DfsVhttH7nLea7AShVpcV9/Ns/8ll+efpOYm1qTfvA4+xauoHaPDlRpcH4fdpvDwdPPPsOOJasYPHgwTz31FKGhocyYMYPCwkL+85//GPLvoqwzOS5cqCAiIiIXadSoEUeOHCEvL8/oKB4nJiaGY8cu3o8b4O6vJlMhMgKAM4kprJ8+l1Nbd2O32qjaqA5tHx3iLIkXOBwOdn+3lN3fLeHs6RQCwitSt9dNtLp/IGbv82NoIT7+vNFuAMeOHOXpp5/mt99+o7CwkA4dOvDGG29oJPo6qVCKiIhcQUREBN7e3pw+fdroKOVGga2Qf2xcQJ7VgqtLyuDYFtxaQ0tAuZouEhAREbmCs2fPUqVKFaNjlCv+Xj7cW6edS8ukGRM1girSvXo9F55VLlChFBERuQy73c65c+eoVauW0VHKnZaVa9K+SgwmF5zLBHiZzTxY70a8dMNNidC/VRERkcs4fPgwAHXr1jU4Sfl0X512NA6vXqxSacKEl8nME426EBVU0VXR5H+oUIqIiFzGpk2bAGjSpInBSconb7MXIxt0plvU+Wlq0zVWSxMQ7hfI0816UK/ixQuZi+to2SAREZHLiI+PB6B169YGJym/vMxm7oprRYtKNfk8YSNJ+WcwY8J+hSssTYDZZKZr9br0j26Kr5fqTknTXd4iIiKXMWjQIL7//ntsNpsWu3YDDoeDhDOp/HH6IAnZKWRaii7l5G0yUzM4jFaVa3Fj1TiCfPwMSlr+qLKLiIhcxvHjx/Hx8VGZdBMmk4m6oVWoG3r+rvvcwnNkWvKwOxz4eXkT4R+M2aT/VkZQoRQREbmMpKQk7evsxoJ8/DQK6SZU40VERC4jMzOTypUrGx1DxO2pUIqIiFxGfn4+UVFRRscQcXsqlCIiIpeQkZGBw+Ggdu3af32wSDmnQikiInIJGzduBKBRo0YGJxFxfyqUIiIil7Bt2zYAWrRoYXASEfenQikiInIJ+/btA6BVq1YGJxFxfyqUIiIil3D48GHMZjPBwcFGRxFxeyqUIiIil5CYmEhQUJDRMUTKBBVKERGRS0hPTycsLMzoGCJlggqliIjIJeTm5hIZGWl0DJEyQVsvioiI/J8PPviAjRs3EhUVhdVqJTAwkMOHD1OjRg18fX2NjifitkwOh8NhdAgRERF30KdPH37++We8vLyw2WzOxyMjI0lMTDQwmYh705S3iIjI/xk2bBhAkTJpMpno1KmTUZFEygSNUIqIiPyf3NxcKleuTEFBgfOxsLAw9u/fT0REhIHJRNybRihFRET+T1BQEIMHD8ZkMjkfmzFjhsqkyF9QoRQREfmT++67jwuTd/379+fOO+80OJGI+9OUt4iIyJ9YrVbnHd2JiYlUq1bN4EQi7k/LBomISLlnsVk5kZtJekEuNoedZv16EOkfQpWqVY2OJlImaIRSRETKJYvNyqbUY6w8ncCJnAwu9cPQx+xF0/AoulSvS52QiCLXVorIf6lQiohIueJwONiceowvDm0mz2rBBJcskxeYMWHHQUxwOA/U60C1wNDSiipSZqhQiohIuWGxWZm1fx3b0k9c82vNmDCZYEjt1twcWacE0omUXSqUIiJSLpyzWZmyczmHz6bjuOKY5F8bGNOcXjUbuiiZSNmnZYNERMTjORwOPtm/1iVlEuD7o9vZnHrMBclEPINGKEVExCPt3r2bf//732zZsoXEpNPg601YdBTN7u5DdMeWzuP2/rScg0vWkHU8kXM5eQRVCiOyRQNa3T+ICpH/XdA8Jzmd/b+s5Pi67WSfTMLs5UXrZs156V8v0qNHDyM+oojbUKEUERGP9Msvv/Duu+/Spl071p1LIi8vnyOrNpIUv5+bnn6IBv26AbB60idYC84RHlcT3wpBnD2dyr6FK3DY7Az+5HWCKocBsGv+EjbM+JKYm1pRrXFdHDY7p37byLE9+5k1axYPPPCAkR9XxFAqlCIi4tFWJx3ks4SNANhtdr5/+AWslkKGfP72ZV+Tuv8I3z/8T9o+MoTm9/YDIOPISQLDQvGvWMF5nKPQyqpR/yEvN5cTJ679Rh8RT6FrKEVExKOtTEzgwuqRZi8zQVUqYcnJu+JrKlSrDMC5Px0XHlujSJkEMPt407hze06ePMnZs2ddmlukLNFOOSIi4rEKbIUcTjuN7Vwhltw8jq7ZyokNO6jdtf3Fx2afxWG3k5OczpZPvwcgqlWjv3yPY6dOEhgYSGBgoMvzi5QVKpQiIuKxTuZksn76XPb+uBwAk9lETOc2dPz7/RcdO3fwE9gshQD4hQZz45PDqdGmyRXPn3Uyie3L/mDYkCF4eXm5PL9IWaFCKSIiHiutIJcmd95GbJd25KVlcnjFehw2O7ZC60XH3vbWM1gthWQdSyRhyRqs+eeueG5rwTmWvfQu3n4+vPKf10rqI4iUCbopR0REPNaapEPMSdhQ5LGfn3odS04eAz6YcNm9uc+cSuabvz1Hu5HDaDz41ouet9vsLHnhHU5uiue2t57l28f/jb+3T4l8BpGyQDfliIiIx/L1ungiLq5LO1L3HSb7xOnLvi4kqiqV68RwcNmaSz7/+8SPOb5uG12ef5SoVo3w0XS3lHOa8hYREY9VPTD0oses5ywAWHLyr/haq8XivKbyz9a/9wUHfllFhyfu44YeNxLhH4yXSeMzUr7pO0BERDxSSkoK1QJD8P5T2bNbrSQs/gMvP1/CYqKwW22cO5t78Wv3HCLj8Aki6scVeXzHlwuJn/czze/rT5M7e2HGRGyFyiX+WUTcnUYoRUTEIz366KOcOXMG//rR5AZ7k5ueycGla8k6nkj70ffgE+jPubO5zL3jCWp3bU9YbA28/f3IOHyCA7/+jm9QIC2HD3Se78jvm9jw/peE1qhGWHR1EpasBiAyMonPNx/mlltuoWrVqkZ9XBFD6aYcERHxSPPmzWPmzJlsi99BRnoGvoH+VK4XS6NBtxLTqRUAtkIrG97/ksRteziblIrtnIXAymFEtWpMy+EDiuzlvXnWfLZ++t1l32/FihV06dKlpD+WiFtSoRQREY9mdzj4z7ZFnMrNwo5rf+QNimlOz5oNXXpOkbJI11CKiIhHM5tMPFCvA1x6haDrOycmagaF0aNGfdedVKQMU6EUERGPFxVUkTtjW7rkXCbAx+zFQ/Vv1N3dIv9H3wkiIlIudIuqR99aV95K8a+YMeFr9ubJJl2JvMSSRCLlla6hFBGRcmV98hG+OLiJQrvtmq+prBFUkYfqdaR6kMqkyJ+pUIqISLmTeS6Pb49sZWvqCRw4LlsrzZiw4yDQ25eeNRpwS1QDvMya3BP5XyqUIiJSbmVb8lmTdJiE7GSO5mSQZ7U4n6vsF0RsSGWahkfRonJNfMzaXlHkclQoRUREAIfDgcVuw+aw42P2UoEUuQYqlCIiIiJSLLoQRERERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESKRYVSRERERIpFhVJEREREikWFUkRERESK5f8Dj/wzMC2i6rwAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def visualize_hop_neighbor_subgraph(node_idx, data, neighbors, n_hops,adj,feat,label):\n",
    "    \"\"\"Visualizes the n-hop neighborhood of a given node.\"\"\"\n",
    "    node_idx_new, sub_adj, sub_feat, sub_label, neighbors = extract_neighborhood(node_idx,adj,feat,label,n_hops)\n",
    "    subdata = data.subgraph(torch.tensor(neighbors))\n",
    "    subindex = subdata.edge_index\n",
    "    Gsub = G = to_networkx(subdata, to_undirected=False)\n",
    "    labeldict = {}\n",
    "    for i,j in zip(range(len(neighbors)),neighbors):\n",
    "        labeldict[i] = j\n",
    "    nx.draw(Gsub, labels = labeldict, node_color = data.y[neighbors], cmap=\"Set2\")\n",
    "    return subdata, subindex\n",
    "\n",
    "\n",
    "node_idx = 1\n",
    "subdata_Data, subindex = visualize_hop_neighbor_subgraph(node_idx, data, neighbors, 2,adj,feat,label)\n",
    "subdata = subdata_Data.x\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Get the original label of the node - we already have it \n",
    "3. Get the predicted label of the node:\n",
    "\n",
    "A. Here is where we have to start thinking about the model that we want to explain.\n",
    "In this next section we will thus implement a very straight - forward GCN model adapted to how the models in GNN explainer have been designed. \n",
    "\n",
    "B. Another option implies taking a very straightforward model and then modify the structure of the explainer such that we can actually use that model\n",
    "\n",
    "\n",
    "For the sake of simplicity we first work on B."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adjacency(data):\n",
    "    adj = torch.zeros(data.num_nodes, data.num_nodes)\n",
    "    for edge in data.edge_index.t():\n",
    "        adj[edge[0]][edge[1]] = 1\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 400/400 [00:54<00:00,  7.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8080\n",
      "Predicted labels for node index, 1 with hops 2: \n",
      "  tensor([4, 4, 4, 4, 4, 4, 4, 4, 3]) \n",
      " Actual labels for node index, 1 with hops 2: \n",
      "  tensor([4, 4, 3, 4, 4, 4, 4, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "#MODEL  : structured as with adjacency matrices\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(1234567)\n",
    "        self.conv1 = GCNConv(dataset.num_features, 16)\n",
    "        self.conv2 = GCNConv(16, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        edge_index = adj.nonzero().t()\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1), adj\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net().to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()  # Clear gradients.\n",
    "      out, adj = model(data.x, get_adjacency(data))  # Perform a single forward pass.\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])  # Compute the loss solely based on the training nodes.\n",
    "      loss.backward()  # Derive gradients.\n",
    "      optimizer.step()  # Update parameters based on gradients.\n",
    "      return loss\n",
    "\n",
    "def test():\n",
    "      model.eval()\n",
    "      out, adj = model(data.x, get_adjacency(data))\n",
    "      pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "      test_correct = pred[data.test_mask] == data.y[data.test_mask]  # Check against ground-truth labels.\n",
    "      test_acc = int(test_correct.sum()) / int(data.test_mask.sum())  # Derive ratio of correct predictions.\n",
    "      return test_acc\n",
    "\n",
    "\n",
    "for epoch in tqdm(range(1, 401)):\n",
    "    loss = train()\n",
    "\n",
    "test_acc = test()\n",
    "print(f'Test Accuracy: {test_acc:.4f}') \n",
    "\n",
    "\n",
    "model.eval()\n",
    "torch.save(model, 'model_cora')\n",
    "pred, adj = model(data.x, get_adjacency(data))\n",
    "pred_label = pred.argmax(dim=1)\n",
    "\n",
    "\n",
    "#we will only be interested in the predicted labels for the neighbirhood of the query node\n",
    "print(f'Predicted labels for node index, {node_idx} with hops {n_hops}: \\n ',pred_label[neighbors], \n",
    "      f'\\n Actual labels for node index, {node_idx} with hops {n_hops}: \\n ',data.y[neighbors])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have the predicted labels for each node stored in pred.\n",
    "4. Call the ExplainModule into an obejct : we will have to dig in the ExplainModule class before going forward with the explanation of the Explainer module"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explain Module\n",
    "inputs: adj, x, model, label \n",
    "\n",
    "1. get mask and mask bias -> construct edge_mask (line 656) - in a similar way the feature masks are initialized\n",
    "\n",
    "->Mask are a torch.nn.parameter.Parameter object randomly initialized with dimension equal to the number of nodes in the neighborhood x number of nodes in the neighborhood (according to different initialization strategies: normal and constant are defined)\n",
    "\n",
    "Feature mask built in a similar way : the size of the nn.Parameter is the size of the last dimension of x (and thus the number of features for the node)\n",
    "Diagonal mask is a  tensor of 1s with 0s on the diagonal \n",
    "\n",
    "2. Forward function ( line 703 )\n",
    "Masked adjacency : (_masked_asdj) is the non linear activated mask (sym_mask: it is symmetric because we add its transpose and then divide by 2) multiplied by the adjacency matrix and the diagonal mask (in this way the diagonal elements are 0s out) -> remember that the adjacency matrix we see here is the one of the neighborhood already so the shapes match \n",
    "??? So the whole idea about masking is that we perturbate the adjacency matrix  - so that the values inside the matrix are not 0s and 1s but can get different values (according to the initialization)\n",
    "Then in the forward:\n",
    "Ypred and adj_att are the model prediction on the node given the masked adjacency matrix (we take the softmax of the node prediction - so the result is a vector of probabilities - and we will be able to inquire how the probability of the correct class change given that we did perturb the graph)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mask functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Num nodes: is how many nodes in the neighborhood (computed as the sum of 1s over the row of the node of interest - as there is a 1 only if the node is connected to other nodes)\n",
    "\n",
    "num_nodes = len(neighbors)\n",
    "diag_mask = torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes) #create a diag mask of 1 and 0s on the diagonal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_edge_mask( num_nodes, init_strategy=\"normal\", const_val=1.0):\n",
    "    \"\"\"\n",
    "    Construct edge mask\n",
    "    input;\n",
    "        num_nodes: number of nodes in the neighborhood\n",
    "        init_strategy: initialization strategy for the mask\n",
    "        const_val: constant value for the mask\n",
    "    output:\n",
    "        mask: edge mask    \n",
    "    \"\"\"\n",
    "    mask = nn.Parameter(torch.FloatTensor(num_nodes, num_nodes))  #initialize the mask\n",
    "    if init_strategy == \"normal\":\n",
    "        std = nn.init.calculate_gain(\"relu\") * math.sqrt(\n",
    "            2.0 / (num_nodes + num_nodes)\n",
    "        )\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "    elif init_strategy == \"const\":\n",
    "        nn.init.constant_(mask, const_val)\n",
    "    return mask\n",
    "\n",
    "edge_mask = construct_edge_mask(num_nodes, init_strategy=\"normal\", const_val=1.0)\n",
    "#edge mask is a matrix of size num_nodes x num_nodes initialized with random values from a normal distribution with mean 1 and std calculated using the formula given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_dim = data.num_features\n",
    "def construct_feat_mask( feat_dim, init_strategy=\"normal\"):\n",
    "    \"\"\"\n",
    "    Construct feature mask\n",
    "    input:\n",
    "        feat_dim: dimension of the feature\n",
    "        init_strategy: initialization strategy\n",
    "    output:\n",
    "        mask: feature mask    \n",
    "    \"\"\"\n",
    "    mask = nn.Parameter(torch.FloatTensor(feat_dim))\n",
    "    if init_strategy == \"normal\":\n",
    "        std = 0.1\n",
    "        with torch.no_grad():\n",
    "            mask.normal_(1.0, std)\n",
    "    elif init_strategy == \"constant\":\n",
    "        with torch.no_grad():\n",
    "            nn.init.constant_(mask, 0.0)\n",
    "            # mask[0] = 2\n",
    "    return mask\n",
    "\n",
    "feat_mask = construct_feat_mask(feat_dim, init_strategy=\"normal\")\n",
    "\n",
    "#feat mask is a vector of size feat_dim initialized with random values from a normal distribution with mean 1 and std 0.1 (if normal strategy is chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original sub_adj: \n",
      " tensor([[0, 1, 0, 0, 1, 1, 0, 0, 0],\n",
      "        [1, 0, 1, 0, 0, 0, 1, 1, 1],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 1, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 1, 0, 0, 0, 0, 0, 0, 0]]) \n",
      " masked_adj: \n",
      " tensor([[0.0000, 0.8011, 0.0000, 0.0000, 0.8071, 0.7909, 0.0000, 0.0000, 0.0000],\n",
      "        [0.8011, 0.0000, 0.8245, 0.0000, 0.0000, 0.0000, 0.7872, 0.6898, 0.7274],\n",
      "        [0.0000, 0.8245, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.6749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.8071, 0.0000, 0.0000, 0.6749, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.7909, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7872, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.6898, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.7274, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "       grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "def _masked_adj(mask,adj, diag_mask):\n",
    "    \"\"\" Masked adjacency matrix \n",
    "    input: edge_mask, sub_adj, diag_mask\n",
    "    output: masked_adj\n",
    "    \"\"\"\n",
    "    sym_mask = mask\n",
    "    sym_mask = torch.sigmoid(mask)\n",
    "    \n",
    "    sym_mask = (sym_mask + sym_mask.t()) / 2\n",
    "    adj = torch.tensor(adj)\n",
    "    masked_adj = adj * sym_mask\n",
    "\n",
    "    return masked_adj * diag_mask\n",
    "\n",
    "masked_adj = _masked_adj(edge_mask,sub_adj, diag_mask)\n",
    "masked_adj\n",
    "print('original sub_adj: \\n', torch.tensor(sub_adj), '\\n masked_adj: \\n', masked_adj)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The whole idea of masking the adjacency matrix is to add perturbations in the node connections - they are not connected with the same weights anymore."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward\n",
    "The method takes several arguments, but the most important one is node_idx, which appears to be the index of a node in a graph. The purpose of this method is to generate a prediction for that node, based on its features and the features of its neighbors, in the form of a softmax output.\n",
    "\n",
    "The method first checks whether the adjacency matrix should be constrained (i.e. symmetrical) or unconstrained, and generates a masked adjacency matrix accordingly. If the mask_features flag is set, it also masks the input features. If the marginalize flag is set, it generates a random noise vector and scales it according to the feature mask.\n",
    "\n",
    "The method then passes the masked input features and masked adjacency matrix to a model, which generates a prediction for the target node. If the graph_mode flag is set, it applies a softmax to the entire output, whereas if it is not set, it extracts the prediction for the target node and applies a softmax to that.\n",
    "\n",
    "Finally, the method returns the softmax output and the adjacency matrix attention, which may be used for visualization or analysis purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Actual labels for node index, 1 with hops 2: \n",
      "  tensor([4, 4, 3, 4, 4, 4, 4, 3, 3]) \n",
      " Predicted labels for node index, 1 with hops 2: \n",
      "  tensor([4, 4, 4, 4, 4, 4, 4, 4, 3]) \n",
      " Predicted labels for node index, 1 with hops 2 using subgraph: \n",
      "  tensor([4, 4, 4, 4, 4, 4, 4, 4, 3])\n"
     ]
    }
   ],
   "source": [
    "#Here we predict the labels for the neighborhood of the query node using the neighborhood subgraph only\n",
    "#We are indeed not using the masked_adj matrix here\n",
    "\n",
    "\n",
    "new_pred, adj = model(torch.Tensor(subdata), torch.Tensor(sub_adj))\n",
    "new_pred_label = new_pred.argmax(dim=1)\n",
    "print(f'\\n Actual labels for node index, {node_idx} with hops {n_hops}: \\n ',data.y[neighbors],\n",
    "    f'\\n Predicted labels for node index, {node_idx} with hops {n_hops}: \\n ',pred_label[neighbors], \n",
    "      f'\\n Predicted labels for node index, {node_idx} with hops {n_hops} using subgraph: \\n ',new_pred_label)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are just exploring how the prediction works if we only consider the subadjacency and the subgraph \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok so now we have to use the simplified version of this fancy more to make some training ---> then we want to try and explain this trained boy with the GNN Explainer simplified method. \n",
    "\n",
    "\n",
    "Let's see if everything will work out well :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from forward line 706 explain.py\n",
    "\n",
    "def explain_forward(x, masked_adj):\n",
    "    ypred, adj_att = model(x, masked_adj)\n",
    "    res = nn.Softmax(dim=0)(ypred)\n",
    "    return res, adj_att\n",
    "\n",
    "#It basically get the predictions with the masked_adj matrix and then applies softmax to it\n",
    "#We will use this to get the importance of each edge in the neighborhood subgraph\n",
    "#But first we gotta do the forward on the masked adjacency matrix - we want to find the masked adjacencye matrix that gives the highest probability for the query node - able to explain the predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 4, 1, 6, 4, 4, 1, 0, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res, adj_att = explain_forward(subdata, masked_adj)\n",
    "pred_label = res.argmax(dim=1)\n",
    "pred_label"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward loop! and how the loss works\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LOSS\n",
    "edge_mask.shape\n",
    "feat_mask.shape\n",
    "masked_adj.shape\n",
    "adj.shape\n",
    "pred.shape\n",
    "pred_label.shape\n",
    "node_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fc(edge_mask, feat_mask, masked_adj,adj, pred, pred_label, node_idx, epoch):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        pred: prediction made by current model\n",
    "        pred_label: the label predicted by the original model.\n",
    "    \"\"\"\n",
    "\n",
    "    pred_label_node = pred_label[node_idx]\n",
    "    gt_label_node = label[node_idx]\n",
    "    print('node',gt_label_node)\n",
    "    print('pred',pred.shape)\n",
    "    logit = pred[gt_label_node]\n",
    "    print('logit',logit)\n",
    "    pred_loss = -torch.log(logit) #this is basically taking the cross entropy loss\n",
    "    print(pred_loss)\n",
    "    # size\n",
    "    \n",
    "    mask = edge_mask\n",
    "    mask = torch.sigmoid(mask)\n",
    "\n",
    "    size_loss = 0.005 * torch.sum(mask)\n",
    "\n",
    "    # pre_mask_sum = torch.sum(self.feat_mask)\n",
    "    # feat_mask = (torch.sigmoid(feat_mask) if self.use_sigmoid else self.feat_mask)\n",
    "    feat_mask = feat_mask\n",
    "    feat_size_loss = 1.0 * torch.mean(feat_mask)\n",
    "\n",
    "    # entropy\n",
    "    mask_ent = -mask * torch.log(mask) - (1 - mask) * torch.log(1 - mask)\n",
    "    mask_ent_loss = 1.0 * torch.mean(mask_ent)\n",
    "\n",
    "    feat_mask_ent = - feat_mask             \\\n",
    "                    * torch.log(feat_mask)  \\\n",
    "                    - (1 - feat_mask)       \\\n",
    "                    * torch.log(1 - feat_mask)\n",
    "\n",
    "    feat_mask_ent_loss = 0.1  * torch.mean(feat_mask_ent)\n",
    "\n",
    "    # laplacian\n",
    "    D = torch.diag(torch.sum(masked_adj, 0))\n",
    "    m_adj = masked_adj \n",
    "    L = D - m_adj\n",
    "    pred_label_t = torch.tensor(pred_label, dtype=torch.float)\n",
    "\n",
    "\n",
    "    # lap_loss = ( 1.0\n",
    "    #     * (pred_label_t @ L @ pred_label_t)\n",
    "    #     / torch.Tensor(adj).numel())\n",
    "\n",
    "\n",
    "    loss = pred_loss + size_loss  + mask_ent_loss + feat_size_loss\n",
    "    #+ lap_loss\n",
    "    print(\"optimization/size_loss\", size_loss, epoch)\n",
    "    print(\"optimization/feat_size_loss\", feat_size_loss, epoch)\n",
    "    print(\"optimization/mask_ent_loss\", mask_ent_loss, epoch)\n",
    "    print(\n",
    "        \"optimization/feat_mask_ent_loss\", mask_ent_loss, epoch\n",
    "    )\n",
    "    # print('optimization/grad_loss', grad_loss, epoch)\n",
    "    print(\"optimization/pred_loss\", pred_loss, epoch)\n",
    "    #print(\"optimization/lap_loss\", lap_loss, epoch)\n",
    "    print(\"optimization/overall_loss\", loss, epoch)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node tensor(4)\n",
      "pred torch.Size([2708, 7])\n",
      "logit tensor([-2.9933, -3.3364, -3.1445, -0.2869, -2.6730, -3.5438, -3.7874],\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([nan, nan, nan, nan, nan, nan, nan], grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2891, grad_fn=<MulBackward0>) 400\n",
      "optimization/feat_size_loss tensor(1.0000, grad_fn=<MulBackward0>) 400\n",
      "optimization/mask_ent_loss tensor(0.5730, grad_fn=<MulBackward0>) 400\n",
      "optimization/feat_mask_ent_loss tensor(0.5730, grad_fn=<MulBackward0>) 400\n",
      "optimization/pred_loss tensor([nan, nan, nan, nan, nan, nan, nan], grad_fn=<NegBackward0>) 400\n",
      "optimization/overall_loss tensor([nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>) 400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_1028/2293146205.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_label_t = torch.tensor(pred_label, dtype=torch.float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan, nan, nan, nan, nan], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fc(edge_mask, feat_mask, masked_adj,adj, pred, pred_label, node_idx, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0281, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[node_idx][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(adj, node_idx, n_hops):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        adj: adjacency matrix of the graph\n",
    "        node_idx: node index of the query node\n",
    "        n_hops: number of hops to find the neighbors\n",
    "    \"\"\"\n",
    "    neighbors = [node_idx]\n",
    "    for _ in range(n_hops):\n",
    "        neighbors = list(set(neighbors + adj[neighbors].nonzero()[1].tolist()))\n",
    "    return neighbors\n",
    "\n",
    "\n",
    "def construct_diag_mask(neighbors):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        adj: adjacency matrix of the graph\n",
    "    \"\"\"\n",
    "    num_nodes = len(neighbors)\n",
    "    diag_mask = torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes) \n",
    "\n",
    "    return diag_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Explain(nn.Module):\n",
    "    def __init__(self, model, data, node_idx, n_hops=1):\n",
    "        super(Explain, self).__init__()\n",
    "        self.model = model\n",
    "        self.data = data\n",
    "        self.node_idx = node_idx\n",
    "        self.n_hops = n_hops\n",
    "        self.adj = get_adjacency(data)\n",
    "        self.label = data.y\n",
    "        self.feat = data.x\n",
    "        self.feat_dim = data.num_features\n",
    "        self.node_idx_new, self.sub_adj, self.sub_feat, self.sub_label, self.neighbors = extract_neighborhood(self.node_idx, self.adj, self.feat, self.label, self.n_hops)\n",
    "        self.num_nodes = len(self.neighbors)\n",
    "        self.edge_mask = construct_edge_mask(self.num_nodes)\n",
    "        self.diag_mask = construct_diag_mask(self.neighbors)\n",
    "        self.feat_mask = construct_feat_mask(self.feat_dim, init_strategy=\"normal\")\n",
    "        self.subdata = data.subgraph(torch.tensor(self.neighbors)).x\n",
    "        #self.neighbors = get_neighbors(self.adj, self.node_idx, self.n_hops)\n",
    "        self.masked_adj = _masked_adj(self.edge_mask,self.sub_adj, self.diag_mask)\n",
    "        # self.pred, self.adj_att = explain_forward(self.subdata, self.masked_adj)\n",
    "        # self.pred_label = self.pred.argmax(dim=1)\n",
    "        # self.loss = loss(self.edge_mask, self.feat_mask, self.masked_adj,self.adj, self.pred, self.pred_label, self.node_idx, epoch)\n",
    "        \n",
    "    def forward(self):\n",
    "        ypred, adj_att = model(self.subdata, self.masked_adj)\n",
    "        res = nn.Softmax(dim=0)(ypred)\n",
    "        #res = res[self.node_idx_new]\n",
    "        return res, adj_att\n",
    "    \n",
    "    def criterion(self, epoch):\n",
    "        pred, self.adj_att = self.forward()\n",
    "        pred_label = pred.argmax(dim=0)\n",
    "        pred = pred[self.node_idx_new]\n",
    "        # print('pred_label',pred_label)\n",
    "        # print('pred shape',pred.shape)\n",
    "        loss_val = loss_fc(self.edge_mask, self.feat_mask, self.masked_adj,self.adj, pred, pred_label, self.node_idx, epoch)\n",
    "        # print('loss',loss_val)\n",
    "        return loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_1028/2699400499.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adj = torch.tensor(adj, dtype=torch.float)\n",
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_1028/1389454049.py:10: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  adj = torch.tensor(adj)\n"
     ]
    }
   ],
   "source": [
    "explainer = Explain(model = torch.load('model_cora'), data = data, node_idx = 0, n_hops=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9922, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0078, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 0\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 0\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 0\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 0\n",
      "optimization/pred_loss tensor(0.0078, grad_fn=<NegBackward0>) 0\n",
      "optimization/overall_loss tensor(1.8256, grad_fn=<AddBackward0>) 0\n",
      "optimization/overall_loss tensor(1.8256, grad_fn=<AddBackward0>) 0\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 0\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 0\n",
      "optimization/overall_loss tensor(1.8256, grad_fn=<AddBackward0>) 0\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 0\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 0\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9922, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0079, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 1\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 1\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 1\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 1\n",
      "optimization/pred_loss tensor(0.0079, grad_fn=<NegBackward0>) 1\n",
      "optimization/overall_loss tensor(1.8256, grad_fn=<AddBackward0>) 1\n",
      "optimization/overall_loss tensor(1.8256, grad_fn=<AddBackward0>) 1\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 1\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 1\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9921, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0079, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 2\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 2\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 2\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 2\n",
      "optimization/pred_loss tensor(0.0079, grad_fn=<NegBackward0>) 2\n",
      "optimization/overall_loss tensor(1.8257, grad_fn=<AddBackward0>) 2\n",
      "optimization/overall_loss tensor(1.8257, grad_fn=<AddBackward0>) 2\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 2\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 2\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9920, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0080, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 3\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 3\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 3\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 3\n",
      "optimization/pred_loss tensor(0.0080, grad_fn=<NegBackward0>) 3\n",
      "optimization/overall_loss tensor(1.8257, grad_fn=<AddBackward0>) 3\n",
      "optimization/overall_loss tensor(1.8257, grad_fn=<AddBackward0>) 3\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 3\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 3\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9920, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0080, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 4\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 4\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 4\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 4\n",
      "optimization/pred_loss tensor(0.0080, grad_fn=<NegBackward0>) 4\n",
      "optimization/overall_loss tensor(1.8258, grad_fn=<AddBackward0>) 4\n",
      "optimization/overall_loss tensor(1.8258, grad_fn=<AddBackward0>) 4\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 4\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 4\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9919, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0081, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 5\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 5\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 5\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 5\n",
      "optimization/pred_loss tensor(0.0081, grad_fn=<NegBackward0>) 5\n",
      "optimization/overall_loss tensor(1.8258, grad_fn=<AddBackward0>) 5\n",
      "optimization/overall_loss tensor(1.8258, grad_fn=<AddBackward0>) 5\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 5\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 5\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9919, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0081, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 6\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 6\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 6\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 6\n",
      "optimization/pred_loss tensor(0.0081, grad_fn=<NegBackward0>) 6\n",
      "optimization/overall_loss tensor(1.8259, grad_fn=<AddBackward0>) 6\n",
      "optimization/overall_loss tensor(1.8259, grad_fn=<AddBackward0>) 6\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 6\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 6\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9918, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0082, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 7\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 7\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 7\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 7\n",
      "optimization/pred_loss tensor(0.0082, grad_fn=<NegBackward0>) 7\n",
      "optimization/overall_loss tensor(1.8259, grad_fn=<AddBackward0>) 7\n",
      "optimization/overall_loss tensor(1.8259, grad_fn=<AddBackward0>) 7\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 7\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 7\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9918, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0082, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 8\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 8\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 8\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 8\n",
      "optimization/pred_loss tensor(0.0082, grad_fn=<NegBackward0>) 8\n",
      "optimization/overall_loss tensor(1.8260, grad_fn=<AddBackward0>) 8\n",
      "optimization/overall_loss tensor(1.8260, grad_fn=<AddBackward0>) 8\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 8\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 8\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9917, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0083, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 9\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 9\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 9\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 9\n",
      "optimization/pred_loss tensor(0.0083, grad_fn=<NegBackward0>) 9\n",
      "optimization/overall_loss tensor(1.8260, grad_fn=<AddBackward0>) 9\n",
      "optimization/overall_loss tensor(1.8260, grad_fn=<AddBackward0>) 9\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 9\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 9\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9917, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0083, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 10\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 10\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 10\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 10\n",
      "optimization/pred_loss tensor(0.0083, grad_fn=<NegBackward0>) 10\n",
      "optimization/overall_loss tensor(1.8261, grad_fn=<AddBackward0>) 10\n",
      "optimization/overall_loss tensor(1.8261, grad_fn=<AddBackward0>) 10\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 10\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 10\n",
      "optimization/overall_loss tensor(1.8261, grad_fn=<AddBackward0>) 10\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 10\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 10\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9917, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0084, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 11\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 11\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 11\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 11\n",
      "optimization/pred_loss tensor(0.0084, grad_fn=<NegBackward0>) 11\n",
      "optimization/overall_loss tensor(1.8261, grad_fn=<AddBackward0>) 11\n",
      "optimization/overall_loss tensor(1.8261, grad_fn=<AddBackward0>) 11\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 11\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 11\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9916, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0084, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 12\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 12\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 12\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 12\n",
      "optimization/pred_loss tensor(0.0084, grad_fn=<NegBackward0>) 12\n",
      "optimization/overall_loss tensor(1.8262, grad_fn=<AddBackward0>) 12\n",
      "optimization/overall_loss tensor(1.8262, grad_fn=<AddBackward0>) 12\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 12\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 12\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9916, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0085, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 13\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 13\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 13\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 13\n",
      "optimization/pred_loss tensor(0.0085, grad_fn=<NegBackward0>) 13\n",
      "optimization/overall_loss tensor(1.8262, grad_fn=<AddBackward0>) 13\n",
      "optimization/overall_loss tensor(1.8262, grad_fn=<AddBackward0>) 13\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 13\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 13\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9915, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0085, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 14\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 14\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 14\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 14\n",
      "optimization/pred_loss tensor(0.0085, grad_fn=<NegBackward0>) 14\n",
      "optimization/overall_loss tensor(1.8263, grad_fn=<AddBackward0>) 14\n",
      "optimization/overall_loss tensor(1.8263, grad_fn=<AddBackward0>) 14\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 14\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 14\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9915, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0086, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 15\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 15\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 15\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 15\n",
      "optimization/pred_loss tensor(0.0086, grad_fn=<NegBackward0>) 15\n",
      "optimization/overall_loss tensor(1.8263, grad_fn=<AddBackward0>) 15\n",
      "optimization/overall_loss tensor(1.8263, grad_fn=<AddBackward0>) 15\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 15\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 15\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9914, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0086, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 16\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 16\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 16\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 16\n",
      "optimization/pred_loss tensor(0.0086, grad_fn=<NegBackward0>) 16\n",
      "optimization/overall_loss tensor(1.8263, grad_fn=<AddBackward0>) 16\n",
      "optimization/overall_loss tensor(1.8263, grad_fn=<AddBackward0>) 16\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 16\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 16\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9914, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0086, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 17\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 17\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 17\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 17\n",
      "optimization/pred_loss tensor(0.0086, grad_fn=<NegBackward0>) 17\n",
      "optimization/overall_loss tensor(1.8264, grad_fn=<AddBackward0>) 17\n",
      "optimization/overall_loss tensor(1.8264, grad_fn=<AddBackward0>) 17\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 17\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 17\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9914, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0087, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 18\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 18\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 18\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 18\n",
      "optimization/pred_loss tensor(0.0087, grad_fn=<NegBackward0>) 18\n",
      "optimization/overall_loss tensor(1.8264, grad_fn=<AddBackward0>) 18\n",
      "optimization/overall_loss tensor(1.8264, grad_fn=<AddBackward0>) 18\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 18\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 18\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9913, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0087, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 19\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 19\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 19\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 19\n",
      "optimization/pred_loss tensor(0.0087, grad_fn=<NegBackward0>) 19\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 19\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 19\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 19\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 19\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9913, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0087, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 20\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 20\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 20\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 20\n",
      "optimization/pred_loss tensor(0.0087, grad_fn=<NegBackward0>) 20\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 20\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 20\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 20\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 20\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 20\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 20\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 20\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9913, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0088, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 21\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 21\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 21\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 21\n",
      "optimization/pred_loss tensor(0.0088, grad_fn=<NegBackward0>) 21\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 21\n",
      "optimization/overall_loss tensor(1.8265, grad_fn=<AddBackward0>) 21\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 21\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 21\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9912, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0088, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 22\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 22\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 22\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 22\n",
      "optimization/pred_loss tensor(0.0088, grad_fn=<NegBackward0>) 22\n",
      "optimization/overall_loss tensor(1.8266, grad_fn=<AddBackward0>) 22\n",
      "optimization/overall_loss tensor(1.8266, grad_fn=<AddBackward0>) 22\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 22\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 22\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9912, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0088, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 23\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 23\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 23\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 23\n",
      "optimization/pred_loss tensor(0.0088, grad_fn=<NegBackward0>) 23\n",
      "optimization/overall_loss tensor(1.8266, grad_fn=<AddBackward0>) 23\n",
      "optimization/overall_loss tensor(1.8266, grad_fn=<AddBackward0>) 23\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 23\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 23\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9912, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0089, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 24\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 24\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 24\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 24\n",
      "optimization/pred_loss tensor(0.0089, grad_fn=<NegBackward0>) 24\n",
      "optimization/overall_loss tensor(1.8266, grad_fn=<AddBackward0>) 24\n",
      "optimization/overall_loss tensor(1.8266, grad_fn=<AddBackward0>) 24\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 24\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 24\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9911, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0089, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 25\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 25\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 25\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 25\n",
      "optimization/pred_loss tensor(0.0089, grad_fn=<NegBackward0>) 25\n",
      "optimization/overall_loss tensor(1.8267, grad_fn=<AddBackward0>) 25\n",
      "optimization/overall_loss tensor(1.8267, grad_fn=<AddBackward0>) 25\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 25\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 25\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9911, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0089, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 26\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 26\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 26\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 26\n",
      "optimization/pred_loss tensor(0.0089, grad_fn=<NegBackward0>) 26\n",
      "optimization/overall_loss tensor(1.8267, grad_fn=<AddBackward0>) 26\n",
      "optimization/overall_loss tensor(1.8267, grad_fn=<AddBackward0>) 26\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 26\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 26\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9911, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0090, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 27\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 27\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 27\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 27\n",
      "optimization/pred_loss tensor(0.0090, grad_fn=<NegBackward0>) 27\n",
      "optimization/overall_loss tensor(1.8267, grad_fn=<AddBackward0>) 27\n",
      "optimization/overall_loss tensor(1.8267, grad_fn=<AddBackward0>) 27\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 27\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 27\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9910, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0090, grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ww/33zq_rh50tx94n81lb4thx0w0000gn/T/ipykernel_1028/2293146205.py:43: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred_label_t = torch.tensor(pred_label, dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 28\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 28\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 28\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 28\n",
      "optimization/pred_loss tensor(0.0090, grad_fn=<NegBackward0>) 28\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 28\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 28\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 28\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 28\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9910, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0090, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 29\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 29\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 29\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 29\n",
      "optimization/pred_loss tensor(0.0090, grad_fn=<NegBackward0>) 29\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 29\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 29\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 29\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 29\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9910, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0091, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 30\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 30\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 30\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 30\n",
      "optimization/pred_loss tensor(0.0091, grad_fn=<NegBackward0>) 30\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 30\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 30\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 30\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 30\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 30\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 30\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 30\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9910, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0091, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 31\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 31\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 31\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 31\n",
      "optimization/pred_loss tensor(0.0091, grad_fn=<NegBackward0>) 31\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 31\n",
      "optimization/overall_loss tensor(1.8268, grad_fn=<AddBackward0>) 31\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 31\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 31\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9909, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0091, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 32\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 32\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 32\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 32\n",
      "optimization/pred_loss tensor(0.0091, grad_fn=<NegBackward0>) 32\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 32\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 32\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 32\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 32\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9909, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0091, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 33\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 33\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 33\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 33\n",
      "optimization/pred_loss tensor(0.0091, grad_fn=<NegBackward0>) 33\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 33\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 33\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 33\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 33\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9909, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0092, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 34\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 34\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 34\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 34\n",
      "optimization/pred_loss tensor(0.0092, grad_fn=<NegBackward0>) 34\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 34\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 34\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 34\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 34\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9909, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0092, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 35\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 35\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 35\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 35\n",
      "optimization/pred_loss tensor(0.0092, grad_fn=<NegBackward0>) 35\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 35\n",
      "optimization/overall_loss tensor(1.8269, grad_fn=<AddBackward0>) 35\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 35\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 35\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9908, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0092, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 36\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 36\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 36\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 36\n",
      "optimization/pred_loss tensor(0.0092, grad_fn=<NegBackward0>) 36\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 36\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 36\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 36\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 36\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9908, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0092, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 37\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 37\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 37\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 37\n",
      "optimization/pred_loss tensor(0.0092, grad_fn=<NegBackward0>) 37\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 37\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 37\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 37\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 37\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9908, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0092, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 38\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 38\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 38\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 38\n",
      "optimization/pred_loss tensor(0.0092, grad_fn=<NegBackward0>) 38\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 38\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 38\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 38\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 38\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9908, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0093, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 39\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 39\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 39\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 39\n",
      "optimization/pred_loss tensor(0.0093, grad_fn=<NegBackward0>) 39\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 39\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 39\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 39\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 39\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9908, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0093, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 40\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 40\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 40\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 40\n",
      "optimization/pred_loss tensor(0.0093, grad_fn=<NegBackward0>) 40\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 40\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 40\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 40\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 40\n",
      "optimization/overall_loss tensor(1.8270, grad_fn=<AddBackward0>) 40\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 40\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 40\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9907, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0093, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 41\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 41\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 41\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 41\n",
      "optimization/pred_loss tensor(0.0093, grad_fn=<NegBackward0>) 41\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 41\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 41\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 41\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 41\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9907, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0093, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 42\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 42\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 42\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 42\n",
      "optimization/pred_loss tensor(0.0093, grad_fn=<NegBackward0>) 42\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 42\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 42\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 42\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 42\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9907, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0093, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 43\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 43\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 43\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 43\n",
      "optimization/pred_loss tensor(0.0093, grad_fn=<NegBackward0>) 43\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 43\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 43\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 43\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 43\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9907, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0094, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 44\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 44\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 44\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 44\n",
      "optimization/pred_loss tensor(0.0094, grad_fn=<NegBackward0>) 44\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 44\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 44\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 44\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 44\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9907, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0094, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 45\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 45\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 45\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 45\n",
      "optimization/pred_loss tensor(0.0094, grad_fn=<NegBackward0>) 45\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 45\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 45\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 45\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 45\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9907, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0094, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 46\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 46\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 46\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 46\n",
      "optimization/pred_loss tensor(0.0094, grad_fn=<NegBackward0>) 46\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 46\n",
      "optimization/overall_loss tensor(1.8271, grad_fn=<AddBackward0>) 46\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 46\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 46\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9906, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0094, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 47\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 47\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 47\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 47\n",
      "optimization/pred_loss tensor(0.0094, grad_fn=<NegBackward0>) 47\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 47\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 47\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 47\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 47\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9906, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0094, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 48\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 48\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 48\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 48\n",
      "optimization/pred_loss tensor(0.0094, grad_fn=<NegBackward0>) 48\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 48\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 48\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 48\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 48\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9906, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0094, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 49\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 49\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 49\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 49\n",
      "optimization/pred_loss tensor(0.0094, grad_fn=<NegBackward0>) 49\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 49\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 49\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 49\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 49\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9906, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 50\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 50\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 50\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 50\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 50\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 50\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 50\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 50\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 50\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 50\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 50\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 50\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9906, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 51\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 51\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 51\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 51\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 51\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 51\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 51\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 51\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 51\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9906, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 52\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 52\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 52\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 52\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 52\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 52\n",
      "optimization/overall_loss tensor(1.8272, grad_fn=<AddBackward0>) 52\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 52\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 52\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 53\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 53\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 53\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 53\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 53\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 53\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 53\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 53\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 53\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 54\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 54\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 54\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 54\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 54\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 54\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 54\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 54\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 54\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 55\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 55\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 55\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 55\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 55\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 55\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 55\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 55\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 55\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0095, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 56\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 56\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 56\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 56\n",
      "optimization/pred_loss tensor(0.0095, grad_fn=<NegBackward0>) 56\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 56\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 56\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 56\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 56\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 57\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 57\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 57\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 57\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 57\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 57\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 57\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 57\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 57\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 58\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 58\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 58\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 58\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 58\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 58\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 58\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 58\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 58\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9905, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 59\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 59\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 59\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 59\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 59\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 59\n",
      "optimization/overall_loss tensor(1.8273, grad_fn=<AddBackward0>) 59\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 59\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 59\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 60\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 60\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 60\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 60\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 60\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 60\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 60\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 60\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 60\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 60\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 60\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 60\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 61\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 61\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 61\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 61\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 61\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 61\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 61\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 61\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 61\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 62\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 62\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 62\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 62\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 62\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 62\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 62\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 62\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 62\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 63\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 63\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 63\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 63\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 63\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 63\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 63\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 63\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 63\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0096, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 64\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 64\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 64\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 64\n",
      "optimization/pred_loss tensor(0.0096, grad_fn=<NegBackward0>) 64\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 64\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 64\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 64\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 64\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 65\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 65\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 65\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 65\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 65\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 65\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 65\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 65\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 65\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 66\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 66\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 66\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 66\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 66\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 66\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 66\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 66\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 66\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 67\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 67\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 67\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 67\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 67\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 67\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 67\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 67\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 67\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 68\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 68\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 68\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 68\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 68\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 68\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 68\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 68\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 68\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 69\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 69\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 69\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 69\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 69\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 69\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 69\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 69\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 69\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9904, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 70\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 70\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 70\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 70\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 70\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 70\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 70\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 70\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 70\n",
      "optimization/overall_loss tensor(1.8274, grad_fn=<AddBackward0>) 70\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 70\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 70\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 71\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 71\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 71\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 71\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 71\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 71\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 71\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 71\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 71\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 72\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 72\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 72\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 72\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 72\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 72\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 72\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 72\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 72\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 73\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 73\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 73\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 73\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 73\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 73\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 73\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 73\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 73\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 74\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 74\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 74\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 74\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 74\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 74\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 74\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 74\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 74\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 75\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 75\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 75\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 75\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 75\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 75\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 75\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 75\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 75\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 76\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 76\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 76\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 76\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 76\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 76\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 76\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 76\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 76\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 77\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 77\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 77\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 77\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 77\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 77\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 77\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 77\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 77\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 78\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 78\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 78\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 78\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 78\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 78\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 78\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 78\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 78\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 79\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 79\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 79\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 79\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 79\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 79\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 79\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 79\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 79\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 80\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 80\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 80\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 80\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 80\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 80\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 80\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 80\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 80\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 80\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 80\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 80\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0097, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 81\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 81\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 81\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 81\n",
      "optimization/pred_loss tensor(0.0097, grad_fn=<NegBackward0>) 81\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 81\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 81\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 81\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 81\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 82\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 82\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 82\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 82\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 82\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 82\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 82\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 82\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 82\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 83\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 83\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 83\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 83\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 83\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 83\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 83\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 83\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 83\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 84\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 84\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 84\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 84\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 84\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 84\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 84\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 84\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 84\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 85\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 85\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 85\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 85\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 85\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 85\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 85\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 85\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 85\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 86\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 86\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 86\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 86\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 86\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 86\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 86\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 86\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 86\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 87\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 87\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 87\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 87\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 87\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 87\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 87\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 87\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 87\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 88\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 88\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 88\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 88\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 88\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 88\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 88\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 88\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 88\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 89\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 89\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 89\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 89\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 89\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 89\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 89\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 89\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 89\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 90\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 90\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 90\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 90\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 90\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 90\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 90\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 90\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 90\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 90\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 90\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 90\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 91\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 91\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 91\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 91\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 91\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 91\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 91\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 91\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 91\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 92\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 92\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 92\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 92\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 92\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 92\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 92\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 92\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 92\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 93\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 93\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 93\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 93\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 93\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 93\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 93\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 93\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 93\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 94\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 94\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 94\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 94\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 94\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 94\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 94\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 94\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 94\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 95\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 95\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 95\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 95\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 95\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 95\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 95\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 95\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 95\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 96\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 96\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 96\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 96\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 96\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 96\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 96\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 96\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 96\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 97\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 97\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 97\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 97\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 97\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 97\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 97\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 97\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 97\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 98\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 98\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 98\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 98\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 98\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 98\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 98\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 98\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 98\n",
      "node tensor(3)\n",
      "pred torch.Size([7])\n",
      "logit tensor(0.9903, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0098, grad_fn=<NegBackward0>)\n",
      "optimization/size_loss tensor(0.2240, grad_fn=<MulBackward0>) 99\n",
      "optimization/feat_size_loss tensor(1.0025, grad_fn=<MulBackward0>) 99\n",
      "optimization/mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 99\n",
      "optimization/feat_mask_ent_loss tensor(0.5912, grad_fn=<MulBackward0>) 99\n",
      "optimization/pred_loss tensor(0.0098, grad_fn=<NegBackward0>) 99\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 99\n",
      "optimization/overall_loss tensor(1.8275, grad_fn=<AddBackward0>) 99\n",
      "optimization/edge_mask Parameter containing:\n",
      "tensor([[ 0.9485,  0.8109,  1.2441,  0.5684,  1.2475,  2.1142,  0.9045,  0.4921],\n",
      "        [ 1.0587,  0.7950,  1.2927,  0.5539,  1.1881,  1.7476,  0.7961,  0.7150],\n",
      "        [ 0.9017,  0.9440,  1.1662,  1.5381,  0.2214,  1.0294,  1.3191,  0.1754],\n",
      "        [ 0.7095,  0.0527, -0.1018,  0.7960,  0.9305,  0.3459,  0.7395,  0.1568],\n",
      "        [ 0.2302,  0.9881,  0.7643,  0.7673,  0.8018,  0.9033,  1.3842,  0.5765],\n",
      "        [ 1.4061,  0.7049,  1.0321,  1.0069,  1.9240,  0.2297,  0.9483,  1.1308],\n",
      "        [ 1.3757,  0.3478,  1.5578,  0.4998,  1.3672,  0.9532,  0.9132,  1.4304],\n",
      "        [ 1.0915,  0.4455,  0.9461,  0.9256,  1.1817,  0.4463,  0.9180,  0.1595]],\n",
      "       requires_grad=True) 99\n",
      "optimization/feat_mask Parameter containing:\n",
      "tensor([1.0135, 1.0109, 1.0496,  ..., 0.9958, 0.8152, 1.0553],\n",
      "       requires_grad=True) 99\n"
     ]
    }
   ],
   "source": [
    "explainer.train()\n",
    "for epoch in range(100):\n",
    "    explainer.zero_grad()\n",
    "    optimizer.zero_grad()\n",
    "    ypred, adj_atts = explainer()\n",
    "\n",
    "    loss = explainer.criterion(epoch)\n",
    "\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(\"optimization/overall_loss\", loss, epoch)\n",
    "    print(\"optimization/edge_mask\", explainer.edge_mask, epoch)\n",
    "    print(\"optimization/feat_mask\", explainer.feat_mask, epoch)\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(\"optimization/overall_loss\", loss, epoch)\n",
    "        print(\"optimization/edge_mask\", explainer.edge_mask, epoch)\n",
    "        print(\"optimization/feat_mask\", explainer.feat_mask, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 0., 1., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 0., 1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 0., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 0., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 0., 1.],\n",
       "        [1., 1., 1., 1., 1., 1., 1., 1., 0.]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def construct_diag_mask(neighbors):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        adj: adjacency matrix of the graph\n",
    "    \"\"\"\n",
    "    num_nodes = len(neighbors)\n",
    "    diag_mask = torch.ones(num_nodes, num_nodes) - torch.eye(num_nodes) \n",
    "\n",
    "    return diag_mask\n",
    "construct_diag_mask(neighbors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
